< extra_id_0 > table 2 shows the throughput for processing the treelstm model on our recursive framework , fold ’ s folding technique , and tensorflow ’ s iterative approach , with the large movie review dataset . the recursive framework performs the best on inference with efficient parallel execution of tree nodes , while fold ’ s folding technique shows better performance on training thanks to its gpu exploitation .
< extra_id_0 > table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness . the balanced dataset exhibits highest throughput thanks to the high degree of parallelization , but at the same time does not improve as well as the linear dataset when the batch size increases from 1 to 25 .
< extra_id_0 > hyper parameter optimization results for each model with different representation . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations .
< extra_id_0 > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) with sdp c > [ bold c > [ bold ] best f1 ( in 5 - fold ) with sdp c > [ bold ] with sdp c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > r - f1 50 % c - f1 100 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 100 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 %
< extra_id_0 > the paragraph level c - f1 and paragraph level r - f1 , respectively , and paragraph level r - f1 and r - f1 , respectively , and paragraph level r - f1 and r - f1 , respectively , and paragraph level r - f1 and r - f1 , respectively , and paragraph level f1 and r - f1 , respectively . the results show that mst - parser performs better than mst - parser and mst - parser performs better than mst - parser performs better than mate ( table 3 ) .
< extra_id_0 > table 4 shows the c - f1 ( 100 % ) in % for the two indicated systems ; essay vs . paragraph level . note that the mean performances are lower than the majority performances over the runs given in table 2 .
< extra_id_0 > bleu c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu c > [ bleu c > [ bleu ser ] ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser
< extra_id_0 > table 1 compares the original e2e data with our cleaned version ( number of distinct mrs , total number of textual references , ser as measured by our slot matching script , see section 3 ) .
< extra_id_0 > bleu c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu ] c > [ bleu c > [ bleu c > [ bleu ser ] ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser
< extra_id_0 > table 4 shows the results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , wrong values , slight disfluencies ) .
< extra_id_0 > gcnseq ( damonte and cohen , 2019 ) has a b r > c > 22 . 0 r > c > 24 . 4 r > c > c > 24 . 4 r > c > c > c > 24 . 4 r > c > c > 24 . 4 r > c > c > 24 . 4 r > c > c > 24 . 4 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points on amr17 . gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points on amr17 . gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . ggnn2seq achieves 24 . 5 bleu points on amr17 .
< extra_id_0 > english - czech # p c > [ bold ] english - german # p c > [ bold ] english - czech # p c > [ bold ] english - german # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - german # p c > [ bold ] english - czech # p c > [ beck et
< extra_id_0 > [ italic ] n c > [ italic ] m c > [ italic ] n c > [ italic ] n c > [ italic ] m c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] m c > [ italic ] c > [ italic ] c >
< extra_id_0 > with baselines . gcn + rc ( 2 ) has b 16 . 8 compared to baselines . gcn + rc + la ( 2 ) has b 47 . 9 compared to baselines . table 6 : comparisons with baselines with baselines . gcn + rc ( 2 ) has b 16 . 8 compared to baselines . gcn + rc ( 4 ) has b 18 . 3 compared to baselines .
< extra_id_0 > # p c > d c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > 420 c > 11 . 3m c >
< extra_id_0 > ablation study for density of connections on the dev set of amr15 . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block .
< extra_id_0 > table 9 : ablation study for modules used in the graph encoder and the lstm decoder . - direction aggregation c > 23 . 7 c > 55 . 4 c > - linear combination c > 22 . 9 c > 52 . 4 c > - coverage mechanism c > 23 . 8 c > 52 . 4 c > - graph attention c > 22 . 9 c > 52 . 4 c > - c >
< extra_id_0 > table 7 : scores for initialization strategies on probing tasks . glorot c > 35 . 1 c > 70 . 8 c > wc c > 59 . 4 c > wc c > 59 . 4 c > wc c > 59 . 4 c > wc c > 59 . 4 c > wc c > 59 . 4 c > wc c > 59 . 4
< extra_id_0 > method c > subjnum c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c >
< extra_id_0 > mrpc and mpqa perform better than mrpc and mrpc . hybrid cmow / 784 performs better than hybrid cmow / 784 in terms of performance . hybrid cmow / 784 performs better than hybrid cmow / 784 in terms of performance . however , hybrid cmow / 784 performs better than hybrid cmow / 784 in terms of performance .
< extra_id_0 > table 3 shows the scores on unsupervised downstream tasks attained by our models . we show the relative change with respect to hybrid . cmow achieves the highest score on unsupervised downstream tasks attained by our models .
< extra_id_0 > table 8 : scores . our paper c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c >
< extra_id_0 > cmow - c performs better than cmow - c on the unsupervised downstream tasks . cmow - c performs better than cmow - c on the unsupervised downstream tasks .
< extra_id_0 > cmow - c performs better than bshift and topconst . cmow - c performs better than bshift and topconst . cmow - c performs better than bshift and topconst . cmow - c performs better than bshift and topconst . cmow - c performs better than cmow - c .
< extra_id_0 > mrpc and mpqa mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c cmow - c
< extra_id_0 > 53 . 61 . in all loc c > all misc c > all org c > all misc c > all misc c > all misc c > all loc c > all org c > all misc c > all misc c > mil - nd c > 57 . 15 c > 89 . 48 c > 89 . 46 c > 89 . 46 c >
< extra_id_0 > system c > all p c > all r c > all f1 c > all p c > all f1 c > all p c > all f1 c > all p c > all f1 c > all p c > all f1 c > mil - nd ( model 2 ) c > 38 . 91 c > 36 . 73 c > 73 . 19 c > 73 . 19 c > c >
< extra_id_0 > ref gen gen gen gen gen gen gen gen gen ref gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gin gin gin gin gin gin gin gin gin
< extra_id_0 > bold > bleu / bold > bold > meteor / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > g2s - ggnn / bold > bold >
< extra_id_0 > 3 : results on ldc2015e86 test set when models are trained with additional gigaword data . c > bold > model / bold > bold > external / bold > bold > model / bold > bold > model / bold > bold > model / bold > bold > model / bold > bold > model / bold > bold > model
< extra_id_0 > 4 shows the results of the ablation study on the ldc2017t10 development set . bilstm has a better performance than bilstm on the ldc2017t10 development set .
< extra_id_0 > graph diameter / bold > 7 - 13
< extra_id_0 > table 8 shows the fraction of elements in the output that are not present in the input ( added ) and the fraction of elements in the input graph that are missing in the generated sentence ( miss ) , for the test set of ldc2017t10 . the token lemmas are used in the comparison .
< extra_id_0 > table 4 : sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer , trained with different target languages on a smaller parallel corpus ( 200k sentences ) . sem and pos tagging accuracy is shown in table 4 .
< extra_id_0 > table 2 shows mft and unsupemb tagging accuracy with baselines and an upper bound . unsupemb and word2tag tagging accuracy with baselines and an upper bound are shown in table 2 .
< extra_id_0 > fr c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > 87 . 9 c > 87 . 9 c >
< extra_id_0 > table 5 shows pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders , averaged over all non - english target languages . pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual encoders .
< extra_id_0 > attacker ’ s performance on different datasets . results are on a training set 10 % held - out . is the difference between the attacker ’ s score and the corresponding adversary ’ s accuracy .
< extra_id_0 > table 1 summarizes the accuracies when training directly towards a single task . pan16 has the highest accuracies when training directly towards a single task . pan16 has the highest accuracies when training directly towards a single task .
< extra_id_0 > table 2 : protected attribute leakage : balanced & unbalanced data splits . pan16 shows a significant increase in the number of protected attribute leakage splits compared to pan16 .
< extra_id_0 > is the difference between the attacker score and the adversary ’ s accuracy . is the difference between the attacker score and the adversary ’ s accuracy . is the difference between the attacker score and the adversary ’ s accuracy . is the difference between the attacker score and the adversary ’ s accuracy .
< extra_id_0 > table 6 summarizes the accuracies of the protected attribute with different encoders . leaky achieves 64 . 5 accuracies compared to guarded , while rnn achieves 54 . 8 accuracies .
< extra_id_0 > 40 . 68 . the model c > lstm c > 22m c > 55 . 97 c > 54 . 44 c > 47 . 69 c > 47 . 69 c > 47 . 69 c > 47 . 69 c > 47 . 69 c > 47 . 69 c > 47 . 69 c > 47 . 69 c > 47 . 69 c > 47 . 69 c > 47 . 68 c >
< extra_id_0 > model c > # params c > model c > # params c > base acc c > base time c > + ln acc c > + bert acc c > + bert time c > + bert time c > + ln + bert time c > c > c > c > c > c > c > c > c >
< extra_id_0 > yelppolar err and yelppolar err c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c >
< extra_id_0 > table 3 shows the tokenized bleu score on wmt14 english - german translation task . bleu scores on wmt14 are similar to those on newstest2014 dataset ( table 3 shows the tokenized bleu score on newstest2014 ) .
< extra_id_0 > “ # params ” : the parameter number of base . rnet * : the results published by wang et al . ( 2017 ) . rnet * : the results published by wang et al . ( 2017 ) .
< extra_id_0 > “ # params ” : the parameter number in conll - 2003 english ner task . “ # params ” : the parameter number in ner task . “ # params ” : the parameter number in ner task .
< extra_id_0 > table 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting and test accuracy on snli task with base + ln setting and test perplexity on snli task with base + ln setting .
< extra_id_0 > w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] # sent c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] # word c > [ italic ] c > [ italic ] r - 2 c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] # sent c > [ italic ] w / system retrieval [ bold ] w / system retrieval [ bold ] w / system retrieval [ bold ] r - 2 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > the highest standard deviation among automatic systems is highlighted in bold , with statistical significance marked with ( approximation randomization test , p0 . 0005 ) . the highest standard deviation among automatic systems is highlighted in bold , with statistical significance marked with ( approximation randomization test , p0 . 0005 ) . the highest standard deviation among automatic systems is 1 . 0 . the highest standard deviation among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is highlighted in bold . the best results among automatic systems are highlighted in bold
< extra_id_0 > dlqs , docsub and docsub perform better than dlqs and docsub in terms of p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c >
< extra_id_0 > dlqs , docsub and docsub , respectively . tlqs , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , hclust , and ted talks have the highest p compared to lang ( p
< extra_id_0 > dlqs , docsub and docsub , respectively . tlqs , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , docsub , and docsub have the highest p
< extra_id_0 > slqs and docsub are based on corpus c > dsim and docsub c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c > hclust c >
< extra_id_0 > avgdepth : 9 . 9 compared to 980 for europarl and 996 for totalroots . europarl has the highest avgdepth of 980 . europarl has the lowest avgdepth of 980 .
< extra_id_0 > table 1 shows the performance ( ndcg % ) comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 . lf is the enhanced version as we mentioned in table 1 . qt is the baseline , answer score sampling , and hidden dictionary learning , respectively . lf is the enhanced version as we mentioned in table 1 .
< extra_id_0 > table 2 shows the performance ( ndcg % ) of ablative studies on different models on visdial v1 . 0 validation set . p2 indicates the most effective one ( i . e . , hidden dictionary learning ) .
< extra_id_0 > table 5 : comparison on hard and soft alignments . cs - en c > de - en c > fi - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > c > c >
< extra_id_0 > zh - en and zh - en , respectively . bertscore - f1 achieves a score of 0 . 552 points . ruse scores a score of 0 . 720 points . ruse scores a score of 0 . 720 points .
< extra_id_0 > inf / bold > sfhotel bold > qual / bold > sfhotel bold > qual / bold > sfhotel bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel bagel
< extra_id_0 > m1 m2 m1 m2 m2 m1 m2 m2 m1 m2 m2 m2 m1 m2 m2 m1 m2 m2 m2 m1 m2 m2 m1 m2 m2 m1 m2 m2 m2 m2 m2 m2 .
< extra_id_0 > m1 : m0 has a better performance than m1 : shen - 1 and m4 : m0 [ italic ] + cyc + para + lang . m5 : m0 has a better performance than m5 : m0 [ italic ] + cyc + para + lang . m5 : m0 has a better performance than m5 : m0 [ cyc + para + lang ] .
< extra_id_0 > transfer quality a > b c > models a c > models b c > models a c > models b c > models a c > models b c > models b c > models a c > models b c > models b c > models a c > models b c > models b c > models b c > models a c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim s
< extra_id_0 > table 5 shows human validation of metrics ; 100 examples for each dataset for validating acc ; 150 examples for validating pp ; see text for validation of gm ; see text for validation of gm ; see text for validation of acc ; see text for validation of gm ; see text for validation of acc ; see text for validation of gm ; see text for validation of acc ; see text for validation of acc ; see text for validation of pp ; see text for validation of acc .
< extra_id_0 > m6 : m0 has a better performance than m5 : m0 [ italic ] + cyc + para + lang . m5 : m0 [ italic ] + cyc + para + lang has a better performance than m5 : m0 [ italic ] + cyc + para + lang . m5 : m0 [ italic ] + cyc + para + lang has a better performance than m5 : m0 [ bold ] with a better performance than m5 : m0 ( bold ) has a better performance than m0 ( bold ) .
< extra_id_0 > bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . our best models achieve higher bleu than previous work , but untransferred sentences achieve the highest bleu than previous work at similar levels of acc . our best models achieve the highest bleu than previous work at similar levels of bleu .
< extra_id_0 > table 2 : percent of reparandum tokens that were correctly predicted as disfluent . reparandum tokens that were correctly predicted as disfluent are shown in table 2 . reparandum tokens that were correctly predicted as disfluent are shown in table 2 . reparandum tokens that were correctly predicted as disfluent are shown in table 2 . reparandum tokens that were correctly predicted as disfluent are shown in table 2 . reparandum tokens that were correctly predicted as disfluent are shown in table 2 .
< extra_id_0 > table 3 shows the relative frequency of rephrases correctly predicted as disfluent for disfluencies that contain a content word in both the reparandum and repair ( content - content ) , either the reparandum or repair ( content - function ) or in neither .
< extra_id_0 > [ bold ] dev mean c > [ bold ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] c > [ italic ] test best c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > c > c > c > c > c > c > c > c > c > early c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > accuracy ( % ) agree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) unrelated c > rnn - based sentence embedding performs better than the state - of - art algorithms on the fnc - 1 test dataset . our model performs better than the state - of - art algorithms .
< extra_id_0 > table 2 shows the accuracy of different methods on the apw and nyt datasets for the document dating problem ( higher is better ) . the unified model significantly outperforms all previous models .
< extra_id_0 > table 3 : accuracy ( % ) comparisons of component models with and without attention . this results show the effectiveness of both word attention and graph attention for this task .
< extra_id_0 > [ bold ] 1 / 1 c > [ bold ] 1 / 1 c > [ bold ] 1 / n c > [ bold ] all c > [ bold ] embedding + t c > 68 . 1 c > 50 . 9 c > 59 . 8 c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c >
< extra_id_0 > c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold
< extra_id_0 > acc dev perp test wer
< extra_id_0 > table 4 shows the results on the dev set and on the test set using discriminative training with only subsets of the code - switched data . the discriminative training with only subsets of the code - switched data achieves a similar performance on both the dev and test set .
< extra_id_0 > table 5 : accuracy on the dev set and on the test set , according to the type of the gold sentence in the set : code - switched ( cs ) vs . monolingual ( mono ) .
< extra_id_0 > table 7 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) . type - aggregated gaze features trained on all three eye - tracking datasets are shown in table 7 .
< extra_id_0 > table 5 shows the precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant improvement ) for using type - aggregated gaze features on conll - 2003 .
< extra_id_0 > hpcd ( full ) is from the original paper , and it uses syntactic skipgram . lstm - pp and lstm - pp have similar results on the belinkov2014exploring test set .
< extra_id_0 > table 2 summarizes the results of rbg dependency parser with features coming from various pp attachment predictors and oracle attachment predictors . the results are presented in table 2 .
< extra_id_0 > table 3 shows the effect of removing sense priors and context sensitivity ( attention ) from the model . the effect of removing sense priors and context sensitivity ( attention ) is shown in table 3 .
< extra_id_0 > adding subtitle data and domain tuning for image caption translation ( bleu % scores ) . all results with marian amun are shown in table 2 .
< extra_id_0 > en - de c > flickr16 c > flickr17 c > mscoco17 c > en - fr c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c >
< extra_id_0 > adding automatic image captioning in table 4 : table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : table 4 : table 4 : table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning in table 4 : adding automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic image captioning with automatic
< extra_id_0 > en - de c > flickr16 c > flickr17 c > mscoco17 c > en - de c > flickr16 c > flickr17 c > mscoco17 c > flickr16 c > flickr17 c > mscoco17 c > flickr16 c > flickr17 c > mscoco17 c > enc - gate c >
< extra_id_0 > mscoco17 and en - fr c > en - fr c > mscoco17 c > mscoco17 c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > c >
< extra_id_0 > en - fr - trans - ff scores better than en - fr - trans - ff , whereas en - fr - trans - ff scores better than en - fr - trans - ff . en - fr - trans - ff scores better than en - fr - trans - ff . en - fr - trans - ff scores better than en - fr - trans - ff scores better than en - fr - trans - ff . en -
< extra_id_0 > table 1 shows the number of parallel sentences in the train , test and development splits for the language pairs we used . the number of parallel sentences in the train , test and development splits is shown in table 1 .
< extra_id_0 > table 2 : training vocabularies for the english , french and spanish data used for our models . the training vocabularies for the english , french and spanish data are shown in table 2 .
< extra_id_0 > table 5 shows the automatic evaluation scores ( bleu and ter ) for the rev systems . the bleu and ter scores for the rev systems are shown in table 5 .
< extra_id_0 > table 2 summarizes the results on flickr8k . the row labeled vgs is the visually supervised model from chrupala2017representations . the row labeled vgs is the visually supervised model from chrupala 2017 .
< extra_id_0 > table 1 : results on synthetically spoken coco . the row labeled vgs is the visually supervised model from chrupala2017representations . the row labeled vgs is the visually supervised model from chrupala2017 .
< extra_id_0 > is so clever you want hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate . we report further examples in table 1 .
< extra_id_0 > table 2 summarizes the rnp and dan scores . the rnp scores are significantly higher than the dan scores , and the rnp scores are significantly higher than the dan scores .
< extra_id_0 > the last two rows correspond to the case where negative labels are flipped to positive and vice versa . the numbers indicate that the score increases in positive and negative sentiment with respect to the original sentence .
< extra_id_0 > it n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t
