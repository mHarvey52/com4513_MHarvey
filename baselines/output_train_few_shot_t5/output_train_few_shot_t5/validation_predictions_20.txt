< extra_id_0 > table 2 shows the throughput for processing the treelstm model on our recursive framework , fold ’ s folding technique , and tensorflow ’ s iterative approach , with the large movie review dataset . the recursive approach performs the best on inference with efficient parallel execution of tree nodes , while the folding technique shows better performance on training thanks to its gpu exploitation .
< extra_id_0 > table 1 shows throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness . the balanced dataset exhibits highest throughput thanks to the high degree of parallelization , but at the same time does not improve as well as the linear dataset when the batch size increases from 1 to 25 instances .
< extra_id_0 > table 2 summarizes the hyper parameter optimization results for each model with different representation . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all models with different representations . the max pooling strategy consistently performs better in all models with different representations .
< extra_id_0 > [ bold ] best f1 ( in 5 - fold ) without sdp compared to [ bold ] best f1 ( in 5 - fold ) without sdp compared to [ bold ] best f1 ( in 5 - fold ) without sdp compared to [ bold ] best f1 ( in 5 - fold ) without sdp compared to [ bold ] best f1 ( in 5 - fold ) without sdp compared to [ bold ] best f1 ( in 5 - fold ) compared to [ bold relationship compared to [ bold relationship compared to [ bold relationship without sdp compared to [ bold relationship without sdp compared to [ bold relationship without sdp compared to [ bold relationship without sdp compared to [ bold relationship without sdp compared to [ bold relationship without sdp compared to [ bold relationship without sdp ) without sdp without sdp ( in 5 - fold ) without sdp ( in 5 - fold ) without sdp ) without sdp ( in table 1 ) .
< extra_id_0 > 30 . 30 / bold > y - 3 : y achieves a c - f1 100 % and a c - f1 50 % r - f1 50 % r - f1 50 % r - f1 50 % r - f1 50 % r - f1 50 % r - f1 50 % r - f1 50 % r - f1 50 % r - f1 50 % r - f1 50 % r - f1 50 % r - f1 50 % r - f1 50 % r - f1 50 % r - f1 50 % r - f1 50 % y - 35 % r -
< extra_id_0 > , and essay level r - f1 . the paragraph level acc . c > paragraph level acc . c > paragraph level c - f1 c > paragraph level r - f1 c > paragraph level f1 c > paragraph level r - f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c >
< extra_id_0 > the mean c - f1 performance is lower than the majority performance over the two indicated systems ; essay vs . paragraph level . note that the mean performance is lower than the majority performance over the two indicated systems ; essay vs . paragraph level .
< extra_id_0 > bleu cider rouge - l cider rouge - l cider rouge - l cider rouge - l cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider ser cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider
< extra_id_0 > table 1 shows the comparison between the original e2e data and our cleaned version ( number of distinct mrs , total number of textual references , ser as measured by our slot matching script , see section 3 ) . the original e2e data contains 4 , 862 distinct mrs , 42 , 061 textual references , and a total number of textual references .
< extra_id_0 > bleu cider rouge - l cider rouge - l cider rouge - l cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider ser cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cider cide
< extra_id_0 > table 4 summarizes the results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , wrong values , slight disfluencies ) . the results of manual error analysis are presented in table 4 .
< extra_id_0 > graphlstm ( song et al . , 2018 ) achieves a b c > 22 . 0 and a b c > 24 . 4 . graphlstm ( song et al . , 2018 ) achieves a b c > 25 . 6 and a b c > 25 . 6 . graphlstm ( song et al . , 2018 ) achieves a b c > 25 . 6 . graphlstm ( song et al . , 2018 ) achieves a 24 . 4 .
< extra_id_0 > gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points . table 2 shows the model size in terms of parameters in terms of amr17 . gcnseq achieves 24 . 5 bleu points . ggnn2seq achieves 24 . 5 bleu points . ggnn2seq achieves 24 . 5 bleu points .
< extra_id_0 > english - czech b c > [ bold ] english - german # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - german b c > [ beck et al . , 2017 ] c > [ beck et al . , 2017 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > n m
< extra_id_0 > gcn has a + rc denoted by a + rc denoted by a + rc denoted by a + rc denoted by a + rc denoted by a + rc denoted by a + rc denoted by a + rc denoted by a + rc denoted by a + rc denoted by a + rc denoted by a + rc denoted by a significant improvement over dcgcn1 and dcgcn4 . table 6 compares dcgcn1 and dcgcn2 score of 22 . 9 compared to dcgcn2 score of 48 . 1 compared to dcgcn2 score of 48 . 1 compared to dcgcn2 score of 48 . 1 compared to dcgcn2 score of 48 . 1 compared to + rc + la score of 47 . 9 compared to + rc + la score of 47 . 9 compared to + rc + la score of 47 . 9 compared to + rc + la score of 47 . 9 compared to + rc + la score of 22 . 9 compared to + rc + la score of 47 . 9 compared to + rc + la score of 47 . 9 .
< extra_id_0 > the d p c c c c c c c c d c c c d c c d c c d c c d c c 420 11 . 3m c 22 . 8m c 23 . 8m c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c
< extra_id_0 > ablation study for density of connections on the dev set of amr15 . - i dense block denotes removing dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block .
< extra_id_0 > 9 : ablation study for modules used in the graph encoder and the lstm decoder . - graph attention and linear combination have significantly higher performance than - global node and linear combination , respectively .
< extra_id_0 > table 7 : scores for initialization strategies on probing tasks . our paper shows that glorot achieves the best initialization scores on probing tasks . glorot achieves the best performance on probing tasks .
< extra_id_0 > the bshift c > method c > depth c > objnum c > topconst c > subjnum c > objnum c > objnum c > objnum c > objnum c > topconst c > topconst c > wc c > wc c > wc c > wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc
< extra_id_0 > cmow / 784 achieves 79 . 2 outperforms [ bold ] and [ cmow ] 79 . 2 outperforms [ bold ] and [ cmow ] 79 . 6 outperforms [ bold ] and [ cmow ] 79 . 6 outperforms [ cmow ] and [ cmow ] 79 . 6 outperforms [ bold ] and [ cmow ] 784 in terms of performance . cmow / 784 achieves 79 . 2 outperforms [ bold ] 79 . 6 outperforms [ bold ] and [ bow ] 79 . 6 ] hybrid .
< extra_id_0 > in sts16 , the model achieves the highest score on unsupervised downstream tasks . the hybrid model achieves the best score on unsupervised downstream tasks . the hybrid model achieves the best score on unsupervised downstream tasks .
< extra_id_0 > our paper has a significant improvement over the baselines of glorot and glorot . our paper has a significant improvement over the baselines of glorot and glorot . our paper has a significant improvement over the baselines of glorot and glorot . our paper has a significant improvement over glorot and glorot .
< extra_id_0 > table 6 shows the scores for different training objectives on the unsupervised downstream tasks . cmow - c achieves the best performance on both the unsupervised and unsupervised tasks . cmow - c achieves the best performance on the unsupervised tasks .
< extra_id_0 > cmow - c performs better than cmow - c in terms of depth and length . cmow - c performs better than cbow - c in terms of depth and tense . cmow - c performs better than cbow - c in terms of depth and depth . cmow - c outperforms cbow - c in terms of depth and depth .
< extra_id_0 > mrpc and mpqa mrpc mrpc mrpc mrpc mrpc mrpc c > cmow - r c > cmow - c c > 79 . 9 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > 78 . 4 c > cmow - r c > 79 . 4 c > cmow - r c > cmow - r c > cmow - r c > cmow - r c > cmow - c c > cmow - r c > 79 . 4 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > cbow - r c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > cbow - r c > c > c > c > c > c > c > c
< extra_id_0 > all org all misc in [ italic ] e + loc in [ italic ] e + org in [ italic ] e + misc in [ italic ] e + org in [ italic ] e + org in [ italic ] e + misc in mil - nd c > 57 . 15 c > 47 . 42 c > 47 . 42 c > 47 . 42 c >
< extra_id_0 > 69 . 38 . in [ italic ] e + p c > all f1 c > 37 . 42 c > 37 . 42 c > 37 . 42 c > 69 . 38 0 . 68 c > 69 . 38 c > 69 . 38 0 . 68 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c >
< extra_id_0 > ref gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin
< extra_id_0 > the ldc2015e86 model outperforms the ldc2015e86 model in terms of bleu and meteor performance . in addition , the g2s model outperforms the s2s model in terms of bleu and meteor performance .
< extra_id_0 > table 3 shows the results on the ldc2015e86 test set when models are trained with additional gigaword data . c > konstas et al . ( 2017 ) compared to song et al . ( 2018 ) compared to song et al . ( 2018 ) compared to song et al . ( 2018 ) compared to song et al . ( 2018 ) compared to song et al . ( 2018 ) .
< extra_id_0 > 4 shows the results of the ablation study on the ldc2017t10 development set . bold > get / italic > + bilstm achieves 57 . 6m bleu . bold > get / italic > + bilstm achieves 57 . 6m bleu . bold > meteor / bold > shows that bilstm achieves the best performance .
< extra_id_0 > bold > graph diameter / bold > 14 - 20
< extra_id_0 > table 8 shows the fraction of elements in the output that are not present in the input ( added ) and the fraction of elements in the input that are missing in the generated sentence ( miss ) , for the test set of ldc2017t10 . the token lemmas are used in the comparison .
< extra_id_0 > table 4 : sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer , trained with different target languages on a smaller parallel corpus ( 200k sentences ) . the sem and pos tagging accuracy is significantly higher than the pos tagging accuracy .
< extra_id_0 > pos and sem tagging accuracy with baselines and an upper bound . pos and sem tagging accuracy with baselines and an upper bound .
< extra_id_0 > fr c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c
< extra_id_0 > pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders , averaged over all non - english target languages . pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders , averaged over all non - english targets .
< extra_id_0 > attacker ’ s performance on different datasets is shown in table 8 . is the difference between the attacker ’ s score and the corresponding adversary ’ s accuracy on different datasets . is the difference between the attacker ’ s score and the corresponding adversary ’ s accuracy .
< extra_id_0 > table 1 summarizes the results for each task . for each task , the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the number of times the task .
< extra_id_0 > 2 : protected attribute leakage : balanced & unbalanced data splits . pan16 shows a significant difference between the two datasets ( table 2 : protected attribute leakage ) .
< extra_id_0 > 3 shows the performance on different datasets with an adversarial training . is the difference between the attacker score and the corresponding adversary ’ s accuracy . is the difference between the attacker score and the adversary ’ s accuracy .
< extra_id_0 > 6 : accuracies of the protected attribute with different encoders . embedding leaky and embedding guarded have the best performance .
< extra_id_0 > wt2 + finetune wt2 + dynamic ptb base ptb + finetune wt2 + dynamic base wt2 + finetune wt2 + dynamic base yang et al . ( 2018 ) reported that yang et al . ( 2018 ) reported that yang et al . ( 2018 ) reported that yang et al . reported that yang et al . ( 2018 ) reported that yang et al . ( 2018 ) et al . ( 2018 ) et al . ( 2018 ) et al . ( 2018 ) et al . ( 2018 ) et al . ( 2018 ) et al . ( 2018 ) et al . ( 2018 ) et al . ( 2018 ) et al . ( 2018 ) et al . ( 2018 ) et al . ( 2018 ) lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base lstm base
< extra_id_0 > base acc c > base time c > base time c > base time c > base time c > + ln acc c > + bert acc c > base time c > + ln acc c > + bert time c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > it is important to note that the < extra_id_1 > , < extra_id_2 > and yelppolar err are evaluated in table 1 . zhang et al . ( 2015 ) reported that the atr and yelppolar err are significantly higher than the gru and yelppolar err , respectively . zhang et al . ( 2015 ) reported that the atr and yelppolar err are significantly higher than the gru and yelppolar err , respectively , and yelppolar err scores are significantly higher than the model performs better than the model performs better than the model performs better than the lstm model performs better than the gru model performs better than the gru model performs better than the model performs better than the model performs better than the lstm model performs better than the lstm model performs better than the gru model performs better than the gru model performs better than the gru model performs better than the gru model performs better than the gru model performs better than the gru model performs better than the gru model performs better than the gru model performs better than the gru model performs better than the gru model performs better than the other two - three - four - four - four - four - five - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - six - s
< extra_id_0 > table 3 shows the tokenized bleu score on wmt14 english - german translation task . the results show that the bleu score on newstest2014 dataset is significantly higher than the bleu score on tesla p100 .
< extra_id_0 > table 4 : exact match / f1 - score on squad dataset . rnet * : results published by wang et al . ( 2017 ) . lstm achieves a score of 71 . 1 / 79 . 5 on the rnet dataset .
< extra_id_0 > the f1 score on conll - 2003 english ner task is shown in table 6 . lstm * denotes the parameter number in ner task . lstm * denotes the reported result on conll - 2003 english ner task .
< extra_id_0 > table 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting and test accuracy on snli task with base + ln setting and test perplexity on snli task with base + ln setting and test accuracy on snli task with ptb task with base + ln setting . elrn outperforms glrn in accuracy and perplexity .
< extra_id_0 > b - 2 , r - 2 , and # sent . we compare the results of the two datasets in table 1 . we compare the results of the two datasets in table 2 . we compare the results of the two datasets in table 2 . we compare the results of the two datasets in table 2 . we compare the results of the two datasets in table 2 . we compare the results of the two datasets in table 2 . we compare the results of the two datasets in table 2 . we compare the results of the two datasets . we compare the results of the two datasets w / r - 2 and r - 2 datasets are shown in table 3 . we also compare the results of the two datasets in table 3 . we compare the results of the two datasets in table 3 .
< extra_id_0 > the highest standard deviation among all automatic systems is 1 . 0 . the highest standard deviation among all automatic systems is highlighted in bold . the best result among automatic systems is highlighted in bold . the highest standard deviation among all automatic systems is 1 . 0 . the highest standard deviation among all automatic systems is 1 . 0 . the highest standard deviation among all automatic systems is highlighted in bold . the highest standard deviation among all automatic systems is 1 . 0 .
< extra_id_0 > slqs and docsub are the only corpus that supports dlqs and docsub and hclust . europarl outperforms all other corpus models except for docsub and docsub in terms of p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c
< extra_id_0 > slqs , docsub and hclust are the only corpus that performs better than df and docsub . europarl outperforms both df and docsub in terms of p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c
< extra_id_0 > slqs and docsub are the only corpus that supports dlqs and docsub and hclust . europarl outperforms all other corpus models except for docsub and docsub in terms of p 0 . 05 .
< extra_id_0 > dlqs and docsub are derived from the dlqs and docsub datasets . the results are summarized in table 1 . europarl has the highest avgdepth and maxdepth , respectively , and the europarl avgdepth has the lowest avgdepth . europarl has the highest avgdepth and maxdepth , respectively . the results are summarized in table 1 .
< extra_id_0 > avgdepth is 9 . 9 and avgdepth is 9 . 9 and avgdepth is 9 . 8 . europarl has the highest avgdepth of 980 . europarl has the highest avgdepth of 980 . europarl has the highest avgdepth of 980 .
< extra_id_0 > r0 , r2 , r3 denote question type , answer score sampling , and hidden dictionary learning , respectively . lf is the enhanced version as we mentioned in table 1 . ndcg compares the qt and d performance for the experiments of applying our principles on the validation set of visdial v1 . 0 on the validation set of visdial v1 . 0 . lf is the baseline version as shown in table 1 .
< extra_id_0 > table 2 shows the performance ( ndcg % ) of ablative studies on different models on visdial v1 . 0 validation set . using p2 indicates the most effective one ( i . e . , hidden dictionary learning ) shown in table 2 .
< extra_id_0 > table 5 : comparison on hard and soft alignments . cs - en de - en fi - en lv - en ruse c > 0 . 624 c > 0 . 681 c > 0 . 712 c > 0 . 708 c > 0 . 708 c > 0 . 708 c > 0 . 708 c > 0 . 708 c > 0 . 708 c > 0 . 708 c > 0 . 708 cs
< extra_id_0 > bold > cs - en c > bold > direct assessment / bold > zh - en c > bold > direct assessment / bold > lv - en c > bertscore - f1 c > 0 . 652 c > 0 . 646 c > 0 . 646 c > 0 . 661 c > 0 . 646 c > 0 . 646 c > 0 . 661 c > cs - en c > bold > direct assessment / bold > cs - en cs - en cs - en cscore - f1 c > c > bertscore - f1 c > ruse ( * ) bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 bertscore - f1 ber
< extra_id_0 > inf : bold > qual / bold > sfhotel bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > c > bleu - 1 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > bleu - 2 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > bleu - 2 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > leic ( * ) scores m1 and m2 respectively , while spice scores m1 and m2 consistently outperform spice and bertscore - recall , respectively . the results of spice and bertscore - recall are summarized in table 1 . the results of spice and bertscore - recall are summarized in table 2 .
< extra_id_0 > m0 has a statistically significant improvement over the previous model , with a statistically significant improvement over the previous model , with a statistically significant improvement over the previous model , with a marginal improvement over the previous model , with a marginal improvement over the previous model , with a marginal improvement over the previous model , with a marginal improvement over the previous model , with a marginal improvement over the previous model , with a marginal improvement over the previous model , with a marginal improvement over the previous model , with only a slight improvement over the previous model , with only a slight improvement over the previous model , with a slight improvement over the previous model , with a slight improvement over the previous model , with a slight improvement over the previous model , with a slight improvement over the previous model , with a slight improvement over the previous model , with a slight improvement over the previous model , with a slight improvement over the previous model , with a slight improvement over the previous model , with a slight improvement over the previous model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model ' s model
< extra_id_0 > transfer quality a > b and transfer quality tie sim c > semantic preservation a > b and transfer quality tie sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim .
< extra_id_0 > acc and pp are validated using yelp and lit . gm and pp are validated using spearman ’ s [ italic ] and spearman ’ s [ italic ] methods . gm and pp are validated using spearman ’ s [ italic ] and spearman ’ s [ italic ] methods ; see text for validation of gm .
< extra_id_0 > we found that m0 and m0 are better than m0 and m0 + cyc + para , respectively . we found that m0 and m0 are better than m0 and m0 + cyc + para , respectively . we found that m0 and m0 are better than m0 and m0 + cyc + para .
< extra_id_0 > bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . our best models achieve higher bleu than previous work at similar levels of acc , but untransferred sentences achieve the highest bleu than prior work at similar levels of bleu . our best models achieve higher bleu than previous work , but untransferred sentences achieve the highest bleu .
< extra_id_0 > table 2 shows the percentage of reparandum tokens that were correctly predicted as disfluent . repetition tokens have a lower rate of accuracy than rephrase tokens . rephrase tokens have a higher rate of accuracy than rephrase tokens . rephrase tokens have a higher rate of accuracy than rephrase tokens .
< extra_id_0 > table 3 shows the relative frequency of rephrases correctly predicted as disfluent for disfluencies that contain a content word in both reparandum and repair ( content - content ) or in neither reparandum or repair ( content - function ) or in neither of these categories .
< extra_id_0 > c > [ bold ] dev mean c > [ bold ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] single c > [ italic ] test mean c > [ italic ] test best c > [ italic ] test best c > [ italic ] test best c > [ italic ] test best c > [ italic ] test best c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > single c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > accuracy ( % ) agree accuracy ( % ) disagree accuracy ( % ) unrelated table 2 : performance comparison with the state - of - art algorithms on the fnc - 1 test dataset . our model achieves a higher accuracy than the state - of - art ones .
< extra_id_0 > table 2 shows the accuracy ( % ) of different methods on the apw and nyt datasets for the document dating problem ( higher is better ) . the unified model significantly outperforms all previous models in terms of accuracy .
< extra_id_0 > table 3 shows the effectiveness of both word attention and graph attention for this task . the results show the effectiveness of both word attention and graph attention for this task .
< extra_id_0 > embedding + t has 1 / 1 and all 1 / n . embedding + t has a better performance than embedding + t and embedding + t , respectively . embedding + t has a better performance than embedding + t and embedding + t . embedding + t has a better performance than embedding + t and embedding + t .
< extra_id_0 > trigger [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > acc test perp test wer test perp test wer test perp test wer test perp test wer test wer test wer test wer test wer test wer test wer test wer test wer test perp test wer test wer test wer test wer test wer test wer test wer test wer test wer test perp test perp tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester
< extra_id_0 > table 4 summarizes the results on the dev set and on the test set using discriminative training with only subsets of the code - switched data . the results on the dev set and on the test set are summarized in table 4 . the results on the dev set and on the test set are summarized in table 4 .
< extra_id_0 > table 5 shows the accuracy of the gold sentence on the dev set and on the test set , according to the type of the gold sentence in the set : code - switched ( cs ) vs . monolingual ( mono ) .
< extra_id_0 > 7 shows the p , recall ( r ) and f1 - score ( f1 ) for using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) . using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset is shown in table 7 . the conll - 2003 dataset shows a significant improvement in p , recall and recall scores .
< extra_id_0 > table 5 shows the p , recall ( r ) and f1 - score ( f1 ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant improvement ) . using type - aggregated gaze features on the conll - 2003 dataset is shown in table 5 .
< extra_id_0 > table 1 summarizes the results on belinkov2014exploring ’ s ppa test set . syntactic - sg and lstm - pp have the best initialization and embedding accuracy . lstm - pp and glove - extended have the best results .
< extra_id_0 > table 2 summarizes results from rbg dependency parser with features coming from various pp attachment predictors and oracle attachments . rbg + hpcd ( full ) achieves 94 . 17 points , compared to 88 . 51 points for hpcd ( full ) .
< extra_id_0 > table 3 shows the effect of removing sense priors and context sensitivity ( attention ) from the model . the effect of removing sense priors and context sensitivity ( attention ) from the model is shown in table 3 .
< extra_id_0 > adding subtitle data and domain tuning for image caption translation ( bleu % scores ) . all results with marian amun are shown in table 2 .
< extra_id_0 > and mscoco17 , respectively . subs1m and lm + ms - coco outperform domain - tuned and lm + ms - coco in terms of labeling . lm + ms - coco outperforms domain - tuned and lm + ms - coco in terms of labeling . lm + ms - coco outperforms domain - tuned and mscoco17 in terms of labeling .
< extra_id_0 > adding automatic image captioning is shown in table 4 . adding automatic image captioning is shown in table 4 . adding automatic image captioning is shown in table 4 . adding automatic image captioning is shown in table 4 . adding automatic image captioning is shown in table 4 . adding automatic image captioning is shown in table 4 . adding automatic image captioning is shown in table 4 . adding automatic image captioning is shown in table 4 . adding automatic image captioning is shown in table 4 .
< extra_id_0 > mscoco17 and en - de c > flickr16 c > flickr17 c > mscoco17 r > c > enc - gate c > 68 . 30 c > dec - gate c > 37 . 47 c > enc - gate c > 46 . 47 c > dec - gate c > 46 . 47 c > dec - gate c > enc - gate
< extra_id_0 > mscoco17 and en - fr en - fr en - fr en - fr en - fr en - fr en - fr en - fr en - fr en - fr en - fr en - fr en - fr en - fr en - fr en - fr en - fr en - fr en - fr en - fr en - fr gn2048
< extra_id_0 > we see that en - fr - smt - back and en - fr - trans - ff perform better than en - fr - smt - back and en - fr - trans - ff , respectively . we see that en - fr - trans - ff performs better than en - fr - trans - ff and en - fr - trans - ff . we observe that en - fr - trans - back performs better than en - fr - trans -
< extra_id_0 > table 1 shows the number of parallel sentences in the train , test and development splits for the language pairs we used . the number of sentences in the train , test and development splits for the language pairs we used is shown in table 1 .
< extra_id_0 > table 2 : training vocabularies for the english , french and spanish data used for our models . the training vocabularies for the english , french and spanish data used for our models are shown in table 2 .
< extra_id_0 > table 5 summarizes the automatic evaluation scores ( bleu and ter ) for the rev systems . the bleu and ter scores for the rev systems are shown in table 5 .
< extra_id_0 > recall @ 10 ( % ) c > rsaimage c > median recall @ 10 ( % ) c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > vgs c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > rsaimage c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c >
< extra_id_0 > table 1 summarizes the results on synthetically spoken coco . recall @ 10 ( % ) is significantly higher than rsaimage and mfcc , respectively . rsaimage achieves a higher average recall rate than rsaimage , which achieves a higher average recall rate .
< extra_id_0 > is so clever you want hate hate hate hate hate hate hate hate . we report further examples in the appendix .
< extra_id_0 > table 2 summarizes the rnp and dan datasets in table 2 . the rnp and dan datasets have the highest percentage of nouns and nouns with the lowest percentage of nouns and nouns with the highest percentage of nouns with the highest percentage of nouns with the highest percentage of nouns with the highest percentage of nouns with the highest percentage of nouns with the highest percentage of nouns with the highest percentage of nouns with the lowest percentage of nouns . table 2 summarizes the results of nouns with the highest percentage of nouns with the highest percentage of nouns with adj .
< extra_id_0 > the last two rows correspond to the case where negative labels are flipped to positive and vice versa . the numbers indicate that the score increases in positive and negative sentiment with respect to the original sentence .
< extra_id_0 > it ’ s good , but it ’ s not good . moreover , it ’ s difficult to evaluate compared to other methods . moreover , it ’ s difficult to distinguish between good and bad results . moreover , it ’ s difficult to distinguish between good and bad results . moreover , it is difficult to distinguish between good and bad results .
