< extra_id_0 > table 2 shows the throughput for processing the treelstm model on our recursive framework , fold ’ s folding technique , and tensorflow ’ s iterative approach , with the large movie review dataset . the recursive framework performs the best on inference with efficient parallel execution of tree nodes , while fold ’ s folding technique shows better performance on training thanks to its gpu exploitation .
< extra_id_0 > table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness . the balanced dataset exhibits highest throughput thanks to the high degree of parallelization , but at the same time does not improve as well as the linear dataset when the batch size increases from 1 to 25 .
< extra_id_0 > hyper parameter optimization results for each model with different representation . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations .
< extra_id_0 > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) with sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] c > [ bold ] c > [ bold ] with sdp c > [ bold ] c > [ bold ] with sdp c > [ bold ] with sdp c > [ bold ] with sdp c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > r - f1 50 % compared to c - f1 100 % compared to r - f1 50 % compared to f1 50 % compared to y - 3 and y - 3 , respectively . y - 3 and y - 3 perform better than y - 3 and y - 3 , respectively . y - 3 and y - 3 perform better .
< extra_id_0 > and paragraph level acc . c > paragraph level c - f1 c > paragraph level r - f1 c > paragraph level f1 c > paragraph level r - f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c >
< extra_id_0 > table 4 shows c - f1 ( 100 % ) in % for the two indicated systems ; essay vs . paragraph level . note that the mean performances are lower than the majority performances over the two indicated systems ; essay vs . paragraph level .
< extra_id_0 > bleu nist meteor rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l
< extra_id_0 > table 1 shows the comparison between the original e2e data and our cleaned version ( number of distinct mrs , total number of textual references , ser as measured by slot matching script , see section 3 ) .
< extra_id_0 > bleu nist meteor rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l
< extra_id_0 > table 4 shows the results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , wrong values , slight disfluencies , slight disfluencies ) .
< extra_id_0 > seq2seqk ( konstas et al . , 2017 ) has a better performance than snrg ( song et al . , 2018 ) and gcnseq ( damonte and cohen , 2019 ) with a better performance than snrg ( song et al . , 2017 ) and gcnseq ( damonte and cohen , 2019 ) with a better performance than snrg ( song et al . , 2017 ) has a better model ( song et al . , 2017 ) has a better performance than snrg ( song et al . , 2017 ) .
< extra_id_0 > gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 .
< extra_id_0 > german # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - german # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > c > [ bold c > c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [
< extra_id_0 > n c > [ italic ] n c > [ italic ] m c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] m c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] m
< extra_id_0 > + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc .
< extra_id_0 > dcgcn ( 2 ) c > 180 c > 10 . 9m c > 22 . 9m c > dcgcn ( 3 ) c > 180 c > 11 . 3m c > 22 . 9m c > dcgcn ( 4 ) c > 14 . 0m c > 23 . 9m c > dcgcn ( 3 ) c > 13 . 9m c > 23 . 9m c > dcgcn ( 4 ) c > 13 . 9m c >
< extra_id_0 > 8 : ablation study for density of connections on the dev set of amr15 . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block .
< extra_id_0 > 9 : ablation study for modules used in the graph encoder and the lstm decoder . - graph attention c > 23 . 7 c > 53 . 2 c > 52 . 4 c > - linear combination c > 22 . 9 c > 52 . 4 c > 52 . 4 c > - coverage mechanism c > 52 . 4 c > 52 . 4 c > - global node c > 24 . 9 c >
< extra_id_0 > table 7 : scores for initialization strategies on probing tasks . glorot c > 35 . 1 c > 70 . 8 c > wc c > 79 . 7 c > [ bold ] 79 . 7 c > [ bold ] 79 . 7 c > [ bold ] 79 . 7 c > [ bold ] 79 . 7 c > [ bold ] 79 . 7 c > [ bold ] 79 . 4 c >
< extra_id_0 > and topconst < extra_id_1 > c > bshift c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst
< extra_id_0 > cmow / 784 performs better than subj and mrpc compared to hybrid cmow / 784 . hybrid cmow / 784 performs better than hybrid cmow / 784 in terms of performance . hybrid cmow / 784 performs better than hybrid cmow / 784 in terms of performance . hybrid cmow / 784 performs better than hybrid cmow / 784 in terms of performance . hybrid cmow / 784 performs better than hybrid
< extra_id_0 > table 3 shows the relative change on unsupervised downstream tasks attained by our models . cmow c > + 26 . 6 % cmp . cmow c > + 26 . 6 % cmp . cmow c > + 26 . 6 % cmp . cmow c > + 26 . 6 % cmp . cmow c > + 26 . 6 % cmp . cmow c > + 26 . 6 % cmp .
< extra_id_0 > table 8 : scores . our paper c > [ bold ] 87 . 5 c > [ bold ] 70 . 6 c > [ bold ] 87 . 3 c > [ bold ] 74 . 4 c > [ bold ] 74 . 4 c > [ bold ] 74 . 4 c > [ bold ] 74 . 4 c > [ bold ] 74 . 4 c > [ bold ] 74 . 4 c > [ bold ] 74 . 4 c >
< extra_id_0 > table 6 shows the scores for different training objectives on the unsupervised downstream tasks . cmow - c has a higher score than cbow - c on the unsupervised downstream tasks .
< extra_id_0 > and topconst . topconst performs better than cmow - c . topconst performs better than cmow - r . topconst performs better than cmow - r . topconst performs better than cmow - r . topconst performs better than cmow - r . topconst performs better than cmow - r . topconst performs better than cmow - r . topconst performs better than wc performs better than wc performs better than wc performs better than wc performs better than wc performs better than wc performs better than wc performs better than wc performs better than wc performs better than wc performs better than wc .
< extra_id_0 > cmow - r has a better performance than subj and mrpc . cmow - r has a better performance than sick - e and sick - b . cmow - r has a better performance than sick - e and sick - b . cmow - r has a better performance than cmow - r .
< extra_id_0 > all loc < extra_id_1 > all misc c > all loc c > all org c > all misc c > all misc c > all loc c > all org c > all misc c > all misc c > mil - nd c > 57 . 15 c > 89 . 48 c > 47 . 42 c > 47 . 42 c > 47 . 42 c >
< extra_id_0 > compared to mil - nd ( model 1 ) and mil - nd ( model 2 ) , respectively . mil - nd ( model 1 ) and mil - nd ( model 2 ) perform better than mil - nd ( model 2 ) and mil - nd ( model 2 ) , respectively . mil - nd ( model 2 ) performs better than mil - nd ( model 2 ) and mil - nd ( model 2 ) , respectively .
< extra_id_0 > gen ref gen con / bold > gen con / bold > gen ref gen con / bold > gen ref gen con / bold > gen ref gen con / bold > gen ref gen con / bold > gen
< extra_id_0 > < extra_id_1 > > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu
< extra_id_0 > 3 : results on ldc2015e86 test set when models are trained with additional gigaword data . c > konstas et al . ( 2017 ) c > 200k c > 27 . 40 c > song et al . ( 2018 ) c > 31 . 60 c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > 4 : results of the ablation study on the ldc2017t10 development set . c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 >
< extra_id_0 > table 8 shows the fraction of elements in the output that are not present in the input ( added ) and the fraction of elements in the input that are missing in the generated sentence ( miss ) , for the test set of ldc2017t10 . the token lemmas are used in the comparison .
< extra_id_0 > table 4 shows sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer , trained with different target languages on a smaller parallel corpus ( 200k sentences ) . sem and pos tagging accuracy is shown in table 4 .
< extra_id_0 > 2 : pos and sem tagging accuracy with baselines and an upper bound . pos and sem tagging accuracy with baselines and an upper bound are shown in table 2 .
< extra_id_0 > fr c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > c >
< extra_id_0 > table 5 shows pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders , averaged over all non - english target languages . bi and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual encoders .
< extra_id_0 > is the difference between the attacker ’ s performance and the corresponding adversary ’ s accuracy . is the difference between the attacker ’ s score and the corresponding adversary ’ s accuracy . is the difference between the attacker ’ s performance and the corresponding adversary ’ s accuracy .
< extra_id_0 > table 1 shows the accuracies when training directly towards a single task . pan16 has the highest accuracies when training directly towards a single task . pan16 has the highest accuracies when training directly towards a single task .
< extra_id_0 > table 2 : protected attribute leakage : balanced & unbalanced data splits . pan16 shows a significant difference between pan16 and unbalanced data split .
< extra_id_0 > is the difference between the attacker ’ s score and the adversary ’ s accuracy . is the difference between the attacker ’ s score and the adversary ’ s accuracy . is the difference between the attacker ’ s score and the adversary ’ s accuracy .
< extra_id_0 > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c >
< extra_id_0 > ptb + finetune wt2 + dynamic wt2 + finetune wt2 + dynamic wt2 + finetune wt2 + dynamic wt2 + finetune wt2 + finetune wt2 + dynamic wt2 + finetune wt2 + finetune wt2 + dynamic wt2 + dynamic wt2 + dynamic wt2 + dynamic wt2 + dynamic wt2 + dynamic wt2 + dynamic wt2 + dynamic wt2 + dynamic wt2 + dynamic wt2 + dynamic wt2 + dynamic
< extra_id_0 > model c > 250k c > 250k c > 250k c > 250k c > 250k c > 250k c > 250k c > 250k c > 250k c > 250k c > 250k c > 250k c > 250k c > 250k c > 250k c > 250k c > 250k c > 250k c >
< extra_id_0 > yelppolar err and yelppolar time , respectively . zhang et al . ( 2015 ) compared the results of zhang et al . ( 2015 ) and zhang et al . ( 2015 ) compared the results of zhang et al . ( 2015 ) and zhang et al . ( 2015 ) compared the results of zhang et al . ( 2015 ) and zhang et al . ( 2015 ) compared the results of zhang et al . ( 2015 ) .
< extra_id_0 > table 3 shows the tokenized bleu score on wmt14 english - german translation task . train and decode bleu score on newstest2014 dataset . train and decode bleu score on newstest2014 dataset .
< extra_id_0 > “ # params ” : the parameter number of base . “ # params ” : the parameter number of elmo . rnet * : results published by wang et al . ( 2017 ) .
< extra_id_0 > “ # params ” : the parameter number in conll - 2003 english ner task . “ # params ” : the parameter number in ner task . “ # params ” : the parameter number in ner task .
< extra_id_0 > 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting and test accuracy on snli task with base + ln setting and test perplexity on snli task with base setting .
< extra_id_0 > w / system retrieval [ bold ] b - 2 c > [ italic ] w / system retrieval [ bold ] b - 4 c > [ italic ] w / system retrieval [ bold ] b - 4 c > [ italic ] w / system retrieval [ bold ] # sent c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] # sent c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > the highest standard deviation among automatic systems is highlighted in bold , with statistical significance marked with ( approximation randomization test , p0 . 0005 ) . the highest standard deviation among automatic systems is highlighted in bold , with statistical significance marked with ( approximation randomization test , p0 . 0005 ) . the highest standard deviation among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is highlighted in bold .
< extra_id_0 > dlqs and docsub , respectively . tlqs and docsub perform better than tlqs and hclust . tlqs performs better than tlqs and hclust . tlqs performs better than tlqs and tlqs . tlqs performs better than tlqs and tlqs .
< extra_id_0 > tlqs and docsub tlqs perform better than tlqs and docsub tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs
< extra_id_0 > tlqs and docsub tlqs perform better than tlqs and docsub tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs tlqs
< extra_id_0 > europarl has a total of 957 total terms and avgdepth of 11 . 82 . europarl has avgdepth of 11 . 82 . europarl has avgdepth of 11 . 82 and avgdepth of 11 . 82 . europarl has avgdepth of 11 . 82 .
< extra_id_0 > avgdepth : 9 . 9 compared to 980 for europarl and 996 for totalroots . europarl has avgdepth of 980 . europarl has avgdepth of 980 compared to 980 for europarl .
< extra_id_0 > r0 , r1 , r2 , r3 denote regressive loss , weighted softmax loss , binary sigmoid loss , and hidden dictionary learning , respectively . lf is the enhanced version as we mentioned in table 1 . ndcg % comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 . ndcg % comparison is shown in table 1 .
< extra_id_0 > table 2 shows the performance ( ndcg % ) of ablative studies on different models on visdial v1 . 0 validation set . p2 indicates the most effective one ( i . e . , hidden dictionary learning ) shown in table 1 .
< extra_id_0 > table 5 : comparison on hard and soft alignments . cs - en c > de - en c > fi - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > c > c >
< extra_id_0 > lv - en and zh - en , respectively . bertscore - f1 and ruse ( * ) have a higher average compared to bertscore - f1 and bertscore - f1 .
< extra_id_0 > and sfhotel bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > qual / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold > / bold
< extra_id_0 > m1 m2 m1 m2 m2 m1 m2 m2 m1 m2 m2 m1 m2 m2 m1 m2 m2 m1 m2 m2 m1 m2 m1 m2 m2 m1 m2 m1 m2 m2 m2 m2 m2 m2 m2 m2 m2 m2 .
< extra_id_0 > m0 : shen - 1 compared to m3 : shen - 1 compared to m4 : m0 compared to m4 : m0 compared to m3 : shen - 1 and m4 : m0 , respectively . m5 : m0 compared to m5 : m0 and m5 : m0 , respectively . m5 : m0 compared to m5 : m0 and m5 : m0 , respectively .
< extra_id_0 > m2 and m3 have significantly higher transfer quality than yelp . yelp has a higher transfer quality than yelp . yelp has a higher transfer quality than yelp . yelp has a higher transfer quality than yelp . yelp has a higher transfer quality than yelp .
< extra_id_0 > table 5 : human sentence - level validation of metrics ; 100 examples for each dataset for validating acc ; 150 for sim and pp ; see text for validation of gm ; see text for validation of gm ; see text for validation of acc ; see text for validation of gm ; see text for validation of acc ; see text for validation of gm ; see text for validation of acc ; see text for validation of gm ; see text for validation of acc ; see text for validation of acc ; see text for validation of acc .
< extra_id_0 > m5 : m0 has a better performance compared to m5 : m0 [ italic ] + cyc + para + lang compared to m5 : m0 [ italic ] + cyc + para + lang compared to m5 : m0 [ italic ] + cyc + para + lang compared to m5 : m0 [ italic ] + cyc + para + lang compared to m5 : m0 [ italic ] + cyc + para + lang compared to m6 : m0 [ italic ] + cyc + para + lang cyc + para + lang cyc + para + lang cyc + para + lang cyc + para + lang cyc + para + lang .
< extra_id_0 > untransferred sentences achieve the highest bleu than prior work at similar levels of acc . our best models achieve higher bleu than previous work at similar levels of bleu , but untransferred sentences achieve the highest bleu than previous work at similar levels of acc . our best models achieve higher bleu than previous work at similar levels of bleu , but untransferred sentences achieve the highest bleu than previous work at similar levels of bleu .
< extra_id_0 > table 2 shows the percentage of reparandum tokens that were correctly predicted as disfluent . reparandum tokens that were correctly predicted as disfluent are shown in table 2 . reparandum tokens that were correctly predicted as disfluent are shown in table 2 . reparandum tokens that were correctly predicted as disfluent are shown in table 2 . reparandum tokens that were correctly predicted as disfluent are shown in table 2 . reparandum tokens that were correctly predicted as disfluent are shown in table 2 .
< extra_id_0 > table 3 shows the relative frequency of rephrases correctly predicted as disfluent for disfluencies that contain a content word in both reparandum and repair ( content - content ) , either the reparandum or repair ( content - function ) or in neither .
< extra_id_0 > c > [ bold ] dev mean c > [ bold ] test mean c > [ bold ] test best c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c
< extra_id_0 > accuracy ( % ) agree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) unrelated c > 81 . 72 c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ]
< extra_id_0 > table 2 shows the accuracy ( % ) of different methods on the apw and nyt datasets for the document dating problem ( higher is better ) . the unified model significantly outperforms all previous models for the document dating problem .
< extra_id_0 > table 3 shows the effectiveness of both word attention and graph attention for this task . this results show the effectiveness of both word attention and graph attention for this task .
< extra_id_0 > [ bold ] 1 / n c > [ bold ] 1 / 1 c > [ bold ] 1 / n c > [ bold ] all c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > c >
< extra_id_0 > [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ b
< extra_id_0 > wer
< extra_id_0 > table 4 shows the results on the dev set and on the test set using discriminative training with only subsets of the code - switched data . the discriminative training with only subsets of the code - switched data is compared to discriminative training with only subsets of the code - switched data .
< extra_id_0 > table 5 shows the accuracy on the dev set and on the test set , according to the type of the gold sentence in the set : code - switched ( cs ) vs . monolingual ( monolingual ) .
< extra_id_0 > table 7 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) .
< extra_id_0 > table 5 shows precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant improvement ) .
< extra_id_0 > hpcd ( full ) is from the original paper , and it uses syntactic skipgram . glove - retro is a glove vector retrofitted by faruqui et al . ( 2015 ) to wordnet 3 . 1 , and glove - extended refers to the embeddings obtained by autoextension rothe and schütze ( 2015 ) on glove .
< extra_id_0 > table 2 shows results from rbg dependency parser with features coming from various pp attachment predictors and oracle attachment predictors . rbg + hpcd ( full ) scores 94 . 17 and 88 . 51 respectively .
< extra_id_0 > table 3 shows the effect of removing sense priors and context sensitivity ( attention ) from the model . the effect of removing sense priors and context sensitivity is shown in table 3 .
< extra_id_0 > adding subtitle data and domain tuning for image caption translation ( bleu % scores ) . adding subtitle data and domain tuning for image caption translation ( bleu % scores ) .
< extra_id_0 > en - fr c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > mscoco17 c > en - fr c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > en - fr and flickr16 perform better than en - fr and flickr17 compared to mscoco17 and mscoco17 in table 4 : adding automatic image captioning to multi30k . adding automatic image captioning to flickr16 and flickr17 performs better than en - fr , flickr16 and mscoco17 .
< extra_id_0 > mscoco17 , en - de and dec - gate perform better than enc - gate and dec - gate compared to flickr16 , flickr17 , mscoco17 , mscoco17 , mscoco17 , mscoco17 , mscoco17 , mscoco17 , mscoco17 , mscoco17 , mscoco17 , mscoco17 , mscoco17 , enc - gate , enc - gate perform better than enc - gate perform better than enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate enc - gate .
< extra_id_0 > mscoco17 and en - fr c > flickr16 c > mscoco17 c > mscoco17 c > en - fr c > en - fr c > en - fr c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > en - fr - trans - ff scores better than en - fr - trans - ff , whereas en - fr - trans - ff scores better than en - fr - trans - ff , whereas en - fr - trans - ff scores better than en - fr - trans - ff scores better than en - fr - trans - ff . en - fr - trans - ff scores better than en - fr - trans - ff scores better than en - trans
< extra_id_0 > table 1 shows the number of parallel sentences in the train , test and development splits for the language pairs we used . the number of parallel sentences in the train , test and development splits for the language pairs we used .
< extra_id_0 > 2 : training vocabularies for the english , french and spanish data used for our models . the training vocabularies for the english , french and spanish data are shown in table 2 .
< extra_id_0 > table 5 shows the automatic evaluation scores ( bleu and ter ) for the rev systems ( table 5 ) .
< extra_id_0 > vgs is the visually supervised model from chrupala2017representations . the row labeled vgs is the visually supervised model from chrupala2017representations . the row labeled vgs is the visually supervised model from flickr8k .
< extra_id_0 > results on synthetically spoken coco . the row labeled vgs is the visually supervised model from chrupala2017representations . the row labeled vgs is the visually supervised model from chrupala2017representations .
< extra_id_0 > is so clever you want hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate
< extra_id_0 > table 2 shows that the rnp is more accurate than the rnp . the rnp is more accurate than the rnp . the rnp is more accurate than the rnp , and the rnp is more accurate than the rnp .
< extra_id_0 > the numbers indicate the changes in percentage points with respect to the original sentence . the last two rows correspond to the case where negative labels are flipped to positive and vice versa . and indicate that the score increases in positive and negative sentiment .
< extra_id_0 > it n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t .
