< extra_id_0 > table 2 : throughput for processing the treelstm model on our recursive framework , fold ’ s folding technique , and tensorflow ’ s iterative approach , with the large movie review dataset . table 2 : throughput for processing the treelstm model on our recursive framework , fold ’ s folding technique , and tensorflow ’ s iterative approach with the large movie review dataset .
< extra_id_0 > table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness . table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness .
< extra_id_0 > hyper parameters l2 reg . c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters l2 reg . c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ]
< extra_id_0 > relation c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] relation c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] relation c > [ bold ] relation c > 60 . 34 c > 80 . 24 c > + 19 . 90 r > c > model - feature c > 48 . 89
< extra_id_0 > 50 % c > r - f1 100 % c > r - f1 50 % c > r - f1 100 % c > r - f1 50 % c > y - 3 : yitalic > c / italic > c / italic > c / italic > c / italic > c / italic > c / italic > c / italic > c / italic > c / italic > c / italic > c
< extra_id_0 > r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c
< extra_id_0 > r > c > [ empty ] c > lstm - parser c > lstm - parser c > lstm - parser c > lstm - parser c > lstm - parser c > lstm - parser c > lstm - parser c > lstm - parser c > lstm - parser
< extra_id_0 > c > [ bold ] test c > [ bold ] test c > [ bold ] test c > [ bold ] test c > [ bold ] test c > [ bold ] test c > [ bold ] test c > [ bold ] test c > [ bold ] test c > [ bold ] test c > [ bold ] test c > [ bold ] test c >
< extra_id_0 > r > c > [ bold ] dataset c > [ bold ] part c > [ bold ] refs c > [ bold ] ser ( % ) r > c > [ 0 . 5pt / 2pt ] cleaned c > test c > 1 , 358 c > 4 , 693 c > ( 0 . 00 ) r > c > [ 0 . 5pt / 2pt ] cleaned c >
< extra_id_0 > c > [ bold ] system c > [ bold ] miss c > [ bold ] miss c > [ bold ] miss c > [ bold ] miss c > [ bold ] miss c > [ bold ] miss c > [ bold ] miss c > [ bold ] miss c > [ bold ] miss c > [ bold ] miss c > [ bold ] miss c >
< extra_id_0 > table 4 : results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , wrong values , slight disfluencies ) .
< extra_id_0 > ( song et al . , 2018 ) c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model
< extra_id_0 > gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points . table 2 : main results on amr17 . gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points . table 2 : main results on amr17 . gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points . table 2 : main results on amr17 . gcnseq ( damonte and cohen , 2019
< extra_id_0 > - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p
< extra_id_0 > c > 2 c > 2 c > 2 c > 3 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1
< extra_id_0 > table 6 : comparisons with baselines . + rc < extra_id_1 > b 16 . 8 c > c 48 . 1 c > [ bold ] + rc + la ( 2 ) c > b 16 . 8 c > [ bold ] + rc + la ( 2 ) c > c 47 . 9 r > c > [ bold ] 52 . 9 r > c > + rc + la ( 3 ) c > 52 . 9 c > + rc + la ( 3 ) c > 52 . 9
< extra_id_0 > 20 . 9m c > 20 . 9m c > 52 . 0m c > [ bold ] 22 . 2m c > [ bold ] 52 . 3m r > c > [ bold ] 52 . 3m c > [ bold ] 53 . 4m c > [ bold ] 53 . 4m c > [ bold ] 53 . 4m c > [ bold ] 53 . 4m c > [ bold ] 53 . 4m c
< extra_id_0 > - i dense block denotes removing dense connections in the i - th block . - i dense block denotes removing dense connections in the i - th block . - i dense block denotes removing dense connections in the i - th block . - i dense block denotes removing dense connections in the i - th block . - i dense block denotes removing dense connections in the i - th block .
< extra_id_0 > table 9 : ablation study for modules used in the graph encoder and the lstm decoder . table 9 : ablation study for modules used in the graph encoder and the lstm decoder . table 9 : ablation study for modules used in the graph encoder .
< extra_id_0 > c > [ bold ] 35 . 1 c > 70 . 8 c > [ bold ] 82 . 0 c > objnum c > tense c > objnum c > topconst c > n ( 0 , 0 . 1 ) c > [ bold ] 82 . 8 c > [ bold ] 82 . 8 c > [ bold ] 82 . 8 c > [ bold ] 82 . 8 c > [ b
< extra_id_0 > > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c
< extra_id_0 > c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc
< extra_id_0 > method c > sts12 c > sts13 c > sts14 c > sts15 c > sts16 r > c > method c > sts12 c > sts13 c > sts14 c > sts16 c > method c > method c > method c > method c > method c > method c > method c >
< extra_id_0 > [ bold ] 70 . 6 c > [ bold ] 70 . 6 c > [ bold ] 70 . 6 c > [ bold ] 70 . 6 c > [ bold ] 70 . 6 c > [ bold ] 76 . 4 c > [ bold ] 74 . 4 c > [ bold ] 74 . 4 c > [ bold ] 74 . 4 c > [ bold ] 74 . 4 c > [ bold ] 74 . 4 c > [ b
< extra_id_0 > method c > sts12 c > sts13 c > sts14 c > sts15 c > sts16 r > c > method c > sts12 c > sts13 c > sts14 c > sts15 c > sts16 r > c > method c > cmow - c c > [ bold ] 43 . 5 c >
< extra_id_0 > depth c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topcon
< extra_id_0 > c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc
< extra_id_0 > loc c > all org c > all misc c > all misc c > all loc c > all org c > all misc c > all misc c > all loc c > all org c > all misc c > all org c > all misc c > all loc c > all org c > all misc c > all
< extra_id_0 > all p c > all r c > all f1 c > system c > all p c > all r c > all f1 r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r >
< extra_id_0 > / bold > c > ref gen / bold > neu / bold > c > ref gen / bold > neu / bold > c > ref gen / bold > neu / bold > c > ref gen ref gen / bold > neu / bold > r > c
< extra_id_0 > / bold > c > bold > bleu / bold > c > bold > bleu / bold > c > bold > bleu / bold > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > c > bold > model / bold > c > song et al . ( 2018 ) c > 200k c > 27 . 40 r > c > bold > bleu / bold > c > song et al . ( 2018 ) c > 200k c > 28 . 20 r > c > song et al . ( 2018 ) c > 200k c > 31 . 60
c > italic > get / italic > + italic > geb / italic > + bilstm c > 26 . 33 c > 32 . 42 c > 59 . 6m r > c > bold > meteor / bold > c > bold > meteor / bold > c > c > c > c > c
< extra_id_0 > / bold > 0 - 7 c > bold > graph diameter / bold > 7 - 13 c > bold > graph diameter / bold > 0 - 7 c > 0 - 20 c > 0 - 20 c > 0 - 20 c > 0 - 20 c > 0 - 20 c > 0 - 20 c > 0 - 20 c > 33 . 2 c > 29 . 9 c >
< extra_id_0 > c > bold > model / bold > c > bold > miss / bold > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ]
< extra_id_0 > r > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ]
< extra_id_0 > mft : most frequent tag ; unsupemb : classifier using unsupervised word embeddings ; word2tag : upper bound encoder - decoder . table 2 : pos and sem tagging accuracy with baselines and an upper bound .
< extra_id_0 > > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c
< extra_id_0 > table 5 : pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders , averaged over all non - english target languages . table 5 : pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders .
< extra_id_0 > table 8 : attacker ’ s performance on different datasets . results are on a training set 10 % held - out . is the difference between the attacker ’ s score and the corresponding adversary ’ s accuracy . is the difference between the attacker ’ s score and the corresponding adversary ’ s accuracy .
< extra_id_0 > r > c > task c > accuracy r > c > dial c > sentiment c > 67 . 4 r > c > [ italic ] gender c > 67 . 7 r > c > [ empty ] c > [ italic ] age c > 64 . 8 cap > table 1 : accuracies when training directly towards a single task .
< extra_id_0 > c > 81 . 2 c > 71 . 5 c > 79 . 5 c > 73 . 5 r > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c
< extra_id_0 > table 3 : performances on different datasets with an adversarial training . is the difference between the attacker score and the corresponding adversary ’ s accuracy . is the difference between the attacker score and the corresponding adversary ’ s accuracy .
< extra_id_0 > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty
< extra_id_0 > # params c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c
< extra_id_0 > c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model
< extra_id_0 > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model
< extra_id_0 > c > # params c > train c > decode c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c > train c
< extra_id_0 > “ # params ” : the parameter number of base . “ # params ” : the parameter number of elmo . “ # params ” : the parameter number of base .
< extra_id_0 > table 6 : f1 score on conll - 2003 english ner task . “ # params ” : the parameter number in ner task . lstm * denotes the reported result .
< extra_id_0 > table 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting . table 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting .
< extra_id_0 > retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] # word c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] # sent c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w /
< extra_id_0 > ( approximation randomization test , p0 . 0005 ) . top - 1 / 2 : % of evaluations a system being ( best ) . top - 1 / 2 : % of evaluations a system being ( best ) . top - 1 / 2 : % of evaluations a system being ( best ) . top - 1 / 2 : % of evaluations a system being ( best ) .
< extra_id_0 > corpus c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub
< extra_id_0 > corpus c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub
< extra_id_0 > dsim c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub
< extra_id_0 > dsim c > patt c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub
< extra_id_0 > 980 c > 902 c > 894 c > 784 c > 849 c > 980 c > 980 c > 980 c > 980 c > 902 c > 884 c > 849 c > 996 c > 996 c > 996 c > 996 c > 996 c > 996 c > 996
< extra_id_0 > [ bold ] 73 . 63 cap > table 1 : performance ( ndcg % ) comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 . lf is the enhanced version as we mentioned . qt , s and d denote question type , answer score sampling , and hidden dictionary learning , respectively . lf is the enhanced version as we mentioned .
< extra_id_0 > table 2 : performance ( ndcg % ) of ablative studies on different models on visdial v1 . 0 validation set . p2 indicates the most effective one ( i . e . , hidden dictionary learning ) shown in table 1 . note that only applying p2 is implemented by the implementations in section 5 .
< extra_id_0 > c > cs - en c > fi - en c > lv - en c > lv - en c > lv - en r > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > / bold > zh - en c > bold > direct assessment / bold > de - en c > bold > direct assessment / bold > de - en c > bold > direct assessment / bold > de - en c > bold > direct assessment / bold > de - en c > bold > direct assessment / bold > de - en c > c >
< extra_id_0 > > qual / bold > c > sfhotel bold > qual / bold > c > sfhotel bold > qual / bold > c > sfhotel bold > qual / bold > c > metrics c > metrics c > metrics c > metrics c > metrics c > metric
< extra_id_0 > bold > 0 . 949 / bold > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r >
< extra_id_0 > c > [ empty ] 22 . 3 c > 8 . 81 r > c > [ bold ] 12 . 8 r > c > [ bold ] 12 . 8 r > c > [ bold ] 12 . 8 r > c > [ bold ] 12 . 8 r > c > [ bold ] 12 . 8 r > c > [ bold ] 12 . 8 c > [ bold ] 12 . 8
< extra_id_0 > dataset c > dataset c > dataset c > dataset c > dataset c > dataset c > dataset c > dataset c > dataset c > dataset c > dataset c > dataset c > dataset c > dataset c > dataset c > dataset c > dataset c > dataset c > dataset
acc c > % of machine and human judgments that match c > 94 c > 84 r > c > acc c > % of machine and human judgments that match c > 0 . 79 c > 0 . 75 r > c > 0 . 67 cap > table 5 : human sentence - level validation of metrics ; 100 examples for each dataset for validating acc ; 150 each for sim and pp ; see text for validation of
< extra_id_0 > c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim
< extra_id_0 > bleu . acc : bleu is between 1000 transferred sentences and human references , and bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . table 6 : results on yelp sentiment transfer , where bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . table 6 : results on yelp sentiment transfer , where bleu is between 1000 transferred sentences and human references .
< extra_id_0 > table 2 : percent of reparandum tokens that were correctly predicted as disfluent . table 2 : percent of reparandum tokens that were correctly predicted as disfluent .
< extra_id_0 > table 3 : relative frequency of rephrases correctly predicted as disfluent for disfluencies that contain a content word in both the reparandum and repair ( content - function ) or in neither . percentages in parentheses show the fraction of tokens belong to each category .
< extra_id_0 > c > [ bold ] test best c > [ bold ] test best c > [ bold ] test best c > [ bold ] test best c > [ bold ] test best c > [ bold ] test best c > [ bold ] test best c > [ bold ] test best c > [ bold ] test best c > [ bold ] test best c > [ bold ] test best
< extra_id_0 > ( % ) agree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) unrelated c > average of word2vec embedding c > 24 . 54 c > 05 . 06 c > 53 . 24 c > 79 . 53 c > 81 . 72 r > c > [ bold ] 83 . 54 c > [ bold ] 83
< extra_id_0 > table 2 : accuracy ( % ) of different methods on the apw and nyt datasets for the document dating problem ( higher is better ) . the unified model significantly outperforms all previous models .
< extra_id_0 > table 3 : accuracy ( % ) comparisons of component models with and without attention . this results show the effectiveness of both word attention and graph attention for this task .
< extra_id_0 > [ bold ] 1 / 1 c > [ bold ] 1 / n c > [ bold ] all r > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ]
< extra_id_0 > [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ]
< extra_id_0 > wer c > test perp c > test perp c > test wer c > test wer c > test perp c > test wer c > test wer c > test wer c > test wer c > test wer c > test wer c > test wer c > test wer c > test wer c > test wer c > test wer c >
< extra_id_0 > table 4 : results on the dev set and on the test set using discriminative training with only subsets of the code - switched data . table 4 : results on the dev set and on the test set using discriminative training with only subsets of the code - switched data .
c > cs - only - lm c > 45 . 20 c > 65 . 87 c > 43 . 20 c > 62 . 80 c > fine - tuned - lm c > 47 . 60 c > 71 . 33 c > fine - tuned - lm c > 47 . 60 c > 47 . 60 c > 70 . 53 c > 70 . 53 c > 70 . 53
< extra_id_0 > baseline ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features trained on all three datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) . table 7 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features trained on all three datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) .
< extra_id_0 > precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant improvement ) . table 5 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant improvement ) .
< extra_id_0 > table 1 : results on belinkov2014exploring ’ s ppa test set . hpcd ( full ) is from the original paper , and it uses syntactic skipgram . glove - extended refers to the synset embeddings obtained by running autoextend rothe and schütze ( 2015 ) on glove .
< extra_id_0 > table 2 : results from rbg dependency parser with features coming from various pp attachment predictors and oracle attachments . table 2 : results from rbg dependency parser with features coming from various pp attachment predictors and oracle attachment predictors .
c > [ bold ] ppa acc . r > c > full c > 89 . 7 c > - sense priors c > 88 . 4 c > - attention c > 87 . 5 cap > table 3 : effect of removing sense priors from the model .
< extra_id_0 > r > c > en - de c > flickr16 c > flickr17 c > mscoco17 r > c > en - de c > multi30k c > 61 . 4 c > 54 . 0 c > 43 . 1 c > mscoco17 r > c > + ensemble - of - 3 c > 59 . 7 c > + ensemble - of - 3
< extra_id_0 > c > flickr16 c > flickr17 c > mscoco17 r > c > a c > subs1m [ italic ] [ italic ] h + ms - coco c > 66 . 3 c > 60 . 5 c > 60 . 9 c > 52 . 7 r > c > t c > subs1m [ italic ] [ italic ] lm + ms - coco
< extra_id_0 > table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : table 4 : autocap 1 - 5 ( concat
< extra_id_0 > c > flickr16 c > flickr17 c > mscoco17 r > c > en - fr c > flickr16 c > flickr17 c > mscoco17 r > c > img [ italic ] w c > [ bold ] 62 . 45 c > [ italic ] 52 . 86 r > c > dec - gate c
< extra_id_0 > 16 c > flickr16 c > flickr17 c > flickr17 c > mscoco17 r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r >
< extra_id_0 > c > mtld c > mtld c > mtld c > mtld c > mtld c > mtld c > en - fr - trans - ff c > en - fr - trans - ff c > en - fr - trans - ff c > en - fr - trans - ff c > en - fr - trans - ff
< extra_id_0 > r > c > language pair c > train c > test c > dev r > table 1 : number of parallel sentences in the train , test and development splits for the language pairs we used .
< extra_id_0 > table 2 : training vocabularies for the english , french and spanish data used for our models . table 2 : training vocabularies for the english , french and spanish data used for our models .
< extra_id_0 > r > c > en - fr - trans - rev c > 33 . 3 c > 50 . 2 r > c > en - fr - trans - rev c > 36 . 5 c > 47 . 1 r > c > en - fr - trans - rev c > 36 . 5 c > 47 . 1 r > c > en - fr - trans - rev c >
< extra_id_0 > table 2 : results on flickr8k . the row labeled vgs is the visually supervised model from chrupala2017representations . the row labeled vgs is the visually supervised model from chrupala2017representations .
< extra_id_0 > table 1 : results on synthetically spoken coco . the row labeled vgs is the visually supervised model from chrupala2017representations . the row labeled vgs is the visually supervised model from chrupala2017representations .
< extra_id_0 > she turns in a u > screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay of u > edges edges edges curves so clever easy want hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate hate
< extra_id_0 > bold > rnn / bold > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r >
< extra_id_0 > c > bold > rnn / bold > c > bold > dan / bold > c > table 3 : sentiment score changes in sst - 2 . the numbers indicate the changes in percentage points with respect to the original sentence .
< extra_id_0 > c > bold > pubmed / bold > positive c > bold > pubmed / bold > positive c > bold > pubmed / bold > negative c > c > c > c > c > c > c > c > c > c > c > c > c >
