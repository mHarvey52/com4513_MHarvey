< extra_id_0 > table 2 : throughput for processing the treelstm model on our recursive framework , fold ’ s folding technique , and tensorflow ’ s iterative approach , with the large movie review dataset . the recursive approach performs the best on inference with efficient parallel execution of tree nodes , while the folding technique shows better performance on training thanks to its gpu exploitation .
< extra_id_0 > table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness . the balanced dataset exhibits highest throughput thanks to the high degree of parallelization , but at the same time does not improve as well as the linear dataset when the batch size increases from 1 to 25 .
< extra_id_0 > activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation
< extra_id_0 > without sdp and [ bold ] best f1 ( in 5 - fold ) with sdp . using the shortest dependency path on each relation type yields the best f1 ( in 5 - fold ) without sdp .
< extra_id_0 > r - f1 50 % , r - f1 50 % , r - f1 50 % , r - f1 50 % , r - f1 50 % , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y ,
< extra_id_0 > , paragraph level c - f1 , and paragraph level r - f1 , respectively . paragraph level c - f1 and paragraph level r - f1 , respectively , and paragraph level r - f1 , respectively , and paragraph level r - f1 , respectively , and paragraph level r - f1 , respectively , and paragraph level r - f1 , respectively , and paragraph level r - f1 , respectively , and paragraph level r - f1 , respectively , and paragraph level r - f1 , respectively , and paragraph level f1 , respectively , respectively , respectively , respectively , respectively .
< extra_id_0 > table 4 shows the c - f1 ( 100 % ) for the two indicated systems ; essay vs . paragraph level . note that the mean performances are lower than the majority performances over the runs given in table 2 .
< extra_id_0 > bleu c > [ bold ] nist c > [ bold ] meteor c > [ bold ] rouge - l c > [ bold ] add c > [ bold ] miss c > [ bold ] miss c > [ bold ] ser c > original c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c > 00 . 05 c >
< extra_id_0 > table 1 : data statistics comparison for the original e2e data and our cleaned version ( number of distinct mrs , total number of textual references , ser as measured by our slot matching script , see section 3 ) .
< extra_id_0 > bleu c > [ bold ] nist c > [ bold ] rouge - l c > [ bold ] meteor c > [ bold ] add c > [ bold ] miss c > [ bold ] add c > [ bold ] miss c > [ bold ] add c > [ bold ] add c > [ bold ] add c > [ bold ] add c > [ bleu c > [ bold ] ser c > [ bold ] ser c > [ bold ] ser c > [ bold ser c > [ bold ] ser c > [ bold ] ser c > [ bold ] ser c > [ bold ] ser c > [ bold ] ser c > [ bold ser c > [ bold ] ser c > [ bold ser c > [ bold ] ser c > [ bold ser c > [ bold ] ser c > [ bold ser c > [ bold ser c > [ bold ] ser c > [ bold ] ser c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold ] c > [ bold c > [ bold ] c > [ bold c > [ bold c > [ bold ] c > [ bold c
< extra_id_0 > table 4 summarizes the results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , wrong values , slight disfluencies ) . the results of manual error analysis are shown in table 4 .
< extra_id_0 > graphlstm ( song et al . , 2018 ) has a better all performance than snrg ( song et al . , 2018 ) and tree2seq ( song et al . , 2018 ) with a better all performance than snrg ( song et al . , 2018 ) with a better all performance than snrg ( song et al . , 2018 ) with a better all performance than snrg ( song et al . , 2018 ) and gcnseq ) has a better all performance score of 24 . 4 , respectively .
< extra_id_0 > gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 .
< extra_id_0 > english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - german # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > c > [ bold c > [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold [ bold [ bold [ bold [ bold ] [ bold [ bold [ bold ] [ bold [ bold ] [ bold [ bold [ bold ] [ bold [ bold ] [ bold ] [ bold ] [ bold [ czech [ english - german b ] [ english - german b ] [ english - german c ] [ english - czech [ english - german b ] [ english - german c ] [ english - german b ] [ english - german c ] [ english - german b ] [ english - german c ] [ english - german b ] [ english - german c ] [ english - german b ] [ english - german c ] [ english - german b ] [ english - german c ] [ english - czech [ english - czech [ english - czech [ english - german b ] [ english - german c ] [ english - czech [ english - czech [ english - german b ] [ english - german c ] [ english - german b ] [ english - german c ] [ english - german b ] [ english - german c ] [ english - german b ] [ english - german c ] [ english - german b ] [ english - german c ] [ english - czech c ] [ english - czech c ] [ english - czech c ] [ english
< extra_id_0 > n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] c >
< extra_id_0 > gcn + rc ( 2 ) has a b 16 . 8 and c 48 . 1 respectively . gcn + rc ( 2 ) has a b 16 . 8 and c 48 . 1 respectively . gcn + rc + la ( 2 ) has a b 16 . 3 and c 47 . 9 respectively . compared to dcgcn3 ( 27 ) and dcgcn4 , gcn + rc ( 4 ) has a better performance than dcgcn3 ( 27 ) and dcgcn4 ( 36 ) and has a better performance than dcgcn4 ( 36 ) and has a better performance .
< extra_id_0 > d c > # p c > # p c > # p c > # p c > # p c > # p c > 420 c > 11 . 3m c > 22 . 8m c > 52 . 8m c > 53 . 4m c > dcgcn ( 3 ) c > 240 c > 11 . 3m c > 22 . 8m c > 53 . 4m c > 53 . 4m c > dcgcn ( 4 ) c >
< extra_id_0 > table 8 : ablation study for density of connections on the dev set of amr15 . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block .
< extra_id_0 > 9 : ablation study for modules used in the graph encoder and the lstm decoder . dcgcn4 achieves 25 . 5 points , compared to 55 . 4 points for - linear combination and 22 . 9 points for - direction aggregation .
< extra_id_0 > table 7 : scores for initialization strategies on probing tasks . the bshift vs . topconst vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs .
< extra_id_0 > and topconst c > bshift c > subjnum c > tense c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > wc c > wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc
< extra_id_0 > mrpc and mpqa mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc c > 79 . 2 c > 79 . 6 c > 79 . 6 c > 79 . 6 c > 79 . 6 c > 79 . 6 c > mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mr
< extra_id_0 > the results are presented in table 3 . the hybrid model achieves the highest score on unsupervised downstream tasks . the hybrid model achieves the highest score on unsupervised downstream tasks . the hybrid model achieves the highest score on unsupervised downstream tasks .
< extra_id_0 > our paper has a score of 69 . 6 compared to the baseline of 69 . 6 for subj and 69 . 6 for subj . our paper has a score of 69 . 6 compared to the baseline of 69 . 6 for subj and 69 . 6 for subj . our paper has a score of 68 . 8 compared to the baseline of 69 . 6 for subj and 76 . 2 for sick - e . our paper has a score of 76 . 9 compared to the baseline of 76 . 9 compared to the baseline of 76 . 9 for sick - r .
< extra_id_0 > cmow - c outperforms sts12 , sts13 , and sts16 . cmow - c outperforms both cmow - c and cmow - c on the unsupervised downstream tasks . cmow - c outperforms both cmow - c and cmow - c in terms of score .
< extra_id_0 > method c > bshift c > objnum c > topconst c > topconst c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c > wc c >
< extra_id_0 > mrpc and mpqa mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc c > sick - e c > sick - b c > sick - e c > sick - r c > 79 . 9 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > cmow - r c c c c c c c c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > e + org c > all misc c > all loc c > all org c > all misc c > all org c > all misc c > all org c > all org c > all misc c > 89 . 46 c > 89 . 46 c > 89 . 46 c > 89 . 46 c > 89 . 46 c > 89 . 46 c >
< extra_id_0 > all p c > all r c > all f1 c > in [ italic ] e + p c > in [ italic ] e + r c > in [ italic ] e + r c > in [ italic ] e + f1 c > in mil - nd ( model 2 ) , we observe that mil - nd performs better than mil - nd ( model 1 ) in terms of p c > and f1 c > . we observe that mil - nd performs better than mil - nd performs better than mil - nd ( model 1 c > .
< extra_id_0 > ref gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin
< extra_id_0 > bold > bleu / bold > bold > meteor / bold > bold > bleu / bold > bold > bleu / bold > bold > g2s - gin c > 22 . 55 0 . 17 0 . 16 0 . 16 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14
< extra_id_0 > 3 : results on ldc2015e86 test set when models are trained with additional gigaword data . konstas et al . ( 2017 ) c > 200k c > 27 . 40 , song et al . ( 2018 ) c > 31 . 60 .
< extra_id_0 > 4 shows the results of the ablation study on the ldc2017t10 development set . bold > meteor / bold > bold > meteor / bold > c > 57 . 6m c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > bold > graph diameter / bold > 0 - 7 bold > graph diameter / bold > 14 - 20
< extra_id_0 > table 8 shows the fraction of elements in the output that are not present in the input ( added ) and the fraction of elements in the input graph that are missing in the generated sentence ( miss ) , for the test set of ldc2017t10 . the token lemmas are used in the comparison . gold refers to the reference sentences .
< extra_id_0 > table 4 : sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer , trained with different target languages on a smaller parallel corpus ( 200k sentences ) . sem and pos tagging accuracy is shown in table 4 .
< extra_id_0 > pos and sem tagging accuracy with baselines and an upper bound . pos and sem tagging accuracy with baselines and an upper bound are shown in table 2 .
< extra_id_0 > , fr c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c
< extra_id_0 > table 5 shows pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders , averaged over all non - english target languages . pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual encoders are shown in table 5 .
< extra_id_0 > attacker ’ s performance on different datasets is shown in table 8 . is the difference between the attacker ’ s score and the corresponding adversary ’ s accuracy on different datasets . is the difference between the attacker ’ s score and the corresponding adversary ’ s accuracy .
< extra_id_0 > table 1 summarizes the accuracies when training directly towards a single task . for pan16 , the accuracies are significantly higher than for pan16 . for pan16 , the accuracies are significantly higher than for pan16 .
< extra_id_0 > 2 : protected attribute leakage : balanced & unbalanced data splits . pan16 prioritizes gender , age , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender splits .
< extra_id_0 > is the difference between the attacker score and the adversary ’ s accuracy . is the difference between the attacker score and the adversary ’ s accuracy . is the difference between the attacker score and the adversary ’ s accuracy .
< extra_id_0 > table 6 summarizes the accuracies of the protected attribute with different encoders . leaky achieves 64 . 5 compared to 67 . 8 for rnn and 54 . 8 for rnn .
< extra_id_0 > ptb + finetune c > wt2 + dynamic c > ptb + finetune c > wt2 + dynamic c > yang et al . ( 2018 ) compared to yang et al . ( 2018 ) compared to yang et al . ( 2018 ) compared to yang et al . ( 2018 ) compared to yang et al . ( 2018 ) compared to yang et al .
< extra_id_0 > base acc c > base time c > base time c > base time c > base time c > base time c > base time c > + ln acc c > + bert acc c > + bert time c > + bert time c > + bert time c > + bert time c > c > c > c > c > c > c >
< extra_id_0 > amapolar time c > yahoo err c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar err c > yelppolar time c > zhang et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 )
< extra_id_0 > table 3 shows the tokenized bleu score on wmt14 english - german translation task . train and decode time in seconds are measured from 0 . 2k training steps on tesla p100 .
< extra_id_0 > “ # params ” : the parameter number of elmo . “ # params ” : the parameter number of base . rnet * : the results published by wang et al . ( 2018 ) .
< extra_id_0 > “ # params ” : the parameter number in conll - 2003 english ner task . lstm * denotes the reported f1 score on conll - 2003 english ner task .
< extra_id_0 > table 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting and test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting .
< extra_id_0 > b - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 and r - 2 , respectively , respectively , respectively , respectively , respectively , respectively .
< extra_id_0 > the highest standard deviation among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is 1 . 0 . the highest standard deviation among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is highlighted in bold . the best result among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is highlighted in bold .
< extra_id_0 > dlqs and docsub , respectively , and hlqs and hlqs and hllust , respectively , and hlqs and docsub and hllust have significantly higher p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c >
< extra_id_0 > dlqs and docsub , respectively , and hlqs and dlqs and hclust , respectively , and tlqs and dlqs and hlqs and docsub have significantly higher p c > than lang c > and patt c > , respectively . tlqs and docsub have significantly higher p c > than dlqs and hlqs , respectively .
< extra_id_0 > dlqs and docsub , respectively , and hclust , respectively . in terms of p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > pt c > pt c >
< extra_id_0 > slqs and docsub are based on df and docsub and hclust . the results show that the europarl model performs better than the corpus model in terms of totalterms and avgdepth . the europarl model performs better than the corpus model in terms of avgdepth .
< extra_id_0 > avgdepth is 9 . 9 and avgdepth is 9 . 8 . europarl has avgdepth of 980 and avgdepth of 984 . europarl has avgdepth of 980 and avgdepth of 984 . europarl has avgdepth of 980 and avgdepth of 984 .
< extra_id_0 > qt , s and d denote question type , answer score sampling , and hidden dictionary learning , respectively . lf is the enhanced version as we mentioned in table 1 . ndcg % comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 is shown in table 1 .
< extra_id_0 > table 2 shows the performance ( ndcg % ) of ablative studies on different models on visdial v1 . 0 validation set . p2 indicates the most effective one ( i . e . hidden dictionary learning ) shown in table 1 .
< extra_id_0 > lv - en c > cs - en c > fi - en c > lv - en c > lv - en c > lv - en c > lv - en c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > bold > de - en c > zh - en c > zh - en c > zh - en c > zh - en c > zh - en c > zh - en c > zh - en c > zh - en c > zh - en c > zh - en c > zh - en c > zh - en c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > . < extra_id_1 > l bold > inf / bold > sfhotel bold > qual / bold > sfhotel bold > qual / bold > sfhotel bold > qual / bold > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r >
< extra_id_0 > m1 m2 m1 m2 m1 m2 m2 m1 m2 m2 m1 m2 m2 m1 m2 m2 m1 m2 m2 m1 m2 m2 m1 m2 m1 m2 m1 m2 r2 r2 r2 r2 .
< extra_id_0 > m1 : m0 + para – shen - 1 – and m6 : m0 – shen - 1 – with para – with para – with para – with para – with para – with para – with para – with para – with para – with para – with para – with para – with para – with para – with para – with para – with para – with para – with para – with para – with para – with para – with para – with par
< extra_id_0 > transfer quality a > b > a > a > transfer quality tie transfer quality tie transfer quality a > b > a > transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie transfer quality tie trans
< extra_id_0 > table 5 shows the human validation of acc and pp metrics ; 150 examples for each dataset for sim and pp ; see text for validation of gm ; see text for validation of gm ; see text for validation of acc ; see text for validation of pp ; see text for validation of acc ; see text for validation of pp ; see text for validation of acc ; see text for validation of pp ; see text for validation of gm .
< extra_id_0 > m0 has a better performance than shen - 1 and cyc + para , respectively . compared to shen - 1 and gm , m0 has a better performance than m0 and cyc + para , respectively . compared to pp and gm , both m0 and m0 have a better performance .
< extra_id_0 > bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . our best models achieve higher bleu than previous work at similar levels of acc , but untransferred sentences achieve the highest bleu than prior work at similar levels of bleu . our best models achieve higher bleu than previous work at similar levels of bleu , but untransferred sentences achieve the highest bleu than previous work .
< extra_id_0 > reparandum length [ bold ] 3 - 5 reparandum length [ bold ] 8 + reparandum length [ bold ] 3 - 5 reparandum length [ bold ] 3 - 5 reparandum length [ bold ] 3 - 5 reparandum length [ bold ] 8 + reparandum length [ bold ] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
< extra_id_0 > table 3 shows the relative frequency of rephrases correctly predicted as disfluent for disfluencies that contain a content word in both the reparandum and repair ( content - content ) , either the reparandum or repair ( content - function ) or in neither .
< extra_id_0 > c > [ bold ] dev mean c > [ bold ] test mean c > [ bold ] dev best c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > c > c > c > c > c > c > c > early c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > accuracy ( % ) agree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) unrelated c > average of word2vec embedding c > 12 . 43 c > 10 . 43 c > 10 . 43 c > 10 . 43 c > 83 . 54 c > table 2 : performance comparison with the state - of - art algorithms on the fnc - 1 test dataset . our model c >
< extra_id_0 > table 2 shows the accuracy ( % ) of different methods on the apw and nyt datasets for the document dating problem ( higher is better ) . the unified model significantly outperforms all previous models in terms of accuracy .
< extra_id_0 > table 3 shows the effectiveness of both word attention and graph attention for this task . this results show the effectiveness of both word attention and graph attention for this task .
< extra_id_0 > 1 / n c > [ bold ] all c > [ bold ] all c > [ bold ] all c > [ bold ] all c > [ bold ] all c > [ bold ] all c > [ bold ] all c > [ bold ] all c > [ bold ] all c > [ bold ] all c > [ bold ] all c > [ bold ] embedding +
< extra_id_0 > trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] c > [ bold ] c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold c > [ bold ] c > [ bold c > [ bold c > [ bold c > [ b
< extra_id_0 > acc dev perp test wer
< extra_id_0 > table 4 summarizes the results on the dev set and on the test set using discriminative training with only subsets of the code - switched data . the results on the dev set and on the test set are summarized in table 4 .
< extra_id_0 > table 5 : accuracy on the dev set and on the test set , according to the type of the gold sentence in the set : code - switched ( cs ) vs . monolingual ( mono ) .
< extra_id_0 > table 7 shows precision ( p ) , recall ( r ) and f1 - score ( f1 ) for using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) . type - aggregated gaze features trained on all three eye - tracking datasets are shown in table 7 .
< extra_id_0 > table 5 shows the precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant improvement ) .
< extra_id_0 > the hpcd ( full ) is from the original paper , and it uses syntactic skipgram . the results on belinkov2014exploring ’ s ppa test set are summarized in table 1 . lstm - pp and glove embeddings are shown in table 1 .
< extra_id_0 > table 2 summarizes results from rbg dependency parser with features coming from various pp attachment predictors and oracle attachments . the results are presented in table 2 .
< extra_id_0 > table 3 shows the effect of removing sense priors and context sensitivity ( attention ) from the model . the effect of removing sense priors and context sensitivity ( attention ) is shown in table 3 .
< extra_id_0 > adding subtitle data and domain tuning for image caption translation ( bleu % scores ) . adding subtitle data and domain tuning for image caption translation ( bleu % scores with marian amun ) .
< extra_id_0 > and mscoco17 , respectively . subs1m and lm + ms - coco outperform domain - tuned and lm + ms - coco . lm + ms - coco outperforms domain - tuned and lm + ms - coco in terms of labeling . lm + ms - coco outperforms domain - tuned and lm + ms - coco in terms of labeling .
< extra_id_0 > autocap 1 ( concat ) and autocap 2 ( concat ) improve the performance of en - de and mscoco in table 4 : adding automatic image captions to flickr and mscoco in table 4 : adding automatic image captions to flickr and mscoco in table 4 : adding automatic image captions to flickr and mscoco in table 4 : adding automatic image captions to flickr and mscoco in table 4 : adding automatic image captions in table 4 : adding automatic captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in table 4 : adding automatic image captions in
< extra_id_0 > mscoco17 and en - de c > flickr16 c > flickr17 c > mscoco17 c > en - de c > flickr16 c > flickr17 c > mscoco17 c > mscoco17 c > enc - gate c > 68 . 30 c > dec - gate c > 36 . 47 c > enc - gate
< extra_id_0 > mscoco17 and subs3m en - fr c > en - fr c > mscoco17 c > mscoco17 c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > mscoco17 c > mscoco17 c > c > subs3m c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > on the other hand , en - fr - trans - ff performs better than en - fr - trans - ff and en - fr - smt - back , respectively . the results show that en - fr - trans - ff performs better than en - fr - trans - ff and en - fr - trans - ff , respectively , and en - fr - trans - ff performs better than en - fr - trans - back .
< extra_id_0 > table 1 shows the number of parallel sentences in the train , test and development splits for the language pairs we used . the number of parallel sentences in the train , test and development splits for the language pairs we used is shown in table 1 .
< extra_id_0 > table 2 : training vocabularies for the english , french and spanish data used for our models . the training vocabularies for the english , french and spanish data used for our models are shown in table 2 .
< extra_id_0 > table 5 shows the automatic evaluation scores ( bleu and ter ) for the rev systems . the bleu and ter scores for the rev systems are shown in table 5 .
< extra_id_0 > results on flickr8k . the row labeled vgs is the visually supervised model from chrupala2017representations . the row labeled vgs is the visually supervised model from chrupala2017representations .
< extra_id_0 > results on synthetically spoken coco . the row labeled vgs is the visually supervised model from chrupala2017representations . the row labeled vgs is the visually supervised model from chrupala2017representations .
< extra_id_0 > she turns in a u > screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay that u > at the edges edges edges curves so clever you want hate hate hate hate hate hate hate hate . we report further examples in the appendix .
< extra_id_0 > bold > rnn / bold > bold > dan / bold > bold > dan / bold > bold > dan / bold > bold > + 63 bold > + 63 bold > + 63 bold > 3 bold > + 63 bold > 3 bold > 3 bold > 3 bold > 4
< extra_id_0 > the last two rows correspond to the case where negative labels are flipped to positive and vice versa . the numbers indicate that the score increases in positive and negative sentiment with respect to the original sentence .
< extra_id_0 > it n ’ t n ’ t evaluate n ’ t elicit n ’ t elicit n ’ t elicit n ’ t elicit n ’ t elicit n ’ t elicit n ’ t elicit n ’ t elicit n ’ t elicit n ’ t elicit n ’ t elicit n ’ t elicit n ’ t elicit n ’ t elicit n ’ t evaluative evaluative evaluative evaluative evaluative evaluative evaluative evaluative evaluative .
