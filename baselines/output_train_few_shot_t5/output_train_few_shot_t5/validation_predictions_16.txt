< extra_id_0 > table 2 : throughput for processing the treelstm model on our recursive framework , fold ’ s folding technique , and tensorflow ’ s iterative approach , with the large movie review dataset . the recursive approach performs the best on inference with efficient parallel execution of tree nodes , while the folding technique shows better performance on training thanks to its gpu exploitation .
< extra_id_0 > table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness . the balanced dataset exhibits highest throughput thanks to the high degree of parallelization , but at the same time does not improve as well as the linear dataset when the batch size increases from 1 to 25 . the balanced dataset exhibits highest throughput thanks to the high degree of parallelization .
< extra_id_0 > table 2 : hyper parameter optimization results for each model with different representation . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all models with different representations . the max pooling strategy consistently performs better in all models with different representations .
< extra_id_0 > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) with sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) with sdp c > [ bold relationship c > [ bold relationship c > [ bold relationship c > [ bold relationship c > [ bold relationship c > [ bold relationship c > [ bold relationship c > [ bold relationship c > [ bold relationship c > [ bold relationship c > [ bold relationship c > [ bold relationship c > [ bold relationship c > [ bold relationship c > [ bold ] with sdp ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with sdp [ bold ] with
< extra_id_0 > r - f1 50 % c - f1 100 % c - f1 50 % c - f1 50 % r - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 % c - f1 50 %
< extra_id_0 > : paragraph level acc . c > paragraph level acc . c > paragraph level c - f1 c > paragraph level r - f1 c > paragraph level f1 c > paragraph level r - f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c > paragraph level f1 c >
< extra_id_0 > 4 shows the c - f1 ( 100 % ) in % for the two indicated systems ; essay vs . paragraph level . note that the mean performances are lower than the majority performances over the two indicated systems ; essay vs . paragraph level .
< extra_id_0 > bleu cider nist rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l ser rouge - l rouge - l ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser
< extra_id_0 > table 1 shows the comparison of the original e2e data and our cleaned version ( number of distinct mrs , total number of textual references , ser as measured by our slot matching script , see section 3 ) . the original e2e data contains 4 , 862 distinct mrs , 42 , 061 textual references , and ser ( % ) .
< extra_id_0 > bleu c > [ bold ] nist c > [ bold ] meteor c > [ bold ] add c > [ bold ] add c > [ bold ] add c > [ bold ] add c > [ bold ] add c > [ bold ] add c > [ bold ] add c > [ bold ] add c > [ bold ] add c > [ bleu ser c > [ bold ] nist ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel sel
< extra_id_0 > table 4 shows the results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , wrong values , slight disfluencies ) . the results of manual error analysis are shown in table 4 .
< extra_id_0 > seq2seqk has a b c > 22 . 0 whereas graphlstm ( song et al . , 2018 ) has a b c > 24 . 4 whereas snrg ( song et al . , 2018 ) has a 22 . 4 c > all . graphlstm has a 24 . 4 c > all and a 24 . 4 c > all . graphlstm ( song et al . , 2018 ) has a 24 . 4 c > all c > 24 . 4 c > all . graphlstm has a 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > 25 . 4 c > c > c > c > c > graphlstm ( seq2seq2seq2seq2seq2seq2s
< extra_id_0 > gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 .
< extra_id_0 > english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - german # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ beck et al . , 2017 c > [ beck et al . , 2017 c > [ beck et al . , 2017 c > [ beck et al . , 2017 c > [ beck et al . , 2018 c > [ beck et al . , 2018 c > [ beck et al . , 2018 c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > [ italic ] n c > [ italic ] m c > [ italic ] n c > [ italic ] n c > [ italic ] m c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic n c >
< extra_id_0 > rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc = rc =
< extra_id_0 > d c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > # p c > dcgcn ( 1 ) c > 180 c > 10 . 9m c > 22 . 2m c > 22 . 8m c > 53 . 4m c > dcgcn ( 4 ) c > 180 c > 22 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > 22 . 8m c > 22 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcg
< extra_id_0 > ablation study for density of connections on the dev set of amr15 . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block .
< extra_id_0 > 9 : ablation study for modules used in the graph encoder and the lstm decoder . dcgcn4 achieves 25 . 5 55 . 4 vs . - linear combination ( 22 . 9 vs . 53 . 2 ) and - direction aggregation ( 22 . 9 vs . 53 . 2 ) .
< extra_id_0 > 7 : scores for initialization strategies on probing tasks . in glorot , initialization scores are significantly higher than in glorot . in glorot , initialization scores are significantly higher than in glorot . in glorot , initialization scores are significantly higher than in glorot .
< extra_id_0 > method c > depth c > objnum c > topconst c > subjnum c > depth c > depth c > depth c > depth c > depth c > depth c > depth c > depth c > depth c > depth c > depth c > 79 . 2 c > 79 . 2 c > depth c > objnum
< extra_id_0 > mrpc and mpqa mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc cmow / 784 cmow / 784 cmow / 784 cmow ( 784 cmow / 784 cmow / 784 cmow / 784 cmow / 784 cmow / 784 cmow ( 784 cmow / 784 cmow / 784 cmow ( 77 . 2
< extra_id_0 > and sts16 . table 3 shows the relative change on unsupervised downstream tasks attained by our models . cmow achieves a higher score than cbow and cmow , respectively . cmow achieves a higher score on unsupervised downstream tasks .
< extra_id_0 > table 8 summarizes the performance of glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs . glorot vs .
< extra_id_0 > and sts14 . cmow - c achieves the best performance on the unsupervised downstream tasks . cmow - c achieves the best performance on both the unsupervised and unsupervised tasks .
< extra_id_0 > topconst c > bshift c > subjnum c > tense c > objnum c > objnum c > objnum c > objnum c > objnum c > topconst c > wc c > cmow - c c > [ bold ] c > 79 . 8 c > [ bold ] c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > mrpc and mpqa mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc c > sick - e c > sick - b c > sick - e c > sick - e c > sick - b c > 79 . 9 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > 79 . 4 c >
< extra_id_0 > e + org c > all misc c > all loc c > all org c > all misc c > all org c > all org c > all misc c > mil - nd c > 57 . 15 c > 89 . 46 c > 89 . 46 c > 89 . 46 c > 89 . 46 c > 89 . 46 c >
< extra_id_0 > system c > all p c > all r c > all f1 c > all p c > all p c > all p c > all f1 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c >
< extra_id_0 > ref gen gen con / bold > neu / bold > gen ref gen con / bold > neu / bold > gen ref gen con / bold > neu / bold > gen ref gen con / bold > gen con / bold > gen gen
< extra_id_0 > bold > bleu / bold > bold > meteor / bold > bold > bleu / bold > bold > g2s - gin c > 22 . 55 0 . 17 0 . 16 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s - g2s -
< extra_id_0 > 3 : results on ldc2015e86 test set when models are trained with additional gigaword data . cap > konstas et al . ( 2017 ) c > 200k c > 27 . 40 , song et al . ( 2018 ) c > 31 . 60 , guo et al . ( 2018 ) c > 31 . 60 , guo et al . ( 2018 ) c > 31 . 60 , on the same test set .
< extra_id_0 > 4 shows the results of the ablation study on the ldc2017t10 development set . bold > get / italic > + bilstm c > 27 . 37 c > 33 . 30 c > 57 . 6m c > 57 . 6m c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > bold > 0 - 7
< extra_id_0 > table 8 shows the fraction of elements in the output that are not present in the input ( added ) and the fraction of elements in the input that are missing in the generated sentence ( miss ) , for the test set of ldc2017t10 . the token lemmas are used in the comparison . the gold refers to the reference sentences .
< extra_id_0 > 4 : sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer , trained with different target languages on a smaller parallel corpus ( 200k sentences ) . the sem and pos tagging accuracy is shown in table 4 .
< extra_id_0 > 2 shows mft and unsupemb tagging accuracy with baselines and an upper bound . pos and sem tagging accuracy with baselines and an upper bound are shown in table 2 .
< extra_id_0 > , fr c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > c >
< extra_id_0 > table 5 shows pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders , averaged over all non - english target languages . pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders are shown in table 5 .
< extra_id_0 > attacker ’ s performance on different datasets is shown in table 8 . is the difference between the attacker ’ s score and the corresponding adversary ’ s accuracy on different datasets . is the difference between the attacker ’ s score and the corresponding adversary ’ s accuracy on different datasets .
< extra_id_0 > table 1 summarizes the results for each task . for each task , the number of participants is significantly higher than the number of participants in pan16 . for each task , the number of participants is significantly higher than the number of participants in pan16 . in pan16 , the number of participants is significantly higher than in pan16 . in pan16 , the number of participants is significantly higher than in pan16 .
< extra_id_0 > 2 : protected attribute leakage : balanced & unbalanced data splits . pan16 shows a significant difference between the two datasets ( table 2 : protected attribute leakage and unbalanced task acc ) .
< extra_id_0 > is the difference between the attacker score and the adversary ’ s accuracy . is the difference between the attacker score and the adversary ’ s accuracy . is the difference between the attacker score and the adversary ’ s accuracy .
< extra_id_0 > 6 : accuracies of the protected attribute with different encoders . leaky achieves 64 . 5 c > 67 . 8 c > embedding guarded achieves 67 . 8 c > embedding leaky achieves 64 . 5 c > 67 . 8 c > embedding guarded achieves 54 . 8 c > 59 . 3 c > 59 . 3 c > 59 . 3 c >
< extra_id_0 > + finetune c > ptb + dynamic c > wt2 + finetune c > wt2 + dynamic c > yang et al . ( 2018 ) compared to yang et al . ( 2018 ) compared to yang et al . ( 2018 ) compared to yang et al . ( 2018 ) compared to yang et al . ( 2018 ) . yang et al . ( 2018 ) compared to yang et al . ( 2018 ) c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm et al . ( 2018 ) et al . ( 2018 ) . yang et al . ( 2018 ) . yang et al . ( 2018 ) .
< extra_id_0 > base acc c > + bert acc c > + bert time c > + ln acc c > + bert time c > + bert time c > + ln + bert time c > 83 . 50 c > this c > gru c > 6 . 41m c > 8 . 36m c > 8 . 36m c > 8 . 36m c > 8 . 36m c > acc c >
< extra_id_0 > amapolar time c > yahoo err c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar err c > yelppolar err c > yelppolar time c > zhang et al . ( 2015 ) compared to zhang et al . ( 2015 ) compared to zhang et al . ( 2015 ) c > c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c > dstm c >
< extra_id_0 > table 3 summarizes the bleu score on the wmt14 english - german translation task . bleu is a case - insensitive tokenized bleu score on the wmt14 english - german translation task .
< extra_id_0 > “ # params ” : the parameter number of base . rnet * : the results published by wang et al . ( 2017 ) . lstm achieves a score of 71 . 1 / 79 . 5 on the rnet dataset .
< extra_id_0 > “ # params ” : the parameter number in conll - 2003 english ner task . lstm * denotes the f1 score on conll - 2003 english task .
< extra_id_0 > 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting and test accuracy on snli task with base + ln setting and test perplexity on snli task with base + ln setting and test accuracy on snli task with ptb task with base + ln setting and test perplexity on ptb task with base + ln setting .
< extra_id_0 > b - 2 and r - 2 , respectively . c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] # sent c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ sent c > [ sent c > [ sent c > [ sent ] c > [ sent c > [ sent c > [ sent c > [ sent c > [ sent c > [ sent c > [ sent c > [ sent c > [ sent c > [ sent c > [ sent c > [ sent c > [ sent c > [ sent c > [ sent c > [ sent c > [ sent c > [ sent c > [ sent c > [ sent c > [ sent c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] c > [ sent ] w / system retrieval [ bold ] w / system retrieval [ bold ] w / system retrieval [ bold ] r - 2 w / system retrieval [ bold ] r - 2 w / system retrieval [ bold ] r - 2 w / system retrieval [ bold ] r - 2 c > r - 2 c > r - 2 c > r - 2 c > r - 2 c > r - 2 c > r - 2 c > r - 2
< extra_id_0 > the highest standard deviation among all automatic systems is 1 . 0 , with statistical significance marked with ( approximation randomization test , p0 . 0005 ) . the best result among automatic systems is highlighted in bold . the highest standard deviation among all automatic systems is 1 . 0 , with statistical significance marked with ( approximation randomization test , p0 . 0005 ) . the best results among automatic systems are highlighted in bold . the highest standard deviation among all automatic systems is 1 . 0 .
< extra_id_0 > dsim and docsub , respectively , and tf c > dsim and docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > europarl c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > dsim and docsub , respectively , and tf c > dsim and docsub c > docsub c > docsub c > docsub c > docsub c > dsim c > dsim c > dsim c > dsim c > dsim c > dsim c > dsim c > dsim c > df c > dsim cluster cluster cluster cluster clust cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster clust cluster clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust
< extra_id_0 > dsim and docsub , respectively , and tf c > dsim and docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > dsim c > dsim c > dsim c > dsim c > dsim c > dsim c > dsim c > df c > dsim c > dsim c > dsim clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust
< extra_id_0 > dsim and docsub perform well on the corpus . the results are summarized in table 3 . europarl performs better on the corpus than the corpus . europarl performs better on the total terms than the corpus . europarl performs better on the total terms . the corpus performs better on the total terms than the corpus .
< extra_id_0 > avgdepth is 9 . 9 and avgdepth is 9 . 8 . europarl has avgdepth of 980 and avgdepth of 984 . europarl has avgdepth of 980 and avgdepth of 984 . europarl has avgdepth of 980 and avgdepth of 984 . europarl has avgdepth of 984 and 996 . europar
< extra_id_0 > r0 , r1 , r2 and r3 denote question type , answer score sampling , and hidden dictionary learning , respectively . lf is the enhanced version as we mentioned in table 1 . lf is the baseline version as we mentioned in table 1 . ndcg compares the performance ( ndcg % ) for the experiments of applying our principles on the validation set of visdial v1 . 0 on the validation set of visdial v1 . 0 .
< extra_id_0 > table 2 shows the performance ( ndcg % ) of ablative studies on different models on visdial v1 . 0 validation set . p2 indicates the most effective one ( i . e . , hidden dictionary learning ) shown in table 1 .
< extra_id_0 > fi - en c > fi - en c > fi - en c > fi - en c > lv - en c > lv - en c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > bold > cs - en c > bold > direct assessment / bold > zh - en c > bold > direct assessment / bold > lv - en c > bertscore - f1 c > 0 . 672 c > 0 . 646 c > 0 . 661 c > 0 . 646 c > 0 . 661 c > 0 . 646 c > 0 . 661 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 > bertscore - f1 >
< extra_id_0 > > qual / bold > sfhotel bold > qual / bold > sfhotel bold > qual / bold > sfhotel bold > qual / bold > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r
< extra_id_0 > and m2 respectively . < extra_id_1 > 1 m2 m3 m2 r > c > bertscore - recall c > leic ( * ) c > 0 . 809 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > c > c > c > c > c > c > c > c > c > c > c > c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 749 c > 0 . 7
< extra_id_0 > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > transfer quality a > b and transfer quality tie c > semantic preservation b > a and transfer quality tie c > semantic preservation b > a and transfer quality tie c > semantic preservation b > a and transfer quality tie c > semantic preservation b > a and transfer quality tie c > semantic preservation b > a and transfer quality tie c > semantic preservation b > a and transfer quality tie c > m0 , respectively , and transfer quality tie c > m7 c > m7 c > m7 c > m9 c > m9 c > m9 c > m9 c > m9 c > m9 c > m9 , respectively .
< extra_id_0 > acc , pp , spearman ’ s [ italic ] and spearman ’ s [ italic ] are validated in table 5 . spearman ’ s [ italic ] and spearman ’ s [ italic ] are validated for b / w negative pp and human ratings of fluency . spearman ’ s [ italic ] and spearman ’ s [ italic ] are validated for b / w negative pp and human ratings of fluency are validated in table 5 .
< extra_id_0 > m0 has a better performance than m0 and m5 : m0 , respectively . m0 has a better performance than m0 and m5 : m0 , respectively . m5 : m0 has a better performance than m5 : m0 and m5 : m0 , respectively . m5 : m0 has a better performance than m5 : m0 and m5 : m0 , respectively .
< extra_id_0 > bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . our best models achieve higher bleu than previous work at similar levels of acc , but untransferred sentences achieve the highest bleu than prior work at similar levels of bleu . the results on yelp sentiment transfer are summarized in table 6 . our best models achieve higher bleu than previous work at similar levels of bleu , but untransferred sentences achieve the highest bleu . the results on fu - 1 embedding sentences .
< extra_id_0 > table 2 shows the percent of reparandum tokens that were correctly predicted as disfluent . rephrase , restart and rephrase are the most common reparandum tokens . rephrase , restart and rephrase are the most common disfluent tokens . rephrase and rephrase are the most common disfluent tokens . rephrase and restart tokens are the most common disfluent tokens . rephrase and restart tokens are the most common disfluent tokens .
< extra_id_0 > table 3 shows the relative frequency of rephrases correctly predicted as disfluent for disfluencies that contain a content word in both the reparandum and repair ( content - content ) , either the reparandum or repair ( content - function ) , or in neither of the two categories .
< extra_id_0 > [ bold ] dev mean c > [ bold ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test best c > [ italic ] test best c > [ italic ] test best c > [ italic ] test best c > [ italic ] model c > [ italic ] model c > [ italic ] model c > single c > single c > single c > single c > single c > single c > single c > single c > single c > single c > single c > single c > single c > single c > single c > single c > single c > single c > single c > single c > single c > single c > single c > text + raw c > innovations c > 86 . 54 c > 86 . 54 c > 86 . 54 c > innovations c > 86 . 54 c > 86 . 54 c > innovations c > 86 . 54 c > 86 . 54 c > 86 . 54 c > 86 . 54 c > 86 . 54 c > 86 . 54 c > 86 . 54 c > 86 . 54 c > 86 . 54 c > 86 . 54 c > 86 . 54 c > 86 . 54 c > 86 . 54 c > 86 . 54 c > 86 . 54 c > 86 . 54 c > 86 . 54 c > 86 . 54 c > 86 . 54 c > 86 .
< extra_id_0 > ( % ) unrelated c > accuracy ( % ) agree c > accuracy ( % ) disagree c > accuracy ( % ) unrelated c > average of word2vec embedding c > 12 . 43 c > 10 . 43 c > 10 . 43 c > 65 . 43 c > 80 . 43 c > [ bold ] 83 . 54 c > rnn - based sentence embedding c > 80 %
< extra_id_0 > table 2 shows the accuracy ( % ) of different methods on the apw and nyt datasets for the document dating problem ( higher is better ) . the unified model significantly outperforms all previous models .
< extra_id_0 > table 3 shows the effectiveness of both word attention and graph attention for this task . the results show the effectiveness of both word attention and graph attention for this task .
< extra_id_0 > [ bold ] 1 / 1 c > [ bold ] 1 / 1 c > [ bold ] 1 / n c > [ bold ] all c > [ bold ] 1 / 1 c > [ bold ] 1 / 1 c > [ bold ] 1 / 1 c > [ bold ] 1 / 1 c > [ bold ] 1 / 1 c > [ bold ] 1 / 1 c > [ bold ] 1 / 1 c > embedding + t c > embedding + t c > embedding + t c > embedding + t c > embedding + t c > embedding + t c > embedding + t c > embedding + t c > embedding + t c > embedding + t c > embedding + t c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > embedding + t c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > embedding + t c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > classification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) .
< extra_id_0 > wer
< extra_id_0 > train dev and on the test set using discriminative training with only subsets of the code - switched data are shown in table 4 . the results on the dev set and on the test set using discriminative training are shown in table 4 .
< extra_id_0 > table 5 shows the accuracy of the gold sentence on the dev set and on the test set , according to the type of the gold sentence in the set : code - switched ( cs ) vs . monolingual ( mono ) . on the dev set and on the test set , the accuracy of the fine - tuned - disc is higher than on the fine - tuned - disc .
< extra_id_0 > 7 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) . using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset is shown in table 7 .
< extra_id_0 > table 5 shows p , recall ( r ) and f1 - score ( f1 ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant improvement ) . using type - aggregated gaze features on the conll - 2003 dataset is shown in table 5 .
< extra_id_0 > table 1 summarizes the results on belinkov2014exploring ’ s ppa test set . syntactic - sg and glove - extended perform better than glove - retro and glove - extended , respectively .
< extra_id_0 > table 2 summarizes results from rbg dependency parser with features coming from various pp attachment predictors and oracle attachments . rbg + hpcd ( full ) achieves 94 . 17 points , compared to 88 . 51 points for full uas .
< extra_id_0 > 3 shows the effect of removing sense priors and context sensitivity ( attention ) from the ppa acc . the effect of removing sense priors and context sensitivity ( attention ) from the model is shown in table 3 .
< extra_id_0 > add subtitle data and domain tuning for image caption translation ( bleu % scores ) . all results with marian amun are shown in table 2 .
< extra_id_0 > and mscoco17 , respectively . subs1m and lm + ms - coco outperform domain - tuned and lm + ms - coco , respectively . lm + ms - coco outperforms domain - tuned and lm + ms - coco , respectively . lm + ms - coco outperforms domain - tuned and lm + ms - coco , respectively . lm + ms - coco outperforms domain - tuned and en - de .
< extra_id_0 > autocap 1 ( concat ) and autocap 1 ( concat ) improves the performance of en - de and mscoco17 in table 4 . adding automatic image captions with automatic image captions improves the performance of flickr16 and mscoco17 in table 4 . adding automatic image captions with automatic image captions improves the performance of flickr16 and mscoco17 . adding automatic image captions with automatic image captions improves the performance of flickr16 and mscoco17 , respectively .
< extra_id_0 > and mscoco17 . we observe that enc - gate and dec - gate perform better than enc - gate and enc - gate . we observe that enc - gate and dec - gate perform better than enc - gate and enc - gate compared to enc - gate and enc - gate compared to flickr16 and mscoco17 . we observe that enc - gate and dec - gate perform better than enc - gate and enc - gate perform better than enc - gate perform better than enc - gate perform better than enc - gate compared to flickr16 compared to flickr17 compared to dec - gate compared to enc - gate compared to flickr16 compared to flickr17 compared to flickr17 compared to enc - gate compared to flickr17 compared to flickr17 compared to enc - gate compared to enc - gate compared to enc - gate compared to flickr16 compared to dec - gate compared to flickr17 compared to enc - gate compared to flickr17 compared to flickr17 compared to enc - gate compared to enc - gate compared to enc - gate compared to enc - gate compared to enc - gate compared to enc - gate compared to flickr16 compared to flickr17 compared to enc - gate compared to flickr17 compared to flickr17 compared to flickr17 compared to enc - gate compared to dec - gate compared to flickr17 compared to enc - gate compared to flickr16 compared to dec - gate compared to flickr17 compared to flickr17 compared to flickr17 compared to flickr17 compared to enc - gate compared to enc - gate compared to enc - gate compared to enc - gate compared to enc - gate compared to flickr16 compared to flickr17 compared to flickr17 compared to enc - gate compared to flickr16 compared to flickr17 compared to flickr17 compared to enc
< extra_id_0 > mscoco17 and subs3m en - fr c > en - fr c > flickr16 c > mscoco17 c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > lm gn2048 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > en - fr - trans - ff and en - fr - smt - back perform better than en - fr - trans - ff and en - fr - trans - back , respectively . mtld performs better than en - fr - trans - ff and en - fr - trans - back , respectively . en - fr - trans - ff performs better than en - fr - trans - back and en - fr - trans - back .
< extra_id_0 > table 1 shows the number of parallel sentences in the train , test and development splits for the language pairs we used . the number of parallel sentences in the train , test and development splits for the language pairs we used is shown in table 1 .
< extra_id_0 > table 2 : training vocabularies for the english , french and spanish data used for our models . the src and trg datasets used for our models are shown in table 2 .
< extra_id_0 > table 5 summarizes the automatic evaluation scores ( bleu and ter ) for the rev systems . the bleu and ter scores for the rev systems are shown in table 5 .
< extra_id_0 > recall @ 10 ( % ) c > rsaimage c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > vgs c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > rsaimage c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c >
< extra_id_0 > table 1 summarizes the results on synthetically spoken coco . recall @ 10 ( % ) is significantly higher than rsaimage and mfcc , respectively . rsaimage has a higher recall rate than rsaimage and mfcc , respectively .
< extra_id_0 > she turns in a u > screenplay that u > at the edges edges edges curves so clever you want hate hate hate hate hate hate . we report further examples in the appendix . we report further examples in table 1 .
< extra_id_0 > bold > rnn / bold > and bold > dan / bold > . in table 2 , we see a significant difference in the number of nouns compared to the number of nouns compared to the number of nouns compared to the number of nouns compared to the number of nouns compared to the number of nouns compared to the number of nouns compared to the number of nouns compared to the number of nouns compared to the number of nouns , respectively .
< extra_id_0 > the last two rows correspond to the case where negative labels are flipped to positive and vice versa . the numbers indicate that the score increases in positive and negative sentiment with respect to the original sentence and vice versa .
< extra_id_0 > it c > better c > it c > it c > it c > it c > it c > it c > it c > it c > it c > it c > it c > it c > it c > it c > it c > it c > it c > it c > it c > it c > it c >
