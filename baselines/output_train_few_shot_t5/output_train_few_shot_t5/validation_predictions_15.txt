< extra_id_0 > table 2 : throughput for processing the treelstm model on our recursive framework , fold ’ s folding technique , and tensorflow ’ s iterative approach , with the large movie review dataset . the recursive approach performs the best on inference with efficient parallel execution of tree nodes , while fold ’ s folding technique shows better performance on training thanks to its gpu exploitation .
< extra_id_0 > table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness . the balanced dataset exhibits highest throughput thanks to the high degree of parallelization , but at the same time does not improve as well as the linear dataset when the batch size increases from 1 to 25 .
< extra_id_0 > activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . activation func . c >
< extra_id_0 > [ bold ] best f1 ( in 5 - fold ) without sdp compared to [ bold ] best f1 ( in 5 - fold ) with sdp compared to [ bold ] best f1 ( in 5 - fold ) without sdp compared to [ bold ] best f1 without sdp compared to [ bold ] best f1 ( in 5 - fold ) with sdp .
< extra_id_0 > r - f1 50 % , r - f1 50 % , r - f1 50 % , r - f1 50 % , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , f1 50 % , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y - 3 : y , y
< extra_id_0 > , paragraph level c - f1 , and paragraph level r - f1 , respectively . paragraph level c - f1 and paragraph level r - f1 , respectively , and paragraph level r - f1 , respectively , and paragraph level r - f1 , respectively , and paragraph level r - f1 , respectively , and paragraph level r - f1 , respectively , and paragraph level f1 and f1 respectively , respectively . the results show that mst - parser performs better than mst - parser and mate perform better than [ empty , respectively .
< extra_id_0 > table 4 shows the c - f1 ( 100 % ) for the two indicated systems ; essay vs . paragraph level . note that the mean performances are lower than the majority performances over the runs given in table 2 .
< extra_id_0 > bleu nist meteor rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l ser rouge - l ser rouge - l ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser
< extra_id_0 > table 1 : data statistics comparison for the original e2e data and our cleaned version ( number of distinct mrs , total number of textual references , ser as measured by our slot matching script , see section 3 ) .
< extra_id_0 > bleu cider rouge - l cider rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l ser rouge - l rouge - l ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser
< extra_id_0 > table 4 summarizes the results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , wrong values , slight disfluencies ) .
< extra_id_0 > graphlstm ( song et al . , 2018 ) has a higher all score than snrg ( song et al . , 2017 ) and gcnseq ( damonte and cohen , 2019 ) with a higher all score than snrg ( song et al . , 2017 ) with a higher all score than snrg ( song et al . , 2017 ) with a higher all score than snrg ( song et al . , 2017 ) with a higher all score of 24 . 4 points outperforms tsp ( damonte and cohen , 2019 ) and gcnseq ( damonte and cohen , 2019 ) .
< extra_id_0 > gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 .
< extra_id_0 > english - czech b c > [ bold ] english - czech b c > [ bold ] english - czech b c > [ bold ] english - czech b c > [ bold ] english - czech b c > [ bold ] english - czech b c > [ bold ] english - czech b c > [ bold ] english - german b c > [ bold ] english - czech b c > [ beck et al . , 2017 ] c > [ beck et al . , 2017 ] c > [ beck et al . , 2017 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > [ beck et al . , 2018 ] c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 2 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 3 c > 4
< extra_id_0 > + rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes the rc denotes the rc denotes the rc denotes the rc denotes the rc denotes the rc denotes the rc .
< extra_id_0 > d c > # p c > # p c > # p c > dcgcn ( 1 ) c > 180 c > 10 . 9m c > 22 . 2m c > 22 . 8m c > 53 . 4m c > dcgcn ( 4 ) c > 180 c > 11 . 3m c > 11 . 3m c > 22 . 8m c > 53 . 4m c > dcgcn ( 3 ) c > 22 . 8m c > 52 . 8m c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > 22 . 8m c > 22 . 8m c > 22 . 8m c > 52 . 8m c > 52 . 8m c > dcgcn ( 4 ) c > 12 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 52 . 8m c > 53 . 4m c > 54 . 4m c > 54 . 4m c > 54 . 4m c > 54 . 4m c > 54 . 4m c > dcgcn ( 2 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn ( 4 ) c > dcgcn
< extra_id_0 > ablation study for dense connections on the dev set of amr15 . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block .
< extra_id_0 > 9 : ablation study for modules used in the graph encoder and the lstm decoder . - graph attention and linear combination perform better than - global node and linear combination . - direction aggregation performs better than - linear combination .
< extra_id_0 > table 7 : scores for initialization strategies on probing tasks . we show that glorot achieves the best initialization scores on probing tasks . glorot achieves the best initialization scores on probing tasks .
< extra_id_0 > and topconst c > dim c > method c > depth c > objnum c > topconst c > objnum c > topconst c > topconst c > topconst c > topconst c > wc c > wc c > wc c > wc c > wc c > wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc
< extra_id_0 > mrpc and mrpc perform better than subj and mrpc and mrpc compared to hybrid and hybrid . hybrid and hybrid perform better than hybrid and hybrid . however , hybrid and hybrid perform better than hybrid and hybrid , respectively .
< extra_id_0 > we present the scores on unsupervised downstream tasks attained by our models in table 3 . the hybrid model achieves a score of 43 . 5 on unsupervised downstream tasks . the hybrid model achieves a score of 52 . 2 on unsupervised downstream tasks . the hybrid model achieves a score of 62 . 2 on unsupervised downstream tasks .
< extra_id_0 > our paper has a score of 69 . 6 and 69 . 6 respectively . our paper has a score of 69 . 6 and 69 . 6 respectively . our paper has a score of 69 . 6 and 69 . 6 respectively . our paper has a score of 69 . 6 and 69 . 6 respectively . our paper has a score of 69 . 6 and 69 . 6 respectively . our paper has a score of 69 . 6 and 69 . 6 respectively . our paper has a score of 76 . 8 respectively .
< extra_id_0 > cmow - c performs better than cmow - c and cmow - c on the unsupervised downstream tasks . cmow - c performs better than cmow - c on the unsupervised downstream tasks .
< extra_id_0 > method c > depth c > objnum c > topconst c > objnum c > objnum c > objnum c > objnum c > objnum c > objnum c > objnum c > objnum c > objnum c > topconst c > wc c > wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc wc cmow - c wc wc wc wc wc wc wc cmow - c wc wc cmow - c wc wc wc cmow - c wc wc wc wc wc wc wc cmow - c wc wc wc wc
< extra_id_0 > mrpc and mpqa mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc mrpc c > sick - e c > sick - b c > sick - r c > 79 . 9 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > 79 . 4 c > 79 . 4 c >
< extra_id_0 > all loc c > all misc c > all org c > all misc c > all misc c > all loc c > all org c > all per c > all misc c > mil - nd c > 57 . 15 c > 89 . 47 c > 89 . 47 c > 89 . 47 c > 89 . 47 c > 89 . 47 c >
< extra_id_0 > all p c > all r c > all f1 c > in [ italic ] e + p c > in [ italic ] e + r c > in [ italic ] e + r c > all f1 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c > 69 . 38 c >
< extra_id_0 > ref gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gen gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin gin
< extra_id_0 > bold > bleu / bold > bold > meteor / bold > bold > bleu / bold > bold > g2s - gin c > 22 . 55 0 . 17 0 . 16 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 0 . 14 - - - - - - - - -
< extra_id_0 > 3 : results on ldc2015e86 test set when models are trained with additional gigaword data . cap > konstas et al . ( 2017 ) c > 200k c > 27 . 40 ; song et al . ( 2018 ) c > 31 . 60 ; guo et al . ( 2018 ) c > 31 . 60 ; song et al . ( 2018 ) c > 31 . 60 ; song et al . ( 2018 ) c > 31 . 60 ;
< extra_id_0 > 4 shows the results of the ablation study on the ldc2017t10 development set . bold > meteor / bold > bold > size / bold > c > 57 . 6m c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > bold > 0 - 7
< extra_id_0 > table 8 shows the fraction of elements in the output that are not present in the input ( added ) and the fraction of elements in the input that are missing in the generated sentence ( miss ) , for the test set of ldc2017t10 . the token lemmas are used in the comparison . the gold refers to the reference sentences .
< extra_id_0 > table 4 : sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer , trained with different target languages on a smaller parallel corpus ( 200k sentences ) . the sem and pos tagging accuracy uses features extracted from the 4th nmt encoding layer .
< extra_id_0 > 2 : pos and sem tagging accuracy with baselines and an upper bound . pos and sem tagging accuracy with baselines and an upper bound are shown in table 2 .
< extra_id_0 > fr c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > table 5 shows pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders , averaged over all non - english target languages . pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders are shown in table 5 .
< extra_id_0 > is the difference between the attacker ’ s performance and the corresponding adversary ’ s accuracy . is the difference between the attacker ’ s score and the corresponding adversary ’ s accuracy . is the difference between the attacker ’ s performance and the corresponding adversary ’ s accuracy .
< extra_id_0 > table 1 : accuracies when training directly towards a single task . c > dial c > 67 . 4 c > mention c > 67 . 4 c > sentiment c > 67 . 4 c > mention c > 67 . 4 c > pan16 c > mention c > 67 . 4 c > mention c > 67 . 4 c >
< extra_id_0 > 2 : protected attribute leakage : balanced & unbalanced data splits . pan16 prioritizes gender , age , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender , gender splits .
< extra_id_0 > 3 : performances on different datasets with an adversarial training . is the difference between the attacker score and the corresponding adversary ’ s accuracy . is the difference between the attacker score and the corresponding adversary ’ s accuracy .
< extra_id_0 > 6 : accuracies of the protected attribute with different encoders with different encoders . leaky achieves 64 . 5 c > 67 . 8 c > 67 . 8 c > 67 . 8 c > 67 . 8 c > 67 . 8 c > 67 . 8 c > 67 . 8 c > 59 . 3 c > 59 . 3 c > 57 . 8 c >
< extra_id_0 > + finetune c > ptb + dynamic c > wt2 base c > wt2 + finetune c > wt2 + dynamic c > yang et al . ( 2018 ) compared to yang et al . ( 2018 ) compared to yang et al . ( 2018 ) compared to yang et al . ( 2018 ) compared to yang et al . ( 2018 ) compared to yang et al . ( 2018 ) c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm c > lstm et al . et al . et al . et al . et al . et al . et al . et al . et al . et al . et al . et al . et al . et al . et al .
< extra_id_0 > base acc c > + bert acc c > + bert time c > + ln acc c > + bert time c > + bert time c > + ln + bert time c > + ln + bert time c > + ln + bert time c > + ln + bert time c > c > c > c > c > c > c >
< extra_id_0 > amafull err c > yahoo err c > yelppolar time c > yelppolar time c > yelppolar err c > yelppolar time c > zhang et al . ( 2015 ) compared the results of zhang et al . ( 2015 ) and zhang et al . ( 2015 ) compared the results of zhang et al . ( 2015 ) and zhang et al . ( 2015 ) c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar err c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppolar time c > yelppol
< extra_id_0 > table 3 shows the tokenized bleu score on the wmt14 english - german translation task . train and decode time in seconds measured from 0 . 2k training steps on tesla p100 dataset .
< extra_id_0 > “ # params ” : the parameter number of base . rnet * : the results published by wang et al . ( 2017 ) . lstm achieves a score of 71 . 1 / 79 . 5 on the rnet dataset .
< extra_id_0 > “ # params ” : the parameter number in conll - 2003 english ner task . “ # params ” : the parameter number in conll - 2003 english ner task .
< extra_id_0 > 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting and test accuracy on snli task with base + ln setting and test perplexity on snli task with base + ln setting and test perplexity on snli task with base + ln setting . elrn and glrn achieve the best performance .
< extra_id_0 > b - 2 and r - 2 , respectively . c > [ italic ] w / system retrieval [ bold ] mtr c > [ italic ] w / system retrieval [ bold ] mtr c > [ italic ] w / system retrieval [ bold ] mtr c > [ italic ] w / system retrieval [ bold ] # sent c > [ italic ] w / system retrieval [ bold ] c >
< extra_id_0 > the highest standard deviation among automatic systems is 1 . 0 , with statistical significance marked with ( approximation randomization test , p0 . 0005 ) . the highest standard deviation among automatic systems is highlighted in bold , with statistical significance marked with ( approximation randomization test , p0 . 0005 ) . the best result among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is 1 . 0 . the highest standard deviation among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is 1 . 0 .
< extra_id_0 > dsim , docsub and docsub are the best performing datasets in terms of p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > europar
< extra_id_0 > dsim , docsub , df and docsub have the best p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c
< extra_id_0 > dlqs and docsub , respectively , and hclust and dlqs , respectively . the p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c > p c
< extra_id_0 > df , docsub and hclust are based on corpus c > dsim c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub c > hclust cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster cluster clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust clust c
< extra_id_0 > avgdepth is 9 . 9 and avgdepth is 9 . 8 . europarl has avgdepth of 980 and avgdepth of 984 . europarl has avgdepth of 980 and avgdepth of 984 . europarl has avgdepth of 980 and avgdepth of 984 . europarl has avgdepth of 984 and 996 are 996 are 996 and 996 .
< extra_id_0 > qt , s and d denote question type , answer score sampling , and hidden dictionary learning , respectively . lf is the enhanced version as we mentioned in table 1 . ndcg % comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 . lf is the baseline version as we mentioned in table 1 .
< extra_id_0 > table 2 shows the performance ( ndcg % ) of ablative studies on different models on visdial v1 . 0 validation set . p2 indicates the most effective one ( i . e . , hidden dictionary learning ) shown in table 1 .
< extra_id_0 > fi - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > lv - en c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > bold > de - en c > bold > direct assessment / bold > zh - en c > bold > direct assessment / bold > lv - en c > bertscore - f1 c > 0 . 552 c > 0 . 661 c > 0 . 646 c > 0 . 661 c > 0 . 661 c > 0 . 661 c > 0 . 661 c >
< extra_id_0 > : sfhotel bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > c > bleu - 2 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > leic ( * ) scores m1 m2 compared to spice ( * ) and spice ( * ) scores m1 m2 compared to spice ( * ) and spice ( * ) scores m1 m2 compared to m1 m2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r2 r
< extra_id_0 > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > sim c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > m0 c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > transfer quality a > b c > models b c > transfer quality tie c > semantic preservation a > b c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie c > semantic preservation tie sim c > m0 c > m7 c > m7 c > m7 c > m7 c > m3 c > m3 c > m3 c > m3 sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim s
< extra_id_0 > table 5 shows the human validation of acc and pp , respectively . acc and pp are validated by spearman ’ s and spearman ’ s ( see text for validation of gm ) . spearman ’ s ( see text for validation of gm ) and spearman ’ s ( see text for validation of gm ) .
< extra_id_0 > m0 has a better performance than shen - 1 and cyc + para with a better performance than m0 and cyc + para . m0 has a better performance than shen - 1 and cyc + para with a better performance than m0 and cyc + para with a better performance than pp and gm . m0 has a better performance than pp and gm , with a better performance than pp and gm .
< extra_id_0 > bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . our best models achieve higher bleu than previous work at similar levels of acc , but untransferred sentences achieve the highest bleu than prior work at similar levels of bleu . our best models achieve higher bleu than previous work at similar levels of bleu , but untransferred sentences achieve the highest bleu than previous work at similar levels of acc .
< extra_id_0 > table 2 : percent of reparandum tokens that were correctly predicted as disfluent . rephrase , rephrase , restart , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , rephrase , etc .
< extra_id_0 > table 3 shows the relative frequency of rephrases correctly predicted as disfluent for disfluencies that contain a content word in both reparandum and repair ( content - content ) or in neither reparandum or repair ( content - function ) or in neither of these categories .
< extra_id_0 > c > [ bold ] dev mean c > [ bold ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] test mean c > [ italic ] single c > [ italic ] innovation c > [ italic ] innovation c > [ italic ] innovation c > [ italic ] innovation c > [ italic ] innovation c > [ italic ] innovation c > [ italic ] innovation c > [ italic ] innovation c > [ italic ] innovation c > [ italic ] innovation c > [ italic ] innovation c > [ italic ] innovation c > [ italic ] model c > [ italic ] model c > [ italic ] model c > [ italic ] model c > [ italic ] model c > [ italic ] model c > [ italic ] model c > [ italic ] model c > [ italic ] model c > [ italic ] model c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > accuracy ( % ) agree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) unrelated c > average of word2vec embedding c > 12 . 43 c > 10 . 43 c > 10 . 43 c > 10 . 43 c > 65 . 43 c > 80 . 43 c > 80 . 43 c > [ bold ] 83 . 54 c > c >
< extra_id_0 > table 2 shows the accuracy ( % ) of different methods on the apw and nyt datasets for the document dating problem ( higher is better ) . the unified model significantly outperforms all previous models on both datasets .
< extra_id_0 > table 3 shows the effectiveness of both word attention and graph attention for this task . this results show the effectiveness of both word attention and graph attention for this task .
< extra_id_0 > 1 / n c > [ bold ] 1 / 1 c > [ bold ] 1 / 1 c > [ bold ] 1 / n c > [ bold ] all c > [ empty ] c > embedding + t c > 69 . 8 c > 59 . 8 c > 59 . 8 c > 59 . 8 c > embedding + t c > 69 . 3 cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn embedding + t cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn embedding + t cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn embedding + t cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn cnn
< extra_id_0 > classification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > wer
< extra_id_0 > and the test set using discriminative training with only subsets of the code - switched data . the results on the dev set and on the test set using discriminative training with only subsets of the code - switched data .
< extra_id_0 > table 5 : accuracy on the dev set and on the test set , according to the type of the gold sentence in the set : code - switched ( cs ) vs . monolingual ( mono ) .
< extra_id_0 > table 7 shows the precision ( p ) , recall ( r ) and f1 - score ( f1 ) for using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) . type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset are shown in table 7 . the accuracy ( p ) , recall ( r ) and f1 - score ( f ) are shown in table 7 .
< extra_id_0 > table 5 shows the precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant improvement ) .
< extra_id_0 > table 1 summarizes the results on belinkov2014exploring ’ s ppa test set . syntactic - sg and lstm - pp provide the best initialization performance . lstm - pp and glove - extended provide the best results on the glove test set .
< extra_id_0 > table 2 summarizes results from rbg dependency parser with features coming from various pp attachment predictors and oracle attachment predictors . rbg + hpcd ( full ) achieves 94 . 17 and 88 . 51 points respectively .
< extra_id_0 > table 3 shows the effect of removing sense priors and context sensitivity ( attention ) from the model . the effect of removing sense priors and context sensitivity ( attention ) from the model is shown in table 3 .
< extra_id_0 > adding subtitle data and domain tuning for image caption translation ( bleu % scores ) . all results with marian amun are shown in table 2 .
< extra_id_0 > and mscoco17 . the subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs1m subs
< extra_id_0 > autocap 1 - 5 ( concat ) and autocap 1 - 5 ( concat ) significantly outperforms en - de and flickr16 and mscoco17 in terms of automatic image captioning . adding automatic image captioning to flickr16 and mscoco17 results in a significant improvement over en - de and flickr17 . adding automatic image captioning to flickr16 and mscoco17 results in a significant improvement over en - de and multi30k .
< extra_id_0 > and mscoco17 , respectively . we show that enc - gate and dec - gate perform better than enc - gate and enc - gate , respectively . we show that enc - gate and dec - gate perform better than enc - gate and enc - gate , respectively . we show that enc - gate and dec - gate perform better than enc - gate and enc - gate , respectively , while enc - gate and dec - gate perform better than enc - gate perform better than enc - gate perform better than enc - gate perform better than enc - gate and enc - gate .
< extra_id_0 > and mscoco17 , respectively . subs3m has the best overall - of - 3 and text - only lm detectron , respectively . subs6m has the best overall - of - 3 and text - only lm detectron , respectively .
< extra_id_0 > en - fr - trans - ff has a better performance than en - fr - trans - back and en - fr - trans - back , respectively . mtld has a better performance than en - fr - trans - ff and en - fr - trans - back , respectively . en - fr - trans - ff has a better performance than en - fr - trans - back and en - fr - trans - back , respectively .
< extra_id_0 > table 1 shows the number of parallel sentences in the train , test and development splits for the language pairs we used . the number of parallel sentences in the train , test and development splits is shown in table 1 .
< extra_id_0 > table 2 : training vocabularies for the english , french and spanish data used for our models . the training vocabularies for the english , french and spanish data used for our models are shown in table 2 .
< extra_id_0 > table 5 shows the automatic evaluation scores ( bleu and ter ) for the rev systems . the bleu and ter scores for the rev systems are shown in table 5 .
< extra_id_0 > recall @ 10 ( % ) c > [ empty ] c > recall @ 10 ( % ) c > vgs c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c > 0 c >
< extra_id_0 > table 1 summarizes the results on synthetically spoken coco . recall @ 10 ( % ) is significantly higher than rsaimage and mfcc , respectively . rsaimage has a higher recall rate than rsaimage and mfcc scores , respectively .
< extra_id_0 > she turns in a u > screenplay that u > at the edges edges edges curves so clever you want hate hate hate hate hate hate . we report further examples in the appendix . we report further examples in table 1 .
< extra_id_0 > 3 bold > rnn / bold > 3 bold > dan / bold > 3 bold > rnn / bold > 3 bold > dan / bold > 4 bold > + 33 bold > + 33 bold > + 33 bold > 4 bold > + 33 / bold > 4 3 4
< extra_id_0 > the numbers indicate the changes in percentage points with respect to the original sentence . the last two rows correspond to the case where negative labels are flipped to positive and vice versa . and indicate that the score increases in positive and negative sentiment .
< extra_id_0 > it n ’ t elicit a conclusion whereas it is better than pubmed . moreover , it is better than pubmed compared to sst - 2 compared to pubmed compared to sst - 2 compared to pubmed compared to sst - 2 compared to pubmed compared to sst - 2 compared to pubmed compared to sst - 2 compared to pubmed compared to sst - 2 compared to pubmed compared to sst - 2 compared with best compared to bad compared to best compared to best compared to best compared to best compared to best compared to best compared to best compared to best compared to best compared to best compared to best compared to best compared to best compared to best compared to best compared to best compared to best compared to best compared to best compared to best compared to best .
