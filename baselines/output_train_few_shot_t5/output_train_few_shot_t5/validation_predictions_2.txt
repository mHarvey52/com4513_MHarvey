< extra_id_0 > cap > table 2 : throughput for processing the treelstm model on our recursive framework , fold ’ s folding technique , and tensorflow ’ s iterative approach , with the large movie review dataset . cap > table 2 : throughput for processing the treelstm model on our recursive framework , fold ’ s folding technique , and tensorflow ’ s iterative approach .
< extra_id_0 > table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness . table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness .
< extra_id_0 > hyper parameters activation func . c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameters learning rate c > [ bold ]
< extra_id_0 > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > + 19 . 90 r >
< extra_id_0 > 50 % c > r - f1 100 % c > r - f1 50 % c > r - f1 100 % c > r - f1 50 % c > r - f1 50 % c > r - f1 100 % c > r - f1 50 % c > r - f1 50 % c > y - 3 : yitalic > c / italic > c / italic > c / italic > c / italic > c
< extra_id_0 > r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level r - f1 c > paragraph level f1 c > paragraph level f1 c
< extra_id_0 > r > c > [ empty ] c > lstm - parser c > lstm - parser c > lstm - parser c > lstm - parser c > lstm - parser c > essay c > 64 . 741 . 97 c > paragraph c > 56 . 242 . 87 c > lstm - parser c
< extra_id_0 > c > [ bold ] train c > [ bold ] test c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c > [ bold ] train c >
cap > [ bold ] dataset c > [ bold ] part c > [ bold ] refs c > [ bold ] ser ( % ) r > c > [ 0 . 5pt / 2pt ] cleaned c > train c > 1 , 358 c > 4 , 693 c > ( 0 . 00 ) c > ( 0 . 00 ) c > [ 0 . 5pt / 2pt ] cleaned c > train c
< extra_id_0 > c > [ bold ] system c > [ bold ] miss c > [ bold ] miss c > [ bold ] miss c > [ bold ] miss c > [ bold ] miss c > [ bold ] miss c > [ bold ] miss c > [ bold ] miss c > [ bold ] miss c > [ bold ] miss c > [ bold ] miss c >
< extra_id_0 > table 4 : results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , wrong values , slight disfluencies ) .
< extra_id_0 > c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c >
< extra_id_0 > shows the model size in terms of parameters on amr17 . gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points . # p shows the model size in terms of parameters on amr17 . gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points . # p shows the model size in terms of parameters on amr17 . gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points .
< extra_id_0 > # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ b
< extra_id_0 > c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c >
< extra_id_0 > rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes + rc denotes
< extra_id_0 > c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c > [ bold ] model c >
< extra_id_0 > - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i -
< extra_id_0 > table 9 : ablation study for modules used in the graph encoder and the lstm decoder . c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty
< extra_id_0 > r > c > [ bold ] 35 . 1 c > 70 . 8 c > [ bold ] 82 . 8 c > [ bold ] 82 . 8 c > [ bold ] 82 . 8 c > [ bold ] 82 . 8 c > [ bold ] 82 . 8 c > [ bold ] 82 . 8 c > [ bold ] 82 . 8 c > [ bold ] 82 . 8 c > [ bold ] 82 . 8
< extra_id_0 > c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst
< extra_id_0 > c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc
< extra_id_0 > c > sts13 c > sts14 c > sts15 c > sts16 c > sts16 c > sts16 c > sts16 c > sts16 c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > table 8 : our paper c > [ bold ] 70 . 6 c > [ bold ] 70 . 6 c > [ bold ] 70 . 6 c > [ bold ] 70 . 6 c > [ bold ] 70 . 6 c > [ bold ] 70 . 6 c > [ bold ] 70 . 6 c > [ bold ] 70 . 6 c > [ bold ] 70 . 6 c > [ bold ] 70 . 6 c > [ bold
< extra_id_0 > c > sts13 c > sts14 c > sts15 c > sts16 r > c > cmow - c c > [ bold ] 43 . 5 c > [ bold ] 50 . 0 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c >
< extra_id_0 > c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst c > topconst
< extra_id_0 > c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc c > mrpc
< extra_id_0 > loc c > all org c > all misc c > all org c > all misc c > all loc c > all org c > all misc c > all org c > all org c > all per c > all misc c > all loc c > all org c > all misc c > all loc c > 89
< extra_id_0 > f1 r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r >
< extra_id_0 > bold > ent / bold > bold > neu / bold > bold > neu / bold > bold > neu / bold > bold > neu / bold > bold > neu / bold > bold > neu / bold > bold > neu / bold > bold > neu / bold > bold >
< extra_id_0 > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold > bleu / bold > bold >
< extra_id_0 > 3 : < extra_id_1 > c > bold > model / bold > c > song et al . ( 2018 ) c > 200k c > 28 . 20 r > c > bold > bleu / bold > c > song et al . ( 2018 ) c > 200k c > 31 . 60 r > c > song et al . ( 2019 ) c > 200k c
< extra_id_0 > c > bold > meteor / bold > c > bold > meteor / bold > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > / bold > 7 - 13
< extra_id_0 > ( added ) and the fraction of elements in the input graph that are missing in the generated sentence ( miss ) for the test set of ldc2017t10 . the token lemmas are used in the comparison . c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c >
< extra_id_0 > table 4 : sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer , trained with different target languages on a smaller parallel corpus ( 200k sentences ) .
< extra_id_0 > table 2 : pos and sem tagging accuracy with baselines and an upper bound . mft : most frequent tag ; unsupemb : classifier using unsupervised word embeddings .
< extra_id_0 > c > fr c > zh c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > fr c > en
< extra_id_0 > cap > table 5 : pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders , averaged over all non - english target languages .
< extra_id_0 > results are on a training set 10 % held - out . is the difference between the attacker ’ s performance and the corresponding adversary ’ s accuracy . is the difference between the attacker ’ s performance and the corresponding adversary ’ s accuracy . is the difference between the attacker ’ s performance and the corresponding adversary ’ s accuracy . is the difference between the attacker ’ s performance and the corresponding adversary ’ s accuracy . is the difference between the attacker ’ s performance and the adversary ’
< extra_id_0 > table 1 : accuracies when training directly towards a single task . table 1 : accuracies when training directly towards a single task .
< extra_id_0 > table 2 : protected attribute leakage : balanced & unbalanced leakage r > c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ]
< extra_id_0 > table 3 : performances on different datasets with an adversarial training . is the difference between the attacker score and the corresponding adversary ’ s accuracy . is the difference between the attacker score and the adversary ’ s accuracy .
< extra_id_0 > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty
< extra_id_0 > amic c > model c > # params c > model c > # params c > yang et al . ( 2018 ) c > yang et al . ( 2018 ) c > yang et al . ( 2018 ) c > yang et al . ( 2018 ) c > yang et al . ( 2018 ) c > lstm c > 22m c >
< extra_id_0 > c > model c > # params c > model c > # params c > base time c > + ln acc c > + bert acc c > + ln + bert time c > + ln + bert time c > + ln + bert time c > + ln + bert time c > + ln + bert time c > c >
< extra_id_0 > c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c > model c
< extra_id_0 > table 3 : bleu score on newstest2014 dataset . train : time in seconds per training batch measured from 0 . 2k training steps on tesla p100 . decode : time in milliseconds used to decode one sentence measured on newstest2014 dataset . train : time in seconds per training batch measured from 0 . 2k training steps on tesla p100 .
< extra_id_0 > “ # params ” : the parameter number of base . “ # params ” : the parameter number of elmo . “ # params ” : the parameter number of base . “ # params ” : the parameter number of base .
< extra_id_0 > “ # params ” : the parameter number in ner task . “ # params ” : the parameter number in ner task . “ # params ” : the parameter number in ner task .
< extra_id_0 > 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting . table 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting .
< extra_id_0 > retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] # word c > [ italic ] w / system retrieval [ bold ] # sent c > [ italic ] w / system retrieval [ bold ] r - 2 c > [ italic ] w / system retrieval [ bold ] # sent c > [ italic ] w /
< extra_id_0 > ( approximation randomization test , p0 . 0005 ) . the highest standard deviation among automatic systems is highlighted in bold , with statistical significance marked with ( approximation randomization test , p0 . 0005 ) . the highest standard deviation among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is highlighted in bold .
< extra_id_0 > c > dlqs c > docsub c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c >
< extra_id_0 > c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs
< extra_id_0 > c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs c > dlqs
< extra_id_0 > c > 1 c > 1 c > europarl c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c >
< extra_id_0 > c > 980 c > 902 c > 894 c > 849 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > 1 c > c >
< extra_id_0 > [ bold ] 73 . 63 cap > table 1 : performance ( ndcg % ) comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 . lf is the enhanced version as we mentioned . cap > table 1 : performance ( ndcg % ) comparison for the experiments of applying our principles on the validation set of visdial .
< extra_id_0 > performance ( ndcg % ) of ablative studies on different models on visdial v1 . 0 validation set . p2 indicates the most effective one ( i . e . , hidden dictionary learning ) .
< extra_id_0 > c > cs - en c > fi - en c > lv - en c > lv - en r > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > > zh - en c > bold > direct assessment / bold > ru - en c > bold > direct assessment / bold > zh - en c > bold > direct assessment / bold > ru - en c > bold > direct assessment / bold > zh - en c > bold > direct assessment / bold > zh - en
< extra_id_0 > > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual
< extra_id_0 > bold > 0 . 949 / bold > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r >
< extra_id_0 > c > 63 . 2 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold ] 12 . 8 c > [ bold
< extra_id_0 > tie sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim sim
acc c > % of machine and human judgments that match c > 0 . 79 c > 0 . 75 r > c > 0 . 67 c > spearman ’ s [ italic ] b / w negative pp and human ratings of fluency c > 0 . 81 c > 0 . 67 r > c > 0 . 67 c > 0 . 67 c > 0 . 67 c > 0 . 67 c > 0 . 67
< extra_id_0 > c > m5 : m0 [ italic ] + cyc + para + lang c > 0 . 818 c > 0 . 813 c > 0 . 813 c > 0 . 813 c > 0 . 813 c > 0 . 813 c > 0 . 813 c > 0 . 813 c > 0 . 813 c > 0 . 813 c > 0 . 813 c > 0 . 813 c > 0 . 813
< extra_id_0 > achieve higher bleu than prior work at similar levels of acc , but untransferred sentences achieve the highest bleu than prior work at similar levels of acc . our best models ( right table ) achieve higher bleu than prior work at similar levels of acc , but untransferred sentences achieve the highest bleu than previous work at similar levels of bleu . our best models ( right table ) achieve the highest bleu than previous work at similar levels of acc .
< extra_id_0 > table 2 : percent of reparandum tokens that were correctly predicted as disfluent . * statistics for repetition tokens exclude repetition tokens .
< extra_id_0 > [ bold ] reparandum length [ bold ] 3 - 5 r > c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] reparandum length [ bold ] 3 - 5 r > c > [ bold ] type c > [ bold ] type c > [ bold ] type c > [ bold ] type c
< extra_id_0 > c > [ bold ] test mean c > [ bold ] test best c > [ bold ] test mean c > [ bold ] test best c > [ bold ] test mean c > [ bold ] test best c > [ bold ] test mean c > [ bold ] test best c > [ bold ] test mean c > [ bold ] test mean c > [ bold ] test best
< extra_id_0 > ( % ) agree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) unrelated c > average of word2vec embedding c > 24 . 54 c > 05 . 06 c > 53 . 24 c > 79 . 53 c > 81 . 72 c > [ b
< extra_id_0 > table 2 : accuracy ( % ) of different methods on the apw and nyt datasets for the document dating problem ( higher is better ) . the unified model significantly outperforms all previous models .
< extra_id_0 > table 3 : accuracy ( % ) comparisons of component models with and without attention . this results show the effectiveness of both word attention and graph attention for this task . please see section 6 . 2 for details .
< extra_id_0 > c > [ bold ] 1 / 1 c > [ bold ] 1 / n c > [ bold ] 1 / n c > [ bold ] all c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty
< extra_id_0 > [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ]
< extra_id_0 > wer
< extra_id_0 > table 4 : results on the dev set and on the test set using discriminative training with only subsets of the code - switched data . table 4 : results on the dev set and on the test set using discriminative training with only subsets of the code - switched data .
cap > table 5 : accuracy on the dev set and on the test set according to the type of the gold sentence in the set : code - switched ( cs ) vs . monolingual ( mono ) .
< extra_id_0 > 7 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) . table 7 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features trained on all three eye - tracking datasets .
< extra_id_0 > 5 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant improvement ) . table 5 : precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features on the conll - 2003 dataset .
< extra_id_0 > 1 : results on belinkov2014exploring ’ s ppa test set . hpcd ( full ) is from the original paper , and it uses syntactic skipgram . glove - extended refers to the synset embeddings obtained by running autoextend rothe and schütze ( 2015 ) on glove 3 . 1 .
< extra_id_0 > 2 : results from rbg dependency parser with features coming from various pp attachment predictors and oracle attachment predictors .
< extra_id_0 > table 3 : effect of removing sense priors and context sensitivity ( attention ) from the model . table 3 : effect of removing sense priors and context sensitivity ( attention ) from the model . table 3 : effect of removing sense priors from the model .
< extra_id_0 > r > c > en - de c > flickr16 c > flickr17 c > mscoco17 r > c > c > + ensemble - of - 3 c > + ensemble - of - 3 c > + ensemble - of - 3 c > + ensemble - of - 3 c > + ensemble - of - 3 c > + ensemble - of - 3 c > + ensemble - of - 3 c > + ensemble
< extra_id_0 > c > en - fr c > flickr16 c > mscoco17 c > mscoco17 c > en - fr c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > mscoco17 c > msco
< extra_id_0 > table 4 : adding automatic image captioning . table 4 : adding automatic image captioning . table 4 : adding automatic image captioning . table 4 : adding automatic image captioning .
< extra_id_0 > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r >
< extra_id_0 > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr c > en - fr
< extra_id_0 > 8902 r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r
< extra_id_0 > table 1 : number of parallel sentences in the train , test and development splits for the language pairs we used . table 1 : number of parallel sentences in the train , test and development splits .
< extra_id_0 > 2 : training vocabularies for the english , french and spanish data used for our models . table 2 : training vocabularies for the english , french and spanish data used for our models .
< extra_id_0 > table 5 : automatic evaluation scores ( bleu and ter ) for the rev systems . c > en - fr - trans - rev c > 33 . 3 c > 50 . 2 c > en - fr - trans - rev c > 36 . 5 c > 47 . 1 c > en - fr - trans - rev c > [ bold ] 40 . 4 c > [ bold ] 42 . 7 c > en -
< extra_id_0 > 2 : results on flickr8k . the row labeled vgs is the visually supervised model from chrupala2017representations . the row labeled vgs is the visually supervised model from chrupala2017representations . the row labeled vgs is the visually supervised model from flickr8k .
< extra_id_0 > table 1 : results on synthetically spoken coco . the row labeled vgs is the visually supervised model from chrupala2017representations . the row labeled vgs is the visually supervised model from chrupala2017representations .
cap > table 1 : example sentences of the different classifiers compared to the original on sst - 2 . we report further examples in the appendix . table 1 : example sentences of the different classifiers compared to sst - 2 .
< extra_id_0 > c > bold > rnn / bold > c > 3 c > 4 c > 3 c > 4 c > 4 c > 4 c > 4 c > 4 c > 4 c > 4 c > 4 c > 4 c > 4 c > c
< extra_id_0 > the numbers indicate the changes in percentage points with respect to the original sentence . the last two rows correspond to the case where negative labels are flipped to positive and vice versa . and indicate that the score increases in positive and negative sentiment .
< extra_id_0 > bold > pubmed / bold > bold > sst - 2 / bold > bold > pubmed / bold > bold > sst - 2 / bold > bold > pubmed / bold > bold > sst - 2 / bold > bold > sst - 2 / bold > bold > sst - 2 / bold > bold >
