< extra_id_0 > table 2 : throughput for processing the treelstm model on our recursive framework , fold ’ s folding technique , and tensorflow ’ s iterative approach , with the large movie review dataset . the recursive approach performs the best on inference with efficient parallel execution of tree nodes , while fold ’ s folding technique shows better performance on training thanks to its gpu exploitation .
< extra_id_0 > table 1 : throughput for the treernn model implemented with recursive dataflow graphs , using datasets of varying tree balancedness . the balanced dataset exhibits highest throughput thanks to the high degree of parallelization , but at the same time does not improve as well as the linear dataset when the batch size increases from 1 to 25 .
< extra_id_0 > hyper parameters l2 reg . c > [ bold ] hyper parameters l2 reg . c > [ bold ] hyper parameters l2 reg . c > [ bold ] hyper parameters learning rate c > [ bold ] hyper parameter optimization results for each model with different representation . the max pooling strategy consistently performs better in all model variations . the max pooling strategy consistently performs better in all model variations .
< extra_id_0 > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) with sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) without sdp c > [ bold ] best f1 ( in 5 - fold ) with sdp c > [ bold diff . c > [ bold diff . c > [ bold diff . c > [ bold diff . c > [ bold diff . c > [ bold diff . c > [ bold diff . c > [ bold diff . c > [ bold c > [ bold diff . c > [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold [ bold ] [ bold ] [ bold [ bold ] [ bold [ bold ] [ bold ] [ bold [ bold ] [ bold ] [ bold ] [ bold ] [ bold [ bold ] [ bold [ bold ] [ bold [ bold ] [ bold [ bold ] [ bold [ bold ] [ bold ] [ bold [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold [ bold ] [ bold ] [ bold [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold ] [ bold [ bold ] [ bold ] [ bold [ bold ] [ bold [ bold ] [ bold ] [ bold [ bold ] [ bold ] [ bold
< extra_id_0 > r - f1 50 % compared to c - f1 100 % compared to r - f1 50 % compared to r - f1 50 % compared to y - 3 : y and y - 3 : y , respectively . y - 3 : y and y - 3 : y perform better than y - 3 : y and y - 3 : y , respectively . y - 3 : y performs better than y - 3 : y and y - 3 : y , respectively . y - 3 : y performs better than y - 3 : y , respectively .
< extra_id_0 > comparing paragraph level acc . and essay level acc . , we observe that the paragraph level acc . and essay level r - f1 differ significantly from the paragraph level acc . we observe that mst - parser performs better than mst - parser in terms of performance . we observe that mst - parser performs better than mst - parser in terms of performance . we observe that mst - parser performs better than mst - parser in terms of performance , we observe that mst - parser performs better than mst - parser performs better than mst - parser performs better than mst - parser performs better than mst - parser performs better than mst - parser in terms of performance .
< extra_id_0 > table 4 shows the c - f1 ( 100 % ) in % for the two indicated systems ; essay vs . paragraph level . note that the mean performances are lower than the majority performances over the runs given in table 2 .
< extra_id_0 > bleu nist meteor rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l rouge - l ser rouge - l ser rouge - l ser rouge - l ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser ser r r r r r r r r r r r r r r r r r r .
< extra_id_0 > table 1 : data statistics comparison for the original e2e data and our cleaned version ( number of distinct mrs , total number of textual references , ser as measured by our slot matching script , see section 3 ) .
< extra_id_0 > bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu ser bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu ser bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bleu bl
< extra_id_0 > table 4 summarizes the results of manual error analysis of tgen on a sample of 100 instances from the original test set : total absolute numbers of errors we found ( added , missed , slight disfluencies , slight disfluencies ) .
< extra_id_0 > seq2seqk ( konstas et al . , 2017 ) has a b c > of 22 . 0 c > whereas graphlstm ( damonte and cohen , 2019 ) has a b c > of 24 . 4 c > whereas snrg ( song et al . , 2017 ) has a b c > of 25 . 6 c > whereas tree2seqk ( song et al . , 2017 ) has a b c > 24 . 4 c > ( 24 . 4 c > 24 . 4 c > ( 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > 24 . 4 c > c > c > c > c > c > c > c > c > c > c > c > c > c > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r >
< extra_id_0 > gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points on amr17 . gcnseq ( damonte and cohen , 2019 ) achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . gcnseq achieves 24 . 5 bleu points on amr17 . ggnn2seq
< extra_id_0 > p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > [ bold ] english - czech # p c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r > r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r ) r )
< extra_id_0 > and 3 c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] n c > [ italic ] c >
< extra_id_0 > + rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denotes rc denoted in table 6 .
< extra_id_0 > compared to dcgcn ( 1 ) , dcgcn ( 2 ) and dcgcn ( 4 ) , respectively , dcgcn ( 3 ) and dcgcn ( 4 ) have significantly higher performance than dcgcn ( 4 ) and dcgcn ( 4 ) . however , dcgcn ( 4 ) and dcgcn ( 4 ) have significantly higher performance than dcgcn ( 4 ) and dcgcn ( 4 ) .
< extra_id_0 > table 8 : ablation study for density of connections on the dev set of amr15 . - i dense block denotes removing the dense connections in the i - th block . - i dense block denotes removing the dense connections in the i - th block .
< extra_id_0 > 9 : ablation study for modules used in the graph encoder and the lstm decoder ( table 9 : ablation study for modules used in the graph encoder and the lstm decoder ) ( table 9 : ablation study for modules used in the graph encoder and the lstm decoder ) ( table 9 : ablation study for modules used in the graph encoder and the lstm decoder ) ( table 9 : ablation study for modules used in both the graph encoder and the
< extra_id_0 > table 7 : scores for initialization strategies on probing tasks . glorot c > 35 . 1 c > 70 . 8 c > 79 . 7 c > [ bold ] 79 . 7 c > [ bold ] 79 . 7 c > [ bold ] 79 . 7 c > [ bold ] 79 . 7 c > [ bold ] 79 . 7 c > [ bold ] 79 . 7 c >
< extra_id_0 > cmow / 400 has a better performance than the h - cbow / 400 with a better performance than the h - cbow / 400 with a better performance than the h - cbow / 400 with a better performance than the h - cbow / 400 with a better performance than the h - cbow / 400 with a better performance than the h - cbow / 400 with a better performance than the h - cbow / 400 with a better performance than the h - cbow / 400 with a better performance than the h - cbow / 400 wc wc wc wc wc wc .
< extra_id_0 > cmow / 784 has a better performance than cmow / 784 and cmow / 784 , respectively . hybrid cmow / 784 has a better performance than hybrid cmow / 784 and cmow / 784 , respectively . hybrid cmow / 784 has a better performance than hybrid cmow / 784 and cmow / 784 , respectively . hybrid cmow / 784 has a better performance than hybrid cmow / 784 and cmow / 784 has a better performance , respectively .
< extra_id_0 > we present the scores on unsupervised downstream tasks attained by our models in table 3 . the hybrid model achieves a higher score than the hybrid model . the hybrid model achieves a higher score on unsupervised downstream tasks than the hybrid model ( table 3 ) .
< extra_id_0 > our paper has a score of 69 . 6 in table 8 . glorot has a score of 69 . 6 in table 8 . glorot has a score of 69 . 6 in table 8 . glorot has a score of 69 . 6 in table 8 . glorot has a score of 88 . 4 in table 8 . glorot has a score of 69 . 6 in table 8 . glorot has a score of 69 . 6 in table 8 . glorot has a score of 69 . 6 in table 8 .
< extra_id_0 > c > sts12 c > sts13 c > sts14 c > sts15 c > sts16 c > cmow - c c > [ bold ] 43 . 5 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c > [ bold ] 52 . 2 c > c > c > c > c > c > c > c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c >
< extra_id_0 > cmow - r has a better performance than bshift and topconst . cmow - r has a better performance than bshift and topconst . cmow - r has a better performance than bshift and topconst . cmow - r has a better performance than cmow - r in terms of depth and depth .
< extra_id_0 > cmow - r has a better performance than subj and mpqa . cmow - r has a better performance than sick - e and sst5 compared to cmow - r and cmow - r . cmow - r has a better performance than sick - e and sst5 compared to cmow - r and cmow - r , respectively . cmow - r has a better performance than cmow - r and cmow - r , respectively .
< extra_id_0 > however , misc has a better performance than mil - nd in all locs and misc in all orgs . mil - nd has a better performance than mil - nd in all locs and misc in all orgs . mil - nd has a better performance than mil - nd in all orgs . mil - nd has a better performance than mil - nd in all orgs . mil - nd has a better performance than mil - nd in all org scores are significantly worse than mil - nd in all org score .
< extra_id_0 > mil - nd ( model 1 ) has a higher f1 score than mil - nd ( model 2 ) with a higher f1 score than mil - nd ( model 2 ) with a higher f1 score than mil - nd ( model 2 ) with a higher f1 score than mil - nd ( model 2 ) with a higher f1 score than mil - nd ( model 2 ) with a higher f1 score than mil - nd ( model 2 ) with a higher f1 score than mil - nd ( model 2 ) with a higher f1 score of a higher f1 score than mil - nd ( model 2 ) .
< extra_id_0 > ref gen gen ent / bold > gen ent / bold > gen ref gen ent / bold > gen ref gen gen ent / bold > gen ref gen gen gen ent / bold > gen ref gen ent / bold >
< extra_id_0 > bleu and meteor have significantly better performance than s2s - gin and g2s - ggnn , respectively . g2s - ggnn and g2s - gin have significantly better performance than s2s - gin and g2s - gin , respectively .
< extra_id_0 > 3 : results on ldc2015e86 test set when models are trained with additional gigaword data . c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > g2
< extra_id_0 > 4 shows the results of the ablation study on the ldc2017t10 development set . bilstm has a better performance than bilstm on the ldc2017t10 development set . bilstm has a better performance than the bilstm model .
< extra_id_0 > the model has a 0 - 7 model and a graph diameter with a 7 - 13 model . the model has a 0 - 7 model and a graph diameter with a 7 - 13 model and a graph diameter with a 7 - 13 model . the model has a 0 - 7 model and a 0 - 7 model with a 7 - 13 model and a 7 - 13 model with a 7 - 13 model and a 7 - 13 model with a 7 - 13 model . the model has a 0 - 7 model has a 0 - 7 model with a 0 - 7 model with 0 - 7 model with 0 - 7 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with 0 - 1 model with
< extra_id_0 > table 8 shows the fraction of elements in the output that are not present in the input ( added ) and the fraction of elements in the input that are missing in the generated sentence ( miss ) , for the test set of ldc2017t10 . the token lemmas are used in the comparison .
< extra_id_0 > table 4 : sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer , trained with different target languages on a smaller parallel corpus ( 200k sentences ) . sem and pos tagging accuracy using features extracted from the 4th nmt encoding layer .
< extra_id_0 > table 2 shows the pos and sem tagging accuracy with baselines and an upper bound . the pos and sem tagging accuracy with baselines and an upper bound are shown in table 2 .
< extra_id_0 > fr c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > zh c > 87 . 9 c > 87 . 9 c >
< extra_id_0 > table 5 shows pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders , averaged over all non - english target languages . pos and sem tagging accuracy with features from different layers of 4 - layer uni / bidirectional / residual nmt encoders are shown in table 5 .
< extra_id_0 > is the difference between the attacker ’ s performance and the corresponding adversary ’ s accuracy . is the difference between the attacker ’ s score and the corresponding adversary ’ s accuracy . is the difference between the attacker ’ s performance on different datasets .
< extra_id_0 > table 1 summarizes the accuracies when training directly towards a single task . pan16 has the highest accuracies when training directly towards a single task . pan16 has the highest accuracies when training directly towards a single task .
< extra_id_0 > table 2 : protected attribute leakage : balanced & unbalanced data splits . pan16 shows a significant increase in the number of protected attribute leakage splits across all datasets .
< extra_id_0 > is the difference between the attacker score and the corresponding adversary ’ s accuracy . is the difference between the attacker score and the adversary ’ s accuracy . is the difference between the attacker score and the adversary ’ s accuracy .
< extra_id_0 > table 6 summarizes the accuracies of the protected attribute with different encoders . leaky achieves 64 . 5 % accuracies compared to guarded ( 59 . 3 % ) .
< extra_id_0 > we find that the ptb base and the wt2 base perform better than the ptb + finetune base and wt2 + dynamic base models . yang et al . ( 2018 ) found that the ptb + finetune base model performs better than the wt2 base model , whereas yang et al . ( 2018 ) found that the ptb base model performs better than the wt2 base model , whereas yang et al . ( 2018 ) showed that the ptb base model performs better than the wt2 base model performs better than the wt2 base model performs better than the yang et al . ( 2018 ) model performs better than the yang et al . ( 2018 ) model performs better than the yang et al . ( 2018 ) model performs better than the yang et al . ( 2018 et al . ( 2018 et al . ( 2018 et al . ( 2018 et al . ( 2018 et al . ( 2018 et al . ( 2018 et al . ( 2018 et al . ( 2018 ) et al . ( 2018 ) et al . ( 2018 ) et al . ( 2018 ) et al . ( 2018 ) et al . ( 2018 ) et al . ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 )
< extra_id_0 > + bert acc c > base time c > base time c > base time c > base time c > base time c > base time c > + bert acc c > + ln + bert time c > + ln + bert time c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > yelppolar err and yelppolar time , respectively . zhang et al . ( 2015 ) compared the results of zhang et al . ( 2015 ) and zhang et al . ( 2015 ) compared the results of zhang et al . ( 2015 ) and zhang et al . ( 2015 ) compared the results of zhang et al . ( 2015 ) and zhang et al . ( 2015 ) compared the results of zhang et al . ( 2015 et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) and zhang et al . ( 2015 et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) et al . ( 2015 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) ( 2017 ) .
< extra_id_0 > table 3 shows the tokenized bleu score on wmt14 english - german translation task . bleu scores on newstest2014 dataset are significantly higher than those on gnmt and olrn .
< extra_id_0 > “ # params ” : the parameter number of base . rnet * : the results published by wang et al . ( 2017 ) . rnet * : the results published by wang et al . ( 2018 ) .
< extra_id_0 > “ # params ” : the parameter number in conll - 2003 english ner task . “ # params ” : the parameter number in ner task . “ # params ” : the parameter number in ner task .
< extra_id_0 > table 7 : test accuracy on snli task with base + ln setting and test perplexity on ptb task with base + ln setting and test perplexity on snli task with base + ln setting and test perplexity on snli task with base + ln setting . elrn and glrn perform better on snli task with base + ln setting .
< extra_id_0 > r - 2 and b - 4 are the best performing mtr compared to the best performing r - 2 and b - 4 mtr compared to the best performing r - 2 mtr compared to the best performing r - 2 mtr compared to the best performing r - 2 mtr compared to the best performing r - 2 mtr compared to the best performing r - 2 mtr compared to the best performing r - 2 mtr compared to the best performing r - 2 mtr compared to the best performing r - 2 mtr compared to the best performing r - 2 mtr compared to the best performing r - 2 mtr compared to the best performing r - 2 mtr compared to the best performing r - 2 mtr compared to the best performing r - 2 mtr compared to the best performing r - 2 mtr compared to the best performing r - 2 mtr compared to the best performing r - 2 mtr compared to the best performing r - 2 mtr compared to the best performing r - 2 mtr compared to the best performing r - 2 mtr .
< extra_id_0 > the highest standard deviation among automatic systems is highlighted in bold , with statistical significance marked with ( approximation randomization test , p0 . 0005 ) . the highest standard deviation among automatic systems is 1 . 0 , with statistical significance marked with ( approximation randomization test , p0 . 0005 ) . the highest standard deviation among automatic systems is highlighted in bold . the highest standard deviation among automatic systems is highlighted in bold .
< extra_id_0 > we see that < extra_id_1 > , < extra_id_2 > , < extra_id_3 > , df , docsub , and hclust have significantly higher p compared to lang c > dsim and patt c > dsim c > docsub c > docsub c > docsub c > docsub c > docsub c > docsub cluster cluster cluster cluster cluster cluster cluster cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p cluster p
< extra_id_0 > tlqs and docsub perform better than tlqs and dlqs , respectively . tlqs and docsub perform better than tlqs and dlqs , respectively . tlqs performs better than tlqs and docsub , respectively . tlqs performs better than tlqs and docsub , respectively .
< extra_id_0 > 0661 compared to df and docsub , respectively . in terms of p p p
< extra_id_0 > tlqs and docsub are similar in terms of maxdepth and avgdepth , respectively . tlqs and docsub are similar in terms of avgdepth and avgdepth , respectively . tlqs and docsub are similar in terms of avgdepth and avgdepth , respectively . tlqs and docsub are similar in terms of avgdepth , respectively .
< extra_id_0 > avgdepth is 9 . 9 and avgdepth is 9 . 8 . europarl has avgdepth of 980 and avgdepth of 984 . europarl has avgdepth of 980 and avgdepth of 984 . europarl has avgdepth of 980 and avgdepth of 984 . europarl has avgdepth of 984 and 996 .
< extra_id_0 > qt , s and d denote question type , answer score sampling , and hidden dictionary learning , respectively . lf is the enhanced version as we mentioned in table 1 . ndcg % comparison for the experiments of applying our principles on the validation set of visdial v1 . 0 . ndcg % comparison for the experiments of applying our principles in table 1 .
< extra_id_0 > table 2 : performance ( ndcg % ) of ablative studies on different models on visdial v1 . 0 validation set . p2 indicates the most effective one ( i . e . , hidden dictionary learning ) shown in table 1 .
< extra_id_0 > table 5 : comparison on hard and soft alignments . wmd - recall + bert achieves a comparable performance on hard and soft alignments .
< extra_id_0 > de - en c > zh - en c > zh - en c > zh - en c > zh - en c > zh - en c > zh - en c > zh - en c > zh - en c > zh - en c > zh - en c > zh - en c > zh - en c >
< extra_id_0 > : inf / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > bold > qual / bold > r > r > r > r > r > r >
< extra_id_0 > m1 compared to m2 compared to spice ( * ) and spice ( * ) compared to spice ( * ) and bertscore - recall ( * ) compared to spice ( * ) and bertscore - recall ( * ) compared to spice ( * ) and bertscore - recall ( * ) compared to spice ( * ) and bertscore - recall ( * ) compared to spice ( * ) and bertscore - recall ( * ) compared to leic ( * ) compared to spice ( * ) compared to leic ( * ) compared to spice ( * ) .
< extra_id_0 > m1 : m0 has a better performance than m1 : shen - 1 with a better performance than m5 : m0 with a better performance than m5 : m0 with a better performance than m5 : m0 with a better performance than m5 : m0 with a better performance than m5 : m0 with a better performance than m5 : m0 with a better performance than m5 : m0 with a better performance than m5 : m0 with a better performance than m5 : m0 with a better performance score than m5 : m0 with a better performance score of a comparable performance score of a comparable performance score of a comparable performance score of a comparable performance score of a comparable performance score of a comparable performance score of a comparable performance score of a comparable performance score of a comparable performance score of a comparable performance score of a comparable performance score of a comparable performance score of a comparable performance score of a comparable performance score of a comparable performance score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of a comparable score of
< extra_id_0 > transfer quality a > b c > models b c > models a c > models b c > models b c > models a c > models b c > models b c > models a c > models b c > models b c > models b c > models a c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > models b c > semantic preservation tie p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p
< extra_id_0 > see text for validation of gm ; see text for validation of acc ; see text for validation of pp ; see text for validation of acc ; see text for validation of pp ; see text for validation of acc ; see text for validation of gm ; see text for validation of acc ; see text for validation of acc ; see text for validation of pp ; see text for validation of acc ; see text for validation of pp ; see text for validation of acc ; see text for validation of acc .
< extra_id_0 > m0 has a better performance than m0 and m5 has a better performance . m0 has a better performance than m0 and m5 has a better performance than m0 and m5 has a better performance . m5 has a better performance than m0 and m5 has a better performance . m5 has a better performance than m0 and m5 has a better performance . m5 has a better performance than m0 and m5 has a better performance .
< extra_id_0 > bleu is between 1000 transferred sentences and human references , and acc is restricted to the same 1000 sentences . our best models achieve higher bleu than previous work at similar levels of acc , but untransferred sentences achieve the highest bleu than prior work at similar levels of bleu . bleu is between 1000 transferred sentences and human references , and bleu is between 1000 transferred sentences and human references . our best models achieve higher bleu than previous work , but untransferred sentences achieve the highest bleu .
< extra_id_0 > table 2 shows the percentage of reparandum tokens that were correctly predicted as disfluent . rephrased tokens have a higher rate of disfluency than rephrased tokens . rephrased tokens have a higher rate of disfluency than rephrased tokens . rephrased tokens have a higher rate of disfluency than rephrased tokens . rephrased tokens have a higher rate of disfluency than rephrased tokens .
< extra_id_0 > table 3 shows the relative frequency of rephrases correctly predicted as disfluent for disfluencies that contain a content word in both reparandum and repair ( content - content ) , either the reparandum or repair ( content - function ) or in neither .
< extra_id_0 > c > [ bold ] dev mean c > [ bold ] dev best c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > [ italic ] c > c > c > c > c > c > c > c > early c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c
< extra_id_0 > accuracy ( % ) agree c > accuracy ( % ) disagree c > accuracy ( % ) disagree c > accuracy ( % ) unrelated c > average of word2vec embedding compared with the state - of - art algorithms on the fnc - 1 test dataset . our model performs better than the state - of - art algorithms on the micro - fnc - 1 test dataset .
< extra_id_0 > table 2 shows the accuracy ( % ) of different methods on the apw and nyt datasets for the document dating problem ( higher is better ) . the unified model significantly outperforms all previous models .
< extra_id_0 > table 3 shows the effectiveness of both word attention and graph attention for this task . this results show the effectiveness of both word attention and graph attention for this task .
< extra_id_0 > [ bold ] 1 / n c > [ bold ] 1 / n c > [ bold ] 1 / n c > [ bold ] all r > c > [ empty ] c > [ empty ] c > [ bold ] c > [ empty ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ empty ] c > [ empty ] c > c > [ bold ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > [ empty ] c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c > c >
< extra_id_0 > trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] trigger [ bold ] classification ( % ) c > [ bold ] trigger [ bold ] identification ( % ) c > [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] classification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold ] identification ( % ) c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold ] c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold c > [ bold ] c > [ bold c > [ bold c > [ bold ] c > [ bold c > [ bold c > [ bold ] c > [ bold ] c > [ bold ] c >
< extra_id_0 > acc test perp test wer test perp test perp test wer test wer test perp test perp test wer test wer test wer test perp test wer test wer test wer test wer test wer test wer test wer test wer test wer test wer test wer test wer test wer test wer tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester tester
< extra_id_0 > table 4 summarizes the results on the dev set and on the test set using discriminative training with only subsets of the code - switched data . cs - only achieves a better performance than cs - only , with a better performance than cs - only .
< extra_id_0 > table 5 : accuracy on the dev set and on the test set , according to the type of the gold sentence in the set : code - switched ( cs ) vs . monolingual ( mono ) .
< extra_id_0 > table 7 shows precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features trained on all three eye - tracking datasets and tested on the conll - 2003 dataset ( * marks statistically significant improvement ) . type - aggregated gaze features trained on all three eye - tracking datasets are shown in table 7 .
< extra_id_0 > table 5 shows the precision ( p ) , recall ( r ) and f1 - score ( f ) for using type - aggregated gaze features on the conll - 2003 dataset ( * marks statistically significant improvement ) for using type - aggregated gaze features on conll - 2003 .
< extra_id_0 > the hpcd ( full ) is from the original paper , and it uses syntactic skipgram . the results on belinkov2014exploring ’ s ppa test set are summarized in table 1 .
< extra_id_0 > table 2 summarizes results from rbg dependency parser with features coming from various pp attachment predictors and oracle attachments . rbg + hpcd ( full ) achieves 94 . 17 and 88 . 51 respectively .
< extra_id_0 > table 3 shows the effect of removing sense priors and context sensitivity ( attention ) from the model . the effect of removing sense priors and context sensitivity ( attention ) from the model is shown in table 3 .
< extra_id_0 > adding subtitle data and domain tuning for image caption translation ( bleu % scores ) . all results with marian amun are shown in table 2 .
< extra_id_0 > and mscoco17 , respectively . subs1m [ italic ] [ italic ] lm + ms - coco outperforms domain - tuned and lm + ms - coco , respectively . lm + ms - coco outperforms domain - tuned and lm + ms - coco , respectively . lm + ms - coco outperforms domain - tuned and lm + ms - coco , respectively . lm + ms - coco outperforms t
< extra_id_0 > autocap 1 - 5 ( concat ) and autocap 1 - 5 ( concat ) perform better than autocap ( dual attn . ) and autocap ( dual attn . ) compared to multi30k and flickr16 , mscoco17 , mscoco17 , mscoco17 , mscoco17 , mscoco17 , mscoco17 , mscoco17 , mscoco17 , mscoco17 , mscoco17 , mscoco17 performs better than autocap 1 - 5 ( concat ) performs better than autocap ( dual attn . ) compared to autocap ( dual attn . ) .
< extra_id_0 > mscoco17 and en - de c > flickr16 c > flickr17 c > mscoco17 r > c > enc - gate c > 68 . 30 c > enc - gate c > 67 . 99 c > dec - gate c > 36 . 47 c > enc - gate c > 67 . 99 c > dec - gate c > dec - gate
< extra_id_0 > mscoco17 and en - fr perform better than en - fr and mscoco17 , respectively . compared to en - fr and mscoco17 , mscoco17 performs better than en - fr and mscoco17 , respectively . compared to en - fr and mscoco17 , mscoco17 performs better than en - fr and mscoco17 , respectively .
< extra_id_0 > the en - fr - trans - ff scores better than the en - fr - trans - ff scores . the en - fr - trans - ff scores better than the en - fr - trans - ff scores . the en - fr - trans - ff scores better than the en - fr - trans - ff scores .
< extra_id_0 > table 1 shows the number of parallel sentences in the train , test and development splits for the language pairs we used . the number of parallel sentences in the train , test and development splits is shown in table 1 .
< extra_id_0 > table 2 : training vocabularies for the english , french and spanish data used for our models . the training vocabularies for the english , french and spanish data used for our models are shown in table 2 .
< extra_id_0 > table 5 shows the automatic evaluation scores ( bleu and ter ) for the rev systems . the bleu and ter scores for the rev systems are shown in table 5 .
< extra_id_0 > results on flickr8k . the row labeled vgs is the visually supervised model from chrupala2017representations . the row labeled vgs is the visually supervised model from chrupala2017representations .
< extra_id_0 > table 1 : results on synthetically spoken coco . the row labeled vgs is the visually supervised model from chrupala2017representations . the row labeled chance is the visually supervised model from chrupala2017representations .
< extra_id_0 > turns in a u > screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay screenplay that ’ s so clever you want hate hate hate hate hate hate hate hate hate hate . we report further examples in the appendix . we report further examples in table 1 .
< extra_id_0 > rnp has a 69 . 0 % rnp and 81 . 5 % dan , respectively . nouns have a 69 . 0 % rnp , compared to a 69 . 0 % rnp and 81 . 5 % dan , respectively . nouns have a 69 . 0 % rnp and 81 . 5 % dan score .
< extra_id_0 > the numbers indicate the changes in percentage points with respect to the original sentence . the last two rows correspond to the case where negative labels are flipped to positive and vice versa . and indicate that the score increases in positive and negative sentiment .
< extra_id_0 > it n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t n ’ t
