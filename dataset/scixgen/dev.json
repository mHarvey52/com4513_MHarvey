[{"tabular": ["  Models  &  PSNR  &  Params  &  Pruned (%)  &  FLOPs  &  Pruned (%) ", " Base-line  &  30.13  &  75888  &  -  &  46M  &  - ", " Ours  &  29.12 (-3%)  &  43023  &  43%  &  23M  &  50% ", " Ours  &  28.89 (-4%)  &  31663  &  58%  &  17M  &  63%  "], "ref_sec": [["<section> <title> 1 INTRODUCTION </title>  Large and deep neural networks, despite of their great successes in a wide variety of applications, call for compact and efficient model representations to reduce the vast amount of network parameters and computational operations, that are resource-hungry in terms of memory, energy and communication bandwidth consumption.", "This need is imperative especially for resource constrained devices such as mobile phones, wearable and Internet of Things (IoT) devices.", "Neural network compression is a set of techniques that address these challenges raised in real life industrial applications.", "\\newline Minimizing network sizes without compromising original network performances has been pursued by a wealth of methods, which often adopt a three-phase learning process, i.e. training-pruning-tuning.", "In essence, network features are first learned, followed by the pruning stage to reduce network sizes.", "The subsequent fine-tuning phase aims to restore deteriorated performances incurred by undue pruning.", "This ad hoc three phase approach, although empirically justified e.g. in [@bib:NetSlim_Liu2017d,IntreprePrune_Qin2018,Lib,Wen2016,Zhou2016a] , was recently questioned with regards to its efficiency and effectiveness.", "Specifically [@bib:RethinkPrune_2018arXiv,PruningNip_2018arXiv] argued that the network architecture should be optimized first, and then features should be learned from scratch in subsequent steps.", "\\newline In contrast to the two aforementioned opposing approaches, the present paper illustrates a novel method which simultaneously learns both the number of filters and network features over multiple optimization epochs.", "This integrated optimization process brings about immediate benefits and challenges \u2014 on the one hand, separated processing steps such as training, pruning, fine-tuning etc, are no longer needed and the integrated optimization step guarantees consistent performances for the given neural network compression scenarios.", "On the other hand, the dynamic change of network architectures has significant influences on the optimization of features, which in turn might affect the optimal network architectures.", "It turns out the interplay between architecture and feature optimizations plays a crucial role in improving the final compressed models.", "\\newline  </section>"], ["<section> <title> 2 RELATED WORK </title>  Network pruning was pioneered [@bib:lecun1990optimal,hassibi1993second,han2015learning] in the early development of neural network, since when a broad range of methods have been developed.", "We focus on neural network compression methods that prune filters or channels.", "For thorough review of other approaches we refer to a recent survey paper [@bib:Cheng2017] .", "\\newline Li {et al} .", "[@bib:Lib] proposed to prune filters with small effects on the output accuracy and managed to reduce about one third of inference cost without compromising original accuracy on CIFAR-10 dataset.", "Wen {et al} .", "[@bib:Wen2016] proposed a structured sparsity regularization framework, in which the group lasso constrain term was incorporated to penalize and remove unimportant filters and channels.", "Zhou {et al} .", "[@bib:Zhou2016a] also adopted a similar regularization framework, with tensor trace norm and group sparsity incorporated to penalize the number of neurons.", "Up to 70% of model parameters were reduced without scarifying classification accuracies on CIFAR-10 datasets.", "Recently Liu {et al} .", "[@bib:NetSlim_Liu2017d] proposed an interesting network slimming method, which imposes L1 regularization on channel-wise scaling factors in batch-normalization layers and demonstrated remarkable compression ratio and speedup using a surprisingly simple implementation.", "Nevertheless, network slimming based on scaling factors is not guaranteed to achieve desired accuracies and separate fine-tunings are needed to restore reduced accuracies.", "Qin {et al} . [@bib:IntreprePrune_Qin2018] proposed a functionality-oriented filter pruning method to remove less important filters, in terms of their contributions to classification accuracies.", "It was shown that the efforts for model retraining is moderate but still necessary, as in the most of state-of-the-art compression methods.", "\\newline DIVNET adopted Determinantal Point Process (DPP) to enforce diversities between individual neural activations [@bib:DivNet_2015arXiv] .", "Diversity of filter weights defined in ( [@ref:LABEL:eq:diversity_ncc] ) is related to orthogonality of weight matrix, which has been extensively studied.", "An example being [@bib:Harandi2016] , proposed to learn Stiefel layers, which have orthogonal weights, and demonstrated its applicability in compressing network parameters.", "Interestingly, the notion of diversity regularized machine (DRM) has been proposed to generate an ensemble of SVMs in the PAC learning framework [@bib:Yu2011] , yet its definition of diversity is critically different from our definition in ( [@ref:LABEL:eq:diversity_ncc] ), and its applicability to deep neural networks is unclear.", "\\newline  </section>"], ["<section> <title> 3 SIMULTANEOUS LEARNING OF ARCHITECTURE AND FEATURE </title>  The proposed compression method belongs to the general category of filter-pruning approaches.", "In contrast to existing methods [@bib:NetSlim_Liu2017d,IntreprePrune_Qin2018,Lib,Wen2016,Zhou2016a,RethinkPrune_2018arXiv,PruningNip_2018arXiv] , we adopt following techniques to ensure that simultaneous optimization of network architectures and features is a technically sound approach.", "First, we introduce an explicit pruning loss estimation as an additional regularization term in the optimization objective function.", "As demonstrated by experiment results in Section [@ref:LABEL:sect:exper] , the introduced pruning loss enforces the optimizer to focus on promising candidate filters while suppressing contributions of less relevant ones.", "Second, based on the importance of filters, we explicitly turn-off unimportant filters below given percentile threshold.", "We found the explicit shutting down of less relevant filters is indispensable to prevent biased estimation of pruning loss.", "Third, we also propose to enforce the diversities between filters and this diversity-based regularization term improves the trade-off between model sizes and accuracies, as demonstrated in various applications.", "\\newline Our proposed method is inspired by network slimming [@bib:NetSlim_Liu2017d] and main differences from this prior art are two-folds: a) we introduce the pruning loss and incorporate explicit pruning into the learning process, without resorting to the multi-pass pruning-retraining cycles; b) we also introduce filter-diversity based regularization term which improves the trade-off between model sizes and accuracies.", "\\newline <subsection> <title> 3.1 Loss Function </title> Liu {et al} .", "[@bib:NetSlim_Liu2017d] proposed to push towards zero the scaling factor in batch normalization (BN) step during learning, and subsequently, the insignificant channels with small scaling factors are pruned.", "This sparsity-induced penalty is introduced by regularizing L1-norm of the learnable parameter $ \\gamma $ in the BN step {i.e.,} \\newline <equation> $ g(\\gamma)=\\left|\\gamma\\right|;\\textnormal{where }\\hat{z}=\\frac{z_{in}-\\mu_{B}% }{\\sqrt{\\sigma^{2}+\\epsilon}};z_{out}=\\gamma\\hat{z}+\\beta, $ </equation> in which $ z_{in} $ denote filter inputs, $ \\mu_{B},\\sigma $ the filter-wise mean and variance of inputs, $ \\gamma,\\beta $ the scaling and offset parameters of batch normalization (BN) and $ \\epsilon $ a small constant to prevent numerical un-stability for small variance.", "It is assumed that there is always a BN filter appended after each convolution and fully connected filter, so that the scaling factor $ \\gamma $ is directly leveraged to prune unimportant filters with small $ \\gamma $ values.", "Alternatively, we propose to directly introduce scaling factor to each filter since it is more universal than reusing BN parameters, especially considering the networks which have no BN layers.", "\\newline By incorporating a filter-wise sparsity term, the object function to be minimized is given by: \\newline <equation> $ L=\\sum_{(\\textbf{x},y)}loss(f(\\textbf{x},\\textbf{W}),y)+\\lambda\\sum_{\\gamma\\in% \\Gamma}g(\\gamma), $ </equation> where the first term is the task-based loss, $ g(\\gamma)=||\\gamma||_{1} $ and $ \\Gamma $ denotes the set of scaling factors for all filters.", "This pruning scheme, however, suffers from two main drawbacks: 1) since scaling factors are equally minimized for all filterers, it is likely that the pruned filters have unignorable contributions that should not be unduly removed.", "2) the pruning process, {i.e., } architecture selection, is performed independantly w.r.t.", "the feature learning; the performance of pruned network is inevitably compromised and has to be recovered by single-pass or multi-pass fine-tuning, which impose additional computational burdens.", "\\newline <subsubsection> <title> 3.1.1 An integrated optimization </title> Let $ \\textbf{W},\\check{\\textbf{W}},\\hat{\\textbf{W}} $ denote the sets of neural network weights for, respectively, all filters, those pruned and remained ones i.e. $ \\textbf{W}=\\{\\check{\\textbf{W}}\\bigcup\\hat{\\textbf{W}}\\} $ .", "In the same vein, $ \\Gamma=\\{P(\\Gamma)\\bigcup R(\\Gamma)\\} $ denote the sets of scaling factors for all filters, those removed and remained ones respectively.", "\\newline To mitigate the aforementioned drawbacks, we propose to introduce two additional regularization terms to Eq. [@ref:LABEL:eq:regularized_sparisty_func] , \\newline <equationgroup> <equation> $  L(\\hat{\\textbf{W}},R(\\Gamma))=\\sum_{(\\textbf{x},y)}loss(f(% \\textbf{x},\\hat{\\textbf{W}}),y)+\\lambda_{1}\\sum_{\\gamma\\in R(\\Gamma)}g(\\gamma) $ $  L(\\hat{\\textbf{W}},R(\\Gamma))= $ $ \\sum_{(\\textbf{x},y)}loss(f(\\textbf{x},\\hat{\\textbf{W}}),y)+% \\lambda_{1}\\sum_{\\gamma\\in R(\\Gamma)}g(\\gamma) $ </equation> <equation> $ -\\lambda_{2}\\frac{\\sum_{\\gamma\\in R({\\Gamma})}\\gamma}{\\sum_{% \\gamma\\in\\Gamma}\\gamma}-\\lambda_{3}\\sum_{l\\in L}Div(\\hat{\\textbf{W}}^{l}), $ $ -\\lambda_{2}\\frac{\\sum_{\\gamma\\in R({\\Gamma})}\\gamma}{\\sum_{% \\gamma\\in\\Gamma}\\gamma}-\\lambda_{3}\\sum_{l\\in L}Div(\\hat{\\textbf{W}}^{l}), $ </equation> </equationgroup> where $ loss(\\cdot,\\cdot) $ and $ \\sum_{\\gamma\\in R(\\Gamma)}g(\\gamma) $ are defined as in Eq. [@ref:LABEL:eq:regularized_sparisty_func] , the third term is the pruning loss and the forth is the diversity loss which are elaborated below.", "$ \\lambda_{1},\\lambda_{2},\\lambda_{3} $ are weights of corresponding regularization terms.", "\\newline </subsubsection> <subsubsection> <title> 3.1.2 Estimation of pruning loss </title> The second regularization term in ( [@ref:LABEL:eq:regularized_all] ) i.e. $ \\gamma^{R}:=\\frac{\\sum_{\\gamma\\in R({\\Gamma})}\\gamma}{\\sum_{\\gamma\\in\\Gamma}\\gamma} $ (and its compliment $ \\gamma^{P}:=\\frac{\\sum_{\\gamma\\in P({\\Gamma})}\\gamma}{\\sum_{\\gamma\\in\\Gamma}% \\gamma}=1-\\gamma^{R} $ ) is closely related to performance deterioration incurred by undue pruning .", "The scaling factors of pruned filters $ P(\\Gamma) $ , as in [@bib:NetSlim_Liu2017d] , are determined by first ranking all $ \\gamma $ and taking those below the given percentile threshold.", "Incorporating this pruning loss enforces the optimizer to increase scaling factors of promising filters while suppressing contributions of less relevant ones.", "\\newline The rationale of this pruning strategy can also be empirically justified in Figure [@ref:LABEL:fig:nsf_compare] , in which scaling factors of three different methods are illustrated.", "When the proposed regularization terms are added, clearly, we observed a tendency for scaling factors being dominated by few number of filters \u2014 when 70% of filters are pruned from a VGG network trained with CIFAR-10 dataset, the estimated pruning loss $ \\frac{\\sum_{\\gamma\\in P({\\Gamma})}\\gamma}{\\sum_{\\gamma\\in\\Gamma}\\gamma} $ equals 0.2994, 0.0288, $ 1.3628\\text{\\times}{10}^{-6} $ , respectively, for three compared methods.", "Corresponding accuracy deterioration are 60.76% and 0% for network-slimming [@bib:NetSlim_Liu2017d] and the proposed methods.", "Therefore, retraining of pruned network is no longer needed for the proposed method, while [@bib:NetSlim_Liu2017d] has to retain the original accuracy through single-pass or multi-pass of pruning-retraining cycles.", "\\newline </subsubsection> <subsubsection> <title> 3.1.3 Turning off candidate filters </title> It must be noted that the original loss $ \\sum_{(\\textbf{x},y)}loss(f(\\textbf{x},{\\textbf{W}}),y) $ is independent of the pruning operation.", "If we adopt this loss in ( [@ref:LABEL:eq:regularized_all] ), the estimated pruning loss might be seriously biased because of undue assignments of $ \\gamma $ not being penalized.", "It seems likely some candidate filters are assigned with rather small scaling factors, nevertheless, they still retain decisive contributions to the final classifications.", "Pruning these filters blindly leads to serious performance deterioration, according to the empirical study, where we observe over 50 $ \\% $ accuracy loss at high pruning ratio.", "\\newline In order to prevent such biased pruning loss estimation, we therefore explicitly shutdown the outputs of selected filters by setting corresponding scaling factors to absolute zero.", "The adopted loss function becomes $ \\sum_{(\\textbf{x},y)}loss(f(\\textbf{x},\\hat{\\textbf{W}}),y) $ .", "This way, the undue loss due to the biased estimation is reflected in $ loss(f(\\textbf{x},\\hat{\\textbf{W}}),y) $ , which is minimized during the learning process.", "We found the turning-off of candidate filters is indispensable.", "\\newline <float> Proposed algorithm \\ procedure Online Pruning \\ \\ $ \\textit{Training data}\\leftarrow\\{x_{i},y_{i}\\}_{i=1}^{N} $ \\ \\ $ \\textit{Target pruning ratio}\\mathbf{Pr}_{N}\\leftarrow\\mathbf{p}\\% $ \\ \\ $ \\textit{Initial network weights}W\\leftarrow\\textit{method by \\@@cite[cite]{% [\\@@bibref{he2015delving}]}} $ \\ \\ $ \\Gamma\\leftarrow\\{0.5\\} $ \\ \\ $ \\hat{W}\\leftarrow W $ \\ \\ $ P(\\Gamma)\\leftarrow\\emptyset $ \\ \\ $ R(\\Gamma)\\leftarrow\\Gamma $ \\ \\ for each epoch $ n\\in $ {$ 1,\\dots,N $ } do \\ \\ $ \\textit{Current pruning ratio}\\mathbf{Pr}_{n}\\in[0,\\mathbf{Pr}_{N}] $ \\ \\ $ \\textit{Sort}\\Gamma $ \\ \\ $ P(\\Gamma)\\leftarrow\\textit{prune filters w.r.t. }\\mathbf{Pr}_{n} $ \\ \\ $ R(\\Gamma)\\leftarrow\\Gamma\\setminus\\textit{P}(\\Gamma) $ \\ \\ $ \\textit{Compute}L(\\hat{\\textbf{W}},R(\\Gamma))\\textit{in Eq.}(\\ref{eq:% regularized_sparisty_func}) $ \\ \\ $ \\hat{\\textbf{W}}\\leftarrow\\textit{SGD} $ \\ \\ $ \\check{\\textbf{W}}\\leftarrow\\hat{\\textbf{W}}\\setminus\\check{\\textbf{W}} $ \\ </float> \\newline </subsubsection> <subsubsection> <title> 3.1.4 Online pruning </title> We take a global threshold for pruning which is determined by percentile among all channel scaling factors.", "The pruning process is performed over the whole training process, {i.e., } simultaneous pruning and learning.", "To this end, we compute a linearly increasing pruning ratio from the first epoch (e.g., 0%) to the last epoch (e.g., 100%) where the ultimate pruning target ratio is applied.", "Such an approach endows neurons with sufficient evolutions driven by diversity term and pruning loss, to avoid mis-pruning neurons prematurely which produces crucial features.", "Consequently our architecture learning is seamlessly integrated with feature learning.", "After each pruning operation, a narrower and more compact network is obtained and its corresponding weights are copied from the previous network.", "\\newline </subsubsection> <subsubsection> <title> 3.1.5 Filter-wise diversity </title> The third regularization term in ( [@ref:LABEL:eq:regularized_all] ) encourages high diversities between filter weights as shown below.", "Empirically, we found that this term improves the trade-off between model sizes and accuracies (see experiment results in Section [@ref:LABEL:sect:exper] ).", "\\newline We treat each filter weight, at layer $ l $ , as a weight (feature) vector $ \\textbf{W}^{l}_{i} $ of length $ w\\times h\\times c $ , where $ w,h $ are filter width and height, $ c $ the number of channels in the filter.", "The diversity between two weight vectors of the same length is based on the normalized cross-correlation of two vectors: \\newline <equationgroup> <equation> $  div(\\textbf{W}_{i},\\textbf{W}_{j}):=1-|\\langle\\mathbf{\\bar{W}}_{% i},\\mathbf{\\bar{W}}_{j}\\rangle|, $ $  div(\\textbf{W}_{i},\\textbf{W}_{j}):=1-|\\langle\\mathbf{\\bar{W}}_{% i},\\mathbf{\\bar{W}}_{j}\\rangle|, $ </equation> </equationgroup> in which $ \\mathbf{\\bar{W}}=\\frac{\\mathbf{{W}}}{|\\mathbf{{W}}|} $ are normalized weight vectors, and $ \\langle\\cdot,\\cdot\\rangle $ is the dot product of two vectors.", "Clearly, the diversity is bounded $ 0\\leq div(\\textbf{W}_{i},\\textbf{W}_{j})\\leq 1 $ , with value close 0 indicating low diversity between highly correlated vectors and values near 1 meaning high diversity between uncorrelated vectors.", "In particular, diversity equals 1 also means that two vectors are orthogonal with each other.", "\\newline The diversities between $ N $ filters at the same layer $ l $ is thus characterized by a N-by-N matrix in which elements $ d_{ij}=div(\\textbf{W}^{l}_{i},\\textbf{W}^{l}_{j}),i,j=\\{1,\\cdots,N\\} $ are pairwise diversities between weight vectors $ \\textbf{W}^{l}_{i},\\textbf{W}^{l}_{j} $ .", "Note that for diagonal elements $ d_{ii} $ are constant 0.", "The total diversity between all filters is thus defined as the sum of all elements \\newline <equationgroup> <equation> $  Div(\\textbf{W}^{l}):=\\sum^{N,N}_{i,j=1,1}d_{i,j}. $ $  Div(\\textbf{W}^{l}):=\\sum^{N,N}_{i,j=1,1}d_{i,j}. $ </equation> </equationgroup> \\newline </subsubsection> </subsection>  </section>"], ["<section> <title> 4 EXPERIMENT RESULTS </title>  In this section, we evaluate the effectiveness of our method on various applications with both visual and audio data.", "\\newline <subsection> <title> 4.1 Datasets </title> For visual tasks, we adopt ImageNet and CIFAR datasets.", "The ImageNet dataset contains 1.2 million training images and 50,000 validation images of 1000 classes.", "CIFAR-10 [@bib:krizhevsky2009learning] which consists of 50K training and 10K testing RGB images with 10 classes.", "CIFAR-100 is similar to CIFAR-10, except it has 100 classes.", "The input image is 32 $ \\times $ 32 randomly cropped from a zero-padded 40 $ \\times $ 40 image or its flipping.", "For audio task, we adopt ISMIR Genre dataset [@bib:cano2006ismir] which has been assembled for training and development in the ISMIR 2004 Genre Classification contest.", "It contains 1458 full length audio recordings from Magnatune.com distributed across the 6 genre classes: Classical, Electronic, JazzBlues, MetalPunk, RockPop, World.", "\\newline </subsection> <subsection> <title> 4.2 Image Classification </title> We evaluate the performance of our proposed method for image classification on CIFAR-10/100 and ImageNet.", "We investigate both classical plain network, VGG-Net [@bib:simonyan2014very] , and deep residual network {i.e., } ResNet [@bib:he2016deep] .", "We evaluate our method on two popular network architecture {i.e., } VGG-Net [@bib:simonyan2014very] , and ResNet [@bib:he2016deep] .", "We take variations of the original VGG-Net, {i.e., } VGG-19 used in [@bib:NetSlim_Liu2017d] for comparison purpose.", "ResNet-164 which has 164-layer pre-activation ResNet with bottleneck structure is adopted.", "As base-line networks, we compare with the original networks without regularization terms and their counterparts in network-slimming [@bib:NetSlim_Liu2017d] .", "For ImageNet, we adopt VGG-16 and ResNet-50 in order to compare with the original networks.", "\\newline To make a fair comparison with [@bib:NetSlim_Liu2017d] , we adopt BN based scaling factors for optimization and pruning.", "On CIFAR, we train all the networks from scratch using SGD with mini-batch size 64 for 160 epochs.", "The learning rate is initially set to 0.1 which is reduced twice by 10 at 50% and 75% respectively.", "Nesterov momentum [@bib:sutskever2013importance] of 0.9 without dampening and a weight decay of $ 10^{-4} $ are used.", "The robust weight initialization method proposed by [@bib:he2015delving] is adopted.", "We use the same channel sparse regularization term and its hyperparameter $ \\lambda=10^{-4} $ as defined in [@bib:NetSlim_Liu2017d] .", "\\newline <subsubsection> <title> 4.2.1 Overall performance </title> The results on CIFAR-10 and CIFAR-100 are shown in Table [@ref:LABEL:tbl:c10] and Table [@ref:LABEL:tbl:c100] respectively.", "On both datasets, we can observe when typically 50-70% fitlers of the evaluated networks are pruned, the new networks can still achieve accuracy higher than the original network.", "For instance, with 70% filters pruned VGG-19 achieves an accuracy of 0.9393, compared to 0.9366 of the original model on CIFAR-10.", "We attribute this improvement to the introduced diversities between filter weights, which naturally provides discriminative feature representations in intermediate layers of networks.", "\\newline As a comparison, our method consistently outperforms network-slimming without resorting to fine-tuning or multi-pass pruning-retraining cycles.", "It is also worth-noting that our method is capable of pruning networks with prohibitively high ratios which are not possible in network-slimming.", "Take VGG-19 network on CIFAR-10 dataset as an example, network-slimming prunes as much as 70%, beyond which point the network cannot be reconstructed as some layers are totally destructed.", "On the contrary, our method is able to reconstruct a very narrower network by pruning 80% filters while producing a marginally degrading accuracy of 0.9302.", "We conjecture this improvement is enabled by our simultaneous feature and architecture learning which can avoid pruning filters prematurely as in network-slimming where the pruning operation (architecture selection) is isolated from the feature learning process and the performance of the pruned network can be only be restored via fine-tuning.", "\\newline The results on ImageNet are shown in Table [@ref:LABEL:tbl:imagenet] where we also present comparison with [@bib:DataDrivenSS_Huang2018] which reported top-1 and top-5 errors on ImageNet.", "On VGG-16, our method provides 1.2% less accuracy loss while saving additionally 20.5M parameters and 0.8B FLOPs compared with [@bib:DataDrivenSS_Huang2018] .", "On ResNet-50, our method saves 5M more parameters and 1.4B more FLOPs than [@bib:DataDrivenSS_Huang2018] while providing 0.21% higher accuracy.", "\\newline </subsubsection> <subsubsection> <title> 4.2.2 Ablation study </title> In this section we investigate the contribution of each proposed component through ablation study.", "\\newline <paragraph> <title> Filter Diversity </title> Fig. [@ref:LABEL:fig:scalings] (a) shows the sorted scaling factors of VGG-19 network trained with the proposed filter diversity loss at various training epochs.", "With the progress of training, the scaling factors become increasingly sparse and the number of large scaling factors, {i.e., } the area under the curve, is decreasing.", "Fig. [@ref:LABEL:fig:nsf_compare] shows the sorted scaling factors of VGG-19 network for the baseline model with no regularization, network-slimming [@bib:NetSlim_Liu2017d] , and the proposed method with diversified filters, trained with CIFAR-10 and CIFAR-100.", "We observe significantly improved sparsity by introducing filter diversity to the network compared with network-slimming, indicated by nsf .", "Remember the scaling factors essentially determine the importance of filters, thus, maximizing nsf ensures that the deterioration due to filter pruning is minimized.", "Furthermore, the number of filters associated with large scaling factor is largely reduced, rendering more irrelevant filter to be pruned harmlessly.", "This observation is quantitatively confirmed in Table [@ref:LABEL:tab_acc_comp] which lists the accuracies of three schemes before and after pruning for both CIFAR-10 and CIFAR-100 datasets.", "It is observed that retraining of pruned network is no longer needed for the proposed method, while network-slimming has to restore the original accuracy through single-pass or multi-pass of pruning-retraining cycles.", "Accuracy deterioration are 60.76% and 0% for network-slimming and the proposed method respectively, whilst the baseline networks completely fails after pruning, due to insufficient preserved filters at certain layers.", "\\newline </paragraph> <paragraph> <title> Online Pruning </title> We firstly empirically investigate the effectiveness of the proposed pruning loss.", "After setting $ \\lambda_{3}=0 $ , we train VGG-19 network by switching off/on respectively (set $ \\lambda_{2}=0 $ and $ \\lambda_{2}=10^{-4} $ ) the pruning loss on CIFAR-10 dataset.", "By adding the proposed pruning loss, we observe improved accuracy of 0.9325 compared to 0.3254 at pruning ratio of 70%.", "When pruning at 80%, the network without pruning loss can not be constructed due to insufficient preserved filters at certain layers, whereas the network trained with pruning loss can attain an accuracy of 0.9298.", "This experiment demonstrates that the proposed pruning loss enables online pruning which dynamically selects the architectures while evolving filters to achieve extremely compact structures.", "\\newline Fig. [@ref:LABEL:fig:scalings] (b) shows the sorted scaling factors of VGG-19 network trained with pruning loss subject to various target pruning ratios on CIFAR-10.", "We can observe that given a target pruning ratio, our algorithm adaptively adjusts the distribution of scaling factors to accommodate the pruning operation.", "Such a dynamic evolution warrants little accuracy loss at a considerably high pruning ratio, as opposed to the static offline pruning approaches, {e.g., } network-slimming, where pruning operation is isolated from the training process causing considerable accuracy loss or even network destruction.", "\\newline </paragraph> </subsubsection> </subsection> <subsection> <title> 4.3 Image Compression </title> The proposed approach is applied on end-to-end image compression task which follows a general autoencoder architecture as illustrated in Fig. [@ref:LABEL:fig:comparch] .", "We utilize general scaling layer which is added after each convolutional layer, with each scaling factor initialized as 1.", "The evaluation is performed on CIFAR-100 dataset.", "We train all the networks from scratch using Adam with mini-batch size 128 for 600 epochs.", "The learning rate is set to 0.001 and MSE loss is used.", "The results are listed in Table."]], "target": "where both parameters and floating-point operations (FLOPs) are reported. Our method can save about 40% - 60% parameters and 50% - 60% computational cost with minor lost of performance (PSNR)."}, {"tabular": ["  Model  &  Feat. Size  &  PolyU  &  Cross-Eyed ", " EER (%)  &  Decidability  &  EER (%)  &  Decidability ", " ResNet50  &  $ 1024 $  &  $ 0.54\\pm 0.09 $  &  $ 6.76\\pm 0.10 $  &  $ 1.61\\pm 0.25 $  &  $ 5.93\\pm 0.13 $ ", " $ 512 $  &  $ 0.56\\pm 0.06 $  &  $ 6.73\\pm 0.08 $  &  $ 1.35\\pm 0.22 $  &  $ 6.00\\pm 0.11 $ ", " $ 256 $  &  $ 0.49\\pm 0.06 $  &  $ 6.75\\pm 0.08 $  &  $ 1.40\\pm 0.26 $  &  $ 5.93\\pm 0.12 $ ", " $ 128 $  &  $ 0.43\\pm 0.05 $  &  $ 6.70\\pm 0.08 $  &  $ 1.35\\pm 0.30 $  &  $ 5.99\\pm 0.13 $ ", " $ 64 $  &  $ 0.37\\pm 0.07 $  &  $ 6.50\\pm 0.08 $  &  $ 1.26\\pm 0.22 $  &  $ 5.93\\pm 0.15 $ ", " $ 32 $  &  $ 0.30\\pm 0.05 $  &  $ 6.05\\pm 0.15 $  &  $ 1.41\\pm 0.27 $  &  $ 5.65\\pm 0.16 $ ", " VGG16  &  $ 1024 $  &  $ 0.99\\pm 0.10 $  &  $ 6.85\\pm 0.08 $  &  $ 2.68\\pm 0.28 $  &  $ 5.29\\pm 0.11 $ ", " $ 512 $  &  $ 0.92\\pm 0.12 $  &  $ 6.94\\pm 0.11 $  &  $ 2.53\\pm 0.38 $  &  $ 5.35\\pm 0.14 $ ", " $ 256 $  &  $ 0.93\\pm 0.10 $  &  $ 6.97\\pm 0.13 $  &  $ 2.66\\pm 0.29 $  &  $ 5.31\\pm 0.12 $ ", " $ 128 $  &  $ 0.80\\pm 0.12 $  &  $ 7.03\\pm 0.10 $  &  $ 2.78\\pm 0.33 $  &  $ 5.28\\pm 0.10 $ ", " $ 64 $  &  $ 0.73\\pm 0.11 $  &  $ 6.93\\pm 0.11 $  &  $ 2.67\\pm 0.37 $  &  $ 5.23\\pm 0.15 $ ", " $ 32 $  &  $ 0.69\\pm 0.10 $  &  $ 6.46\\pm 0.07 $  &  $ 2.79\\pm 0.47 $  &  $ 4.98\\pm 0.17 $  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Iris recognition using nir wavelength images acquired under controlled environments can be considered a mature technology, which proved to be effective in different scenarios [@bib:Proenca2012] .", "In contrast, performing iris recognition in uncontrolled environments and at vis wavelength is still a challenging problem [@bib:proenca2005,proenca2010] .", "Some of the latest researches consist of biometrics recognition on cross-spectral scenarios, i.e., using images of eyes from the same subject obtained at the vis and nir wavelengths [@bib:Hosseini2010,Sharma2014,Nalla2017,Algashaam2017] .", "\\newline Recently, machine learning techniques based on deep learning have been achieving great popularity due to the results reported in the literature, which advance the state-of-the-art in various problems, such as speech recognition [@bib:Hinton2012,Zhang2017,Kim2017] , natural language processing [@bib:Glorot2011,Socher2011] , digit and character recognition [@bib:laroca2018robust,hochuli2018,laroca2019efficient] and face recognition [@bib:Omkar2015,Cao2017] .", "In the field of ocular biometrics, using deep learning representation has been advocated both for the periocular [@bib:Luz2018,Proenca2018] and iris [@bib:Liu2016,Gangwar2016,Al-Waisy2017,Nguyen2018,Proenca2017,Nalla2017,Wang2019,Zanlorensi2018] regions, with interesting and promising results being reported.", "\\newline As stated in previous works [@bib:demarsico2016,Liu2016] , an often and open problem in ocular recognition is the matching heterogeneous images captured at different resolutions, distances and devices (cross-sensor and cross-spectral).", "Regarding these problems it is difficult to design a robust handcrafted feature extractor to address the intra-class variations present in this scenarios.", "In this sense, several recent works demonstrate that deep representations report better results compared to handcrafted features in iris and periocular region recognition [@bib:Liu2016,Luz2018,Proenca2018,Wang2019] .", "\\newline Having in mind that deep learning frameworks are typically able to produce robust representations, in this article we apply this family of frameworks to extract and combine features from the ocular region, obtained at different wavelengths, e.g., vis and nir .", "The strategy described in this article is composed of some methodologies extracted from the literature.", "For both the iris and ocular traits we use as input the bounding box delimited regions used in the state-of-the-art methods [@bib:Zanlorensi2018,Luz2018] .", "Then, the features from these traits were extracted using a similar approach proposed by [@bib:Zanlorensi2018] .", "In this direction, the main contribution of this article is the extensive experiments on two datasets comparing iris, periocular, and fusion results for both cross-spectral ( vis to nir ) and intra-spectral ( vis to vis , nir to nir ) matching, reaching a new state-of-the-art results.", "There is also the following four-fold contributions: (i) we show that deep learning yield robust representations on two well-known cross-spectral databases (PolyU and Cross-Eyed) for ocular verification using closed- and open-world protocols; (ii) we report how two off-the-shelf networks can be fine-tuned from the face domain to the periocular and iris one; (iii) we analyze the use of a single deep representation extraction schema, for both cross-spectral and the same spectra scenarios; and (iv) we conclude about the benefits of fusing the periocular and iris representations to improve the recognition accuracy.", "\\newline The remainder of this work is organized as follows.", "In Section [@ref:LABEL:sec:related] , we describe some recent works that use deep learning for iris and periocular recognition.", "Section [@ref:LABEL:sec:methodology] provides the details of the proposed approach.", "Section [@ref:LABEL:sec:protocol] presents the databases, metrics and evaluation protocol used in our empirical evaluation.", "The results are presented and discussed in Section [@ref:LABEL:sec:results] .", "Lastly, the conclusions are given in Section [@ref:LABEL:sec:conclusion] .", "\\newline  </section>"], ["<section> <title> 2 Related Work </title>  This section surveys the works that use deep learning frameworks for iris and periocular recognition.", "Also, we summarize the most relevant ocular recognition methodologies focused on the cross-spectral scenario.", "\\newline One of the first works applying deep learning to iris recognition only was the {DeepIris} framework, proposed by Liu et al. [@bib:Liu2016] .", "Having as a goal the recognition of heterogeneous irises using images obtained by different sensors (i.e., the cross-sensor scenario), the authors proposed a framework that establishes the similarity between a pair of iris images using cnn by learning a bank of pairwise filters.", "The experiments were performed in the Q-FIRE and CASIA cross-sensor databases, reporting promising results with eer of $ 0.15 $ % and $ 0.31 $ %, respectively.", "\\newline Another deep learning application for cross-sensor iris recognition, designated DeepIrisNet, was proposed by Gangwar & Joshi [@bib:Gangwar2016] .", "In their study, two cnn architectures were presented and used to extract features and representations of iris images.", "Comparing to the baselines, their methodology showed better robustness with respect to five different factors: effect of segmentation, image rotation, input size, training size, and network size.", "\\newline Nguyen et al. [@bib:Nguyen2018] argued that generic descriptors yielding from deep learning frameworks can appropriately represent iris features from nir images obtained in controlled environments.", "The authors compared five cnn architectures trained in the ImageNet database [@bib:Imagenet2009] : AlexNet, VGG, Inception, ResNet and DenseNet.", "Deep representations were extracted from normalized iris images at different depths of each cnn model.", "Afterward, a simple multi-class svm was applied to perform the identification.", "The experiments were carried out in the LG2200 (ND-CrossSensor-Iris-2013) and CASIA-Iris-Thousand databases and compared with a baseline feature descriptor [@bib:Daugman2004] .", "As main result, the authors argued that features extracted from intermediate layers of the networks reported better results than the representations in the deeper layers.", "\\newline Luz et al. [@bib:Luz2018] extracted deep representations of the periocular region using the VGG16 cnn model.", "The authors reported promising results by using transfer learning techniques from the face recognition domain, followed by fine-tuning using the ocular images.", "The experiments achieved the state-of-the-art in the NICE.II and MobBIO databases, which were obtained in uncontrolled environments at the vis wavelength.", "\\newline Also using the NICE.II database, Silva et al. [@bib:Silva2018] proposed a fusion method of iris and periocular deep representations by means of feature selection using the Particle Swarm Optimization (PSO).", "Similar to the methodology proposed in [@bib:Luz2018] , the iris and periocular deep representations were extracted with the VGG16 model trained for face recognition and fine-tuned for each trait.", "Promising results were reported in the verification mode only using iris information and also using iris and periocular fusion.", "\\newline Proen\u00e7a and Neves [@bib:Proenca2018] argue that periocular recognition performance is optimized when the iris and sclera regions are discarded.", "Also, these authors describe a processing chain based on cnn that defines the regions-of-interest in the input image.", "In their approach, a segmentation process is only required to create the training samples.", "This process consists in generating a periocular image of a subject containing an ocular (sclera and iris) region belonging to other subjects.", "Then, the generated samples are used for data augmentation and to feed the learning phase of the cnn model.", "The experiments were performed in the UBIRIS.v2 and FRGC databases and consistently advances the state-of-the-art in the closed-world setting.", "\\newline Zanlorensi et al. [@bib:Zanlorensi2018] evaluated the impact of the segmentation for noise removal and normalization when deep representations were extracted from the iris images.", "The experiments reported that deep representations extracted from an iris bounding box without segmentation process achieved better results than normalized and segmented images.", "In addition, the authors compared representations extracted from the VGG16 and ResNet50 models and the impact of using data augmentation techniques.", "A new state-of-the-art was reached in the NICE.II database using only information from the iris region.", "\\newline In terms of cross-sensor iris recognition, the methodology proposed by Nalla and Kumar [@bib:Nalla2017] introduced a domain adaptation framework to address this problem and reported a new approach using Markov random fields.", "The experiments were performed using two cross-sensor iris databases: IIT-D CLI and ND Cross sensor 2012; and one cross-spectral iris database: PolyU. The results reported in PolyU database in the verification protocol at closed-world achieved an eer value of $ 3.97 $ % in nir vs nir comparisons and $ 6.56 $ % in vis vs vis comparisons.", "Using the Markov random fields on cross-spectral comparisons, their methodology achieved $ 23.87 $ % of eer .", "\\newline In [@bib:Wang2019] , the authors evaluated a range of deep learning architectures applied to the cross-spectral iris recognition.", "The experimental results were performed in the PolyU and Cross-Eyed databases.", "Experimental analysis indicates that iris features extracted from cnn models are generally sparse and can be used for template compression.", "Several hashing algorithms were evaluated and the most effective was supervised discrete hashing achieving more accurate performance and reducing the size of iris template.", "The best results reported were achieved by incorporating supervised discrete hashing on the deep representations extracted with a cnn model trained with a softmax cross-entropy loss.", "This methodology reached an eer value of $ 12.41\\% $ and $ 6.34\\% $ on the PolyU and Cross-Eyed databases, respectively.", "However, the authors do not report the system performance on the open-world protocol, which is a more realistic scenario.", "Also, this methodology requires an approach for the segmentation and normalization of the iris.", "To the best of our knowledge, this work is the state-of-the-art on cross-spectral recognition in the verification mode.", "Thus, it is used for comparison with the methodology presented in this paper.", "\\newline Also applied in the cross-spectral scenario, Hernandez-Diaz et al. [@bib:Diaz2019] proposed a method using a ResNet-101 model pretrained in the Imagenet database [@bib:Imagenet2009] to extract deep representation from periocular images.", "The experiments were carried out in verification mode using the IIITD Multispectral Periocular database [@bib:Sharma2014] in three different spectra: Visible, Night Vision, and Near-Infrared.", "The results were reported using features extracted at each layer from the model using chi-square distance and cosine similitude to perform the matching.", "The authors stated that the features extracted from the intermediate layer from the ResNet-101 model achieved the best results in the cross-spectral experiments.", "\\newline Recently, two contests were performed using the Cross-Eyed database, aiming to recognize iris and periocular (without the iris region) traits in a cross-spectral environment [@bib:Sequeira2016,Sequeira2017] .", "However, as stated by Wang and Kumar [@bib:Wang2019] , the results reported in these competitions should be considered preliminary, as they employed a comparison protocol with less matching challenge than usual (only 3 images of each class were used in the inter-class comparison instead of all against all) and did not provide information regarding which images of each class were used in the inter-class matching (the authors\u2019 work only reported that the images were randomly selected).", "Other problems include the availability of codes and also details of the methodologies, which limit the reproducibility.", "\\newline Previous works on cross-spectral recognition such as [@bib:Nalla2017,Wang2019] only use iris traits and require a methodology for iris segmentation and normalization.", "Our proposal in this article combine information from the iris and periocular regions.", "Also, for the iris trait, we use only a bounding box, which does not require segmentation for noise removal and normalization steps.", "\\newline For completeness, there are several other applications with ocular images based on deep learning such as: spoofing detection [@bib:Menotti2015] , recognition of mislabeled left and right iris images [@bib:Du2016] , liveness detection [@bib:He2016b] , iris/periocular region location/detection [@bib:severo2018benchmark,lucio2019simultaneous] , sclera and iris segmentation [@bib:lucio2018fully,bezerra2018robust] , gender classification [@bib:Tapia2017] and sensor model identification [@bib:Marra2017] .", "\\newline  </section>"], ["<section> <title> 3 Methodology </title>  In this paper we analyze the use of deep representations from the eye regions (iris and periocular) on cross-spectral scenario, i.e., obtaining models able to match vis against nir wavelength images.", "Particularly, we evaluate and combine deep representations extracted from two modalities (traits): the iris and periocular regions.", "In the periocular modality, features were extracted from the entire image (considering the iris, sclera, skin, eyelids and eyelashes components).", "On the other way, the iris features were extracted from a bounding box, i.e., a cropped image that contains only the iris region, as described by Zanlorensi et al. [@bib:Zanlorensi2018] .", "These bounding boxes were generated manually by coarse annotations and are publicly available to the research community and appears in [@bib:lucio2019simultaneous] .", "Samples of the periocular and iris images used in this work are shown in Figure [@ref:LABEL:fig:datasamples] .", "\\newline Deep representations from the periocular and iris regions were extracted using a similar approach proposed in [@bib:Zanlorensi2018] .", "In this way, the VGG16 [@bib:Omkar2015] and ResNet-50 [@bib:Cao2017] cnn models trained for face recognition were fine-tuned to each modality.", "We choose these models because they reported promising results in recent works applied in ocular recognition [@bib:Luz2018,Zanlorensi2018,Silva2018,Wang2019] .", "The architecture modifications for both models consist of the removal of the last layer and the addition of two new layers.", "The first one is a fully-connected layer with $ 256 $ neurons that will be used as the feature representation and aim to reduce the feature dimensionality, since originally VGG16 and ResNet-50 have $ 4096 $ and $ 2048 $ features/outputs, respectively.", "The other layer added has a softmax cross-entropy loss function and it is used only in the training phase in an identification mode.", "We chose a feature vector of 256 features based on the results reported by Luz et al. [@bib:Luz2018] , where the authors evaluated different feature vector sizes and stated that vector with such size (256) showed the best trade-off regarding matching time, amount of memory required and matching effectiveness.", "The strategy applied to extract features from nir and vis images is detailed in Figure [@ref:LABEL:fig:cnnextract] .", "\\newline The number of epochs used for training was chosen based on a validation subset composed of $ 20\\% $ of the training set images.", "After defining the number of epochs, the cnn models were trained using the entire training set.", "The training was performed with the Stochastic Gradient Descent (SGD) optimizer and without freezing any weights of the pre-trained layers.", "\\newline In the test phase, as previously mentioned, the last layer of each model was removed and the features were extracted from the first new last layer, composed by $ 256 $ neurons.", "\\newline The all-against-all matching was performed using the cosine distance metric, which measures the cosine of the angle between two vectors.", "Regarding the similarity of biometrics features/representations, it is known that orientation is more important than the magnitude coefficient.", "The cosine distance metric faithfully matches this feature, being given by: \\newline <equation> $ d_{c}(A,B)=1-\\frac{\\sum_{j=1}^{N}A_{j}B_{j}}{\\sqrt{\\sum_{j=1}^{N}A_{j}^{2}}% \\sqrt{\\sum_{j=1}^{N}B_{j}^{2}}}\\,, $ </equation> where $ A $ and $ B $ stand for the feature vectors.", "\\newline The iris and periocular region representations were combined, applying the score-level fusion technique.", "Similar to approaches that also used score-level fusion for iris and periocular region traits [@bib:Ahmed2016,Ahmed2017,Nalla2017] and also based on the individual performance of each trait in our experiments, we chose to use weights of $ 0.6 $ and $ 0.4 $ for the periocular region and iris representations, respectively.", "To perform fusion at the score-level, first, we compute the matching for each trait independently, and then we calculated the weighted arithmetic mean between the cosine distances computed for the iris and periocular modalities.", "\\newline It is important to note that, in the model learning process, all images ( nir and vis ) were used to feed the cnn models, making a single model to learn discriminant features of images captured in both spectra.", "To the best of our knowledge, this procedure is similar to the adopted in [@bib:Wang2019] for the CNN architecture.", "In the test phase the features are extracted for all images nir or vis images.", "However, note that for evaluating the cross-spectral scenario, only images acquired under different wavelengths are paired to match.", "\\newline  </section>"], ["<section> <title> 4 Databases, Metrics and Protocol </title>  This section describes the databases used, the experimental protocol defined and the metrics considered appropriate to provide a meaningful comparison between our method and the baselines.", "\\newline <subsection> <title> 4.1 Databases </title> Two well-known databases were used in our empirical evaluation: 1) the PolyU; and the 2) Cross-Eyed databases, described below: \\newline <subsubsection> <title> 4.1.1 PolyU database </title> PolyU (PolyU Bi-spectral) database is composed of images obtained simultaneously under both nir and vis wavelengths.", "The entire database has $ 12{,}540 $ images with a resolution of $ 640\\times 480 $ pixels.", "For every spectrum, there are $ 15 $ samples of each eye (left and right) from $ 209 $ subjects ( $ 418 $ classes) [@bib:Nalla2017] .", "\\newline </subsubsection> <subsubsection> <title> 4.1.2 Cross-Eyed database </title> The Cross-Eyed (Cross-eyed-cross-spectral) iris database has $ 3{,}840 $ images from $ 120 $ subjects ( $ 240 $ classes).", "There are $ 8 $ samples from each of the classes for every spectrum.", "The resolution of the images is $ 400\\times 300 $ pixels.", "All images were obtained at a distance of 1.5 meters, in an uncontrolled indoor environment, with a wide variation of ethnicity and eye colors, and lightning reflexes [@bib:Sequeira2016] .", "\\newline </subsubsection> </subsection> <subsection> <title> 4.2 Metrics </title> For evaluating the algorithms, we choose the eer metric , which is determined by the intersection point of far and frr curves generated when the acceptation/rejection threshold is varied.", "\\newline We also report the decidability score $ d^{\\prime} $ [@bib:Daugman2003] .", "The metric or index $ d^{\\prime} $ measures how well separated are the two types of distributions ( {genuines} and {impostors} ), in the sense that recognition errors correspond to the regions where both distributions overlap: \\newline <equation> $ d^{\\prime}=\\frac{|\\mu_{E}-\\mu_{I}|}{\\sqrt{\\frac{1}{2}(\\sigma^{2}_{E}+\\sigma^{2% }_{I})}}\\,, $ </equation> \\newline where the means and standard deviations of the genuine and impostor distributions are given by $ \\mu_{I} $ , $ \\mu_{E} $ , $ \\sigma_{I} $ , and $ \\sigma_{E} $ , respectively.", "\\newline Whereas the index $ d^{\\prime} $ can be related to the feature vector discrimination ability of an approach, the eer metric measures the real performance of a biometric system.", "Therefore, regarding a real-world application, we consider the eer as the primary metric in the results reported in this work.", "\\newline </subsection> <subsection> <title> 4.3 Protocol </title> In all experiments, the {verification} setting was the unique considered, in which pairs of images are compared in order to determine whether a subject is who he claims to be or not.", "For this, following a {one-against-all} pairwise matching strategy, all pairs of genuine and impostor comparisons were generated.", "\\newline For a fair comparison with the state-of-the-art methods, the test protocol used in this work follows the procedures given in [@bib:Nalla2017,Wang2019] , which consists of a closed-world protocol, where different instances of the same class are distributed in the training and test sets.", "In the PolyU database, the first ten instances from every subject were used for training and the remainder (five) were employed for the matching.", "In the Cross-Eyed database, the first five instances from every subject are used for training and the remaining three instances were employed for the matching.", "\\newline To perform the experiments, we considered that in both databases, the nir and vis images were obtained synchronously.", "Thus, here in the intra-class comparison in the cross-spectral scenario, images of the same index were not matched, because the pair represents the same image but in different spectra.", "Note that in the work by Wang and Kumar [@bib:Wang2019] , the authors considered that in the Cross-Eyed database, non-synchronously spectrum images were obtained (based on the numbers of intra- and inter-class comparisons), so they matched nir against vis images of the same index in the intra-class comparison.", "Then for a fair comparison with the state-of-the-art method [@bib:Wang2019] , in the closed-world protocol, we also report results considering that the nir and vis images where obtained non-synchronously in the Cross-Eyed database.", "\\newline In order to evaluate the robustness of the proposed methodology, we also evaluate and then report results on the open-world protocol, in which the training and test sets have images from different classes.", "In other words, there are no images from the same subject in the training and testing.", "In this protocol, for both databases, we use the first half of the subject images for training and the second half for testing.", "\\newline The distributions of images and classes in the training and test sets, as well as the number of genuine and impostors pairs generated in the test phase for both databases and protocols are detailed in Table [@ref:LABEL:tab:protocol] .", "\\newline The mean and standard deviation of $ 30 $ repetitions for the eer and decidability figures obtained by the proposed methodology are shown.", "\\newline </subsection>  </section>"], ["<section> <title> 5 Results and Discussion </title>  In this section, we present and discuss the results observed for the intra-spectral cross-spectral scenarios, in both the iris and periocular modalities.", "We start by providing the results using the closed-world protocol, in order to establish a baseline with respect to the state-of-the-art.", "We also investigate the impact of the feature vector size and the weights used to merge information from the periocular region and iris traits.", "Then, the results using the open-world protocol are presented, to perceive how robust deep representations can be obtained.", "Using the ResNet-50 model, a comparison of the verification effectiveness using features extracted from various network depths is performed.", "Lastly, we performed a subjective analysis of the pairwise errors.", "\\newline In a complementary setting, we explore the advantages yielding from fusing representations of the periocular and iris traits to improve performance.", "Similar to previous works [@bib:Nalla2017,Ahmed2016,Ahmed2017] that applied higher weights in the most discriminating traits, and also considering that in all our experiments the periocular region reported better results compared to the iris, we decided to use constant weights of $ 0.6 $ and $ 0.4 $ respectively for the periocular and iris representations when obtaining the fused score by linear combination.", "\\newline The experiments performed in this work and reported here used an NVIDIA ^(\u00ae) Titan Xp GPU with 12GB memory and $ 3,840 $ CUDA cores, and the tensorflow ^(\u2122) and {Keras} frameworks were used to implement the cnn models.", "\\newline <subsection> <title> 5.1 Closed-world protocol </title> At first, Table [@ref:LABEL:tab:PolyUclosed] and Table [@ref:LABEL:tab:CrossEyedclosed] report the results observed for verification mode, in the cross-spectral and intra-spectral scenarios ( nir against nir and vis against vis ) and using the closed-world protocol.", "In a way similar to Nalla and Kumar [@bib:Nalla2017] and also to guarantee a fair comparison to their method, the fusion of two spectra on the PolyU database was carried out by linear combination, using weights of $ 0.6 $ and $ 0.4 $ , respectively, to the nir and vis images.", "However, based on the individual spectral results, on the Cross-Eyed database, we used weights of $ 0.6 $ and $ 0.4 $ for the vis and nir representations, respectively.", "Also, on the Cross-Eyed database, we can perceive that the spectral fusion using iris representations extracted by the VGG16 model reported lower results than using the only vis spectral information.", "The results show that the representations obtained from nir images presented a high eer value, which penalized the fusion of spectra.", "Therefore, lower weight for nir representations may improve the fusion result.", "The results of those fusions are shown in Table [@ref:LABEL:tab:PolyUclosed] and Table [@ref:LABEL:tab:CrossEyedclosed] (VIS and NIR Fusion section).", "\\newline Anyway, it can be seen that - for both databases - the proposed approach achieves better results than the state-of-the-art methods, both in the cross-spectral and in the intra-spectral scenarios even that the protocol used in this paper is more challenging.", "For example, in the PolyU database, we used images from all 209 subjects in the experiments, while the approaches proposed by Wang and Kumar [@bib:Wang2019] , and Nalla and Kumar [@bib:Nalla2017] used images from only 140 subjects.", "In the Cross-Eyed database, based on the number of pairs of intra-class comparisons reported in the experiments by Wang and Kumar [@bib:Wang2019] , the authors considered that the database has images obtained non-synchronously.", "Images from the Cross-Eyed database were obtained using a dual sensor with a beam splitter, so the nir and vis images are acquired simultaneously.", "However, we visually verified that the images of the same index, i.e., those that should be the same one in the nir and vis , have a random shift in each spectrum.", "Thus, for a fair comparison with the state-of-the-art approaches, we report the results using both protocols, considering the images obtained synchronously and non-synchronously.", "Note that we collected the state-of-the-art results from the original papers [@bib:Nalla2017,Wang2019] , i.e., we did not have implemented any approach from these works.", "\\newline In terms of the CNN architectures, the ResNet-50 model reported lower eer values compared to the VGG16 model in all cases.", "However, in some cases, specifically in the PolyU database, the representations extracted with the VGG16 model obtained a better separation of intra- and inter-class distributions, as can be seen in their Decidability index.", "\\newline The results show that in Cross-Eyed, the periocular modality achieves better results than the iris one.", "However, in the PolyU database, there is no significant difference between iris and periocular representations, mainly in the intra-spectral experiments.", "From a visual inspection analysis of the pairwise comparison errors (some examples are shown in Section [@ref:LABEL:ssec:subjectiveevaluation] ), we perceive that in the PolyU database, some uncontrolled conditions present in the images such as pose, eye gaze, and rotation may penalize the quality of the periocular representations.", "These conditions are more controlled in the cross-eyed images.", "Also, Cross-Eyed images are smaller than PolyU images, so the iris region is even smaller, and the periocular images are better centralized based on the iris region in the Cross-Eyed and not in the PolyU database.", "Nevertheless, Cross-Eyed images present a more significant difference in color and illumination among classes, which makes them more distinct and may explain the better results in vis against vis comparisons than nir against nir .", "\\newline </subsection> <subsection> <title> 5.2 Feature size and fusion weights analyses </title> In this section, we analyze and discuss the impact of feature vector size and the weights used for the fusion of the iris and periocular region representations.", "\\newline As state in Section [@ref:LABEL:sec:methodology] , we choose the feature size of $ 256 $ based on the experiments and results reported by Luz et al [@bib:Luz2018] .", "Therefore, we also performed some experiments creating new models with different sizes in the last layer before the softmax one, i.e., the layer used to extract the features (representations)."]], "target": "The results of the fusion of iris and periocular representations extracted with these models are presented in Table . Luz et al. stated that for the cosine distance metric, high dimensional vectors resulted in better performance. Conversely, our results show that representations extracted with the ResNet50 model achieve lower values of eer when the feature vector is smaller. The same occurs in the VGG16 model features in the PolyU database. Regarding the decidability index, the size of the feature vector does not show to have much impact. These results may be related to the fact that both models can generate sparse feature vectors, as stated by Wang and Kumar . Thus a bigger feature vector will not always improve the performance of the biometric system. Here, we decided to keep a feature vector size of 256 because it keep a trade-off between eer and Decidability."}, {"tabular": ["  Tokenization  &  dev-011  &  dev-018 ", " mmseg  &  35.96  &  63.15 ", " jieba  &  35.52  &  62.31  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Speech recognition has made tremendous progress in the past decade, thanks to the rise of the deep learning techniques and the development of various open-source speech recognition toolkits.", "To give an example, the original Librispeech paper [@bib:panayotov2015librispeech] in 2015 reports a word-error-rate (WER) of 13.97% for its test-other evaluation set, while in [@bib:zhang2020pushing] , the authors report 2.6% for the same evaluation set.", "That is a reduction of 81.4% in terms of WER in just 5 years!", "\\newline Most of the efforts, however, have been devoted to adults\u2019 speech recognition systems.", "Children\u2019s speech recognition, on the other hand, remains very challenging, despite the rising demands from applications such as smart speakers and language learning.", "\\newline There are a number of reasons why children\u2019s speech recognition remains difficult.", "First, children typically have shorter vocal tracts and smaller vocal folds, which lead to higher fundamental and formant frequencies.", "This means that a large part of the children\u2019s speech spectrum will be ignored at the typical speech recognition sampling rate of 16kHz [@bib:gray2014child] .", "Second, children\u2019s speech tend to have higher level of variability [@bib:shivakumar2020transfer] , both acoustically and linguistically, which makes it harder to model.", "Finally, unlike speech recognition for adults, where training data is generally available and can be easily collected when necessary, collecting speech recognition training data for children is oftentimes laborious and expensive.", "As a result, children\u2019s speech recognition systems usually trained with limited amount of children\u2019s speech data.", "\\newline Researchers have proposed various techniques to alleviate the above problems.", "In [@bib:giuliani2003investigating,stemmer2003acoustic,shivakumar2014improving] , Vocal Tract Length Normalization (VTLN) is used to suppress the acoustic variability introduced by children\u2019s shorter vocal tracts.", "In [@bib:gray2014child,shivakumar2014improving] , adaptation methods such as Maximum Likelihood Linear Regression (MLLR), Maximum A-Posteriori (MAP) and Speaker Adaptive Training (SAT) are found helpful when dealing with children\u2019s speech.", "Those methods usually fall into the speaker normalization and adaptation category, which handle the acoustic variability to some degree.", "[@bib:das1998improvements] tries to improve children\u2019s speech recognition from the linguistic variability angle.", "It adopts language models trained on children\u2019s speech, and finds that it yields better performance than language models trained on adults\u2019 speech.", "[@bib:shivakumar2020transfer] improves children\u2019s speech recognition from the data insufficiency point of view.", "It adapts children\u2019s model from adults\u2019 model using transfer learning, and finds it very helpful.", "\\newline In this paper, we propose data augmentation for children\u2019s speech recognition.", "Different data augmentation techniques, such as pitch perturbation, speech perturbation, tempo perturbation, volume perturbation, reverberation augmentation, spectral augmentation, are experimented with the SLT 2021 Children Speech Recognition Challenge data.", "We conduct experiments with both Kaldi\u2019s chain models [@bib:Povey2016Purely] and ESPnet\u2019s attention-based encoder-decoder end-to-end models [@bib:Watanabe2018ESPnet] .", "We find that data augmentation generally helps to improve model\u2019s robustness towards the acoustic variability in children\u2019s speech, and as a result, improves children\u2019s speech recognition performance across speech recognition toolkits and model architectures.", "Our final submitted system is trained with ESPnet\u2019s attention-based encoder-decoder end-to-end model, and it achieves 18.82% CER and 16.53% CER on the challenge\u2019s Track 1 and Track 2 evaluation sets respectively.", "\\newline The rest of this paper is organized as follows.", "In Section 2 we introduce the SLT 2021 Children Speech Recognition Challenge.", "Section 3 presents our data processing techniques, and Section 4 explains the data augmentation techniques we propose for children\u2019s speech recognition.", "We describe our speech recognition systems in Section 5, and experiments setup and results in Section 6.", "Finally, Section 7 concludes the paper and discusses future work.", "\\newline  </section>"], ["<section> <title> 2 The Challenge </title>  We briefly introduce the SLT 2021 Children Speech Recognition Challenge (CSRC) in this section, including datasets and tracks.", "\\newline <subsection> <title> 2.1 Datasets </title> CSRC releases three datasets, namely Set A , Set C1 and Set C2 .", "In addition to the three released datasets, external data listed on OpenSLR [@bib:openslr] is allowed for the Track 2 task.", "\\newline <paragraph> <title> Set A. </title> The Set A dataset consists of 341.4 hours of Mandarin adult reading speech.", "It has 1999 speakers, with ages between 18 - 60 years old.", "\\newline </paragraph> <paragraph> <title> Set C1.", "</title> The Set C1 dataset consists of 28.6 hours of Mandarin child reading speech.", "It has 927 speakers, with ages between 7 - 11 years old.", "\\newline </paragraph> <paragraph> <title> Set C2.", "</title> The Set C2 dataset consists of 29.5 hours of Mandarin child conversational speech.", "It has 54 speakers, with ages between 4 - 11 years old.", "\\newline </paragraph> <paragraph> <title> External Data.", "</title> External data listed on OpenSLR [@bib:openslr] is allowed for the Track 2 task.", "\\newline </paragraph> </subsection> <subsection> <title> 2.2 Tracks </title> CSRC has two separate tasks, namely the Track 1 task and the Track 2 task.", "Teams can participate in either one of the tracks, or both tracks.", "\\newline <paragraph> <title> Track 1.", "</title> In the Track 1 task, only Set A , Set C1 and Set C2 can be used to train the acoustic and language models.", "\\newline </paragraph> <paragraph> <title> Track 2.", "</title> In the Track 2 task, in addition to the Set A , Set C1 and Set C2 datasets, external data listed on OpenSLR [@bib:openslr] can be used for acoustic model training.", "Only the transcripts associated with the provided speech data and the external speech data on OpenSLR [@bib:openslr] can be used for language model training.", "\\newline </paragraph> </subsection> <subsection> <title> 2.3 Evaluation </title> Both tracks share the same evaluation dataset.", "The evaluation dataset consists of 16.3 hours of Mandarin child reading and conversational speech, with 216 speakers.", "Character-error-rate (CER) is used to evaluate the model performance.", "\\newline </subsection>  </section>"], ["<section> <title> 3 Data Processing </title>  We split the official datasets into train and dev sets, and then apply text normalization and tokenization for the train and dev sets respectively before we train the speech recognition system.", "\\newline <subsection> <title> 3.1 Data Partitioning </title> Since CSRC focuses on children\u2019s speech recognition, our dev set is selected only from the child portion of the datasets, that is Set C1 and Set C2 .", "We randomly choose 20 speakers from Set C1 , around 1.4 hours of children\u2019s speech.", "We call this set dev-011 .", "We also select 5 speakers from Set C2 , around 0.6 hours of children\u2019s speech.", "We call this set dev-018 .", "The rest of the released data is treated as our train set.", "\\newline </subsection> <subsection> <title> 3.2 Text Normalization </title> The transcripts released by CSRC have been properly normalized.", "In addition to the official text normalization, we also map symbols (e.g., \u201c $ > $ \u201d, \u201c@\u201d, etc.) to their corresponding Chinese characters.", "\\newline </subsection> <subsection> <title> 3.3 Tokenization </title> The official training transcripts are not tokenized.", "We evaluate both mmseg [@bib:mmseg] and jieba [@bib:jieba] tokenizers for this particular task.", "For each tokenizer, we train a typical triphone system with the Kaldi [@bib:povey2011kaldi] toolkit, on our train set.", "We then evaluate the recognition performance on our dev-011 and dev-018 sets."]], "target": "Table reports the CER for both tokenizers on our dev sets. It is clear that jieba outperforms mmseg on both dev sets. For the rest of the task, jieba is used for tokenization."}, {"tabular": ["    &  Rank of ", " Rank of  &  PhD Granting Institution ", " Faculty Institution  &  $ \\leq $ 4  &  $ \\leq $ 10  &  $ \\leq $ 15  &  $ \\leq $ 25 ", " $ \\leq $ 4  &  59  &  67  &  75  &  82 ", " $ \\leq $ 10  &  49  &  63  &  71  &  79 ", " $ \\leq $ 15  &  46  &  62  &  72  &  80 ", " $ \\leq $ 25  &  43  &  59  &  67  &  78  "], "ref_sec": [["<section> <title> 1 Summary </title>  Although the computer science community successfully harnessed exponential increases in computer performance to drive societal and economic change, the exponential growth in publications is proving harder to accommodate.", "To gain a deeper understanding of publication growth and inform how the computer science community should handle this growth, we analyzed publication practices from several perspectives: ACM sponsored publications in the ACM Digital Library as a whole; subdisciplines captured by ACM\u2019s Special Interest Groups (SIGs); ten top conferences; institutions; four top U.S. departments; authors; faculty; and PhDs between 1990 and 2012.", "ACM publishes a large fraction of all computer science research.", "\\newline We first summarize how we believe our main findings inform (1) expectations on publication growth, (2) how to distinguish research quality from output quantity; and (3) the evaluation of individual researchers.", "We then further motivate the study of computer science publication practices and describe our methodology and results in detail.", "\\newline (1) The number of computer science publications and researchers are growing exponentially.", "Figure [@ref:LABEL:fig:acm-pubs] shows that computer science publications experienced exponential growth (9.3% per annum), doubling every eight years.", "Figure [@ref:LABEL:fig:acm-unique] shows that the number of computer science authors increased even more than publications.", "We distinguish {established} researchers, whose publications span five or more years ( $ N_{e}=5 $ ), with authors with $ N_{e}=2 $ and $ 10 $ , and all authors.", "Authors grew 10.6% per annum at all experience levels, correlating with post-PhD participation in research publications.", "\\newline Growth stems from increasing enrollments in research programs and yet there is still unmet demand for computer science graduates and computer science innovations.", "This growth is critical for continued progress in computing.", "Publication practices will need to innovate to keep this growth from overwhelming the research publication process while maintaining rigorous peer reviewing standards, giving high quality feedback to authors, and moderating reviewer workloads.", "For example, communities are experimenting with practices such as tiered reviewing, increasing participation in the reviewing process, and limiting repeated reviewing of rejected submissions to multiple venues.", "We need these innovations and more to support individual researcher\u2019s careers and scientific progress.", "\\newline (2) Research quantity and quality are not correlated.", "As is well recognized, the volume of research output is not and should not be used as a proxy for research quality [@bib:CAL:2015,CRA:TPH:2015,JudgingQuality:2003] , but nor is high output an indicator of low quality or vice versa.", "Research output per author has actually declined between 1990 and 2012 as measured by fractional authorship.", "Figure [@ref:LABEL:fig:acm-fraction-papers-per-author] shows that the weighted publications per author.", "Each author on a paper accrues a fractional publication as a function of the total number of authors.", "We plot the 50th (median), 90th, and 99th percentile authors.", "Figure [@ref:LABEL:fig:acm-raw-papers-per-author] shows while the raw number of papers for the 99th most prolific authors has grown steadily, the 90th percentile of authors produce one or two papers per year.", "The most prolific 1% of authors produced just two papers per year when weighted for authorship contribution.", "Unweighted, this translates to five or more publications, whereas the 90th percentile of authors produce one or two publications per year.", "Furthermore graduate student growth continues to outpace faculty growth [@bib:Taulbee:2015] .", "Because producing successful graduate students requires publishing with them, each faculty member should be publishing more, but they are not.", "If some perceive that research quality has dropped over time, it is {not} due to an increase in per-author output.", "\\newline The top conferences and institutions set research standards explicitly and implicitly, in part because the U.S. computer science professoriate is disproportionately populated by PhDs trained by four U.S. departments, i.e., Berkeley, CMU, MIT, and Stanford [@bib:CAL:2015,elitism:2015,Taulbee:2015] .", "We find that authors in these four departments are equally prolific as compared to all authors, measured both in raw publications and weighted by fractional authorship (Figure [@ref:LABEL:fig:acm-institutions] ).", "We then restrict the comparison to established researchers, where an established researcher at N = 5, means their publications spanned five or more years.", "Established researchers at these four departments are slightly more prolific than all established researchers \u2014 suggesting that high output alone is not an indicator of poor quality research.", "\\newline (3) Collaboration increases the impact of individual researchers.", "We find collaboration is highly correlated with quality.", "In particular, researchers at the top four institutions collaborate more and papers in top conferences have more authors than other venues in the same subdiscipline.", "Figure [@ref:LABEL:fig:acm-percentile-avg-authors] shows shows the average number of authors per paper has systematically grown and researchers in the top departments collaborate significantly more than all authors on average (p-value $ << $ 0.0001).", "Furthermore, we find that higher rates of collaboration are strongly correlated with quality.", "We analyze in more detail the ten largest ACM Special Interest Groups (SIGs): SIGCHI, SIGGRAPH, SIGWEB, SIGDA, SIGIR, SIGSOFT, SIGARCH, SIGMOD, SIGPLAN, and SIGMOBILE.", "We compare the top venue in each subdiscipline (SIG) to collaboration practices for all venues in the SIG.", "We find more average authors on top venue papers with p-value $ < $ 0.07 for 8 of 10 SIGs.", "Only two (SIGIR and SIGARCH) were not significantly higher.", "Furthermore, we add to the evidence that it is unsound to compare publication practices (e.g., number of publications, citations, and collaborations) of computer scientists in different subdisciplines.", "For instance in 2012, SIGPLAN published 739 papers with 3.13 average authors per paper, whereas SIGCHI published the most papers at 2562 in 2012 and SIGARCH had the highest average authors at 4.00.", "\\newline Collaboration complicates the job of hiring and promotion committees, which must evaluate individuals.", "Since collaboration correlates with quality and collaboration is increasing over time, these committees should expect successful researchers to exhibit a combination of leadership, shared team leadership, and supporting roles in impactful collaborative research.", "Instead of giving no credit to collaborative research or forcing researchers to divy up credit, committees should consider magnifying the credit to individuals in highly impactful collaborations.", "Furthermore collaboration is good for training graduate students.", "They benefit from exposure to more research ideas, research styles, and research area expertise.", "The whole is sometimes more than the sum of the parts.", "\\newline We were surprised by several of these findings and it would be interesting to see what has happened since 2012.", "(We were delayed in disseminating this analysis since several fine venues chose not to publish this paper.) We sincerely thank ACM for providing a complete snapshot of their digital library.", "We hope these findings spark some new conversations around growth and the value of collaboration.", "\\newline Our summary analysis is available as supplementary material on arXiv [@bib:BMX:ACM:analysis:2019] .", "\\newline  </section>"], ["<section> <title> 2 Motivation: Publication Overload </title>  Science makes progress by identifying important problems, developing new approaches, and incrementally improving existing approaches.", "To handle growth, the computing community has introduced more venues, more papers at the same venues, tiered peer review, year-round conference submissions, and other innovations.", "However, the community is still under stress.", "Many researchers have pointed out problems stemming from growth and suggested improvements to the peer reviewing process in a spate of CACM editorials, workshops, and suggestions for best practices [@bib:culture:2015,web:kathryn:2015,usenix-atc] .", "This paper seeks to understand better the source of growth to inform how the community responds to this growth.", "\\newline Analysis of science as a whole finds that there is exponential growth in authors, publications, venues, and citations over time [@bib:exponential:2000] .", "These results indicate that as a science matures, it diversifies and specializes, adding more participants and their publications, and science progresses faster.", "In this paper, we examine computer science trends using computer science author and publication practices from the ACM Digital Library (DL), a large sample of computer science publications, focusing on 1990 to 2012.", "\\newline For our investigation, we mine ACM DL data on authors, institutions, and venues for papers in ACM proceedings (conferences, symposia, and workshops) [@bib:ACM:DL] .", "We examine subdiscipline trends based on Special Interest Group (SIG) sponsorship and compare with prior subdiscipline studies [@bib:Balzarotti:15,SE:Healthy:2014] .", "We correlate author trends with faculty and PhD student growth from the Taulbee Surveys of North American PhD-granting institutions [@bib:Taulbee:2015] .", "We consider research quantity and quality by examining ten top conferences from the most prolific SIGs and publication practices at Berkeley, CMU, MIT, and Stanford.", "We choose these institutions because they are well regarded and their PhD students dominate Northern American academic positions in computer science [@bib:CAL:2015,Taulbee:2015,elitism:2015] .", "\\newline We address questions such as: How is the field growing? Have authors changed their behaviors?", "Is there a relationship between the quantity and quality of an individual\u2019s research? Our subdiscipline breakdown by Special Interest Groups (SIGs) is motivated by citation analysis results that indicate citation practices should not be compared across subdisciplines [@bib:exponential:2000] .", "Our deeper analysis of the citation patterns of ten top conferences exposes further differences in subdiscipline citations practices over time and interactions between fields.", "We limit our analysis to ten conferences because cleaning the data is time consuming.", "\\newline <subsection> <title> 2.1 Overview of Findings </title> This section overviews all our findings on publications, authors, venues, top conferences, top departments, quantity, and quality.", "Section [@ref:LABEL:sec:methodology] presents our methodology for using the ACM DL.", "Section [@ref:LABEL:sec:analysis] presents our analysis of authors and publications in detail.", "Section [@ref:LABEL:sec:quality] examines quantity and quality based on venues, discipline, and departments.", "\\newline <paragraph> <title> Publications, authors, and venues </title> We compare growth in publications (Figure [@ref:LABEL:fig:acm-pubs] ) and authors (Figures [@ref:LABEL:fig:acm-unique] , [@ref:LABEL:fig:acm-papers-with-n-authors] , and [@ref:LABEL:fig:acm-avg-authors] ).", "We distinguish established authors with publications spanning $ N_{e} $ or more years with $ N_{e}=2,5 $ , and $ 10 $ and focus on growth from 1990 to 2012.", "These results show that the yearly increases in publications of 9.3% per annum are explained by yearly growth in the number of unique authors of 10.6% per annum.", "Figure [@ref:LABEL:fig:acm-fraction-papers-per-author] shows that authors are actually publishing {less} when measured in fractional contribution to each paper.", "Collaboration has increased steadily and thus indvidual authors are publishing slightly more when measured in raw papers (Figure [@ref:LABEL:fig:acm-raw-papers-per-author] ).", "In 2012, the most prolific 1% of authors produced five or more papers per year or 1.8 papers per year weighted by co-authorship, accounting for 3% of all publications.", "\\newline {Exponential growth in the total number of authors and more collaboration explains publication growth.", "} \\newline Individual authors are not publishing more than authors published in the past.", "Therefore, {if} the quality of publications is or has changed, the explanation is not simply rooted in author output.", "\\newline We next examine authors and venues in more detail.", "Computing research is increasingly a growing international community [@bib:international:2012] .", "The number of institutions producing publications increased at 10.8% per annum from 1990 to 2012, doubling every seven years, with most of this growth from industry and non-U.S. institutions.", "While the authors from four top U.S. departments continue to produce a disproportionate number of publications compared to their numbers, their overall fraction is dropping.", "The growth in North American PhD graduates reported in the Taulbee Survey [@bib:Taulbee:2015] correlates with publication growth.", "The per annum growth rate of PhDs granted by North American institutions from 2003 to 2014 was 7.0%.", "A consequent growth in publications is consistent with community standards that require that PhD graduate students publish in order to graduate.", "\\newline To understand venues and quality, we examined ten conferences that are recognized as extremely high quality.", "We use sponsoring ACM Special Interest Groups (SIGs) to represent subdisciplines and chose one high quality (top) conference from each of the ten most active SIGs based on the subdisciplines\u2019 judgements.", "Any quality changes in these venues over the period of our study are orthogonal to our analysis.", "The median growth in publications was 4.1% per annum and the acceptance rates at these conferences did not change.", "\\newline {While ten of the ACM\u2019s top venues are publishing an increasingly small fraction of all publications, new venues are expanding research topics and scope.} \\newline Most growth in the ACM DL was instead due to new subdisciplines and venues.", "Whereas the number of ACM-sponsored conferences grew by 6.8% per annum, doubling every decade, the number of workshops grew far faster, at 21.3% per annum, doubling every three and a half years.", "A cursory examination of workshops shows they serve a wide variety of functions.", "For example, they (a) jump-start topics that evolve into conferences, (b) become part of existing conferences, (c) last a short while, and (d) last for decades.", "New areas and deeper treatment of some topics are still flourishing and likely to generate future conferences and SIGs.", "Subdisciplines are experiencing different growth rates.", "For instance, publications in SIGCHI, SIGSOFT, SIGIR, and SIGCOMM grew by 11% to 13% per annum, substantially faster than average.", "Some new venues in these SIGs stem from specialization.", "\\newline More often however, researchers established new SIGs, such as SIGMOBILE, SIGBED, SIGKDD, SIGMM, SIGSAC, SIGWEB, and SIGHPC, and venues that both deepened and broadened research communties.", "The SIG\u2019s statements of purpose, histories, and conference call for papers reveal these trends.", "For example, several new SIGs span all aspects of their topics, e.g., the theory, programming systems, runtimes, architectures, and applications of web, mobile, and embedded systems.", "Many of the newest SIGs expanded the fastest.", "\\newline </paragraph> <paragraph> <title> Quality </title> We study the relationship between {quality} , {quantity} , and {collaboration} by comparing the ten top venues to their subdisciplines and four top U.S. computer science research departments (Berkeley, CMU, MIT and Stanford) to the field as a whole.", "We note that quantifying research publication quality and changes over time across all of computer science is essentially impossible.", "Even expert reviewers have trouble judging the quality of a given publication.", "While detecting poor quality research is relatively easily, examining best paper awards retrospectively shows that relative judgements on high quality work have poorer predictive power than author productivity [@bib:JudgingQuality:2003] .", "\\newline We find that the top conferences sustained the {same} paper acceptance rates, while the number of submissions and accepted papers grew at a median rate of 4.1% per annum.", "The publications in the respective parent SIGs grew faster, at a median rate of 10% per annum, about double the rate of these top tier conferences, reflecting a growing number of venues in each SIG.", "The number of authors on publications at top venues grew fifty percent faster than publications because authors collaborated more.", "Compared to the ACM and the sponsoring SIGs, which represent the distinct subdisciplines, the papers at top conferences have more authors.", "\\newline {Publications in eight of ten top conferences have statistically significantly more authors on average than than their subdiscipline and than the ACM as a whole.} \\newline One quality judgement the academic community makes is through faculty hiring [@bib:CAL:2015] .", "Curated Taulbee data [@bib:Taulbee:2015,elitism:2015] shows that PhDs from four top departments disproportionately dominate the professoriate at the top 25 institutions (43 to 59% of all faculty in 2014).", "Figure [@ref:LABEL:fig:acm-avg-authors] shows that four top U.S. computer science departments collaborate more than the rest of the field, averaging 3.9 authors per paper in 2012, compared to 3.4 for the field on the whole.", "However, their output is the same as the field, with the exception of their established and most prolific 1% authors, which publish slightly more than everyone else.", "The 90th percentile of researchers at four top departments publish the same modest number of papers (one or two) per year as the rest of the field, although the established 90th percentile at the top four publish slightly more (four or more papers) than other established authors in the field.", "\\newline {Compared to all authors, researchers at four top U.S. departments are similarly prolific, but collaborate more.", "The most prolific established researchers at the top four departments publish slightly more than other established researchers.", "} \\newline </paragraph> </subsection>  </section>"], ["<section> <title> 3 Methodology </title>  This section presents our methodology in detail, describing the ACM Digital Library data we use and our analysis process.", "\\newline We analyze publications and authors in the ACM Digital Library (DL) corpus [@bib:ACM:DL] , which incudes every article from conferences, symposium, journals, magazines, workshops, etc.", "that the ACM published since 1954.", "We present data from 1954, but focus on recent growth from 1990 to 2012, the last year of complete data when we started this project.", "The ACM graciously provided us with a download of the entire database of articles in late 2014 which includes metadata such as author names, venue, and date of publication.", "We restrict our analysis to ACM sponsored proceedings which include conferences, symposia, and workshops.", "The full list of venues and publications are available from the DL http://librarians.acm.org/digital-library .", "We classify proceedings by the sponsoring SIG, using DL metadata, and use them to explore subdisciplines.", "Co-sponsored events accrue to all sponsoring SIGs in the individual SIG analysis, but only once for ACM totals.", "This corpus represents a large and representative fraction of computing publications, but is not exhaustive.", "For example, some USENIX conferences, several top security venues, IEEE venues, and many international computer science venues are not included.", "Many of these publications are in the DL.", "Because, however, only ACM-sponsored venues are systematically included in the corpus, we limit our analysis to ACM-sponsored venues.", "These venues do include co-sponsored venues, e.g., co-sponsored with IEEE and others.", "We limit our top conference analysis to ten because we found classification errors on publication types (see below) that required that we hand-correct and hand-verify the analysis; a time consuming process.", "\\newline Large data sets such as this one inevitably contain errors.", "During verification of the ten sampled conferences, we found a number of classification errors, which we fixed in our analysis and reported to the ACM.", "For instance, many of the conferences including CHI, OOPSLA, and SIGRAPH include posters and/or workshop publications in the main conference proceedings and either do not use the metadata to label them, or incorrectly label them as conference papers.", "To make things worse, these errors are not systematic across instances of a given conference.", "Because this type of validation is time consuming, we did not analyze more individual conferences.", "We urge each SIG to devote resources to checking and correcting their metadata, venues names, and addressing other errors.", "\\newline We use the ACM\u2019s author identifiers for the analysis, which contain errors due to name aliasing, authors who change their name, and authors who spell their names inconsistently, such as different initials or middle name usage.", "\\newline To understand author trends over time in more detail, we define an {established author} as someone (with the same author identifier) who publishes papers spanning $ N $ calendar years, with $ N_{e} $ = 1 to 10.", "When $ N_{e} $ = 1, all authors are called \u2018established\u2019.", "When $ N_{e} $ = 2, authors become established in their second year; when $ N_{e} $ = 5, authors are established in the fifth year, i.e., four years after their first publication.", "We use $ N_{e} $ = 5 by default, but found that our analysis was not very sensitive to the choice of $ N_{e} $ [@bib:BMX:ACM:analysis:2019] .", "When restricting analysis to established authors, we remove the impact of authors who only publish once and many students who do not continue to publish after completing their degree.", "Analysis of established authors focuses on career behavior in academia, industry, and government.", "\\newline We report publishing institutions per year, which has a systematic over-reporting bias.", "On occasion author affiliation is missing.", "More common is that institutions have multiple names, over-reporting the total number of institutions.", "Author reporting of institution is more inconsistent than names.", "Institutions vary in the policy that the ACM enforces.", "We analyzed data for four top U.S. departments, checking for aliases by hand.", "As one might expect, ACM captures Stanford publications as coming from the corresponding single institution.", "On the other hand, MIT, CMU, and Berkeley have multiple department and lab institution identifiers in the DL.", "The DL counts each of these separately.", "Ambiguity also stems from Universities with multiple campuses.", "These errors tend to over-report the number of institutions.", "\\newline To analyze author growth in more detail, we use some Taulbee survey data [@bib:Taulbee:2015] .", "Since 1971 this survey has gathered enrollment, production, and employment information of PhDs and faculty in North American (U.S. and Canadian) computer science (CS) and computer engineering (CE) departments, and recently added information systems (IS) departments.", "Similar data is unfortunately not available from other countries or regions.", "The Taulbee survey held department rank constant for the top 104 in this period for analysis purposes.", "We compute tenure-track faculty and PhD production per annum growth rates using data from 2003 and 2014 from 104 reporting and ranked CS and CE departments obtained from Betsy Bizot at the Computing Research Association (CRA) \u2014 the data for these years and departments was easily available.", "\\newline To examine quality, we consider the behavior of authors at four top departments: Berkeley, CMU, MIT, and Stanford.", "Taulbee ranks these four departments as the top departments.", "One distributed judgement of quality is faculty hiring, which supports this ranking.", "Clauset et al. show that the hiring practices over 205 North American computer science departments between May 2011 and March 2012, suggests a ranking of Stanford (1), Berkeley (2), and MIT (3), CMU (7), and Cal Tech (4) [@bib:CAL:2015] .", "(The size of PhD granting department is not a statistically significant factor in PhD placement [@bib:CAL:2015] .) We use the 2003 and 2014 Taulbee data to report current PhD employment as a function of PhD granting institution in the top ranked departments [@bib:elitism:2015] and then compare publication practices at the top four to the wider community.", "This ranking selects the top four we use in our study.", "\\newline  </section>"], ["<section> <title> 4 Publication Trends </title>  This section starts with aggregate author and publication trends over time, and then examines departments, institutions, venues, and subdisciplines in more detail.", "\\newline <subsection> <title> 4.1 Publications and Authors </title> Figure [@ref:LABEL:fig:acm-pubs] presents the articles newly published in proceedings each year.", "In the modern computing era between 1990 to 2012, the number of published articles per year grew exponentially from 2,650 to 14,521, a factor of 5.5 (9.3% per annum) \u2014 not quite as fast as the doubling of transistors every two or so years delivered by hardware manufacturers.", "This substantial growth in publications is hardly a surprise.", "\\newline In the same period, the number of unique authors per year grew {faster} , at 10.6 % per annum from 4,865 authors to 35,725, a factor of 7.3.", "Figure [@ref:LABEL:fig:acm-unique] plots the number of unique authors and established authors by year.", "In 1990, there were 1253 unique established authors ( $ N_{e} $ =5), which grew to 15,232 in 2012, a factor of 12.2.", "The growth in established authors is interesting when coupled with with the slower rate of U.S. faculty growth (see Section [@ref:LABEL:sec:phd-faculty] ) and recent findings that document substantial growth in international computer science research [@bib:international:2012] .", "Together they suggest more research participation world-wide coming from industry and government, not just academia.", "\\newline The growth in active authors each year is higher than the growth in publications, but this difference is only in part explained by increases in collaboration.", "Figure [@ref:LABEL:fig:acm-avg-authors] plots the average number of authors per paper, which has risen from 2.1 in 1990 to 3.4 in 2012.", "Since the mid-eighties, the average number of authors per paper from the top four departments has consistently been higher than for the ACM as a whole.", "Figure [@ref:LABEL:fig:acm-papers-with-n-authors] plots a line as a function of year and shades the region for the percentage of publications with one, two, three, four, and five or more authors.", "The lowest line is one author ( $ N=1 $ ).", "Since the late 1960s, publications increasingly have more authors every year, but as late as 1980, 50% of publications had only one author.", "In 2012, 23% of publications have four or more authors, whereas in 1990 just 6% did.", "The proportion of single author papers per year has declined over time from 34% in 1990 to 11% in 2012.", "Section [@ref:LABEL:sec:quality] shows that ten top conferences and researchers from four top U.S. schools have even more authors on average.", "\\newline Several hypotheses may explain the increase in collaborations.", "For example, a cultural change may have occurred in which advisors play a larger role in the research process, or their role is acknowledged more, and thus faculty appear on more of their students publications.", "Increases in collaboration may be due to the type of research.", "Computer science is increasingly impinging upon and enabling other disciplines.", "Multidisciplinary research that combines distinct sub-disciplines in computing or other fields, such as computational biology or finance requires more expertise, which is easier to acquire by adding a co-author compared to earning a degree or otherwise gaining sufficient background in another field.", "Larger more sophisticated and ambitious projects may require more people to build and understand the entire system.", "For instance, when the DaCapo NSF ITR project built performance evaluation methodologies for managed languages and a Java benchmark suite [@bib:DaCapo] , it required developing new tools; new analysis; new data sets; modifying about 30 active open-source projects; and then evaluating and discarding some candidate benchmarks.", "The result was a publication with 20 authors.", "The data shows collaboration is increasingly common.", "\\newline Figures [@ref:LABEL:fig:acm-raw-papers-per-author] and [@ref:LABEL:fig:acm-raw-papers-per-established-author] show the {raw} mean number of publications per author and per established author per year, as well as the number of publications per author for the 90th and 99th percentiles.", "Note that these statistics are {not} computed per individual author year over year.", "The mean publications per year per author rose from 1.2 in 1990 to 1.4 in 2012, 0.7% per annum.", "The 90th and 99th percentiles report number of papers published by the author at the respective percentile.", "For the most prolific 1% of authors, raw papers per year has risen from 3 and 4 to 6.", "Among established authors, the mean publications per year per author grew slowly from 1.4 to 1.7.", "The 99th percentile most prolific established authors had 5 publications per year in 1990 and now have 7.", "These publications comprised 1,412 out of 14,521 papers in 2012 (9.7%).", "Consequently, although eye-catching, these authors have relatively low impact on the field as a whole.", "Whereas 90% of all authors produce one or two papers each year, 90% of established authors produce one, two, or three papers.", "\\newline Figures [@ref:LABEL:fig:acm-fraction-papers-per-author] and [@ref:LABEL:fig:acm-fraction-papers-per-established-author] show the {fraction} of publications per author and per established author per year, for the median as well as the 90th percentile and 99th percentiles.", "We compute the fractional publications per author by partitioning the publication equally among the authors and summing for each author each year.", "Author output has declined since 1990 by this metric.", "The median author was responsible for 0.5 publications in 1990, and in 2012 is responsible for 0.33 publications.", "The 90th percentile of all and established authors follows the same trend.", "The 99th percentile authors dropped from 2 publications to 1.8.", "The median established author has the same trend, dropping from 0.5 to 0.33 publications per year.", "The 99th percentile fluctuates more in this period: 2.33 in 2000, to a high of 2.81 in 2005, and a low of 2.25 in 2012.", "This data taken together with the rising average number of authors per publication shows that author output is relatively constant, even for the most prolific authors, when normalized by author count.", "\\newline </subsection> <subsection> <title> 4.2 North American PhD and faculty growth </title> This section examines the correlation in author growth with PhD and faculty growth.", "Table [@ref:LABEL:fig:faculty-phd] presents the growth in North American PhD production per year between 2003 and 2014 and faculty size for 104 ranked departments from the Taulbee data.", "PhD production increased at 7% per annum, whereas the number of faculty grew by 1.4% per annum.", "On average, an increase in PhD students per faculty member represents an increase in workload.", "Comparing with author growth rate (10.6% per annum) and established researcher growth rate, this reveals that much author growth is from authors in student cohort, industry, government, and international institutions, rather than North American faculty [@bib:international:2012] .", "\\newline Note that the faculty of top ranked departments grew more than lower ranked departments.", "Furthermore, overall they produce a disproportionate fraction of North American PhDs \u2014 44% of PhDs graduated from the top 25 ranked schools in 2014, slightly lower than the 48% in 2003.", "The fraction of PhD students from four top schools has not changed \u2014 four schools have disproportionally produced 12% of all U.S. PhDs since at least 2003.", "\\newline </subsection> <subsection> <title> 4.3 Institutions </title> Figure [@ref:LABEL:fig:acm-institutions] plots the number of unique institutions with one or more publications each year and compares it with growth in papers.", "We include each institution only once regardless of the number of authors or papers.", "The ACM directly computed only this data on all publications in the DL, including ones not published by the ACM (without the restrictions described in Section [@ref:LABEL:sec:methods] ).", "Note that the publications are close to 100,000.", "We did not use this dataset for the other analysis because many non-ACM venues were not consistently included, as shown by the declines.", "The number of institutions grew at a rapid pace, 8% per annum from 1990 to 2012.", "Growth in institutions would likely be lower if the institutional data reporting was more systematic (see Section [@ref:LABEL:sec:methods] ).", "According to the 2014 Taulbee report [@bib:Taulbee:report:2014] (page 2), in 1995 there were 133 U.S. CS departments and in 2014, there were 188, a growth rate of 1.8% per annum.", "Total CS, CE, and IS departments in the U.S. and Canada grew slightly faster at a rate of 2.7% per annum.", "Institutional growth thus stems more from increases in international academic participation in computing research, as well as government and industry world-wide, as documented by previous work [@bib:international:2012] .", "Since participant growth outstrips institutional growth, the unique researchers at other institutions must be growing as well.", "\\newline </subsection> <subsection> <title> 4.4 Venues </title> Figure [@ref:LABEL:fig:acm-venues] presents the total number of conferences (identified as \u2018conference\u2019 and \u2018symposium\u2019), workshops, and other proceedings publications published by the ACM.", "The number of ACM-sponsored conference venues grew at 5.9% per annum from 47 to 167, but has been relatively flat since 2007.", "On the other hand, the number of workshops grew at 17% per annum, from 6 to 190.", "If workshop organizers are becoming more likely to include their proceedings in the DL, then the growth rate for workshops would be over-reported.", "The growth in venues is slightly more than the growth in publications, but well below the growth in authors.", "Workshops are a predictor of new research directions that subsequently create SIG and conference venues, and thus signal that the field continues to grow.", "\\newline </subsection> <subsection> <title> 4.5 Subdiscipline analysis by SIG </title> This section examines growth by subdisciplines based on the sponsoring ACM Special Interest Group (SIG).", "Table [@ref:LABEL:tab:sigs] presents the sponsoring SIG, the number of publications and average number of authors in 2012.", "Columns four and five present growth rate per annum for publications and authors from the period 1990 to 2012 (except where noted in the last column).", "We order the table by the number of publications in 2012.", "If a conference is co-sponsored by multiple SIGs, we credit it to both SIGs in this analysis \u2014 3,102 publications fall into this category.", "The sum of all the SIG publications (17,623) is thus larger than the last row, which presents all proceedings papers in the ACM DL (14,521) from 1990 to 2012, where each publication is counted only once.", "The table clearly shows the distinct collaboration patterns among subdisciplines, with systems-oriented SIGS such as SIGCOMM (4.16), SIGARCH, SIGOPS, SIGBE and SIGMOBILE having the highest average authorship, and SIGACT (2.66) having the lowest.", "This finding is consistent with statistically significant differences found between citation and collaboration networks among disciplines and subdisciplines [@bib:BMG:2004] .", "In other words, it is unsound to compare scientists in different disciplines and subdisciplines based on collaboration, publication, and citation patterns.", "\\newline SIGCHI has the most publications and their number has grown at an above-average rate \u2014 15% per annum compared to 9.3% of ACM as a whole.", "Eight SIGs have very high growth rates: SIGWEB, SIGIR, SIGMOBILE, SIGKDD, SEBED, SIGSA, SIGSPATIAL, and SIGACCESS.", "While the least prolific SIGs generally have low growth rates, several of the newest SIGs (SIGSPATIAL, SIGACCESS, and SIGecom) are not yet prolific, but they are growing at above average rates (19, 15, and 10% per annum respectively).", "\\newline Subdiscipline growth in computing has spurred new venues and new special interest groups.", "The addition of fifteen SIGs and the demise of two in this period, as noted in the table, shows both the dynamism of our field and the growth in subdisciplines.", "The new venues are not only specializing.", "Many of the new SIGs seek to both deepen the treatment of a topic and at the same time broaden it.", "For instance, Victor Bahl and Imrich Chlamtac, researchers who were publishing often in SIGCOMM and IEEE INFOCOM, started SIGMOBILE in 1996 to deepen the treatment of wireless networking as a distinct discipline and to establish a broader community studying mobility of systems, users, data, and computing [@bib:web:sigmobile] .", "SIGMOBILE help establish the community and clearly remains an important research venue.", "Publications in SIGMOBILE grew at the second most rapid rate of all the SIGs at 26% per annum and participants grew at 27% per annum.", "Only SIGBED grew faster, at 28% (publications) and 29% (authors) per annum.", "SIGBED is a similar example of a SIG that was created to cover all aspects of a topic, in this case, embedded computing.", "Whereas SIGHPC was formed to recognize an existing community, most new SIGs, e.g., MOBISYS and SIGBED, built new communities.", "These SIGs are breaking down some of the traditional subdiscipline boundaries between theory, compilers, hardware, networking, and applications.", "New SIGs are defining communities with shared research interests, often beyond traditional subdiscipline boundaries.", "\\newline </subsection> <subsection> <title> 4.6 Summary </title> Most publication growth stems from new conference and workshop venues that deepen and diversify research areas.", "Individual author output has declined, even for the most prolific authors, when measured in fractional authorship.", "When measured in raw publications, authors have modestly increased their output over this period, mostly by collaborating more.", "The very modest increases in raw output for the average author, established authors, and even the most productive authors (all less than 2% per annum) is not the source of the 9.3% per annum growth in total publications.", "The growth in computer science publications stems from the growth of the field as whole \u2014 more researchers working on more topics.", "\\newline </subsection>  </section>"], ["<section> <title> 5 Quality </title>  This section examines quality from the perspective of venue and researcher institution.", "(1) We sample ten top conference venues.", "These ten conferences differ from the field as a whole: they are growing more slowly and their average paper has more authors than their subdiscipline, as represented by their sponsoring SIG.", "(2) We examine departmental hiring, PhD production, and the research output of four top ranked departments.", "These departments hired more faculty and disproportionately produced faculty for other departments.", "Researchers at these four departments are similarly productive as other researchers, but they collaborate more.", "\\newline <subsection> <title> 5.1 Venue Quality: Top conferences </title> This section considers a sample of top ACM conferences and compares their trends with those of their parent SIGs and ACM overall.", "From each of the ten most prolific SIGs, we chose one of the most prestigious venues based the SIG web page, citation counts, and our personal experience.", "These conferences are widely considered as very high quality and their high citation rates show that they significantly influence scientific progress.", "Table [@ref:LABEL:tab:conferences] presents for each conference: its publication growth rate and that of its parent SIG; its author growth rate and that of its parent SIG; the average number of authors per paper in 2012 for it and its parent SIG; the student T-test $ p $ -value comparing the average number of authors per paper in the SIG (minus the conference) and the conference in 2012; whether the submissions are double-blind; the acceptance rate in 2012; and finally, the change in paper acceptance rate for the conference over the period.", "\\newline Publication growth rates at conferences, except for WSDM, are much lower than their parent SIGs and the ACM as a whole, varying from 8.2% per annum for CHI to 1.3% per annum for ISCA, with most between 2% and 6% per annum, with a median of 4.1%, which is substantially lower than the median 10.4% per annum growth rate for their parent SIGs and 9.3% for the ACM as a whole.", "Growth in total author numbers is also consistently lower in the conferences (except WSDM) than their parent SIG and ACM as a whole.", "The conference median growth rate is 6.3% per annum, just half that of the parent SIGS.", "The SIG authorship pool grew at 12.9%.", "Similar to the ACM as a whole, average authors at the top conferences grew substantially faster than publications.", "\\newline In all cases, the average number of authors per paper in the top conference is larger than the average number of authors on all papers sponsored by the SIG.", "We use the Student T-test to determine whether this difference is statistically significant.", "We compare the average authors on all publications in the sponsoring SIG minus the conference, with the conference.", "The table presents the $ p $ -values.", "For all conferences except for ISCA and SIGIR, the $ p $ -value $ <0.07 $ , which means that the higher number of authors per paper is strongly correlated with the highest quality venue.", "\\newline Finally, conferences have essentially not changed their acceptance rates.", "These results are consistent with the subjective assessment that the top venues in our field are maintaining very high standards whilst seeing a modest growth in publications and a somewhat larger growth in author participation.", "\\newline </subsection>  </section>"], ["<section> <title> 6 Visualizing venue citations </title>  We designed a series of visualizations to analyze citation patterns as a function of venue in more depth.", "Figures [@ref:LABEL:fig:pldi-in-out] and [@ref:LABEL:fig:pldi-survival] shows two example \u2018flowers\u2019 for PLDI.", "Flowers for a wide range of conferences are available on the ANU\u2019s Computational Media Lab\u2019s webpage [@bib:web:anu-cml-2019] .", "More motivation and descriptions of these visualizations are in a separate paper [@bib:shin2019influence] .", "Because ACM citation data is limited to ACM DL venues, these visualizations use data from the Microsoft Academic Graph (MAG) [@bib:sinha2015overview] .", "MAG curates a much larger corpus of computer science venues than ACM and it provides an open-access querying and analysis of all their citation data.", "\\newline Figure [@ref:LABEL:fig:pldi-in-out] visualizes the amount of incoming and outgoing citations between PLDI and 25 other venues.", "The plot contains a union of 25 venues that cite PLDI papers the most, or outgoing scientific ideas from PLDI (in red), and top 25 cited by PLDI papers, or incoming scientific ideas (in blue).", "We place PLDI at bottom center, and place the other venues, including both journals and conferences on a half-circle.", "Edge width represent the volume of citations in either direction.", "Nodes are sized by the total volume of citations in either direction, and ordered (from right to left, blue to red) by ascending ratio of outgoing ideas to incoming ideas.", "In other words, the six blue-ish nodes such as Communications of the ACM are cited more by PLDI than they cite PLDI; and the 25 red-ish nodes cite PLDI more than PLDI cites them.", "\\newline The incoming/outgoing flow to PLDI itself, by definition, are equal, and of high volume (thick edges).", "We can see that PLDI, focusing on programming language design and implementation, is influenced by broad-scope computer science journals such as Communications of the ACM and conferences such as Operating System Design and Implementation (OSDI).", "PLDI in turn influences conference such as ASPLOS (International Conference on Architectural Support for Programming Languages and Operating Systems) and the more specialized ECOOP conference (the European Conference on Object-Oriented Programming).", "\\newline Figure [@ref:LABEL:fig:pldi-survival] describes citation survival over time \u2014 the fraction of papers (that are at least X years old) that are cited at least once more than X years after being published.", "We can see that about 90% (at x=0) of PLDI papers are cited at least once, and 60% of papers are still being cited after 20 years.", "Quantifying the long-term impact of papers and venues has been of interest to the computer science and science communities alike [@bib:wang2013quantifying] .", "Citation survival graph is an intuitive visualization tool for this purpose.", "\\newline Such in-depth analysis of citation statistics for a venue provides a view of scholarly impact that complements the ones based on authors and organizations.", "These graphs visualize the flow of ideas among communities, quantify the pace of innovation or the last impact of a scientific community, and trace the interaction among different sub-disciplines.", "\\newline Just as any data sourced from the world-wide web, the data quality on citations is not perfect.", "While the number of PLDI papers found by the MAG mostly agree with the statistics at the publisher, for some venues there are missing or spurious paper entries.", "Such data issues can arise from data recording ambiguity at publishers, conference (or journal) venue resolution, publishing of the same or similar papers with varying detail in different venues, and a variety of other sources.", "While we recommend that the academic community embrace quantitative tools for visualizing and analyzing scientific impact, we caution the reader to take online statistics with a grain of salt, and validate them with well-known community know-how when such knowledge exists.", "\\newline  </section>"], ["<section> <title> 7 Top Department Behavior </title>  This section further explores the relationship between quality and productivity by examining practices at four top departments.", "Clauset et al. observe that faculty hiring is an assessment of research and training quality that is widely distributed and fundamentally shapes academic disciplines [@bib:CAL:2015] .", "Across computer science, business, and history, they find doctoral prestige predicts faculty hiring, reflecting social inequality in academia.", "For instance, department prestige predicts PhD production, increasing social advantage, and women place worse than men even with a degree from the same program.", "Clauset et al. identify Stanford (1), Berkeley (2), MIT (3), and CMU (7) as dominant producers of computer science faculty between May 2011 and March 2012.", "Using Taulbee data for 2003 and 2014 with current PhD granting institutions of the faculty at 104 departments, we select these four departments.", "We correlate these quality judgements to productivity.", "We find researchers at four top departments are neither more nor less productive than all authors in the ACM, except for the very most productive established authors at these four institutions.", "\\newline We find researchers at four top departments are much more collaborative than other researchers with 3.92 average authors per paper in 2012, compared to 3.37 for all of ACM.", "Using the Student T-test, we compare the average number of authors per paper from all of ACM with papers from top departments in 2012 and obtain a $ p $ -value $ <<0.0001 $ .", "Figure [@ref:LABEL:fig:acm-avg-authors] shows the trends over time \u2014 researchers at four top have become increasingly more collaborative over time.", "Deeper bibliometrics analysis shows that collaboration networks are deeply coupled with citation networks and reinforce scientific influence [@bib:BMG:2004] .", "\\newline We illustrate these networks with the Taulbee data, which holds rank constant over time for purposes of longitudinal analysis [@bib:Taulbee:2015] ."]], "target": "Based on faculty hiring, North American computing departments support the Taulbee ranking as shown in Table . Each column in the table presents the percentage of faculty that earned their PhD at one of the top 4, 10, 15, and 25 departments and is now on the faculty of the row ranked department. Hiring reflects this ranking since a disproportionate amount, 43% of tenure-track faculty at the 25 top ranked U.S. departments, earned their PhDs from one of these four departments. Furthermore, 78% of faculty at the top 25 institutions earned their PhDs from a top 25 institution."}, {"tabular": ["  Scenario  &  TX  &  RX  &  Examined <ln> Area <ln> (m $ {}^{2} $ ) <ln> ", " EIRP <ln> (dBm)  &  Height <ln> (m)  &  Distance <ln> to TX <ln> (m)  &  Height <ln> (m)  &  Max <ln> Throughput <ln> (Gbps) ", " Mesh  &  32  &  6  &  200  &  6  &  1.0  &  10 $ \\times $ 20 ", " Picocell  &  32  &  6  &  50  &  1  &  1.5  &  10 $ \\times $ 20 ", " Peer-to-Peer  &  23  &  1  &  10  &  1  &  1.5  &  4 $ \\times $ 5  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Wireless communication has always been more vulnerable to attacks than its wired counterparts.", "The fact that wireless signals are broadcast means they are more easily eavesdropped.", "This weakness has been exploited in many wireless networks [@bib:crack_bluetooth,sheldon2012insecurity,crack_wepwpa] .", "Even more recent security protocols like WPA2-PSK have been successfully compromised by snooping attacks [@bib:crack_wpa2psk,nakhila2015] via simple tools [@bib:aircrack] .", "Despite existing encryptions, one can still infer the specific sources of traffic by observing just packet sizes and counts in data transmissions [@bib:pet-http,marc06inferhttp] .", "\\newline While we continue to improve encryption algorithms, an equally promising direction is to use wireless beamforming to defend against eavesdroppers at the physical layer.", "Beamforming allows a transmitter (TX) to send a highly focused, directional signal towards a target receiver (RX), so that nearby attackers not directly between the two endpoints cannot capture the transmission.", "The narrow beam is built by leveraging signal cancellations among multiple antennas in a phased array , and is most easily built on millimeter-wave (mmWave) transmitters [@bib:mmwave_secure] .", "For example, 60GHz phased arrays could fit on small devices like smartphones, and can generate highly focused beams ( e.g., 3 $ ^{\\circ} $ using 32 $ \\times $ 32 antennas) while achieving Gbps throughput.", "\\newline While earlier applications focused on short-range indoor applications, e.g., home routers [@bib:tplink11ad] and wireless virtual reality headsets [@bib:htcvive60g] , new applications of mmWave leverage its high directionality and throughput for long-range communication.", "Many such applications have already been deployed.", "Facebook has deployed a mesh network using 60GHz communications in downtown San Jose [@bib:facebook_sanjose] .", "Google is considering replacing wired fiber with mmWave to reduce cost [@bib:googlefiber] .", "Academics have proposed picocell networks using mmWave signals towards next 5G network [@bib:marzi_globecom15,picocell_tracking,zhu14a] .", "\\newline With a growing number of deployed networks and applications, understanding physical properties of mmWave is critical.", "One under-studied aspect of directional transmissions is the artifact of array side lobes .", "Fig. [@ref:LABEL:fig:sidelobe_example] shows an example of the series of side lobes pointing in different directions.", "Side lobes are results of imperfect signal cancellation among antenna elements.", "While weaker than the main lobe, side lobes carry the same information, and can be exploited by eavesdroppers to recover the transmission.", "As physical imperfections, they are very difficult to eliminate.", "\\newline In this paper, we conduct the first empirical study of the security properties of mmWave communications against side-lobe eavesdropping attacks.", "While theoretical studies have shown the problem of side-lobe leakage [@bib:kim2017analysis] , it is never validated using network measurements, especially for long-range communications.", "We use a commercial 60GHz testbed from Facebook\u2019s Terragraph project [@bib:terragraph] to evaluate the effectiveness of side-lobe eavesdropping in both indoor and outdoor scenarios.", "Specifically, we answer three key questions: \\newline <list> \\ How severe is mmWave side-lobe eavesdropping? (\u00a7 [@ref:LABEL:sec:measurement] ) We observe that side-lobe eavesdropping is incredibly effective in both indoor and outdoor scenarios.", "Attacker can recover transmission in a large area with high success rate (details below).", "Particularly for outdoor scenarios, most eavesdropping areas are connected, and the attacker can move freely and launch stealthy attacks.", "\\newline \\ \\ Can better mmWave hardware improve security? (\u00a7 [@ref:LABEL:sec:simulation] ) We find that improved hardware can only reduce the impact of the eavesdropping attack, but not fully defend against it.", "Eavesdropping side lobes is still possible even after removing hardware artifacts from antennas and deploying more antenna elements.", "\\newline \\ \\ Are existing defenses effective against side-lobe eavesdrop attacks? (\u00a7 [@ref:LABEL:sec:existing] ) Although existing defenses show promising results against single-device eavesdroppers, they either impose impractical hardware requirements, or remain vulnerable against more advanced attackers, e.g., those with multiple devices.", "\\newline \\ </list> \\newline  </section>"], ["<section> <title> 2 Background </title>  To provide context for later study, we first describe the adversarial model and then our measurement methodology.", "\\newline Adversarial Model.", "We consider passive eavesdropping, where an attacker listens to side-lobe signals and recovers packet header or payload.", "The attacker stays hidden from its victim TX and RX, but is unable to manipulate the communication between the victims.", "Without knowing the attacker\u2019s physical location, victims cannot apply conventional defenses like null-forming .", "\\newline We do not consider eavesdropping attacks on the main lobe of the transmission.", "Such an attack would affect the communication between TX and RX, as the attacker has to stay inside the main lobe or use a reflector, and thus can be detected [@bib:steinmetzer2015eavesdropping] .", "Finally, we assume the attacker has one or more synchronized devices as powerful as the victim\u2019s hardware.", "The attacker knows the victim\u2019s location and hardware configuration .", "The attacker and his device(s) are free to move around the victims.", "\\newline Application Scenarios.", "We consider three practical scenarios where mmWave signals are commonly used: mesh networks [@bib:facebook_sanjose] , picocell networks [@bib:zhu14a] , and indoor peer-to-peer transmissions [@bib:tplink11ad,htcvive60g] .", "Fig. [@ref:LABEL:fig:scenarios] shows an illustration of the three.", "\\newline mmWave signals are commonly considered for indoor peer-to-peer scenarios (Fig. [@ref:LABEL:fig:scenarios] (c)), e.g., virtual reality [@bib:htcvive60g,abari17enabling] and wireless display [@bib:delldock] .", "Here TX and RX are within very short range ( $ \\leq $ 10m) and often at the same height ( $ \\sim $ 1m).", "As mmWave signals degrade much faster than lower frequency signals in the air, it is less known that they can also be used outdoor for long-range communications (20\u2013200m).", "For example, Facebook has deployed a mesh network in downtown San Jose [@bib:facebook_sanjose] , supporting up to 200m link using 60GHz phased array radios .", "Researchers [@bib:marzi_globecom15,zhu14a] also propose picocell networks using 60GHz signals.", "In both scenarios, TX is mounted higher than human height, e.g., 6m. Depending on the scenario, RX is either mounted at a similar height or on the ground, shown in Fig. [@ref:LABEL:fig:scenarios] (a) and (b), respectively.", "\\newline Measurement Hardware.", "Our testbed consists of three identical 60GHz radios.", "We use them as TX, RX, and the attacker.", "Each radio has a 16 $ \\times $ 8 rectangular phased array (Fig. [@ref:LABEL:fig:testbed] ) and follows the 802.11ad single-carrier standard for 60GHz communication [@bib:802.11ad] .", "Our radios are designed for outdoor mesh network scenario with a maximum Equivalent Isotropically Radiated Power (EIRP) of 32dBm, supporting 1Gbps (QPSK) transmissions at 200m range (line-of-sight). But we could re-purpose these radios for picocell and peer-to-peer scenarios as well, by lowering the EIRP.", "Each receiving radio can report received signal-to-noise-ratio (SNR) of each packet in real time.", "\\newline Measurement Setup.", "We place our testbed radios at different heights and distances apart to emulate the three application scenarios.", "In all scenarios, TX sends 32KB TCP packets to RX at 1Gbps by default."]], "target": "Equipment placement details and specifications are listed in Table . In particular for (c) peer-to-peer, we choose 23dBm EIRP the same as the commodity 60GHz chipset from Wilocity . Given TX\u2019s EIRP and the distance from victim RX to TX, RX can at best communicate with TX at 1Gbps, 1.5Gbps, and 1.5Gbps with less than 5% packet loss in mesh, picocell, and peer-to-peer networks, respectively. Further reducing TX power will affect RX\u2019s performance."}, {"tabular": ["    &  RMS  &  RMS  &  RMS  &  av $ \\pm $ std  &  max ", "  &  MRI  &  US  &  MRI-US  &  MRI-US  &  vel. ", " 3DP  &  $ 0.02 $  &  $ 0.08 $  &  $ 0.04 $  &  $ -0.02\\pm 0.03 $  &  0.96 ", " LEGO  &  $ 0.02 $  &  $ 0.03 $  &  $ 0.06 $  &  $ -0.03\\pm 0.05 $  &  0.55  "], "ref_sec": [["<section> <title> I INTRODUCTION </title>  Motion phantoms are a useful tool to validate and develop new techniques in medical imaging.", "In particular, cardiac and respiratory motion are an important source of imaging artefacts, especially for relatively slow imaging modalities such as magnetic resonance imaging (MRI) [@bib:henningsson2012whole] , [@bib:scott2009motion] , Computed Tomography (CT) [@bib:ionasec2010patient] or Positron Emission Tomography (PET) [@bib:huang2014mr] .", "Moreover, motion modelling, tracking and quantification are active areas of research, and require controlled motion data for validation, ideally from multiple sources (modalities).", "\\newline Most published work acknowledges motion phantoms as an essential tool for controlled motion experiments [@bib:cloonan20143d] .", "Effectively, two types of motion imaging phantoms are used: electrically powered phantoms, and phantoms powered by pressurised air.", "In both cases, the phantoms rely on a pump which must be located outside the scanner.", "In electrically powered phantoms (the most common type), the pump has an electric motor that is unsafe in the proximity of the MRI scanner, hence must be placed outside the 5 Gauss line, and connected to the phantom through a non-ferromagnetic transmission system [@bib:gaddum2014starling] .", "As a result, electrically powered phantoms require cumbersome set-ups and are relatively large and therefore difficult to transport.", "In the recently introduced air powered phantoms [@bib:yue2018mri] , the phantom is connected to a compressed air source, and the air pressure drives the moving parts through a pipe system.", "Compressed air sources are relatively common in hospital settings, however they are not widely available elsewhere.", "Both types of phantoms are typically expensive, bulky and large, rendering them inconvenient for use with ultrasound systems, were physical contact with the transducer (or easy placement of the transducer within a fluid medium) is required.", "For this reason, as well as in the pursue for simplicity and portability, Grice et al. [@bib:grice2016new] proposed a flow phantom for Doppler ultrasound which used gravity to move blood-mimicking fluid through a tube, by having two connected reservoirs placed at different heights.", "Basically, energy is stored as potential energy by manually sending fluid to the upper reservoir, and released as kinetic energy of the moving fluid by opening a valve.", "However, this design does not allow any other type of motion, for example intra-cardiac flows [@bib:Gomez15] .", "\\newline We propose to use a novel type of motion phantoms which do not require an external power source and are compatible with multiple imaging systems including MRI and ultrasound (US): mechanical energy storing motion phantoms.", "This new class of phantoms is flexible enough to simulate a wide variety of physiological motion patterns, including fluid flow and tissue motion.", "More specifically, we propose two self-contained phantoms: an in-house 3D printed model with a wind-up spring and a Lego built model with elastic bands.", "\\newline Most methods for image-based motion quantification (e.g. registration, tracking) require tuning modality-specific parameters, therefore introducing a potential source of discrepancy when comparing across modalities.", "In this paper, we propose a novel, modality independent method to quantify periodic motion, and discuss potential extensions to other types of motion.", "\\newline The contributions of this paper are threefold: first, we propose a novel type of motion mechanism to make motion imaging phantoms.", "Second, we demonstrate two examples of rotary motion phantoms under MRI and US imaging.", "Finally, we propose a image analysis pipeline to estimate the rotary velocity over time from the acquired images.", "\\newline  </section>"], ["<section> <title> II MATERIALS AND METHODS </title>  <subsection> <title> II-A Design Considerations </title> In order to make a multi-modality motion imaging phantom usable for medical imaging research, the design must: \\newline <list> \\ Not have any electric or ferromagnetic parts (for MRI safety and minimum artefacts in CT and US).", "\\newline \\ \\ Be water resistant (many experiments and particularly US imaging are likely to involve a water tank).", "\\newline \\ \\ Produce velocities in the physiological range, e.g. $ [1,10] $ cm/s for tissue, and $ [10,100] $ cm/s for blood.", "\\newline \\ \\ Last for longer than one physiological cycle, e.g. $ >1s $ for cardiac motion, and $ >1m $ for respiratory motion.", "\\newline \\ \\ Be customisable to the application of interest, easy to transport and set-up, and cost-effective.", "\\newline \\ </list> \\newline In this section we propose designs that meet the requirements listed above using mechanically stored energy.", "\\newline </subsection> <subsection> <title> II-B Mechanically Powered Motion Phantom </title> The proposed motion phantom concept is illustrated in Fig. [@ref:LABEL:fig:phantoms] (a).", "We propose two simple designs: a custom 3D printed model (Fig. [@ref:LABEL:fig:phantoms] (b)), where the Mechanical Energy Storage (MES) subsystem is a spiral spring and the phantom is made of a piece of reticulated foam; and a mechanism made with Lego (Fig. [@ref:LABEL:fig:phantoms] (c)), where the MES is an elastic band and the phantom is made of Lego bars.", "In both cases, the Motion Transformation (MT) subsystem is a geared transmission chain which propagates a rotary motion to the phantom.", "\\newline </subsection> <subsection> <title> II-C 3D Printed Phantom </title> We demonstrate the customised fabrication of motion phantoms by adapting an available wind-up mechanism [@bib:thingiverse1] .", "We designed a new stand, knob, and mainspring.", "The mainspring is a spiral which comes out tangent to the central axle.", "This can be parameterised as follows: \\newline <equation> $ \\begin{array}[]{cc}x(\\theta)&=R_{1}-(R_{0}-R_{1})\\frac{\\theta}{2\\pi N}\\cos(% \\theta)\\\\ y(\\theta)&=R_{1}-(R_{0}-R_{1})\\frac{\\theta}{2\\pi N}\\sin(\\theta)\\\\ \\end{array} $ </equation> where $ R_{0} $ is the inner radius (axle radius), $ R_{1} $ is the outer radius, and $ N $ is the number of turns (pitch) of the mainspring at rest.", "The last gear of the transmission system was attached to a $ 11\\times 2\\times 1.5 $ cm block of open-pore reticulated foam (Fig. [@ref:LABEL:fig:phantoms] (b)).", "The foam block rotated around its centre when the loaded mainspring was released.", "The stand had four attachments in its base to fix it to the bottom of a plastic water tank for the imaging experiments.", "The prototype parts were printed in PLA using a Delta WASP 2040 Turbo2 printer.", "\\newline </subsection> <subsection> <title> II-D Lego Phantom </title> We demonstrate the use of low-cost motion phantoms by proposing a Lego based design inspired by the Stillinger\u2019s {Supercharged Speedster} [@bib:stillinger2008crazy] .", "In this design, energy is stored in an elastic band that is winded around the axle of the first gear of a transmission chain, the last gear is connected to a $ 10\\times 2 $ Lego Technic bar (Fig. [@ref:LABEL:fig:phantoms] (c)), which rotates around its centre when the loaded band is released.", "As with the other phantom, four Lego blocks were glued to the bottom of a plastic water tank to attach the phantom for the experiments.", "\\newline </subsection> <subsection> <title> II-E Experiment Design </title> Both phantoms were imaged with US and MRI.", "US imaging was carried out with a Philips EPIQ V7 and a X6-1 transducer which was statically held at a fixed position such that the 2D imaging plane contained the rotating bar of the phantom completely.", "US acquisition settings were tuned to achieve a frame rate of 20Hz at maximum width in 2D mode.", "MRI was carried out with a 1.5T Philips Ingenia scanner, using a 2D balanced steady-state free precession (bSSFP) sequence, with a temporal resolution of $ 50 $ ms.", "\\newline For the experiments, a $ 32\\times 45\\times 25 $ cm plastic water tank was filled up with water and located on a workbench (US) or inside the scanner (MRI).", "The mechanism was wound up by the operator, to a fixed number of turns for each phantom.", "Imaging was started and immediately after the operator released the phantom, until rotation stopped completely.", "The same process was repeated 5 times for each modality and each phantom, totalling 20 acquired sequences (Fig. [@ref:LABEL:fig:images] ).", "\\newline </subsection>  </section>"], ["<section> <title> III DATA ANALYSIS </title>  Feature tracking and image registration techniques require the non-trivial set-up of a number of registration parameters (similarity measure, interpolation type, or optimisation method to cite a few) that are specific to each imaging modality.", "Hence, comparison across different modalities, which may require different parameters, is particularly challenging.", "In this paper, we propose to exploit the repetitive pattern in the appearance of the images of the rotating objects to quantify the time-varying angular velocity in a fully automatic, robust, and modality-independent way.", "\\newline Because the in-plane rotation of a block can be described with one parameter at each frame (the angle), it follows that our acquired images can be embedded in a 1D manifold, and that the embedding will be representative of the angle.", "If this was true, the image sequence would be represented as a frequency-decreasing sinusoidal wave, and a time-frequency analysis of the embedding would yield the angular velocity of the block as a function of the time.", "Figure [@ref:LABEL:fig:embedding-spectrogram] (top) shows an example of such embedding using Laplacian Eigenmaps [@bib:belkin2002laplacian] , confirming our hypothesis.", "\\newline We carried out a spectrogram analysis (Fig. [@ref:LABEL:fig:embedding-spectrogram] ) of the manifold embedding.", "The spectrogram $ \\mathcal{S}_{\\tau} $ of a signal $ r(t) $ is the power of the short-time Fourier transform (STFT), this is: \\newline <equation> $ \\mathcal{S}_{\\tau}(r)=|STFT_{\\tau}(r)|^{2}(\\omega,t) $ </equation> where $ \\tau $ is a time interval to window the computation of the Fourier transforms, and from Nyquist-Shannon sampling theorem must be chosen bigger than twice the inverse of the lowest velocity to be measured (in our case, the lowest velocity before the mechanism stops is about 0.25 Hz).", "\\newline The energy is clustered over a curve (in yellow) that indicates the main frequency of the embedding.", "It is worth noting that this frequency is equal to half the rotation rate, because each cycle in the embedding is half a rotation \u2013bar orientations 180 degrees apart are represented in the same region in the manifold.", "A spline was fitted to the spectrogram (weighted by the power).", "To remove unnecessary points, for each time sample only the $ 5\\% $ higher power rows were used.", "\\newline  </section>"], ["<section> <title> IV RESULTS </title>  A summary of the velocity consistency is given in Table [@ref:LABEL:tab:results] .", "For every phantom and imaging modality, the five velocity traces were compared over time, and gave the average angular velocity (represented as a solid line in Fig. [@ref:LABEL:fig:vel-traces] ), and the velocity dispersion (the difference between the average velocity and each individual trace)."]], "target": "The first two columns of table show the root mean square (RMS) of this intra-modality dispersion. The third and fourth columns measure the RMS and the average $ \\pm $ standard deviation (respectively) over the inter-modality difference in average velocities for each phantom. The last column reports the maximum angular velocity (on average over all experiments)."}, {"tabular": ["  Language  &  Types  &  Tokens ", " Bengali  &  7,932  &  72,614 ", " Tamil  &  14,264  &  70,258 ", " Turkish  &  10,069  &  67,362 ", " Zulu  &  13,628  &  58,027  "], "ref_sec": [["<section> <title> I Introduction </title>  Conversational speech is very different in style from broadcast news and prepared speeches, so the language models used in automatic speech recognition (ASR) of conversational speech rely on training from speech transcripts, which are more costly to obtain than more formal written text.", "Thus, data sparsity is typically the limiting factor for language model performance.", "For many less well-studied languages, there is little transcribed speech available and obtaining additional training data in the target domain is no easy task.", "An attractive alternative to collecting additional data is to direct that effort towards building models that require less training data.", "Since little additional work is needed to reuse these models, the benefit of this effort is compounded with each new language thus lowering the barrier for bringing ASR to low-resource languages.", "While new modeling approaches are valuable, it is the case that even these models benefit from additional data, and researchers have long been exploring mechanisms for using out-of-domain data in combination with a small in-domain corpus to build more robust language models.", "Different sources of spontaneous speech can help with common words, but these are often not available for less well-studied languages.", "Even with such data, covering domain-specific vocabulary typically means using written text sources for training language models for ASR.", "Finding informal text that is useful for modeling conversational speech can be a challenge.", "\\newline The Internet has been an attractive place to go for researchers looking to expand their training data, as described in the next section.", "However, if done without care, pulling large amounts of data from the Internet will give no benefit.", "For example, in work on recognizing English conversational speech in broadcast talk shows, the Google n-grams provided no benefit to perplexity or word error rate [@bib:Marin09] .", "Here, we instead propose to use only Twitter for collecting out-of-domain data for ASR language models for conversational speech.", "\\newline We have several reasons to prefer searching Twitter for data instead of the whole Internet.", "First, Twitter has a semi-structured format that makes it easy to select the user generated content and ignore ads, boilerplate text and other unwanted text.", "Second, the writing style is somewhat conversational which is a better match for the conversational speech domain than other types of writing often found on the Internet.", "Third, since Twitter is used all over the world, we will likely be able to find good data for most of the languages that we care about.", "Lastly, Twitter provides a friendly API that makes it easy to access a lot of data quickly.", "When working under a time constraint, we were able to collect as much as 6 million sentences from low resource languages in under 24 hours.", "\\newline Of course, Twitter text is notoriously noisy in that tweets often contain abbreviated or misspelled forms of words, as well as URLs, hashtags, usernames, etc.", "In this work, we describe simple language-independent methods for handling these that require filtering out a large amount of data but lead to surprisingly useful text.", "In fact, we find that Twitter text is more useful for learning word classes than the original in-domain text.", "The word classes can be used to achieve large reductions in perplexity for low-resource language models.", "Further, we introduce a prioritizing scheme for downloading text from \u201cuseful\u201d users that results in a significant improvement in vocabulary coverage over random selection.", "\\newline In the remainder of the paper, we begin by summarizing prior work on leveraging text harvested from the web in language modeling in Section [@ref:LABEL:section:related] , to provide the context for our work.", "Next, in Section [@ref:LABEL:section:twitter] , we describe our initial process for collecting data from Twitter and two methods for using the data in language modeling.", "Section [@ref:LABEL:section:experiments] contains details of experiments demonstrating the effectiveness of the collection and modeling methods.", "Finally, in Section [@ref:LABEL:section:crawling] we describe a method for prioritizing the crawling queue and how it can be applied to improve the utility of additional collected data.", "\\newline  </section>"], ["<section> <title> II Related Work </title>  This work brings together two strategies for improving language models for conversational speech in limited training data scenarios \u2013 web text collection and class language models \u2013 but changes key elements in the particular approach for both.", "\\newline As mentioned previously, there have been several efforts aimed at using text gathered from the web.", "Early work used the number of search results returned by the search engine as a proxy for the n-gram probability [@bib:Zhu_Rosenfeld:2001] , but this method does not capture the domain characteristics of the target task.", "The penalty for domain-mismatch is quite severe.", "When working with conversational speech, a small set of conversation transcripts makes for better training data than 100 times as much newswire text [@bib:Rosenfeld00] .", "Other studies find that even speech transcripts can be of little utility if there is a formality mismatch, e.g. using broadcast news as out-of-domain data for a conversational task.", "\\newline A series of papers used frequent in-domain n-grams as queries to Google for collecting text [@bib:Bulyko_etal:2003,Schwarm+04,Bulyko07] and perplexity filtering for improving the match to the target domain.", "Good results were obtained on a variety of conversational speech recognition tasks by several sites.", "Variations on this approach changing the query generation and filtering stages have also been explored [@bib:Sethy+05,Sarikaya+05,Yoshino13] or by using cross-entropy rather than perplexity as a data selection criterion [@bib:MooreLewis10,Axelrod11] .", "Recent work has shown reduced perplexity and word error rate for a task of transcribing university YouTube videos [@bib:Lecorve+12] .", "Unfortunately, this method was not effective for the low-resource languages we are working with, perhaps because of the specific choice of languages.", "Other recent alternatives have used targeted text collections, e.g. broadcast news transcripts [@bib:Marin09] and RSS feeds [@bib:web20] .", "\\newline Schlippe et al. [@bib:web20] also collected Twitter text for augmenting the language model training data and the vocabulary for a French news transcription task, which led to a small (1.5% relative) reduction in word error rate.", "The tweets are collected using topic words from the RSS feeds for a 5-day period before the show, and text normalization uses language-specific knowledge (dictionary spell checking and abbreviation expansion).", "Key differences in our use of Twitter text are the focus on general conversational speech rather than recent news topics, simple text normalization methods that are minimally language-dependent, and the introduction of a new priortization strategy for rapid collection.", "\\newline A standard approach to incorporating web text in language modeling is via n-gram mixture models, where component n-grams are trained on different data sources.", "Class language models [@bib:brown92] have been used to reduce the number of parameters in the model for combining data from different domains [@bib:IyerOst97] , but also to provide more degrees of freedom in mixture model combinations of data from different sources by allowing history-dependent mixture weights using classes [@bib:Bulyko07] .", "Because of the limited resources, the work here emphasizes reducing the number of parameters, but the novel contribution is using the out-of-domain data to learn the word classes, which turn out to be more powerful than those learned on the sparse in-domain data.", "\\newline  </section>"], ["<section> <title> III Twitter Text for Language Modeling </title>  <subsection> <title> III-A Twitter Data Collection </title> A small set of in-domain data forms the basis from which the data collection is bootstrapped.", "We want to query Twitter using phrases from the in-domain data to find additional phrases from a similar distribution.", "The queries are composed of bigrams from the in-domain data taken in descending order of frequency.", "Not all bigrams from the in-domain data are suitable queries.", "For example, due to code switching the randomly chosen query may not actually be in the target language.", "If the chosen query happens to be in English but the target language is Bengali, then keeping this query could pose a significant problem.", "If the query matches an English bigram then an overwhelming amount of irrelevant results will be returned.", "This can be avoided by checking that the query results overlap in vocabulary with the in-domain data and discarding queries that fail to meet a minimum threshold.", "In our experiments, we required an in-vocabulary hit rate of at least 10%.", "\\newline Instead of using the query results directly, we take the set of users who matched our query and then collect the entire history (up to 2,000 tweets per user) of those users\u2019 posts.", "By taking the users\u2019 histories, instead of using the query results directly, we gather sentences that have no overlap with our query words and avoid over-representing the queries in the collected data.", "\\newline Like previous researchers [@bib:web20] , we find it necessary to do significant cleaning of the Twitter text before building any language models.", "In the cleaning process, tokens such as URLs and hashtags are removed but other out-of-vocabulary (OOV) tokens such as mentions (\u201c@username\u201d) are left in place to provide appropriate context breaks when building the language model.", "Capitalization is standardized when appropriate for that language.", "We perform duplicate sentence removal to deal with spam and retweets.", "We found a consistent but small gain from exempting very short tweets (those consisting of one or two words) from the de-duplication.", "Presumably, this is because many short phrases are naturally repeated many times in conversation but the same is not true for longer phrases.", "\\newline After the text is cleaned, much of the collected data is still not useful for training the language model due to topic and style mismatch.", "We would like to select, from all of the collected text, the sentences that are the best match to our target domain.", "\\newline When the in-domain data is very limited, in-vocabulary hit rate with respect to the target domain provides a useful proxy for stylistic and topical similarity.", "In prior work [@bib:Bulyko07] , we found that a two-stage process of vocabulary hit rate followed by perplexity filtering was useful.", "Here, efforts to use the estimated n-gram probabilities to rank the Twitter sentences were not successful.", "There are two possible reasons for this.", "First, the in-domain LM training data is small and perplexity estimates on individual sentences have high variance.", "Second, for the high vocabulary growth rate languages explored here, many of the words are not in-vocabulary, so n-gram context is often broken and unigrams dominate the score.", "\\newline We put a threshold on the in-vocabulary (IV) hit rate to decide which sentences we will keep and choose the threshold that minimizes perplexity on a held-out set.", "Obviously, there is a trade-off between the amount of data used to build the language model and the degree to which the data matches the target domain.", "The optimal threshold depends upon the amount of data we have to begin with.", "As the size of the unfiltered data increases, the optimal filtering threshold becomes more aggressive.", "This is most easily seen in Figure [@ref:LABEL:fig:iv_threshold] when the unfiltered data size ranges from 14 million to 27 million tokens.", "Even though the 27 million token data is almost twice as big as the 14 million token one, the more aggressive filtering threshold on the bigger source causes them both to have about the same number of tokens after filtering.", "In our experiments the optimal vocabulary hit rate threshold tends to fall between $ 50\\% $ and $ 70\\% $ .", "Typically, only a small percentage of sentences have IV hit rates above the chosen threshold.", "\\newline </subsection> <subsection> <title> III-B Language Modeling Approaches </title> After filtering, the Twitter LM is built from the remaining sentences concatenated with the in-domain data.", "The LM is a trigram model with modified Kneser-Ney smoothing and is built using the SRILM toolkit [@bib:stolcke02] .", "This is interpolated with another LM built only from the target domain data.", "Here, the vocabulary is restricted to the words found in the in-domain data.", "\\newline Concatenating the Twitter data with the in-domain data ensures that the full vocabulary from the in-domain data is represented in the language model training data.", "Thus, the mixture model combines two components: in-domain only and the in-domain plus Twitter combination.", "The size of the in-domain data, in our case, is typically less than 1% of the size of the Twitter data.", "Except for rare words that only appear in the in-domain data, the n-gram counts of the in-domain plus Twitter combination are dominated by the Twitter data.", "\\newline As noted earlier, prior work has shown that class-based models can be useful for combining data from multiple domains, though much of the work used part-of-speech (POS) classes.", "There is no POS tagger readily available for the languages we are working with.", "Instead, we need to learn the word class assignments from the data.", "Specifically, we use the unsupervised hierarchical clustering approach from Brown et al. [@bib:brown92] .", "The clustering algorithm attempts to find the assignment of words to clusters that maximizes the mutual information between adjacent tokens in the data.", "This corresponds to maximizing the likelihood of the data assuming a bigram model.", "\\newline The benefit of using word classes is that the resulting language model can have fewer parameters than a word-based n-gram model.", "In our case, the in-domain training text is so small that it can be a real advantage to have fewer parameters to learn in the language model.", "The problem is that if the data is too small to reliably estimate word transition probabilities ( $ p(w_{i}|w_{i-1}) $ ), then it will also be difficult to learn a good partitioning of the words into classes.", "\\newline Our hypothesis is that the advantage in learning the word class assignments on the Twitter data, which solves the data sparsity problem, outweighs any performance penalty that is incurred due to domain mis-match.", "This differs from the traditional approach where the class assignments ( $ w_{i}\\in c_{j} $ ) are learned from the same training text which is used to estimate the class transition probabilities ( $ p(c_{i}|c_{i-1}) $ ) and the word probabilities ( $ p(w_{i}|c_{j}) $ ).", "Twitter data, in these experiments, refers to the concatenation of the text downloaded from Twitter with our in-domain data for the reasons described above.", "The experiments in Section [@ref:LABEL:section:class_experiments] will compare learning the class assignments on out-of-domain data (hybrid method) to the traditional approach (baseline).", "\\newline </subsection>  </section>"], ["<section> <title> IV Experiments </title>  <subsection> <title> IV-A Experimental Data </title> The in-domain data used in the experiments in this paper comes from the IARPA Babel program.", "This program focuses on keyword search for low-resource languages.", "The languages are low resource in the sense that they have fewer native speakers than the languages receiving the most attention from researchers and also in the sense that the provided training data is small in comparison to what is typically used.", "We exclusively focused on the so-called limited language pack, which consists of only ten hours of recorded telephone conversations.", "Our experiments were conducted using the Bengali, Tamil, Turkish and Zulu languages.", "The languages that we selected for our experiments have the largest vocabulary sizes (See Table [@ref:LABEL:babel] ) of the languages in the Babel program and thus suffer the most from the data sparsity problem.", "As a point of comparison, Tagalog, which was not used in our experiments, has one third as many vocabulary items as Tamil.", "\\newline </subsection> <subsection> <title> IV-B N-gram Language Models </title> We performed data collection and language model training experiments on the Bengali, Tamil, Turkish and Zulu languages.", "We were able to collect useful data for each of the four languages as seen in Table [@ref:LABEL:baseline_improvements] .", "The data collection experiment was especially successful for Turkish and Bengali.", "For both of those languages the interpolation weight given to the Twitter LM was over 20% and the corresponding reduction in perplexity was more than 12%.", "\\newline A large amount of data was also collected for Zulu and Tamil although the perplexity reduction was not as large as it was for Bengali and Turkish.", "There are a few possible explanations for this outcome."]], "target": "Both Zulu and Tamil have larger vocabularies (See Table ) than the other languages, which makes it hard to find enough webtext to adequately cover the vocabulary. For Zulu, there is an overlap in the character set with English and many Zulu speakers also tweet in English. The official Babel data also has some English words in the Zulu vocabulary. These factors combine to make it difficult to prevent the Zulu Twitter data from being polluted by a large amount of English text and could explain the relatively small gain for Zulu. However, as we shall see in the next section, the Zulu data is quite useful in the class n-gram model."}, {"tabular": ["    &    &  Fixed  &  Supervised ", "  &    &  (min/maj)  &  (min/maj) ", " CIFAR-10  &  Pr  &  0.919/0.809  &  0.928/0.801 ", " Re  &  0.792/0.914  &  0.778/0.920 ", " F1  &  0.851/0.857  &  0.845/0.854 ", " STL-10  &  Pr  &  0.882/0.666  &  0.886/0.666 ", " Re  &  0.576/0.907  &  0.571/0.903 ", " F1  &  0.694/0.772  &  0.692/0.766  "], "ref_sec": [["<section> <title> 1 Introduction </title>  The advances of deep learning models that enable automatic extraction of discriminative features from a massive amount of labeled data have eased the burden of hand-engineering them in many classification applications.", "The preparation of ground-truth labels, in turn, has become critical for those applications, and in cases where its cost is too steep, techniques to exploit additional information, such as transfer learning and weakly-supervised learning, are employed.", "\\newline The problem of class imbalance can occur in cases where the preparation of labeled data is difficult for specific classes.", "The imbalanced settings can typically deteriorate the retrieval measures for the classes of {minority} [@bib:Branco:2016:SPM:2966278.2907070,Krawczyk2016] , as well as the representation learning of deep neural nets [@bib:10.1007/978-3-319-71249-9_46] .", "\\newline On the topic of class imbalance, a large portion of the studies have focused on binary cases and multi-class cases with less than ten classes.", "However, deep learning models commonly address problems with a much larger number of classes, at which the impact is much more difficult to handle.", "In this paper, we attempt to leverage a type of weak-labels to address class imbalance over a large number, e.g., up to one hundred, of classes.", "Weak-labels are side-information used in weakly-supervised learning to complement a limited amount of labeled data.", "They are generated automatically or by inexpensive means such as labeling functions [@bib:delbp18-ratner] and crowdsourcing, and usually of low-quality or abstract-level [@bib:doi:10.1093/nsr/nwx106] .", "\\newline In this paper, we consider external knowledge in the form of abstract-labels assigned to every training instances, providing a categorization of the original classes.", "For example, training instances with classes: {{airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck} }, may be categorized with abstract-labels: {{animals, vehicles} } using a set of rules: {{bird, cat, deer, dog, fish, horse} } $ \\to $ {animals} , {{airplane, automobile, ship, truck} } $ \\to $ {vehicles} .", "We assume that, as in this example, each class is categorized by only one label.", "\\newline Such categorization can contain relevant information regarding the hierarchical structure of the classes, and provide useful guidance for learning the structure of the deep representation to counter the effect class imbalance which may be over- or under-estimation of class boundaries.", "Our intuition to exploit such abstract-labels, to this end, is to acquire deep representation which induce the separation of the subtasks, i.e., discriminating among a subset of classes categorized to each label.", "We implement a framework to associate an independent subspace of the deep features to each label and guide the instances towards the targets projected onto the corresponding subspaces.", "\\newline We build on the framework of Deep Over-sampling (DOS) [@bib:10.1007/978-3-319-71249-9_46] which drew inspiration from the classic synthetic minority over-sampling [@bib:Chawla:2002:SSM:1622407.1622416] that re-balances the class distribution by augmenting synthetic minority-class instances sampled from the neighborhood of existing ones into the training data.", "DOS integrates re-sampling into deep learning, by implementing an additional back-propagation for the output of the embedding layers to directly guide its representation learning.", "\\newline The caveat on the weakly-supervised learning is that the weak-label may not always be of ideal granularity or hierarchical structure.", "That is, enforcing instances onto orthogonal subspaces that reflect the abstract-label categorization may not be entirely beneficial.", "Alternatively, we attempt to induce a {soft} -separation of subtasks using the gradient of squared-sum error to gradually separate the representations of different labels in terms of cosine distance.", "The proposed framework can also benefit from the multi-task learning framework, where the net parameters are simultaneously trained based on the standard class prediction, which can counteract the detrimental aspects of weak-supervision.", "\\newline  </section>"], ["<section> <title> 2 Background </title>  <subsection> <title> 2.1 Class imbalance </title> Class imbalance is a practical issue, where a large discrepancy in the number of samples among classes causes the learning algorithm to over-generalize for the classes in the {majority} .", "Its effect on the retrieval measures for the {minority} classes, which is of the primary interest for many applications, is critical.", "\\newline The typical approaches to counter class imbalance include re-sampling, instance-weighting, and cost-sensitive learning.", "The re-sampling approach directly addresses the imbalance by over- or under-sampling on the training data.", "Synthetic Minority Over-sampling (SMOTE) is a popular over-sampling method, which worked successfully with many traditional classification models.", "\\newline It was demonstrated in [@bib:10.1007/978-3-319-71249-9_46] that use of SMOTE on the deep representation acquired by a convolutional neural net (CNN) under the effect of imbalance do not yield as much merit as it does with hand-engineered features.", "To address this issue, they proposed Deep Over-sampling (DOS), which implemented the sampling of the minority class into the deep learning process.", "The synthetic samples were used as supervising targets for the representation learning, which provided an additional feed-back to the embedding layers of the CNN to improve the in-class and inter-class separation among deep representation.", "\\newline With regards to the number of classes, the previous studies on class imbalance have mainly focused on binary classification and cases with a small number of classes.", "Imbalance among a large number of classes, meanwhile, has received limited attention.", "In recent surveys, the class imbalance problems been categorized between binary or multi-class and only few multi-class methods have addressed more than ten classes [@bib:He:2009:LID:1591901.1592322,Krawczyk2016,Fernandez2017] .", "\\newline </subsection> <subsection> <title> 2.2 Weakly-supervised Learning </title> Supervised learning, deep learning especially, requires a large amount of labeled data, which can be costly in some applications.", "Weakly-supervised learning exploits various side-information from crowdsourcing, heuristic labeling, external knowledge base, etc., to achieve better performances [@bib:doi:10.1093/nsr/nwx106] .", "Techniques, such as semi-supervised learning, multi-instance learning, and learning with noisy-labels are employed to address various conditions of weak-labels, including coverage, granularity, or accuracy.", "\\newline Heuristic labeling, as opposed to hand-curated annotations, require little cost for assigning weak-labels to the training data.", "In [@bib:Ratner:2017:SRT:3173074.3173077] , labeling functions written by domain experts were used to generate labels specifying the hierarchy of sub-tasks in image and document classification.", "The relation between the weak-labels and the ground-truth labels were captured using an exponential family generative model which is integrated into training the discriminative model.", "\\newline As mentioned in the previous section, we consider abstract-labels that categorize the original classes and is relevant to the task at hand, such that dividing subsets of classes with abstract-labels can reduce the complexity of the classification problem.", "But as with other weakly-supervised learning scenarios, we take into account that hierarchical structure of the label may not be ideal and possibly introduce added perplexity.", "\\newline </subsection> <subsection> <title> 2.3 Preliminary Results </title> To demonstrate the motivation of our study, we conducted an experiment with artificially imbalanced settings.", "We modify the CIFAR-10 image benchmark [@bib:citeulike:7491128] by removing 80% of the samples from selected classes.", "Then, we trained a CNN with VGG16 layers of pre-trained weights [@bib:DBLP:journals/corr/SimonyanZ14a] and two fully-connected layers of randomly initialized weights.", "\\newline Following imbalanced settings were compared in our analysis: 1) maintaining 100% of samples of all classes (Full Data), 2) maintaining 100% of samples in six classes and removing 80% of samples from four classes (Imbalanced), 3) removing 80% of samples from all classes (Balanced).", "In setting (2), we refer to the four classes from which we removed the samples as {minority} classes and the rest as {majority} classes.", "For evaluation, each experiment was repeated ten times from different initial parameters.", "The four minority classes and the removed samples were chosen randomly for each repetition.", "\\newline In Table [@ref:LABEL:tab:accuracy_prelim] , we compare the accuracies, which is standard when using the full data.", "The drop-off from (1) to (2) indicates the impact of the class imbalance.", "We note that the parameters of VGG16 net is trained on a balanced dataset, thus reduces the impact of imbalance, and that the discrepancy is much larger if the entire parameters are obtained from the imbalanced training set.", "Furtheremore, the significant difference between (2) and (3) suggests that the imbalance in sample sizes can be detrimental even if the number of samples is larger in total.", "\\newline For further investigation, we evaluated the class-wise precision and recall in (2) and (3) as shown in Table [@ref:LABEL:tab:precision/recall_prelim] .", "The first two rows show the measurements on the majority and the minority classes from (2) and the third row shows the measurements from (3).", "The impact of class imbalance is shown strongly in the recall of the minority classes and the precision of the majority classes, which are significantly worse than in (3), with smaller but balanced number of samples.", "\\newline From the preliminary results, we found that class imbalance can affect the discriminative power over the classes in the majority as well as the minority, and addressing it can be more crucial than the preparation of majority class samples.", "\\newline </subsection>  </section>"], ["<section> <title> 3 Deep Subspace Sampling </title>  <subsection> <title> 3.1 Basic Definitions </title> We denote the layers of the CNN as two groups: the embedding layers and the classification layers.", "The former projects the input onto the deep feature space, and the latter makes the class prediction from the feature vectors.", "We denote the function of the embedding layers as $ f:\\Phi\\to\\mathbb{R}^{d} $ , where $ \\Phi $ is the domain of input data.", "The function of the classification layers, whose output is the vector of class probabilities over $ k $ classes, is denoted as $ g:\\mathbb{R}^{d}\\to[0:1]^{n} $ .", "\\newline The training data is a set of input/output pairs denoted by $ {\\mathcal{X}}={(x^{(i)},y^{(i)})}_{i=1}^{n} $ , where $ x^{(i)}\\in\\Phi $ and the output $ y^{(i)} $ takes a values from a set of classes $ {\\mathcal{C}}=\\{c_{1},\\ldots,c_{k}\\} $ .", "Additionally, weak-supervision is provided by a deterministic labeling function $ \\Lambda:{\\mathcal{C}}\\to{\\mathcal{L}} $ , where $ {\\mathcal{L}}=\\{\\lambda_{1},\\ldots,\\lambda_{l}\\} $ denotes a set of abstract-labels.", "We denote the abstract-label of the $ i^{\\text{th}} $ data by $ z^{(i)} $ , i.e., $ z^{(i)}=\\Lambda(y^{(i)}) $ .", "\\newline Let $ {\\mathcal{V}=\\{f(x^{(i)})\\}} $ denote the set of projections of the input by the tentative embedding function $ f $ .", "We define the subset of $ {\\mathcal{V}} $ belonging to class $ c $ as $ {\\mathcal{V}}({c})=\\{f(x^{(i)}):y^{(i)}=c\\} $ .", "The subset of projections with abstract-label $ \\lambda $ is denoted by $ {\\mathcal{V}}_{\\lambda}=\\{f(x^{(i)}:z^{(i)}=\\lambda\\} $ .", "\\newline </subsection> <subsection> <title> 3.2 Deep Over-sampling </title> Following the DOS framework [@bib:10.1007/978-3-319-71249-9_46] , we implement an in-class neighborhood sampling over the deep projections to generate a multi-task learning training set.", "For each $ x^{(i)} $ in $ \\mathcal{X} $ , a subset of $ m $ in-class neighbors $ {\\mathcal{N}} $ defined as \\newline <equation> $ {\\mathcal{N}}_{m}\\left(x^{(i)}\\right)=\\mathop{\\arg\\min}\\limits_{\\begin{matrix}% \\mathcal{S}\\subset{\\mathcal{V}}\\left(y^{(i)}\\right)\\\\ \\#(S)=m\\end{matrix}}\\sum\\limits_{v\\in{\\mathcal{S}}}\\|f(x^{(i)})-v\\|^{2} $ </equation> is selected.", "We generate each instance of multi-task training set is as a tuple $ (x,y,{\\mathcal{N}}(x),{\\mathbf{w}}) $ where $ (x,y) $ is the original input/output, $ {\\mathcal{N}(x)} $ its neighbors, and random weights $ {\\mathbf{w}}=(w_{1},\\ldots,w_{k}) $ which sums to 1, i.e., $ \\sum_{i}w_{i}=1 $ . \\newline By randomly sampling the weights $ {\\mathbf{w}} $ , we can sample {different} numbers of tuples from a common original input/output $ (x_{i},y_{i}) $ , and we generate the training set $ {\\mathcal{X}}^{\\prime}=\\{(x^{(i)},y^{(i)},{\\mathcal{N}},{\\mathbf{w}})\\}_{j=1}^% {n^{\\prime}} $ such that the sample sizes are balanced among all classes.", "\\newline The network architecture for multi-task learning includes two outputs: one at the classification layers and the other at the embedding layers.", "The back propagation for the former output is implemented with a standard, cross-entropy loss on class prediction.", "For the latter, a squared-sum loss is defined as follows.", "\\newline <equation> $ l(x,y,{\\mathcal{N}},{\\mathbf{w}})=\\sum_{v\\in{\\mathcal{N}}}w_{i}\\|f(x)-v\\|^{2} $ </equation> ( [@ref:LABEL:eq:loss] ) is minimized when the deep representation of the original input is at an interpolation of the neighbors.", "This loss thus sets a target for the embedding function, which guides the representation towards the class-mean, as the local means distribute closer to the class mean than the original samples.", "The DOS framework makes up for induces smaller in-class variance by iteratively updating the representation with this process and \\newline </subsection> <subsection> <title> 3.3 Subspace Selection </title> The proposed framework builds on DOS to exploit abstract-labels, by guiding instances of different labels towards independent subspaces.", "This section describes two approaches for selecting such subspaces: {fixed subspace allocation} and {supervised subspace selection} .", "\\newline Let $ {\\mathcal{U}}_{i} $ denote the subspace corresponding to the label $ \\lambda_{i} $ and $ {\\mathcal{B}}_{i} $ its basis.", "For simplicity, we define the dimensionality of all subspaces to be $ p $ , such that $ p\\times{l}<d $ .", "The fixed subspace allocation simply assigns a subset of variables to each label, defining, in turn, a subspace where all complementary variables are zero.", "The basis $ {\\mathcal{B}}_{i}=\\{(b_{i1},\\ldots,b_{id})\\}_{i=1}^{p} $ is defined such that $ b_{ij}=1 $ for $ j\\in[1+p(i-1):p+p(i-1)] $ and $ b_{ij}=0 $ for all other $ j\\in[1:d] $ .", "\\newline In the supervised subspace selection, we attempt to find subspaces that preserve the discriminative information relevant to the subtask of each label.", "To that end, we adopt a supervised dimensionality reduction method, such as linear discriminant analysis, as a function into the following process.", "The function takes $ {\\mathcal{V}}(\\lambda) $ as an input and returns a primary component $ {\\mathbf{b}} $ , such as the first eigenvector, that maximizes its classification objective for a subset of classes $ \\{c:\\Lambda(c)=\\lambda\\} $ .", "\\newline A brief description of the supervised subspace selection is given as follows.", "\\newline <list> \\ Initialize the basis $ \\{{\\mathcal{B}}_{1},\\ldots,{\\mathcal{B}}_{k}\\}\\leftarrow\\{\\emptyset,\\ldots,\\emptyset\\} $ \\newline \\ \\ Set $ {\\mathcal{V}}^{1}={\\mathcal{V}} $ .", "\\newline \\ \\ For $ t=1,\\ldots,q $ .", "\\newline \\ \\ Select a label $ \\lambda_{i}\\in{\\mathcal{L}} $ \\newline \\ \\ Compute a primary component $ {\\mathbf{b}} $ by supervised dimensionality reduction over $ {\\mathcal{V}}^{t}(\\lambda_{i}) $ \\newline \\ \\ Update $ {\\mathcal{B}}_{i}\\leftarrow{\\mathcal{B}}_{i}\\cup{\\mathbf{b}} $ \\newline \\ \\ Update $ {\\mathcal{V}}^{t+1} $ with a projection of $ {\\mathcal{V}}^{t} $ such that $ {\\mathcal{V}}^{t+1}\\perp{\\mathbf{b}} $ \\newline \\ \\ Back to step 3 \\newline \\ </list> In essence, this process iteratively allocates a discriminative component to a subspace and removes it from the the original or residual representation.", "In step 4, the label $ \\lambda_{i} $ is selected randomly and evenly so that each label is chosen $ p $ times over the entire repetition, thus $ q=l\\times{p} $ at step 3.", "The steps 3-8 are not necessarily repeated until $ {\\mathcal{V}}^{q+1}=\\emptyset $ since $ q<d $ in general.", "In such a case, the basis of the residual subspace $ {\\mathcal{V}}^{q+1} $ can simply be appended to the basis of all subspaces.", "\\newline Fig. [@ref:LABEL:fig:visualization] illustrates our intuition for guiding the deep representation towards independent subspaces.", "The blue markers indicate the tentative vector representation in the deep feature space.", "Each instance comes from different classes, as indicated by callout texts and the shapes of the markers.", "Let us assume that the abstract-labels of the {airplane} and {ship} classes, indicated by solid markers, is label 1 and that of {fish} and {bird} classes, indicated by circled markers, is label 2. Let $ x $ - and $ y $ -axes represent the subspaces associated with labels 1 and 2, respectively.", "\\newline The red markers indicate the synthetic targets generated from in-class neighbors.", "The targets for label 1-classes are generated on subspace 1 and those for label 2-classes are generated on subspace 2.", "Descending the gradient of the squared-sum error, their representations are updated to be closer to the red markers.", "The green markers indicate the updated vector representation.", "\\newline By guiding representation towards these subspaces, we aim to induce a structure where the subtask can be addressed more independently, even if their representations are not strictly orthogonal, as the cosine distances among the classes assigned to different labels can grow larger.", "\\newline </subsection> <subsection> <title> 3.4 Multi-task learning </title> This section describes the multi-task learning framework which integrates representation learning using the subspaces described in the previous section.", "The overview of the framework is illustrated in Fig. [@ref:LABEL:fig:SOS_framework] .", "\\newline On the left side of the figure, the basic architecture of a deep neural net comprised of the embedding layers and the classification layers is shown.", "Their outputs are the deep representation and the class prediction, respectively.", "The input and the output makes up the original training instance, and a single-task learning can be conducted with a back-propagation from the prediction error.", "\\newline on the right side of Fig. [@ref:LABEL:fig:visualization] , the components related to representation learning with re-sampling and weak-supervision are shown.", "The synthetic target and the weak-label are additionally included in the training instance for multi-task learning.", "Another back-propagation explicitly for the embedding layers is prompted by the difference between the synthetic target and the deep representation.", "The proposed framework is referred to as Deep SubSpace Sampling (DS3).", "\\newline The training instance for multi-task learning is a tuple $ \\left(x^{(i)},y^{(i)},{\\mathbf{w}},{\\mathcal{N}}(x^{(i)}),z^{(i)}\\right) $ , where $ z^{(i)}=\\Lambda(y^{(i)}) $ .", "The loss function for the classification function $ g $ is the standard cross-entropy loss \\newline <equation> $ \\ell_{g}(x,y,{\\mathcal{N}},{\\mathbf{w}},z)=H(g(v),y) $ </equation> \\newline Additionally, the loss function for the embedding function $ f $ is defined as a weighted mean squared-sum error \\newline <equation> $ \\ell_{f}(x,y,{\\mathbf{w}},{\\mathcal{N}},z_{j})=\\alpha\\sum_{v\\in{\\mathcal{N}}}^% {k}w_{i}\\|f(x)-u(v;z_{j})\\|^{2} $ </equation> where $ u(v;\\lambda_{j}) $ denote the projection of deep feature vector $ v $ onto the subspace $ {\\mathcal{U}}_{j} $ and $ \\alpha $ is a trade-off coefficient against the first loss in ( [@ref:LABEL:eq:loss3] ).", "\\newline Recalling that $ {\\mathbf{w}} $ is a randomized weight vector, one of the merit from ( [@ref:LABEL:eq:loss2] ) is inducing robustness to avoid overfitting, similar to that of adding noise to the output of different layers.", "Another merit comes from guiding the instances toward an interpolation of the in-class neighbors and closer to the class mean.", "Subsequently, it can increase the inter-class discrepancies in the deep feature space.", "\\newline The two back-propagations based on the above two loss functions constitutes a multi-task learning of a standard classification learning and an explicitly supervised representation learning.", "Note that while the propagation from ( [@ref:LABEL:eq:loss3] ) updates parameters of all layers, ( [@ref:LABEL:eq:loss2] ) only affects those of the embedding layers.", "\\newline </subsection> <subsection> <title> 3.5 Subspace Sampling Algorithm </title> The Deep Subspace Sampling framework combines the merits of over-sampling and explicitly supervised representation learning with weak-supervision by abstract-labels.", "Its multi-task learning framework allows for (a) augmenting training set with synthetic projections of the minority class samples, (b) inducing robustness with randomized targets, and (c) separating subspaces to acquire discriminative information for different subtasks.", "\\newline The overview of the algorithm is shown in Algorithm [@ref:LABEL:alg:DS3] .", "\\newline <float> Deep Subspace Sampling algorithm \\ Input : Training set $ {\\mathcal{X}} $ , class-wise over-sampling size $ \\{r_{j}\\}_{j=1}^{k} $ , abstract-labels $ \\{\\lambda_{j}\\}_{j=1}^{l} $ , # of training rounds $ T $ \\ \\ Output : A trained CNN \\ \\ function SubspaceSelect: subspace selection method \\ \\ Method : \\ \\ Initialize CNN by single task learning with $ {\\mathcal{X}} $ \\ \\ for $ t=1,\\ldots,T $ do \\ \\ Compute projections $ {\\mathcal{V}} $ from $ {\\mathcal{X}} $ \\ \\ for $ j=1,\\ldots,l $ do \\ \\ $ U_{j}\\leftarrow\\text{SubspaceSelect}({\\mathcal{V}}(z_{j})) $ \\ \\ end for \\ \\ $ {\\mathcal{X}^{\\prime}}=\\emptyset $ \\ \\ for $ i=1,\\ldots,n $ do \\ \\ Set resampling size $ R{\\leftarrow}r_{j}:y^{(i)}=c_{j} $ \\ \\ for $ j=1,\\ldots,R $ do \\ \\ $ {\\mathcal{N}}\\leftarrow $ NeighboorhoodSampling $ (x^{(i)},k) $ \\ \\ Generate random weight $ {\\mathbf{w}} $ \\ \\ $ {\\mathcal{X}^{\\prime}}\\leftarrow{\\mathcal{X}^{\\prime}}\\cup\\{(x,y,{\\mathcal{N}}% ,{\\mathbf{w}},z)\\} $ \\ \\ end for \\ \\ end for \\ \\ Update CNN by multi-task learning with $ {\\mathcal{X}}^{\\prime} $ \\ \\ end for \\ </float> \\newline The initial embedding and classifier functions are obtained by a standard training a CNN with the original, imbalanced data, at line 5.", "The basis for each subspace is updated after each update of the CNN, at lines 8-10, assuming that the subspace selection method is supervised selection.", "If the subspace selection method is fixed allocation, it can be executed at initialization at line 6, i.e., before the start of the outer loop.", "The synthetic targets are re-computed at each iteration as in-class neighbors are updated with the deep representation.", "\\newline The trade-off coefficient $ \\alpha $ is an important hyper-parameter which controls the speed of the descent towards orthogonal representation, which could be detrimental if it is too strong, relative to the classification learning.", "Its value was selected empirically as described in the next section.", "The computationally intensive operations in this process, outside of deep learning, are the dimensionality reduction at line 9 and the neighbor search at line 13.", "A practical run time analysis is also provided in the next section.", "\\newline </subsection>  </section>"], ["<section> <title> 4 Empirical Results </title>  The empirical study is organized in three parts: (1) comparison between the two subspace selection methods, (2) sensitivity analysis on essential parameters, and (3) comparative analysis with baseline methods.", "\\newline <subsection> <title> 4.1 Datasets </title> The four image classification benchmarks were used in this experiment", "are: CIFAR-10/100 [@bib:citeulike:7491128] , STL-10 [@bib:coates2011analysis] , and SVHN [@bib:37648] .", "The properties of the datasets are summarized in Table [@ref:LABEL:tab:dataset_summary] .", "All results are reported on the default test split.", "\\newline For the CIFAR-10 and STL-10 datasets, the abstract-labels {animals,vehicles} were assigned by semantic rules .", "For the CIFAR-100 dataset, the twenty super-classes in the original dataset were used as abstract-labels.", "For SVHN, labels {odd, even} were assigned according to the class digits.", "With this set of labels, we measure the effect of abstract-labels that do not provide relevant information for the task.", "\\newline The imbalanced settings were set up by randomly selecting 50% of the classes from each label to be the minority classes and removing 80% of their samples also at random.", "\\newline <subsubsection> <title> 4.1.1 Settings and Evaluation </title> The same CNN architecture is trained by a standard single-task learning, the DOS framework, and the DS3 framework.", "The first two models are used to provide the baselines for a comparative analysis.", "For the CIFAR-10/100 and STL-10 datasets, we employed the architecture of VGG16 [@bib:DBLP:journals/corr/SimonyanZ14a] joined to two fully-connected layers of randomly initialized weights, or C64-C128-C256-C512-C512-F $ p $ -F $ n $ .", "$ p $ is the dimensionality of the deep representation vectors, which was set to $ 1000 $ , and $ n $ is the number of classes.", "For the SVHN dataset, we employed the architecture used in [@bib:10.1007/978-3-319-71249-9_46] , two convolutional layers with 6 and 16 filters, respectively joined to two fully-connected layers, or C6-C16-F400-F120.", "\\newline The number of training rounds $ T $ was set to 8, after empirical analysis described in a later subsection.", "The neighborhood sampling size $ m $ is set to five for the DOS and the DS3 framework.", "Deep learning was conducted on NVIDIA TITAN V graphic card with 2560 cores and 12 GB global memory.", "For evaluation, we measured the overall accuracy and three retrieval measures: precision, recall, and F1-score averaged over the majority and the minority classes, respectively.", "We include the accuracy for comparison against {full-data} performances.", "\\newline </subsubsection> </subsection> <subsection> <title> 4.2 Subspace Selection </title> We first compare between the two subspace selection methods: the supervised selection and fixed allocation.", "Table [@ref:LABEL:tab:subspacemethods] summarizes their retrieval measures on artificially imbalanced CIFAR-10 and STL-10 datasets.", "\\newline The third and the fourth columns show the measurements for the Fixed allocation and the Supervised selection, respectively.", "The precision (Pr), recall (Re), and F1 are averaged over the minority (min) and the majority (maj) classes.", "The averages are taken over ten repetitions.", "\\newline From the results on F1 and accuracy, the fixed allocation yielded slightly better average over the supervised selection and also smaller deviations.", "In addition, we observed that fixed allocation showed small but significant advantage in the average recall of the minority classes.", "Overall, we found fixed allocation to be a preferable approach with regards to the retrieval performances and the computational complexity.", "In the following, we report the results of DS3 with fixed subspace allocation.", "\\newline </subsection> <subsection> <title> 4.3 Sensitivity and Convergence Analysis </title> Next, we evaluated the sensitivity of the DS3 framework regarding the trade-off weight $ \\alpha $ with a grid search over five values: $ \\{0.0025,0.005,0.01,0.02,0.04\\} $ in ten repetitions over imbalanced CIFAR-10 and STL-10.", "\\newline We observed that all measures show similar tendencies, and only report the average accuracies for brevity.", "The results are summarized in Table [@ref:LABEL:tab:alpha] .", "On both datasets, the accuracies were reasonably robust over the tested values.", "We report the results in the following section for $ \\alpha=0.01 $ .", "\\newline Additionally, we empirically analyzed the convergence of accuracy."]], "target": "Fig. shows a typical run of DS3 on CIFAR-100. The $ x $ - and $ y $ -axes indicate the iteration and the accuracy, respectively. We observed that the performance can start to decline after $ 10 $ rounds, and selected $ T=8 $ for the following experiment."}, {"tabular": ["  Protein  &  SGT-PC  &  Identity ", " S9A4Q5  &  33.02  &  46.3% ", " S8TYW5  &  34.78  &  46.3% ", " A0A029UVD9  &  39.21  &  45.1% ", " A0A030I738  &  39.34  &  45.1% ", " A0A029UWE3  &  39.41  &  45.1%  "], "ref_sec": [["<section> <title> 1 Introduction </title>  A sequence can be defined as a contiguous chain of discrete {alphabets} , where an alphabet can be an event, a value or a symbol, sequentially tied together in a certain order, e.g., $ \\mathtt{BAABCCADECDBBA} $ .", "Sequences are one of the most common data types found in diverse fields such as social science, web, healthcare, bioinformatics, marketing and text mining.", "Some examples of sequences are: web logs, music listening histories, patient movements through hospital wards, and protein sequences in bioinformatics.", "\\newline The omnipresence of sequence data has made development of new sequence mining methods important.", "Some examples of its applications include: a) understanding users\u2019 behavior from their web surfing and buying sequences data to serve them better advertisements, product placements, promotions, and so on, b) assessing process flows (sequences) in a hospital to find the expected patient movement based on diagnostic profiles to better optimize the hospital resource and service, and c) analysis of biological sequences to understand human evolution, physiology and diseases.", "\\newline A fundamental requirement for data mining is the ability to measure the (dis)similarity, often translated as measuring a distance between the objects.", "In sequence mining, sequences are the objects, but finding the distances between them is challenging because they are unstructured\u2014arbitrary strings of arbitrary length.", "To mitigate this challenge, feature representations of sequence are often used.", "For example, an {n} -gram method extracts sequence features by looking at the substrings up to length {n} and embeds them in a feature vector; in an {n} -order Markov model, the sequence features are represented by the transition probability matrix.", "\\newline However, in addition to other limitations (discussed in \u00a7 [@ref:LABEL:subsec:related-work] ), most of the existing methods either limit themselves by extracting only short-term patterns or suffer from exponentially increasing computation upon extracting the long-term patterns.", "For instance, in the abovementioned {n} -gram and -Markov models, {n} is kept small due to computational limitations, and thus, unable to capture long-term patterns.. \\newline In this paper, we develop a new function, Sequence Graph Transform (SGT), that extracts the short- and long-term sequence features without any increase in the computation.", "As depicted in Fig. [@ref:LABEL:fig:sgt-unique-property] , SGT can extract any amount of short- to long-term sequence patterns just by dialing a hyperparameter $ \\kappa $ .", "This unique property of SGT removes the computation limitations; it enables us to tune the amount of short- to long-term patterns that will be optimal for a given sequence mining problem.", "Additionally, SGT is a finite-dimensional feature space that can be used as a vector for implementing any mainstream data mining, and as a graph for applying graph mining methods and interpretable visualizations.", "\\newline These properties lead to a significantly higher sequence data modeling accuracy with lower computation.", "We theoretically prove the SGT properties, and experimentally and practically validate its efficacy.", "In the following, \u00a7 [@ref:LABEL:subsec:related-work] -\u00a7 [@ref:LABEL:subsec:Solution] , we discuss the related work and the problem specification in more detail.", "\\newline <subsection> <title> 1.1 Related Work </title> Early research works used {edit} -distances between sequences after alignment.", "Methods for global alignment and local alignment, with or without overlapping, were developed by [@bib:needleman1970,smith1981] .", "Based on these methods, heuristic approaches were proposed for larger datasets [@bib:edgar2004,edgar2010,Fu2012] .", "These methods mainly focus on bioinformatics sequence problems and lack general applicability due to difficulty in tuning, high computational complexity, and inability to work on sequences with significantly varying lengths.", "Additionally, these methods do not provide any feature representation of sequences.", "\\newline More universally applicable and relatively powerful methods broadly work on one of the following assumptions: a) the sequence process has an underlying parametric distribution, b) similar sequences have common substrings, and c) a sequence evolves from hidden strings.", "\\newline The parametric methods typically make Markovian distribution assumptions (more specifically a first-order Markovian) on the sequence process [@bib:cadez2003,ranjan2015] .", "However, such distributional assumptions are not always valid.", "General {n-} order Markov models were also proposed but not popular in practice due to high computation.", "Beyond them, Hidden Markov model-based approaches are popular in both bioinformatics and general sequence problems [@bib:remmert2012,helske2016] .", "This assumes a hidden layer of latent states that results in the observed sequence.", "Due to the multi-layer setting, the first-order property is not transmitted to the observed sequence.", "However, tuning HMM (finding optimal hidden states) is difficult and computationally intensive, thus effecting HMM\u2019s {generality } and {scalability} .", "\\newline {N} -gram methods (also known as {k} -mer methods in the bioinformatics area) are the most popular approaches that work on the second assumption [@bib:tomovic2006] .", "Although the pretext of this assumption seems appropriate, the optimal selection of substring length, i.e. {n} in {n} -gram or {k } in {k} -mer, is difficult.", "In sequence mining, selection of a small value for {n } can lead to inclusion of noise, but increasing it severely increases the computation.", "Some other variants, such as {spaced-words} and adaptive {n} , are more difficult to optimize [@bib:comin2012] .", "\\newline Another class of methods hypothesizes that sequences are generated from some evolutionary process in which a sequence is produced by reproducing complex strings from simpler substrings ( [@bib:siyari2016] and references therein).", "This method solves an NP-hard optimization problem to identify the underlying evolution hierarchy and corresponding substrings.", "These substrings can also be used as features for sequence data mining.", "However, the estimation algorithms for this and similar methods are heuristics that usually do not guarantee optimality.", "The algorithms can also lead to several solutions that will cause identifiability and ambiguity issues.", "Moreover, the evolutionary assumption may not be always true.", "\\newline The above methods either limit the extent of sequence pattern extraction due to restrictive assumptions or search for (hidden) states or strings in an unobservable universe.", "This causes limited accuracy and/or computational issues.", "\\newline Besides these methods, Prefixspan [@bib:han2001] is another sequence pattern mining approach, but it works on a different type of sequence in which the sequence is a list of elements and each element consists of a set of items, e.g. \u27e8a(abc)(ac)d(cf)\u27e9. For the sequence problems addressed here, Prefixspan\u2019s performance will be similar to n-grams.", "\\newline Sequence mining problems have also been given attention by the deep learning research community.", "Embedding spaces for sequences have been proposed using Recurrent Neural Networks (RNN) and Long Short Term Memory [@bib:graves2013] .", "However, the dimension of these embeddings is typically large, and finding the optimal dimension and embeddings requires the use of rigorous optimization problems in a deep learning network.", "Training such models is computationally intensive, sometimes not interpretable and requires a large amount of training data.", "\\newline </subsection> <subsection> <title> 1.2 Problem Specification </title> The related methods discussed above fail to address at least one of the following challenges: a) feature mapping: effective extraction of sequence characteristics into a finite-dimensional feature space (a vector), b) universal applicability: this requires the absence of distributional or domain-specific assumptions and a small number of tuning hyper-parameters, and c) scalability: it relies on the computational complexity, which should be small with respect to sequence length, size of the database and the alphabets set.", "\\newline We propose a new sequence feature extraction function, Sequence Graph Transform (SGT), that addresses all of the above challenges and is shown to outperform existing state-of-the-art methods in sequence data mining.", "SGT works by quantifying the pattern in a sequence by scanning the positions of all alphabets relative to each other.", "We call it a {graph } transform because of its inherent property of interpretation as a graph, where the alphabets form the nodes and a directed connection between two nodes shows their \u201cassociation.", "\u201d These \u201cassociations\u201d between all alphabets represent the signature features of a sequence.", "A Markov model transition matrix can be compared analogously with the SGT\u2019s feature space; however, among other differences (explored further in the paper), the associations (graph edges) do not represent a probability, and SGT is non-parametric.", "The non-parametric property also makes it robust to any underlying sequence generation distribution.", "\\newline Regardless, sequence analysis problems can be broadly divided into: a) {length-sensitive} : the inherent patterns, as well as the sequence lengths, should match to render two sequences as similar, e.g., in protein sequence clustering; and b) {length-insensitive} : the inherent patterns should be similar, irrespective of the lengths, e.g., weblog comparisons.", "In contrast with the existing literature, SGT provides a solution for both scenarios.", "The advantage of this property becomes more pronounced when we have to perform both types of analysis on the same data and implementing different methods for each becomes cumbersome.", "\\newline In this paper, our major contribution is the development of a new feature extraction function, SGT, for sequences.", "In the following, we develop SGT, and provide its theoretical support and extensions.", "We perform an extensive experimental evaluation, and show that SGT bridges the gap between sequence mining and mainstream data mining through implementation of fundamental methods, viz.", "PCA, k-means, SVM and graph visualization via SGT on real sequence data analysis.", "\\newline </subsection>  </section>"], ["<section> <title> 2 Sequence Graph Transform (SGT) </title>  <subsection> <title> 2.1 Overview and Intuition </title> By definition, a sequence can be either feed-forward or \u201cundirected.", "\u201d In a feed-forward sequence, events (alphabet instances) occur in succession; e.g., in a clickstream sequence, the click events occur one after another in a \u201cforward direction.", "\u201d On the other hand, in an \u201cundirected\u201d sequence, the directional or chronological order of alphabet instances is not present or not important.", "In this paper, we present SGT for feed-forward sequences; SGT for undirected is given in the extended version.", "\\newline For either of these sequence types, the developed Sequence Graph Transform works on the same fundamental premise\u2014the relative positions of alphabets in a sequence characterize the sequence\u2014to extract the pattern features of the sequence.", "This premise holds true for most sequence mining problems because similarity in sequences is often measured based on the similarities in their pattern from the alphabet positions.", "\\newline In the following, we illustrate and develop the SGT\u2019s feature extraction approach for a feed-forward sequence and later extend it to \u201cundirected\u201d sequences.", "\\newline Fig. [@ref:LABEL:fig:Illustration-of-effect] shows an illustrative example of a feed-forward sequence.", "In this example, the presence of alphabet $ \\mathtt{B} $ at positions 5 and 8 should be seen in context with or as a result of all other predecessors.", "To extract the sequence features, we take the relative positions of one alphabet pair at a time.", "For example, the relative positions for pair ( $ \\mathtt{A} $ , $ \\mathtt{B} $ ) are {(2,3),5} and {(2,3,6),8}, where the values in the position set for $ \\mathtt{A} $ are the ones preceding $ \\mathtt{B} $ .", "In the SGT procedure defined and developed in the following sections (\u00a7 [@ref:LABEL:subsec:SGT-definition] - [@ref:LABEL:subsec:SGT-properties] ), the sequence features are shown to be extracted from these positions information.", "\\newline These extracted features are an \u201cassociation\u201d between $ \\mathtt{A} $ and $ \\mathtt{B} $ , which can be interpreted as a connection feature representing \u201c $ \\mathtt{A} $ leading to $ \\mathtt{B} $ .", "\u201d We should note that \u201c $ \\mathtt{A} $ leading to $ \\mathtt{B} $ \u201d will be different from \u201c $ \\mathtt{B} $ leading to $ \\mathtt{A} $ .", "\u201d The associations between all alphabets in the alphabet set, denoted as $ \\mathcal{V} $ , can be extracted similarly to obtain sequence features in a $ |\\mathcal{V}|^{2} $ -dimensional feature space.", "\\newline This is similar to the Markov probabilistic models, in which the transition probability of going from $ \\mathtt{A} $ to $ \\mathtt{B} $ is estimated.", "However, SGT is different because the connection feature 1) is not a probability, and 2) takes into account all orders of relationship without any increase in computation.", "\\newline Besides, the SGT features also make it easy to visualize the sequence as a directed graph, with sequence alphabets in $ \\mathcal{V} $ as graph nodes and the edge weights equal to the directional association between nodes.", "Hence, we call it a sequence {graph} transform.", "Moreover, we show that under certain conditions, the SGT also allows node (alphabet) clustering.", "\\newline A high level overview of our approach is given in Fig. [@ref:LABEL:fig:SGT-overview-a-one-seq] - [@ref:LABEL:fig:SGT-overview-b-seq-data] .", "In Fig. [@ref:LABEL:fig:SGT-overview-a-one-seq] , we show that applying SGT on a sequence, $ s $ , yields a finite-dimensional SGT feature vector, $ \\Psi^{(s)} $ , for the sequence, also interpreted and visualized as a directed graph.", "For a general sequence data analysis, SGT can be applied on each sequence in a data corpus, as shown in Fig. [@ref:LABEL:fig:SGT-overview-b-seq-data] , to yield a finite and equal dimensional representation for each sequence.", "This facilitates a direct distance-based comparison between sequences and thus makes application of mainstream data mining methods for sequence analysis rather straightforward.", "\\newline </subsection> <subsection> <title> 2.2 Notations </title> Suppose we have a dataset of sequences denoted by $ \\mathcal{S} $ .", "Any sequence in the dataset, denoted by $ s $ ( $ \\in\\mathcal{S} $ ), is made of alphabets in set $ \\mathcal{V} $ .", "A sequence can have instances of one or many alphabets from $ \\mathcal{V} $ .", "For example, sequences from a dataset, $ \\mathcal{S} $ , made of alphabets in $ \\mathcal{V}=\\{\\mathtt{A,B,C,D,E}\\} $ (suppose) can be $ \\mathcal{S}=\\{\\mathtt{AABAAABCC,DEEDE} $ , $ \\mathtt{ABBDECCABB,}\\ldots\\} $ .", "The length of a sequence, $ s $ , denoted by, $ L^{(s)} $ , is equal to the number of events (in this paper, the term \u201cevent\u201d is used for an alphabet instance) in it.", "In the sequence, $ s_{l} $ will denote the alphabet at position $ l $ , where $ l=1,\\ldots,L^{(s)} $ and $ s_{l}\\in\\mathcal{V} $ .", "\\newline As mentioned in the previous section, we extract a sequence $ s $ \u2019s features in the form of \u201cassociations\u201d between the alphabets, represented as $ \\psi_{uv}^{(s)} $ , where $ u,v\\in\\mathcal{V} $ , are the corresponding alphabets and $ \\psi $ is a function of a helper function $ \\phi $ .", "$ \\phi_{\\kappa}(d) $ is a function that takes a \u201cdistance,\u201d $ d $ , as an input and $ \\kappa $ as a tuning hyper-parameter.", "\\newline </subsection> <subsection> <title> 2.3 SGT Definition </title> As also explained in \u00a7 [@ref:LABEL:subsec:SGT-Overview] , SGT extracts the features from the relative positions of events.", "A quantification for an \u201ceffect\u201d from the relative positions of two events in a sequence is given by $ \\phi(d(l,m)) $ , where $ l,m $ are the positions of the events and $ d(l,m) $ is a distance measure.", "This quantification is an effect of the preceding event on the later event.", "For example, see Fig. [@ref:LABEL:fig:phi-individual-effect] , where $ u $ and $ v $ are at positions $ l $ and $ m $ , and the directed arc denotes the effect of $ u $ on $ v $ .", "\\newline For developing SGT, we require the following conditions on $ \\phi $ : a) strictly greater than 0: $ \\phi_{\\kappa}(d)>0;\\>\\forall\\,\\kappa>0,\\,d>0 $ ; b) strictly decreasing with $ d $ : $ \\frac{\\partial}{\\partial d}\\phi_{\\kappa}(d)<0 $ ; and c) strictly decreasing with $ \\kappa $ : $ \\frac{\\partial}{\\partial\\kappa}\\phi_{\\kappa}(d)<0 $ .", "\\newline The first condition is to keep the extracted SGT feature, $ \\psi=f(\\phi) $ , easy to analyze and interpret.", "The second condition strengthens the effect of closer neighbors.", "The last condition helps in tuning the procedure, allowing us to change the effect of neighbors.", "\\newline There are several functions that satisfy the above conditions: e.g., Gaussian, Inverse and Exponential.", "We take $ \\phi $ as an exponential function because it will yield interpretable results for the SGT properties (\u00a7 [@ref:LABEL:subsec:SGT-properties] ) and $ d(l,m)=|m-l| $ .", "\\newline <equation> $ \\phi_{\\kappa}(d(l,m))=e^{-\\kappa|m-l|},\\>\\forall\\,\\kappa>0,\\,d>0 $ </equation> \\newline In a general sequence, we will have several instances of an alphabet pair.", "For example, see Fig. [@ref:LABEL:fig:phi-general-effect] , where there are five $ (u,v) $ pairs, and an arc for each pair shows an effect of $ u $ on $ v $ .", "Therefore, the first step is to find the number of instances of each alphabet pair.", "The instances of alphabet pairs are stored in a $ |\\mathcal{V}|\\times|\\mathcal{V}| $ asymmetric matrix, $ \\Lambda $ .", "Here, $ \\Lambda_{uv} $ will have all instances of alphabet pairs $ (u,v) $ , such that in each pair instance, $ v $ \u2019s position is after $ u $ .", "\\newline <equationgroup> <equation> $ \\Lambda_{uv}(s)=\\{(l,m):\\,s_{l}=u,s_{m}=v,l<m,(l,m)\\in 1,\\ldots,L% ^{(s)}\\} $ $ \\Lambda_{uv}(s) $ $ = $ $ \\{(l,m):\\,s_{l}=u,s_{m}=v, $ $  l<m,(l,m)\\in 1,\\ldots,L^{(s)}\\} $ </equation> </equationgroup> \\newline After computing $ \\phi $ from each $ (u,v) $ pair instance for the sequence, we define the \u201cassociation\u201d feature $ \\psi_{uv} $ as a normalized aggregation of all instances, as shown below in Eq. [@ref:LABEL:eq:psi-main-len-sensi] - [@ref:LABEL:eq:psi-main-len-insensi] .", "Here, $ |\\Lambda_{uv}| $ is the size of the set $ \\Lambda_{uv} $ , which is equal to the number of $ (u,v) $ pair instances.", "Eq. [@ref:LABEL:eq:psi-main-len-sensi] gives the feature expression for a {length-sensitive } sequence analysis problem because it also contains the sequence length information within it (proved with a closed-form expression under certain conditions in \u00a7 [@ref:LABEL:subsec:SGT-properties] ).", "In Eq. [@ref:LABEL:eq:psi-main-len-insensi] , the length effect is removed by standardizing $ |\\Lambda_{uv}| $ with the sequence length $ L^{(s)} $ for {length-insensitive } problems.", "\\newline <equationgroup> <equationgroup> <equation> $ \\psi_{uv}(s)=\\cfrac{\\sum_{\\forall(l,m)\\in\\Lambda_{uv}(s)}e^{-% \\kappa|m-l|}}{|\\Lambda_{uv}(s)|};\\textnormal{\\,length\\,sensitive} $ $ \\psi_{uv}(s) $ $ =\\cfrac{\\sum_{\\forall(l,m)\\in\\Lambda_{uv}(s)}e^{-\\kappa|m-l|}}{|% \\Lambda_{uv}(s)|};\\textnormal{\\,length\\,sensitive} $ </equation> <equation> $ =\\cfrac{\\sum_{\\forall(l,m)\\in\\Lambda_{uv}(s)}e^{-\\kappa|m-l|}}{|% \\Lambda_{uv}(s)|/L^{(s)}};\\textnormal{\\,length\\,insensitive} $ $ =\\cfrac{\\sum_{\\forall(l,m)\\in\\Lambda_{uv}(s)}e^{-\\kappa|m-l|}}{|% \\Lambda_{uv}(s)|/L^{(s)}};\\textnormal{\\,length\\,insensitive} $ </equation> </equationgroup> </equationgroup> \\newline and $ \\Psi(s)=[\\psi_{uv}(s)],\\>u,v\\in\\mathcal{V} $ is the SGT feature representation of sequence $ s $ .", "\\newline For illustration, the SGT feature for alphabet pair $ \\mathtt{(A,B)} $ in sequence in Fig. [@ref:LABEL:fig:Illustration-of-effect] can be computed as (for $ \\kappa=1 $ in length-sensitive SGT): $ \\Lambda_{\\mathtt{AB}} $ $ = $ $ \\{(2,5);(3,5); $ $ (2,8);", "$ $ (3,8); $ $ (6,8)\\} $ and $ \\psi_{\\mathtt{AB}} $ $ = $ $ \\frac{\\sum_{\\forall(l,m)\\in\\Lambda_{\\mathtt{AB}}}e^{-|m-l|}}{|\\Lambda_{\\mathtt% {AB}}|}=\\\\ \\frac{e^{-|5-2|}+e^{-|5-3|}+e^{-|8-2|}+e^{-|8-3|}+e^{-|8-6|}}{5}=0.066 $ .", "\\newline The features, $ \\Psi^{(s)} $ , can be either interpreted as a directed \u201cgraph,\u201d with edge weights, $ \\mathcal{\\psi} $ , and nodes in $ \\mathcal{V} $ , or vectorized to a $ |\\mathcal{V}|^{2} $ -vector denoting the sequence $ s $ in the feature space.", "\\newline </subsection> <subsection> <title> 2.4 SGT properties </title> In this section, we show SGT\u2019s property of capturing both short- and long-term sequence pattern features.", "This is shown by a closed-form expression for the expectation and variance of SGT feature, $ \\psi_{uv} $ , under some assumption.", "Note that the assumption defined below is only for showing an interpretable expression and is not required in practice.", "\\newline <theorem> Assumption 1 .", "A sequence of length $ L $ with an inherent pattern: $ u $ , $ v $ occurs closely together with in-between stochastic gap as $ X\\sim N(\\mu_{\\alpha},\\sigma_{\\alpha}^{2}) $ , and the intermittent stochastic gap between the pairs as $ Y\\sim N(\\mu_{\\beta},\\sigma_{\\beta}^{2}) $ , such that, $ \\mu_{\\alpha}<\\mu_{\\beta} $ (See Fig. [@ref:LABEL:fig:Representation-of-short-long] ).", "$ X $ and $ Y $ characterize the short- and long-term patterns, respectively.", "\\newline </theorem> <theorem> Theorem 1 .", "The expectation and variance of SGT feature, $ \\psi_{uv} $ , has a closed-form expression under Assumption 1, which shows that it captures both short- and long-term patterns present in a sequence in both length-sensitive and -insensitive SGT variants.", "\\newline <equationgroup> <equation> $  E[\\psi_{uv}]=\\begin{cases}\\cfrac{2}{pL+1}\\gamma&;\\text{length % sensitive}\\\\ \\cfrac{2L}{pL+1}\\gamma&;\\text{length insensitive}\\end{cases} $ $  E[\\psi_{uv}] $ $ = $ $ \\begin{cases}\\cfrac{2}{pL+1}\\gamma&;\\text{length sensitive}\\\\ \\cfrac{2L}{pL+1}\\gamma&;\\text{length insensitive}\\end{cases} $ </equation> <equation> $ \\lim_{L\\rightarrow\\infty}\\text{var}(\\psi_{uv})\\rightarrow 0 $ $ \\lim_{L\\rightarrow\\infty}\\text{var}(\\psi_{uv}) $ $ \\rightarrow $ $  0 $ </equation> </equationgroup> \\newline where, \\newline <equation> $ \\begin{array}[]{ccc}\\gamma&=&\\frac{e^{-\\tilde{\\mu}_{\\alpha}}}{\\left|\\left(1-e^% {-\\tilde{\\mu}_{\\beta}}\\right)\\left[1-\\frac{1-e^{-pL\\tilde{\\mu}_{\\beta}}}{pL(e^% {\\tilde{\\mu}_{\\beta}}-1)}\\right]\\right|}\\end{array} $ </equation> \\newline and, $ \\tilde{\\mu}_{\\alpha}=\\kappa\\mu_{\\alpha}-\\frac{\\kappa^{2}}{2}\\sigma_{\\alpha}^{2% };\\tilde{\\mu}_{\\beta}=\\kappa\\mu_{\\beta}-\\frac{\\kappa^{2}}{2}\\sigma_{\\beta}^{2} $ , $ p\\rightarrow\\text{constant} $ .", "\\newline </theorem> <proof> Proof.", "See Appendix A. \u220e \\newline </proof> As we can see in Eq. [@ref:LABEL:eq:E-phi-AB-part-2-2] , the expected value of the SGT feature is proportional to the term $ \\gamma $ .", "The numerator of $ \\gamma $ contains the information about the short-term pattern, and its denominator has the long-term pattern information.", "\\newline In Eq. [@ref:LABEL:eq:weight-constant-lambda-1] , we can observe that if either of $ \\mu_{\\alpha} $ (the closeness of $ u $ and $ v $ in the short-term) and/or $ \\mu_{\\beta} $ (the closeness of $ u $ and $ v $ in the long-term) decreases, $ \\gamma $ will increase, and vice versa.", "This emphasizes two properties: a) the SGT feature, $ \\psi_{uv} $ , is affected by changes in both short- and long-term patterns, and b) $ \\psi_{uv} $ increases when $ u,v $ becomes closer in the short or long range in the sequence, providing an analytical connection between the observed pattern and the extracted feature.", "Besides, it also proves the graph interpretation of SGT: $ \\psi_{uv} $ that denotes the edge weight for nodes $ u $ and $ v $ (in the SGT-graph) increases if closeness between $ u,v $ increases in the sequence, meaning that the nodes become closer in the graph space (and vice versa).", "\\newline Furthermore, the length-sensitive SGT feature expectation in Eq. [@ref:LABEL:eq:E-phi-AB-part-2-2] contains the sequence length, $ L $ .", "This shows that the SGT feature has the information of the sequence pattern, as well as the sequence length.", "This enables an effective length-sensitive sequence analysis because sequence comparisons via SGT will require both patterns and sequence lengths to be similar.", "\\newline In the length-insensitive SGT feature expectation in Eq. [@ref:LABEL:eq:E-phi-AB-part-2-2] , it is straightforward to show that it becomes independent of the sequence length as the length increases.", "Therefore, as sequence length, $ L $ , increases, the $ (u,v) $ SGT feature approaches a constant, given as $ \\lim_{L\\rightarrow\\infty}E[\\psi_{uv}]\\rightarrow\\cfrac{2}{p}\\left|\\cfrac{e^{-% \\tilde{\\mu}_{\\alpha}}}{1-e^{-\\tilde{\\mu}_{\\beta}}}\\right| $ .", "\\newline Besides, it is shown in Appendix A, $ \\lim_{L\\rightarrow\\infty}\\text{var}(\\psi_{uv})\\underset{1/L}{\\rightarrow}0 $ .", "Thus, the expected value of the SGT feature becomes independent of the sequence length at a rate of inverse to the length.", "In our experiments, we observe that the SGT feature approaches a length-invariant constant when $ L>30 $ .", "\\newline <equationgroup> <equation> $ \\lim_{L\\rightarrow\\infty}\\Pr\\left\\{\\psi_{uv}=\\cfrac{2}{p}\\left|% \\cfrac{e^{-\\tilde{\\mu}_{\\alpha}}}{1-e^{-\\tilde{\\mu}_{\\beta}}}\\right|\\right\\}% \\underset{1/L}{\\rightarrow}1 $ $ \\lim_{L\\rightarrow\\infty}\\Pr\\left\\{\\psi_{uv}=\\cfrac{2}{p}\\left|% \\cfrac{e^{-\\tilde{\\mu}_{\\alpha}}}{1-e^{-\\tilde{\\mu}_{\\beta}}}\\right|\\right\\} $ $ \\underset{1/L}{\\rightarrow} $ $  1 $ </equation> </equationgroup> \\newline Furthermore, if the pattern variances, $ \\sigma_{\\alpha}^{2} $ and $ \\sigma_{\\beta}^{2} $ , in the above scenario are small, $ \\kappa $ allows regulating the feature extraction: higher $ \\kappa $ reduces the effect from long-term patterns and vice versa.", "\\newline The properties discussed above play an important role in SGT\u2019s effectiveness.", "Due to these properties, unlike the methods discussed in \u00a7 [@ref:LABEL:subsec:related-work] , SGT can capture higher orders of relationship without any increase in computation.", "Besides, SGT can effectively find sequence features without the need for any hidden string/state(s) search.", "\\newline </subsection> <subsection> <title> 2.5 Extensions of SGT </title> <subsubsection> <title> 2.5.1 Undirected sequences </title> SGT can be extended to work on undirected sequences.", "In such sequences, the directional pattern or directional relationships (as in feed-forward) are not important.", "In other words, it is immaterial whether $ \\mathtt{B} $ occurs before or after $ \\mathtt{A} $ ; occurring closely (or farther) is important.", "From SGT\u2019s operation standpoint, we have to remove the condition, $ l<m $ , from Eq. [@ref:LABEL:eq:psi-lambda-main] , denoted by $ \\tilde{\\Lambda} $ .", "\\newline It is easy to show that $ \\tilde{\\Lambda}=\\Lambda+\\Lambda^{T} $ and \\newline <equation> $ \\tilde{\\Psi}=\\cfrac{|\\Lambda|\\Psi+|\\Lambda^{T}|\\Psi^{T}}{|\\Lambda|+|\\Lambda^{T% }|} $ </equation> \\newline where $ \\Lambda $ and $ \\Psi $ are given in Eq. [@ref:LABEL:eq:psi-lambda-main] and Eq. [@ref:LABEL:eq:psi-main-len-sensi] - [@ref:LABEL:eq:psi-main-len-insensi] , respectively (see Appendix B for proof).", "\\newline Moreover, for sequences with a uniform marginal distribution of occurrence of elements, $ v\\in\\mathcal{V} $ , $ \\Lambda $ will be close to symmetric; thus, the undirected sequence graph can be approximated as, $ \\tilde{\\Psi}\\approx\\cfrac{\\Psi+\\Psi^{T}}{2} $ .", "In practice, this approximation is useful in most cases.", "\\newline </subsubsection> <subsubsection> <title> 2.5.2 Alphabet clustering </title> Node clustering in graphs is a classical problem solved by various techniques, including spectral clustering, graph partitioning and others.", "SGT\u2019s graph interpretation facilitates grouping of alphabets that occur closely via any of these node clustering methods.", "\\newline This is because SGT gives larger weights to the edges, $ \\psi_{uv} $ , corresponding to alphabet pairs that occur closely.", "For instance, consider a sequence in Fig. [@ref:LABEL:fig:Illustrative-sequence-example-ele-clus] , in which $ v $ occurs closer to $ u $ than $ w $ , also implying $ E[X]<E[Y] $ .", "Therefore, in this sequence\u2019s SGT, the edge weight for $ u $ $ \\rightarrow $ $ v $ should be greater than for $ u $ $ \\rightarrow $ $ w $ , i.e. $ \\psi_{uv}>\\psi_{uw} $ .", "\\newline From Assumption.", "[@ref:LABEL:main_assump] in \u00a7 [@ref:LABEL:subsec:SGT-properties] , we will have, $ E[|\\Lambda_{uv}|]=E[|\\Lambda_{uw}|] $ (see Appendix C).", "Therefore, $ \\psi_{uv}\\propto E[\\phi(X)] $ and $ \\psi_{uw}\\propto E[\\phi(Y)] $ , and due to Condition 2 on $ \\phi $ given in \u00a7 [@ref:LABEL:subsec:SGT-definition] , if $ E[X]<E[Y] $ , then $ E[\\psi_{uv}]>E[\\psi_{uw}] $ .", "\\newline Moreover, for an effective clustering, it is important to bring the \u201ccloser\u201d alphabets in the sequence {more} close in the graph space.", "In the SGT\u2019s graph interpretation, it implies that $ \\psi_{uv} $ should go as high as possible to bring $ v $ closer to $ u $ in the graph and vice versa for $ (u,w) $ .", "Thus, effectively, $ \\Delta=E[\\psi_{uv}-\\psi_{uw}] $ should be increased.", "It is proved in Appendix C that $ \\Delta $ will increase with $ \\kappa $ , if $ \\kappa d>1,\\forall d $ , where we have $ d\\in\\mathbb{N} $ .", "\\newline Thus, an SGT can represent a sequence as a graph with its alphabets connected with weighted edges, which enables clustering of associated alphabets.", "\\newline </subsubsection> </subsection>  </section>"], ["<section> <title> 3 SGT Algorithm </title>  We have devised two algorithms for SGT.", "The first algorithm (see Algorithm [@ref:LABEL:alg:Parsing-Sequence-algo] ) is faster for $ L<|\\mathcal{V}|^{2} $ , while the second (see Algorithm [@ref:LABEL:alg:Parsing-Sequence-algo-1] ) is faster for $ L>|\\mathcal{V}|^{2} $ .", "Their time complexities are $ O(L^{2}) $ and $ O(|\\mathcal{V}|(L+|\\mathcal{V}|)) $ , respectively.", "The space complexity is $ O(|\\mathcal{V}|^{2}) $ .", "However, in most datasets, not all alphabets in $ \\mathcal{V} $ are present in a sequence, resulting in a sparse SGT features representation.", "In such cases, the complexity reduces by a factor of the sparsity level.", "\\newline Additionally, as also evident from Fig. [@ref:LABEL:fig:SGT-overview-b-seq-data] , the SGT operation on any sequence in a dataset is independent of the other.", "This means we can easily parallelize the SGT operation on sequences in dataset $ \\mathcal{S} $ to reduce the computation time.", "\\newline The resulting SGT for the sequence, $ s $ , will be a $ |\\mathcal{V}|\\times|\\mathcal{V}| $ matrix, which can be vectorized (size, $ |\\mathcal{V}|^{2} $ ) for use in distance-based data mining methods, or it can be used as is for visualization and interpretation purposes.", "Note that we output the $ \\kappa^{\\text{th }} $ root as the final SGT features as it makes the SGTs easy to interpret and comparable for any $ \\kappa $ .", "\\newline The optimal selection of the hyper-parameter $ \\kappa $ will depend on the problem in hand.", "If the end objective is building a supervised learning model, methods such as cross-validation can be used.", "For unsupervised learning, any goodness-of-fit criteria can be used for the selection.", "In cases of multiple parameter optimization, e.g. the number of clusters (say, $ n_{c} $ ) and $ \\kappa $ together in clustering, we can use a random search procedure.", "In such a procedure, we randomly initialize $ n_{c} $ , compute the best $ \\kappa $ based on some goodness-of-fit measure, then fix $ \\kappa $ to find the best $ n_{c} $ , and repeat until there is no change.", "From our experiments on real and synthesized data, the results of SGT-based data mining are not sensitive to minor differences in $ \\kappa $ .", "In our implementations, we selected $ \\kappa $ from $ \\{1,5,10\\} $ .", "\\newline  </section>"], ["<section> <title> 4 Experimental Analysis </title>  Here we perform an experimental analysis to assess the performance of the proposed SGT.", "The most important motivation behind SGT is the need for an accurate method to find (dis)similarity between sequences.", "Therefore, to test SGT\u2019s efficacy in finding sequence (dis)similarities, we built a sequence clustering experimental setup.", "A clustering operation requires accurate computation of (dis)similarity between objects and thus is a good choice for efficacy assessment.", "\\newline We performed four types of experiments: a) Exp-1: length-insensitive with non-parametric sequence pattern, b) Exp-2: length-insensitive with parametric sequence pattern, c) Exp-3: length-sensitive sequence problem, and d) Exp-4: alphabet clustering.", "The settings for each are given in Table [@ref:LABEL:tab:Experimentation-settings] .", "Alphabet set is, $ \\mathcal{V}=\\{\\mathtt{A},\\mathtt{B}\\ldots,\\mathtt{Z}\\} $ , for all sequences.", "Except for Exp-2, clustered sequences were generated such that sequences within a cluster share common patterns.", "Here two sequences having a common pattern primarily means that the sequences have some common subsequences of any length, and these subsequences can be present anywhere in the sequence.", "The sequences also comprise of other events, which can be either {noise} or some other pattern.", "This setting is non-parametric; however, the subsequences can also bring some inherent parametric properties, such as a mixture of Markov distribution of different orders.", "In Exp-2, clustered sequences were generated from a mixture of parametric distributions.", "In all the experiments, k-means with Manhattan distance was applied on the sequences\u2019 SGTs.", "\\newline In Exp-1, we compared SGT with commonly used sequence analysis techniques, viz.", "n-gram, mixture Hidden Markov model (HMM), Markov model (MM) and semi-Markov model (SMM)-based clustering.", "For n-gram, we take $ n=\\{1,2,3\\} $ , and their combinations.", "Note that 1-gram is equivalent to the bag-of-words method.", "For these methods, we provided the known $ n_{c} $ to the algorithms.", "We use F1-score as the accuracy metric.", "\\newline In this experiment, we set different scenarios such that the overlap of the clusters\u2019 \u201ccentroid\u201d is increased.", "A high overlap between clusters implies that the sequences belonging to these clusters have a higher number of common patterns.", "Thus, separating them for clustering becomes difficult, and clustering accuracy is expected to be lower.", "\\newline The Exp-1\u2019s result in Fig. [@ref:LABEL:fig:Overlap-f1] - [@ref:LABEL:fig:Overlap-time] shows the accuracy (F1-score) and the runtimes (with the legend) for each method, where SGT is seen to outperform all others in accuracy.", "MM and SMM have a poorer accuracy because of the first-order Markovian assumption.", "HMM is found to have a comparable accuracy, but its runtime is more than six times that of SGT, proving SGT\u2019s superiority.", "N-gram methods\u2019 accuracies lie in between.", "Low-order n-grams have smaller runtime than SGT but significantly lower accuracy.", "Interestingly, the 1-gram method is better when overlapping is high, showing the higher order n-grams\u2019 inability to distinguish between sequences when pattern overlap is high.", "\\newline Furthermore, we did Exp-2 to see the performance of SGT in sequence datasets having an underlying mixture of parametric distributions, viz.", "mixture of HMM, MM and SMM.", "The objective of this experiment is to test SGT\u2019s efficacy on parametric datasets against parametric methods.", "In addition to obtaining datasets from mixed HMM and first-order mixed MM and SMM distributions, we also get second-order Markov (MM2) and third-order Markov (MM3) datasets.", "Fig. [@ref:LABEL:fig:Beating-f1] - [@ref:LABEL:fig:Beating-time] shows the F1-score and the runtime (as bar labels).", "As expected, the mixture clustering method corresponding to the underlying distribution is performing the best.", "Note that SMM is slightly better than MM in the MM setting because of its over-representative formulation, i.e. a higher dimensional model to include a variable time distribution.", "However, the proposed SGT\u2019s accuracy is always close to the best.", "This shows SGT\u2019s robustness to underlying distribution and its universal applicability. And, again, its runtime is smaller than all others.", "\\newline In Exp-3, we compared SGT with length-sensitive algorithms, viz.", "MUSCLE, UCLUST and CD-HIT, which are popular in bioinformatics.", "These methods are hierarchical in nature, and thus, themselves find the optimal number of clusters.", "For SGT-clustering, the number of clusters is found using the random search procedure recommended in \u00a73.", "\\newline Fig. [@ref:LABEL:fig:Exp-1] shows the results, where the y-axis is the ratio of the estimated optimal number of clusters, $ \\hat{n}_{c} $ , and the true number of clusters, $ n_{c} $ .", "On the x-axis, it shows the clustering accuracy, i.e. the proportion of sequences assigned to a same cluster given that they were actually from the same cluster.", "For a best performing algorithm, both metrics should be close to 1.", "As shown in the figure, CD-HIT and UCLUST overestimated the number of clusters by about twice and five times, respectively.", "MUSCLE had a better $ n_{c} $ estimate but had about 95% accuracy.", "On the other hand, SGT could accurately estimate $ n_{c} $ and has a 100% clustering accuracy.", "\\newline Finally, we validated the efficacy of the SGT extensions given in \u00a7 [@ref:LABEL:subsec:Extensions-of-SGT] in Exp-4.", "Our main aim in this validation is to perform alphabet clustering (in \u00a7 [@ref:LABEL:subsec:SGT-for-element-clustering] ).", "Additionally, we use the undirected SGT (in \u00a7 [@ref:LABEL:subsec:SGT-for-element-clustering] ).", "We set up a test experiment such that across different sequence clusters some alphabets occur closer to each other.", "We create a dataset that has sequences from three clusters and alphabets belonging to two clusters (alphabets A-H in one cluster and I-P in another).", "\\newline This emulates a biclustering scenario in which sequences in different clusters have distinct patterns; however, the pattern of closely occurring alphabets is common across all sequences.", "This is a complex scenario in which clustering both sequences and alphabets can be challenging.", "\\newline Upon clustering the sequences, the F1-score is found to be 1.0.", "For alphabet clustering, we applied spectral clustering on the aggregated SGT of all sequences, which yielded an accurate result with only one alphabet as mis-clustered.", "Moreover, a heat map in Fig. [@ref:LABEL:fig:Heat-map-showing-alphabets'] clearly shows that alphabets within same underlying clusters have significantly higher associations.", "Thus, it validates that SGT can accurately cluster alphabets along with clustering the sequences.", "\\newline  </section>"], ["<section> <title> 5 Applications on Real Data </title>  <subsection> <title> 5.1 Clustering </title> Sequence clustering is an important application area across various fields.", "One important problem in this area is clustering user activity on the web (web log sequences) to understand user behavior.", "This analysis can result into better services and design.", "\\newline We took users\u2019 navigation data on msnbc.com collected during a 24-hour period.", "The navigation data are weblogs that correspond to the page views of each user.", "The alphabets of these sequences are the events corresponding to a user\u2019s page request.", "These requests are recorded at a higher abstract level of page category, e.g. frontpage, tech , which are representative of the structure of the website.", "The dataset has a random sample of 100,000 sequences for our analysis.", "The sequences\u2019 average length is 6.9 and their standard deviation is 27.3, with the range between 2 and 7440 and a skewed distribution.", "\\newline Our objective is to cluster the users with similar navigation patterns, irrespective of differences in their session lengths.", "We, therefore, take the {length-insensitive } SGT and use the random search procedure for optimal clustering in \u00a73.", "We performed k-means clustering with Manhattan distance and the goodness-of-fit criterion as db-index, and found the optimality at $ n_{c}=104 $ for $ \\kappa=9 $ .", "\\newline The frequency distribution (Fig. [@ref:LABEL:fig:Frequency-distribution-of-msnbc-clusters] ) of the number of members in each cluster has a long-tail\u2014the majority of users belong to a small set of clusters.", "These clusters tell us the distinct behaviors of both the majority and minority user types.", "\\newline </subsection> <subsection> <title> 5.2 Visualization </title> Effective visualization is a critical need for easy interpretation of data and its underlying properties.", "For example, in the above msnbc.com navigation data analysis, interpreting behavior of different user clusters is quite important.", "\\newline SGT enables a visual interpretation of the different user behaviors.", "In Fig. [@ref:LABEL:fig:Cluster=000023-1] - [@ref:LABEL:fig:Cluster=000023-3] , we show a graph visualization of some clusters\u2019 centroids (which are in the SGT space), because a centroid represents the behavior of users present in the cluster.", "We have filtered edges with small weights for better visualization.", "\\newline Fig. [@ref:LABEL:fig:Cluster=000023-1] shows the centroid for the first cluster that contains the highest membership ( $ \\sim $ 12%) and thus indicates the \u201cmost\u201d general behavior.", "This cluster\u2019s users\u2019 behavior is centered around frontpage and misc , with users\u2019 tendency to navigate between frontpage, misc, weather, opinion, news, travel and business at different levels.", "\\newline Fig. [@ref:LABEL:fig:Cluster=000023-3] shows another majority cluster with about 7.5% membership.", "This group of users seems to have a liking for sports.", "They primarily visit sports -related pages (the box around the sports node indicates a self-visiting edge), and also move back and forth from sports to frontpage, travel and others.", "\\newline </subsection> <subsection> <title> 5.3 Classification </title> At many occasions, we have labeled sequence data where it is required to build a classification model.", "SGT can be used for this, and is demonstrated on two datasets: a) protein sequences having either of two known functions, which act as the labels, and b) network intrusion data containing audit logs and any attack as a positive label.", "\\newline The dataset details are given in Table [@ref:LABEL:tab:Dataset-attributes] .", "For both problems we use the {length-sensitive} SGT.", "For proteins, it is due to their nature, while for network logs, the lengths are important because sequences with similar patterns but different lengths can have different labels.", "Take a simple example of following two sessions: {login, password, login, password, mail,... } and {login, password,...(repeated several times)..., login, password }.", "While the first session can be a regular user mistyping the password once, the other session is possibly an attack to guess the password.", "Thus, the sequence lengths are as important as the patterns.", "\\newline For the network intrusion data, the sparsity of SGTs was high.", "Therefore, we performed principal component analysis (PCA) on it and kept the top 10 PCs as sequence features.", "We call it SGT-PC, for further modeling.", "For proteins, the SGTs are used directly.", "\\newline After obtaining the SGT (-PC) features, we trained an SVM classifier on them.", "For comparison, we used popular n-gram sequence classifiers, viz.", "bag-of-words (1-gram), 2-, 3-, 1+2-, and 1+2+3-gram.", "The SVM was built with an RBF kernel.", "The cost parameter, $ c $ , is equal to 1, while the value for the kernel parameter, $ \\gamma $ , is shown within braces in Table [@ref:LABEL:tab:Classification-accuracy-(F1-score)] .", "The table reports the average test accuracy (F1-score) from a 10-fold cross-validation.", "\\newline As we can see in Table [@ref:LABEL:tab:Classification-accuracy-(F1-score)] , the F1-scores are high for all methods in the protein data, with SGT-based SVM surpassing all others.", "On the other hand, the accuracies are small for the network intrusion data.", "This is primarily due to: a) a small dataset but high dimension (related to the alphabet set size), leading to a weak predictive ability of models, and b) a few positive class examples (unbalanced data) causing a poor recall rate.", "Still, SGT outperformed other methods by a significant margin.", "Although the accuracies of the methods can be further increased using other classifiers such as Boosting and Random Forest, it is beyond the scope of this paper.", "Here our purpose is to make a simplistic comparison to highlight the superiority of SGT features in building a supervised learning model.", "\\newline </subsection> <subsection> <title> 5.4 Search </title> Most sequence databases found in the real world are very large.", "For example, protein databases have billions of sequences and increasing.", "Here we show that SGT sequence features can lead to a fast and accurate sequence search.", "\\newline We collected a random sample of 1000 protein sequences from the UniProtKB database on www.uniprot.org.", "We transformed them to feature space using {length-sensitive } SGT (with $ \\kappa=1 $ ) to incorporate their lengths\u2019 information.", "Thereafter, to reduce the dimension we applied principal component analysis and preserved the first 40 principal components (explaining $ \\sim $ 83% of variance), denoted by SGT-PC.", "We arbitrarily chose a protein sequence, Q9ZIM1 (ID notation from UniProtKB), as the search query.", "\\newline We compute the Manhattan distance between the SGT-PCs of the query and each sequence in the dataset."]], "target": "The top five closest sequences are shown with their SGT-PC distances in Table . For a reference, we also find the {identities} \u2014an identity between two sequences is the edit-distance between them after alignment. Here we find the identities after a global alignment, with cost of gap-opening as 0 and gap-extension as 1. Note that alignment algorithms are approximate heuristics; thus, the identities should be seen only as a guideline and not ground truth."}, {"tabular": ["  dataset  &  albert  &  fr079  &  fr101  &  kwing1  &  run1  &  Avg ", " BoW  &  24.6  &  22.6  &  21.7  &  55.8  &  36.6  &  25.4 ", " $ S^{1} $  &  12.3  &  10.3  &  18.9  &  31.6  &  30.0  &  14.4 ", " $ S^{2} $  &  20.7  &  11.3  &  28.8  &  29.3  &  26.3  &  19.4 ", " $ S^{3} $  &  33.6  &  34.8  &  39.8  &  45.0  &  51.2  &  36.3 ", " $ S^{4} $  &  13.8  &  11.2  &  23.0  &  42.2  &  41.7  &  16.9 ", " $ S^{5} $  &  15.7  &  14.5  &  17.4  &  32.3  &  36.6  &  16.9  "], "ref_sec": [["<section> <title> I Introduction </title>  Map retrieval, the problem of similarity search over a large collection of local maps previously built by mobile robots, is crucial for autonomous navigation in indoor and outdoor environments.", "This study addresses a general map retrieval problem in which a 2D pointset map is provided as a query, and the system searches a size $ N $ map database to determine similar database maps that are relevant under rigid transformation.", "One of the most popular approaches to address this problem is bag-of-words (BoW), a method derived from image retrieval techniques [@bib:ps1,nnl2,bow5] .", "In BoW, a collection of local invariant appearance features (e.g., shape context [@bib:sc1] , polestar [@bib:polestar] ) is extracted from an input map and each feature is translated into a visual word.", "Consequently, an input map is described compactly and matched efficiently as an unordered collection of visual words, termed \u201cbag-of-words\u201d [@bib:ps1] .", "\\newline A major limitation of the BoW scene model is the lack of spatial information.", "The BoW methods ignore the spatial layout information of the features, and hence, they have severely limited descriptive ability [@bib:ps1] .", "Key relevant studies to address this issue include recent image retrieval techniques, such as spatial pyramid matching [@bib:spm] .", "In such techniques, weak robust constraints are extracted from the spatial information, and are incorporated into the BoW model to significantly improve the discriminative power of the model.", "However, to apply such methods that were originally proposed for image data, we must first define the origin or viewpoint of an input map with respect to which the poses of local features are defined.", "This task is non-trivial because of the following reasons: (1) Unlike image data, map data lacks an explicit viewpoint; (2) Unlike image data, the area of a map is variable; it is incrementally updated by mapper robots and can grow in an unbounded manner.", "\\newline The main contribution of this study is an extension of the BoW map retrieval method to enable the use of spatial information from local features (Fig. [@ref:LABEL:fig:N] ).", "Our strategy is to explicitly model a unique viewpoint of an input local map; the pose of the local feature is defined with respect to this unique viewpoint, and can be viewed as an additional invariant feature for discriminative map retrieval.", "Specifically, we wish to determine a unique viewpoint that is invariant to moving objects, clutter, occlusions, and actual viewpoints.", "Hence, we perform scene parsing to analyze the scene structure, and consider the \u201ccenter\u201d of the scene structure to be the unique viewpoint.", "Our scene parsing is based on a Manhattan world grammar that imposes a quasi-Manhattan world constraint to enable the robust detection of a scene structure that is invariant to clutter and moving objects.", "We also discuss several strategies for extracting the \u201ccenter\u201d of a given scene structure.", "We generated a database of 2D local maps built by mobile robots from the publicly available radish dataset [@bib:radish] , and experimentally validated the efficacy of the proposed method.", "\\newline <subsection> <title> I-A Related Work </title> Existing approaches to scene retrieval can be classified according to the feature descriptors used, the manner in which the feature descriptors are used, and whether the feature approach is global or local.", "A global feature approach describes the global structure of a scene by using a single global feature descriptor (e.g., Gist, HOG).", "In contrast, a local feature approach describes a scene by using a collection of local feature descriptors (e.g., SIFT).", "In general, both the approaches can be used complementarily; however, the focus of this paper is on the local feature approach.", "\\newline Direct feature matching [@bib:neira03,tipaldi2010flirt,m3rsm] and BoW [@bib:ps1,nnl2,bow5] are two popular local feature approaches.", "In [@bib:neira03] , the authors introduce the concept of RANSAC map matching for loop closure detection using pointset maps.", "In [@bib:tipaldi2010flirt] , the authors detect interest points, extract appearance descriptors (e.g., shape context), and perform a direct match between the appearance descriptors of the query and database images.", "Very recently, in [@bib:m3rsm] the authors presented an efficient direct matching based on multi-resolution many-to-many map matching framework.", "In [@bib:kanji09] , we also addressed the scalability issue by introducing a pre-filter based on the appearance descriptor.", "However, the direct matching methods have limited scalability because they require a large amount of time and space that is linearly proportional to the number of maps.", "\\newline BoW methods [@bib:ps1,nnl2,bow5] are well known for efficient map retrieval.", "In these methods, an input map is described compactly by an unordered collection of vector quantized appearance descriptors.", "In [@bib:iros15a] , we alse employed a bag-of-words scene model to achieve efficient visual robot localization.", "However, their descriptive ability is limited because they ignore all the layout information of the local features.", "We address this limitation in our study.", "\\newline A majority of the existing BoW map retrieval methods explicitly or implicitly assume that the viewpoint trajectory of the mapper robot with respect to the local map is unavailable [@bib:ps1] .", "In contrast, we explicitly use the viewpoint information produced by our viewpoint planner as a cue to compute the local map descriptor.", "The success of our approach is based on the assumption that the viewpoint planner provides a unique viewpoint for a local map; therefore, we also consider viewpoint planning.", "These two issues have not been explored in existing literature.", "\\newline Our study is also similar to several image retrieval techniques that describe the appearance and spatial information of local features.", "Among these methods, the part model [@bib:part2008] , in which a scene is modeled as a collection of visual parts, is extremely popular.", "Spatial pyramid matching is an alternative method that places a sequence of increasingly coarser grids over the image region, and considers a weighted sum of the number of matches that occur at each level of resolution.", "However, most existing studies focus on image data, and do not handle map data that has no explicit viewpoint, as we discussed in Section [@ref:LABEL:sec:1] .", "\\newline Our map parsing method can be viewed as an instance of scene parsing, which has been extensively studied in the fields of point-based geometry [@bib:octree2006] , image description [@bib:i2t] , scene reconstruction [@bib:instantarchitecture] , and scene compression [@bib:scenecompression] .", "Scene parsing approaches are broadly classified as generic approaches (e.g., line primitives [@bib:lineprimitives2002] , plane primitives [@bib:planeprimitives2004] , etc.) and parametric approaches (e.g., constructive solid geometry [@bib:csg2007] , hierarchical model [@bib:hierarchical2003] , grammar-based [@bib:shapegrammar2006] , etc.).", "Our study can be viewed as a novel application of scene parsing to the map retrieval problem.", "\\newline This study is a part of our studies on loop closure detection [@bib:kanji06] and map-matching [@bib:shogo2013partslam] , and related to our previous works in ICRA15, IROS15, and PPNIV15 papers [@bib:iros15a,icra15a,ppniv15] .", "However, the use of viewpoint planning in map retrieval tasks is not addressed in existing studies.", "\\newline </subsection>  </section>"], ["<section> <title> II Map Retrieval Approach </title>  For clarity of presentation, we first describe the overview of the map retrieval system that is the basis for our approach and is a performance comparison benchmark in the experiments described in Section [@ref:LABEL:sec:exp] .", "The main steps in the process are as follows: (1) Building informative local maps, (2) Planning the unique viewpoint of the local map, (3) Constructing a local map descriptor (LMD), and (4) Indexing/Retrieving the map database from the LMD descriptors.", "These four steps are explained below.", "\\newline <subsection> <title> II-A Map Building </title> Based on existing literature [@bib:paz2008large] , we build a local map from a short sequence of perceptual and odometry measurements; each measurement sequence must be sufficiently long to capture the rich appearance and geometric information of the local surroundings of the robot.", "In the implementation, each sequence corresponds to a 5 m run of the robot.", "Any map-building algorithm (e.g., FastSLAM, scan matching) can be used to register a measurement sequence to a local map.", "We start generating a local map every time the viewpoint of the robot moves 1 m along the path.", "Thus, a collection of overlapping local maps along the path is generated.", "\\newline </subsection> <subsection> <title> II-B Viewpoint Planning </title> In order to determine a unique viewpoint of a given input map that is invariant to moving objects, clutter, occlusions, and actual viewpoints, we first perform scene parsing to analyze the scene structure.", "Then, we consider the \u201ccenter\u201d of the scene structure to be the unique viewpoint.", "We will discuss several strategies for viewpoint planning in Section [@ref:LABEL:sec:3] .", "For example, in the strategy $ S^{1} $ , the scene structure is first analyzed to obtain a set of points, termed \u201cstructure points,\u201d that belong to a structure (e.g., walls); then, the center-of-gravity of the structure points is computed, and finally, a nearest-neighbor unoccupied location relative to the center of gravity is determined as the unique viewpoint.", "\\newline </subsection> <subsection> <title> II-C Map Description </title> We follow a standard BoW approach [@bib:ps1] for extracting and representing appearance features.", "We adopt the polestar feature because it has several desirable properties, including viewpoint invariance and rotation independence, and has proven effective as a landmark for map matching in previous studies [@bib:tanaka2012multi] .", "The extraction algorithm consists of three steps: (1) First, a set of keypoints is sampled from the raw 2D scan points.", "(2) Next, a circular grid is imposed and centered at each keypoint with different $ D=10 $ radius.", "(3) Finally, the points located in each circular grid cell are counted, and the resulting $ D $ -dim vector is generated as the output, the polestar descriptor.", "We quantize the appearance descriptor (i.e., $ D $ -dim polestar vector) of each feature to a 1-dimensional code termed an \u201cappearance word\u201d.", "This quantization process consists of three steps: (1) normalization of the $ D $ -dim vector by the L1 norm of the vector, (2) binarization of each $ i $ -th element of the normalized vector into $ b_{i}\\in\\{0,1\\} $ , and (3) translation of the binarized $ D $ -dim vector into a code or a visual word, $ w_{a}=\\sum_{i}2^{i}b_{i} $ .", "Currently, the threshold for binarization is determined by calculating the mean of all the elements of the vector.", "Thus, a map is represented by an unordered collection of visual words, $ \\{w_{a}|w_{a}\\in[1,K]\\} $ , called BoW. We consider $ D $ -dim binarized polestar descriptors, and hence, the vocabulary size is $ K=2^{10} $ .", "\\newline In order to translate the pose of each feature with respect to the planned unique viewpoint to a visual word, we quantize the pose or keypoint of the feature by using a resolution quantization step size of 0.1 m to obtain a code, $ (w_{x},w_{y}) $ , termed \u201cpose word\u201d.", "\\newline Finally, we obtain a BoW representation of the input local map, termed \u201clocal map descriptor (LMD)\u201d.", "An LMD is an unordered collection of visual words, each having the form: \\newline <equation> $ \\langle w_{x},w_{y},w_{a}\\rangle.", "$ </equation> \\newline </subsection> <subsection> <title> II-D Map Indexing/Retrieval </title> In order to index and retrieve the BoW map descriptors, we use the appearance word $ w_{a} $ as the primary index for the inverted file system, and the pose word $ (w_{x},w_{y}) $ as an additional cue for fine matching.", "The retrieval stage begins with a search of the map collection.", "The given appearance word $ w_{a} $ is used as a query to obtain all the memorized feature points with common appearance words, and to filter out the feature points whose pose word $ (w_{x}^{\\prime},w_{y}^{\\prime}) $ is distant from that of the query feature $ (w_{x},w_{y}) $ : \\newline <equation> $ |w_{x}-w_{x}^{\\prime}|>D_{x,y}, $ </equation> <equation> $ |w_{y}-w_{y}^{\\prime}|>D_{x,y}. $ </equation> Thus, the final shortlist of maps is obtained.", "Currently, we use a large threshold, $ D_{x,y}=3[m] $ , to suppress false negatives, i.e., incorrect identification of relevant maps as not being relevant.", "\\newline We use the BoW representation for the database construction and retrieval processes.", "In the database construction process, each local map is indexed by the inverted file system; each word $ w_{a} $ belonging to the map is used as an index.", "In the retrieval process, all the indexes that have words in common with the query map are accessed, and the resulting candidate database maps are ranked based on the frequency or the number of words matched.", "For $ K $ words in the vocabulary, a frequency histogram of visual words is represented by a $ K $ -dim vector.", "\\newline </subsection>  </section>"], ["<section> <title> III Viewpoint Planning </title>  In order to determine a unique viewpoint that is invariant to moving objects, clutter, and actual viewpoints, we first parse the scene structure using a Manhattan world grammar (Fig. [@ref:LABEL:fig:rules] ), and then, determine the unique viewpoint with respect to the structure points.", "In the following subsections, first, we briefly introduce the Manhattan world grammar.", "Then, we describe the scene parsing algorithm, and discuss several strategies for viewpoint planning.", "\\newline <subsection> <title> III-A Manhattan World Grammar </title> We use the formulation of context free grammar (CFG) to implement the Manhattan world grammar.", "CFG defines the grammar as \\newline <equation> $ G=(V,T,R,U), $ </equation> where $ V $ is a set of non-terminal nodes.", "Each non-terminal node is represented by a capital letter, etc.", "$ T $ is a set of terminal nodes.", "Each terminal node is represented by a capital letter with a bar over it, e.g., \u2019 $ \\bar{A} $ \u2019, \u2019 $ \\bar{B} $ \u2019, \u2019 $ \\bar{C} $ \u2019, etc.", "\\newline In the case of a map parsing problem, either a terminal or a non-terminal node is modeled as a geometric primitive; in our study, we use a \u201croom\u201d or \u201cwall\u201d primitive.", "$ R $ is a set of replacement rules.", "Each replacement rule $ r\\in R $ is in the form \\newline <equation> $ A\\rightarrow a $ </equation> and replaces a non-terminal node $ A $ with a sequence of terminal or non- terminal nodes $ a $ .", "$ U $ is the start variable.", "Let constant $ N $ denote the upper bound on the number of grammar rules applied in a map parsing task.", "Let variable $ r_{i} $ denote the $ i $ -th rule in the length $ N $ rule sequence.", "The solution space of a map parsing problem is defined as \\newline <equation> $ p=\\{(r_{1},r_{2},\\cdots,r_{N})\\}. $ </equation> The score $ S(p) $ $ (p\\in P) $ of a policy $ p $ is evaluated in terms of how well the original input map is explained by a set of primitives (i.e., terminal nodes) produced by the rule sequence $ p $ .", "The objective of a map parsing problem is to find a \u201cbest\u201d policy $ p^{best}(\\in P) $ that maximizes the score function $ S(p) $ .", "In our method, the score $ S(p) $ is evaluated in terms of the ratio of datapoints that are explained by the rule sequence $ p $ : $ Size(O\\setminus O^{c})/Size(O) $ , where $ Size(\\cdot) $ is the number of datapoints, $ O $ is the set of datapoints in the input map, and $ O^{c}(\\subset O) $ is a subset that is explained by the grammar $ p $ .", "\\newline In order to adapt CFG to our map parsing method, we model the entire map as a set of \u201cManhattan worlds,\u201d and \u201crooms\u201d and \u201cwalls\u201d.", "A Manhattan world [@bib:MWorg] is a set of rectangular rooms aligned with the orthogonal directions.", "A room is composed of a set of four orthogonal walls.", "A wall is represented by a 2D line segment.", "The grammar is represented by a set of rules, R1, R2, R3, R4, and R5.", "Figure [@ref:LABEL:fig:rules] illustrates each rule and its parameter settings.", "The symbol $ O $ represents the original pointset map.", "A Manhattan world $ M(\\theta) $ is explained by a collection of orthogonal room primitives and is oriented at angle $ \\theta $ .", "A room primitive $ R_{\\theta}(x,y,w,h) $ is explained by smaller orthogonal rooms or a set of four orthogonal walls.", "The angle, width, and height of a room primitive are $ \\theta $ , $ w $ and $ h $ , respectively.", "A wall primitive $ \\bar{W}_{x,y,\\theta,a,b,c,d} $ is represented by a straight line segment, which is the result of rotating a line segment $ (a,b) $ - $ (c,d) $ by angle $ \\theta $ around the point $ (x,y) $ .", "\\newline </subsection> <subsection> <title> III-B Map Parsing </title> Our method for determining a best policy uses a hypothesize-and-verify approach.", "Given an input pointset map, we wish to determine a policy that maximizes a pre-defined score function $ p^{best}(\\in P) $ .", "Our approach first estimates the dominant orientation $ \\theta $ of the Manhattan world; then, it generates $ K $ random hypotheses for the policy, assigns a score to each hypothesis, and selects the hypothesis with the highest score as the best policy.", "The above methods for estimating the dominant orientation, generating hypotheses, and assigning a score to the hypotheses are explained in algorithms I-IV in Fig. [@ref:LABEL:fig:rules] .", "As mentioned, the score $ S(\\cdot) $ of a policy hypothesis is defined by the number of datapoints that would be explained by the policy.", "A data-driven algorithm is used for policy generation and evaluation.", "\\newline </subsection> <subsection> <title> III-C Viewpoint Planning </title> Given a scene understanding from the grammar-based parsing, we identify the \u201ccenter\u201d of a map and use it as the unique viewpoint (UVP), as shown in Fig. [@ref:LABEL:fig:M] .", "In this study, we implement five strategies, $ S^{1} $ - $ S^{5} $ , to identify the center of a given input map, and experimentally evaluate the effectiveness of each strategy in terms of \u201cviewpoint uniqueness\u201d and map retrieval performance.", "\\newline In this subsection, we use the following technical terms: grid map, free cells, unknown cells, wall cells, structure cells, and unoccupied cells.", "A grid map is a classical representation of a map that imposes a discretized grid on the $ xy $ -plane and classifies each cell as occupied, free, or unknown [@bib:thrun2005probabilistic] .", "We denote occupied, free, and unknown cells as $ C^{occupied} $ , $ C^{free} $ and $ C^{unknown} $ , respectively.", "The grid map is constructed during the map building process described in Section [@ref:LABEL:sec:2a] .", "In addition, wall, structure, and unoccupied cells are defined based on the three cell classes mentioned above.", "Wall cells, $ C^{wall} $ , are the cells that are occupied by the wall primitives defined in Section [@ref:LABEL:sec:3a] .", "Structure cells, $ C^{structure} $ , are defined as $ C^{structure}=C^{occupied}\\cap C^{wall} $ .", "Unoccupied cells, $ C^{unoccupied} $ are defined as $ C^{unoccupied}=C^{free}\\setminus C^{structure} $ .", "\\newline The strategy $ S^{1} $ determines UVP as an unoccupied location near the center-of-gravity of structure points.", "First, $ S^{1} $ parses the scene structure and obtains a set of wall points; then, it computes structure points $ C^{structure}=\\{(x_{i},y_{i})\\}_{i=1}^{N} $ from the wall points and occupied cells as shown above, and, based on the result, it computes the center-of-gravity of the structure points $ p^{cog}=N^{-1}\\sum_{i=1}^{N}[x_{i}y_{i}]^{T} $ .", "Finally, it searches the unoccupied cells and determines a nearest-neighbor unoccupied cell relative to the center-of-gravity to be UVP: $ p^{uvp}=\\arg\\min_{v\\in C^{unoccupied}}|v-p^{cog}| $ .", "\\newline The strategy $ S^{2} $ determines UVP as an unoccupied cell that minimizes the distance to the farthest structure points.", "Similar to the strategy $ S^{1} $ , $ S^{2} $ parses the scene structure to obtain the structure and unoccupied cells.", "Then, for each viewpoint candidate $ v $ (i.e., unoccupied cell), $ S^{2} $ evaluates the distance $ d(v)=\\max_{p\\in C^{structure}}|v-p| $ between the viewpoint and its farthest structure point, and selects one candidate that minimizes the evaluated distance: $ p^{uvp}=\\arg\\min_{v\\in C^{unoccupied}}d(v) $ .", "\\newline The strategy $ S^{3} $ determines UVP as an unoccupied cell that maximizes the distance to the nearest structure points.", "The process for viewpoint planning is similar to that in $ S^{2} $ .", "The only difference is that $ S^{3} $ uses the minimum distance instead of the maximum distance, and the maximum operator instead of the minimum operator, i.e., $ d(v)=\\min_{p\\in C^{structure}}|v-p| $ , and $ p^{uvp}=\\arg\\max_{v\\in C^{unoccupied}}d(v) $ .", "\\newline The strategy $ S^{4} $ is based on the analysis of dominant structures, which are defined as the longest line segments on the input map.", "This strategy is similar to $ S^{1} $ ; however, instead of using every structure point, $ S^{4} $ uses only the 10 longest walls to compute the structure cells.", "\\newline The strategy $ S^{5} $ determines UVP as the center of the unoccupied regions.", "In the viewpoint planning process, $ S^{5} $ searches a set of bounding boxes of unoccupied cells aligned with the orthogonal directions of the Manhattan world; then, it generates two histograms $ f^{x},f^{y} $ of unoccupied cells along two dominant directions of the Manhattan world.", "Next, the peaks $ x^{*}=\\arg\\max_{x}f^{x}(x) $ and $ y^{*}=\\arg\\max_{y}f^{y}(y) $ of the two histograms are searched.", "Further, a bounding box of unoccupied cells $ (x,y) $ whose $ f^{x}(x) $ and $ f^{y}(y) $ values exceed $ 0.9f^{x}(x^{*}) $ and $ 0.9f^{y}(y^{*}) $ , respectively, is computed.", "Finally, UVP is defined as the center of the bounding box.", "\\newline </subsection>  </section>"], ["<section> <title> IV Experiments </title>  We conducted map retrieval experiments to verify the efficacy of the proposed approach.", "In the following subsections, first, we describe the datasets and the map retrieval tasks used in the experiments; then, we present the results and compare the performance of our method with that of other methods.", "\\newline <subsection> <title> IV-A Dataset </title> For map retrieval, we created a large-scale map collection from the publicly available radish dataset [@bib:radish] , which comprises odometry and laser data logs acquired by a car-like mobile robot in indoor environments (Fig. [@ref:LABEL:fig:D] ).", "We used a scan matching algorithm to create a collection of query-database maps from each of six datasets \u2014\u201calbert,\u201d \u201cfr079,\u201d \u201crun1,\u201d \u201cfr101,\u201d \u201cclaxton,\u201d and \u201ckwing\u201d\u2014 that were obtained from 212, 209, 80, 277, 79, and 286 m travel of the mobile robot, corresponding to 4167, 3118, 2882, 5299, 4150, and 609 scans.", "Fig. [@ref:LABEL:fig:O] shows examples of the query and database maps.", "The map collection comprises more than 1065 maps.", "Our map collections contain many virtually duplicate maps, thus making map retrieval a challenging task.", "We use \u201cclaxton\u201d only as additional distructer maps for increasing the database size, as \u201cclaxton\u201d does not contain any loop closure.", "\\newline </subsection> <subsection> <title> IV-B Qualitative Results </title> The objective of map retrieval is to find a relevant map from the map database for a local map given as a query.", "The relevant map is defined as a database map that satisfies two conditions: (1) Overlap of datapoints between the query and the relevant maps exceeds $ R^{overlap}=75\\% $ , and (2) Its distance traveled along the robot\u2019s trajectory is distant from that of the query map, such as in a \u201cloop-closing\u201d situation in which a robot traverses a loop-like trajectory and returns to a previously explored location.", "\\newline For each relevant map pair, map retrieval is performed using a query map and a size $ N $ map database, which consists of the relevant map and $ (N-1) $ random irrelevant maps.", "The spatial resolution of the occupancy map is set to 0.1 m. We implemented the map retrieval algorithm in C++, and successfully tested it with various maps.", "Fig. [@ref:LABEL:fig:O] shows the results of map retrieval performed using the baseline (\u201cBoW\u201d) and the proposed (\u201cLMD\u201d) systems.", "As described in Section [@ref:LABEL:sec:baseline] , BoW differs from LMD only in that it does not use pose word but only uses appearance word.", "It is observed that the proposed LMD method yields fewer false positives than the BoW method.", "The reason for this result is that, in the proposed LMD method, many incorrect matches are successfully filtered out by the proposed descriptor, which uses the keypoint configuration as a cue.", "It can be observed that, for these examples, the proposed LMD method using the spatial layout of local features as a cue is successful in finding relevant maps.", "\\newline </subsection> <subsection> <title> IV-C Quantitative Results </title> For performance comparison, we evaluated the averaged normalized rank (ANR) [@bib:shogo2013partslam] for the BoW and LMD methods.", "ANR is a ranking-based performance measure in which a lower value is better.", "In order to determine the ANR, we performed several independent map retrieval tasks with various queries and databases.", "For each task, the rank assigned to the ground-truth database map by a map retrieval method of interest was investigated, and the rank was normalized by the database size $ N $ .", "The ANR was subsequently obtained as the average of the normalized ranks over all the map retrieval tasks.", "All map retrieval tasks were conducted using 247 different queries and a size 1065 map database.", "\\newline Table [@ref:LABEL:tab:A] and Fig. [@ref:LABEL:fig:R] summarize the ANR performance.", "The proposed LMD system with strategies $ S^{1} $ , $ S^{2} $ , $ S^{4} $ , and $ S^{5} $ clearly outperforms the baseline BoW system.", "An exception is the strategy $ S^{3} $ and will be discussed in the next subsection, Section [@ref:LABEL:sec:st_exp] .", "By filtering out incorrect matches using the keypoint configuration as a cue, the LMD method was able to successfully perform map retrieval in many cases, as shown in the table.", "In contrast, the BoW system based only on appearance words does not perform well in many cases, mainly owing to the large number of false matches.", "The above results verify the efficacy of our approach.", "\\newline </subsection> <subsection> <title> IV-D Comparing Different Strategies </title> Table [@ref:LABEL:tab:A] also compares different viewpoint planning strategies for the proposed LMD algorithm.", "One can see that $ S^{4} $ and $ S^{5} $ are best strategies in the current experiment.", "The strategy $ S^{4} $ is based on dominant structure in the map and it was successful in finding center of structures.", "The strategy $ S^{5} $ is based on analysis of unoccupied regions and it was often successful in finding center of unoccupied regions.", "On the other hand, $ S^{3} $ was not as good as other strategies and the BoW method.", "A main reason is that because $ S^{3} $ maximizes the distance from UVP to the nearest structure points, it often determines UVP near the boundary between free and unknown region, which is naturally far apart from the center of the map.", "On the other hand, $ S^{2} $ provided a good result as it minimizes the distance from UVP to the farthest structure points, which is often located at the center of a map.", "Finally, $ S^{1} $ uses all the datapoints in a map and tends to be influenced by non-structure points and noises, and as a result, it performs not as good as $ S^{4} $ .", "\\newline </subsection> <subsection> <title> IV-E Viewpoint Planning </title> In this subsection, we investigate the performance of our viewpoint planning method.", "As mentioned earlier, the success of our approach is based on the assumption that the viewpoint planner provides a unique viewpoint for a given local map.", "As a proof-of-concept experiment, we investigate the similarity between the planned viewpoints of the query and those of the relevant database maps.", "We performed viewpoint planning for the 247 pairs of query and relevant maps, and computed the errors in the viewpoints planned.", "Fig. [@ref:LABEL:fig:Q] shows a summary of the investigation in the form of a histogram.", "The difference between the planned viewpoint of the query and that of the relevant database maps was, for 90% of the viewpoints considered in the current study, within 5 m, 7.8 m, 12 m, 6.2 m, and 6.4 m for strategies $ S^{1} $ - $ S^{5} $ , respectively.", "\\newline </subsection> <subsection> <title> IV-F Matching Visual Words </title> Figs. [@ref:LABEL:fig:Bbca] and [@ref:LABEL:fig:Bbcb] show the results of matching visual words using the baseline (\u201cBoW\u201d) and the proposed (\u201cLMD\u201d) systems.", "In these figures, purple and green points indicate the query and the database maps, while the red lines indicate correspondence found by either method.", "To facilitate visualization, both maps are aligned w.r.t.", "the true viewpoints.", "With the above visualization, one can recognize false positive matches produced by either BoW or LMD method as they appear as relatively long red line segments that connect wrong pairs of datapoints between query and database maps.", "One can see that LMD methods provide significantly less amount of matches for irrelevant pairs than for relevant pairs comparing to BoW method.", "\\newline </subsection> <subsection> <title> IV-G Dissimilar Map Pairs </title> As a final investigation, we conducted an additional experiments on a challenging map retrieval scenario.", "In this study, we are interested in how robust individual map retrieval algorithms are and how well they perform on retrieving dissimilar maps.", "To this end, we use a lower threshold of overlap $ R^{overlap}=50\\% $ , instead of the previous setting $ R^{overlap}=75\\% $ ."]], "target": "Table reports the ANR performance. The strategies $ S^{4} $ and $ S^{5} $ again performed well and $ S^{1} $ was best performed in this case. We can observe that despite the challenging setting, the proposed algorithm is still successful in viewpoint planning and map retrieval."}, {"tabular": ["  Imbalanced data sets  &  Balanced data sets ", " Algorithm  &  Avg. Ranking  &  Algorithm  &  Avg. Ranking ", " Bagging  &  1.00  &  Bagging  &  3.00 ", " RandomForest  &  3.75  &  RandomForest  &  4.00 ", " REPTree  &  3.75  &  BayesNet  &  5.50 ", " C4.5  &  5.50  &  DecisionTable  &  5.75 ", " MultiClassClassifier  &  5.50  &  REPTree  &  6.00 ", " DecisionTable  &  6.75  &  SimpleCart  &  6.00 ", " K*  &  6.75  &  NaiveBayes  &  6.75 ", " SimpleCart  &  7.00  &  KNN  &  6.75 ", " BayesNet  &  7.75  &  MultiClassClassifier  &  7.25 ", " KNN  &  9.75  &  C4.5  &  7.75 ", " RIPPER  &  10.50  &  K*  &  9.00 ", " NaiveBayes  &  10.50  &  RIPPER  &  10.25 ", " LibSVM  &  13.00  &  AdaBoost  &  13.25 ", " AdaBoost  &  13.50  &  LibSVM  &  14.00 ", " ZeroR  &  15.00  &  ZeroR  &  14.75  "], "ref_sec": [["<section> <title> Example of a social group on Facebook </title>  The Facebook platform allows to perform various social activities like discussion in groups, content sharing, commenting, expressing opinions and emotions.", "One of the platform\u2019s tools allows to create and join independent discussion groups devoted to a specific topic.", "For example, there are groups intended for mothers living in Singapore, which purpose is to talk about and comment on new products for babies, share general advices about raising children, sell used clothes, etc.", "\\newline By obtaining and processing data of a single discussion group we are able to create its social network graph, and furthermore, we can track its evolution.", "Depending on what we are trying to achieve, we would process data in a different way.", "In the simplest case we can assume that one post (content posted to the discussion group) and all interactions to this post (likes, comments, shares) reflect a social group at a particular time.", "By obtaining social groups for each post we can create a temporal social network of the considered discussion group and analyze its activeness over time.", "In a more complex scenario, we can analyze the content of the comments and types of interactions within each post to discover two or more groups with different opinions, e.g. recommending and criticizing a new product for babies.", "\\newline  </section>"], ["<section> <title> Group Evolution Prediction methods </title>  The summary of the most relevant methods for group evolution prediction known from the literature confronted with GEP, which is described in this paper, can be found in Tab.", "[@ref:LABEL:tab:methods] .", "\\newline  </section>"], ["<section> <title> Data sets used </title>  Fifteen real-world data sets were analyzed in the iterative process of evaluating and improving the GEP method.", "Nonetheless, the results presented in this work refer to ten out of fifteen analyzed data sets.", "The limitation was made to keep the paper clear and concise.", "The data sets were selected in such way, that the networks created from them had diverse characteristics, see Tab.", "[@ref:LABEL:tab:datasets] .", "During the experimental studies, the parameters of the GEP method and its components (algorithms, methods, tools) were adjusted based on the literature review, authors suggestion, previous results and experience, and sometimes as a result of repeating the experimental study endless number of times.", "\\newline  </section>"], ["<section> <title> Evolution chain duplication </title>  Let\u2019s consider creating evolution chains of length 2 for the exemplary community evolution depicted in Fig. [@ref:LABEL:fig:duplicated_chains] .", "The list of evolution chains would contain five unique pairs of following states, see Tab.", "[@ref:LABEL:tab:duplicated_2states] .", "As one can observe, some evolution chains are partially duplicated, e.g., state $ ST_{2} $ and event $ EV_{2} $ of chain $ EC_{1} $ are the same as state $ ST_{1} $ and event $ EV_{1} $ of chain $ EC_{2} $ , chains $ EC_{2} $ and $ EC_{3} $ have the same state $ ST_{1} $ and event $ EV_{1} $ , chains $ EC_{4} $ and $ EC_{5} $ share the same state $ ST_{2} $ and event $ EV_{2} $ , and so on.", "The number of duplicated states and events would be even higher for a longer evolution chains.", "The partial duplication is a result of mixing (crossing) lifetimes of several groups, as the splitting and merging events involve at least two communities from the same time window: $ G_{1,3} $ and $ G_{2,3} $ in this example.", "\\newline Even partially duplicated chains might be a problem, as they may affect the classification results.", "For example, if chains $ EC_{2} $ and $ EC_{4} $ would be in the training set, used to learn a classifier, and chains $ EC_{3} $ and $ EC_{5} $ would be in the test set, used to evaluate the classification model, the classification accuracy for chains $ EC_{3} $ and $ EC_{5} $ could be falsely improved, because the classifier might assign the correct event type based on \u201cremembering\u201d the data, rather than learning from them.", "One may try to remove the partially duplicated chains by applying procedure similar to the \u201cgroup by\u201d SQL command.", "However, this will always result in losing some information as well.", "In this example, grouping chains on state $ ST_{2} $ and event $ EV_{2} $ would result in removing chain $ EC_{5} $ .", "\\newline A better solution is to use single-state chains, see Tab.", "[@ref:LABEL:tab:duplicated_1state] for the set of chains obtained from the considered exemplary evolution.", "Single-state chains can also contain duplicated states, e.g., when a method for tracking evolution will assign two different event types to the same community, but it is a rare case, and such duplication can be easily removed.", "Throughout this paper, the process of removing partially duplicated chains is called \u201cremoving duplicates.", "\u201d \\newline  </section>"], ["<section> <title> Feature selection </title>  Feature extraction is an essential step that needs to be performed prior to the classification.", "Various measures can be used to represent the characteristic of the community at any given time step.", "Much effort has been made by various researchers to propose such measures, leading to their abundance.", "However, the high number of features is not always beneficial in the classification process.", "It can lead to the necessity of obtaining more data for training, which is not always feasible.", "Not all classifiers are resilient to the presence of uninformative features, which can weaken their performance.", "Finally, feature extraction can be a time consuming procedure, during both training and evaluation of the model.", "Due to abovementioned factors, the number of utilized features should ideally be kept to the minimum, as long as it does not lead to loss in performance.", "\\newline To address this issue, feature selection process [@bib:guyon2003introduction] can be performed prior to classification.", "Feature selection is a procedure of automatically selecting a subset of features from the larger set, possibly containing irrelevant or mutually redundant features.", "The aim of such task is twofold: to improve the performance of the trained model, as well as to reduce the evaluation time during its testing.", "However, feature selection does not address the issue of long training time.", "On the contrary, based on the chosen method of selection, training can be significantly prolonged.", "Furthermore, feature selection might itself require large amounts of data to lead to meaningful results, instead of overfitting to the task at hand.", "Finally, feature selection by itself gives little insight into the problem.", "Selected features may or may not generalize well to the other, related problems, which in uncertain when the selection is performed on a single dataset.", "\\newline In the experiment described in this section, we implemented a slightly different task \u2013 feature ranking, with the aim of providing more insight about all considered measures.", "Given a large number of benchmark datasets, we tried to evaluate which measures lead to the best performance during the classification.", "To this end, we performed a feature selection based on the evolutionary algorithm [@bib:back2000evolutionary] .", "This procedure was repeated for various datasets and random data partitionings.", "Finally, we constructed a feature rankings based on the frequency of the occurrence of the given feature in the final selection.", "Because the feature selection strategy aims to optimize the classification performance, we postulate that the produced rankings indicate the quality of the features in the group evolution prediction task, with the quality being defined as an expected performance on the problems from the same domain.", "To the best of our knowledge, such evaluation has not been done before in the context of social group prediction.", "In the remainder of this section, we describe the proposed method more in-depth along with the most significant results.", "\\newline <subsection> <title> Method </title> The goal of the feature selection procedure is selecting a subset of features maximizing classification performance, at the same time minimizing the cost (most often computational) of producing the final subset.", "Given specific performance and cost measures, as well as the weights associated with both of these factors, in principle, it is possible to find the optimal feature subset, at least with regard to the available data.", "However, individually valuable features, i.e. the ones leading to the highest performance if used as the only predictor, will not necessarily be a part of the optimal subset.", "It has been shown [@bib:guyon2003introduction] that the feature useless by itself can improve performance significantly when taken with others, and that the presence of highly correlated features can negatively affect the performance.", "Therefore, if finding the optimal feature subspace was possible, a distinction between high-quality features (those included in the optimal subset) and low-quality features (the remaining ones) can be made.", "However, as the number of the available features grows larger, evaluating all of the possible subsets becomes infeasible.", "Instead of the optimal feature subset, one has to rely on its approximation produced by the feature selection procedure.", "If numerous such approximations can be produced, one can associate feature quality with the frequency of the occurrence of the feature in the selected subset.", "Similarly, the optimality can be discussed only with regard to the available data, which is only an approximation of the underlying distribution.", "By selecting different data sample, we obtain a different feature subset, which is only an approximation of the optimal one.", "\\newline We propose associating individual feature quality with the fraction of time it appears in the selected feature subset.", "On the data level, we provide diversity in the produced feature subsets by performing $ 5\\times 2 $ -fold partitioning [@bib:alpaydm1999combined] on the original dataset.", "Furthermore, we perform a non-deterministic feature selection using basic evolutionary algorithm [@bib:yang1998feature] and repeat it multiple times with a random initialization.", "The goal of the evolutionary algorithm is selecting a feature subset optimizing the defined fitness function.", "\\newline Let us denote the original data by a tuple $ (X,y) $ , with $ X $ being a $ n\\times d $ dimensional matrix of $ n $ observations consisting of $ d $ features each, and $ y $ being a vector of $ n $ class labels associated with observations.", "Furthermore, let us denote a $ d $ -dimensional binary mask encoding which features are present in the selected subset by $ \\hat{s} $ , with $ \\hat{s}_{i} $ indicating the presence of the $ i $ th feature.", "Finally, let us denote by $ X^{(\\hat{s})} $ the subselection of the observations, consisting only of the features encoded in $ \\hat{s} $ .", "Given the partitioning of $ (X,y) $ into the training data $ (X_{train},y_{train}) $ , validation data $ (X_{val},y_{val}) $ and test data $ (X_{test},y_{test}) $ , we denote the weighted $ F_{1} $ score obtained by training the classifier on subselection $ (X^{(\\hat{s})}_{train},y_{train}) $ and evaluating its performance on subselection $ (X^{(\\hat{s})}_{val},y_{val}) $ as $ F_{1}(\\hat{s}) $ .", "We can then define the final fitness function, optimized by the evolutionary algorithm, as \\newline <equation> $ f(\\hat{s})=\\gamma\\times F_{1}(\\hat{s})-\\delta\\times\\frac{\\sum_{i=1}^{d}{\\hat{s% }_{i}}}{d}, $ </equation> with $ \\gamma $ being the coefficient assigned to the classification performance, and $ \\delta $ \u2013 the coefficient assigned to the number of the selected features.", "The evolutionary algorithm using such fitness function performs a multi-objective optimization, with the objectives: maximize the classification performance and minimize the number of selected features, and the weight associated to the objectives based on the choice of $ \\gamma $ and $ \\delta $ .", "\\newline For the experiments, the values of $ \\gamma $ and $ \\delta $ have been set to 0.8 and 0.2, respectively.", "They were chosen to keep the number of features in a given selection relatively small, with the exact value dependent on the dataset.", "The Random Forest was chosen as the classifier used to evaluate the classification performance of a given feature subset.", "The original data has been split into the training, validation and test partitions in the proportion of 0.375, 0.125 and 0.5, respectively.", "Finally, the following parameters of the evolutionary algorithm have been used: number of generations of 100, population size of 500, probability of mutation of 0.02, probability of crossover of 0.7, and the tournament selection with the size of 3.", "For each of the $ 5\\times 2 $ folds, the evolutionary algorithm has been run 100 times, leading to 1000 feature subsets, based on which the final feature rankings have been computed.", "\\newline During the conducted experimental study, all GEP features (Tab. [@ref:LABEL:tab:predictiveFeatures] ), and additionally the features proposed by \u0130lhan et al. in [@bib:Ilhan:2016] were analyzed.", "The features were obtained from 7 real-world data sets: Digg, Facebook, Infectious, IrvineMessages, Loans, MIT, Slashdot, see Tab. [@ref:LABEL:tab:datasets] .", "The Infomap method was applied to obtain the disjoint communities, which evolution was then tracked by means of the GED method with the alpha and beta parameters set to 50%.", "Time windows of various type and size, as well as the evolution chains of various length, were used to evaluate abovementioned data sets, which led to 28 separate rankings.", "See Tab. [@ref:LABEL:tab:parameters] for the detailed information about the data setup parameters.", "For each configuration from Tab. [@ref:LABEL:tab:parameters] , a separate ranking was created.", "However, to draw more general conclusions some rankings were merged together by averaging occurrences of features in separate rankings.", "Only rankings containing the same set of features can be merged, thus, the same length of the evolution chain is required.", "Therefore, the merged rankings were obtained from the evolution chains of the following lengths: all 1-state evolution chains - Tab. [@ref:LABEL:tab:topTenFeatures1s] (ids 1-12 in Tab.", "[@ref:LABEL:tab:parameters] ), all 2-state evolution chains - Tab. [@ref:LABEL:tab:topTenFeatures2s] (ids 13-18 in Tab. [@ref:LABEL:tab:parameters] ), all 3-state evolution chains - Tab. [@ref:LABEL:tab:topTenFeatures3s] (ids 19-24 in Tab. [@ref:LABEL:tab:parameters] ), and all 9-state evolution chains - Tab. [@ref:LABEL:tab:topTenFeatures9s] (ids 26, 27, 28 in Tab. [@ref:LABEL:tab:parameters] ).", "\\newline In summary, the rankings of the most prominent features were different between various data sets and types of the time window, since the characteristics of the obtained temporal social networks were different.", "However, it was possible to identify a few measures, which appeared more often in the top ten features of various rankings.", "The variations of the eigenvector-, eccentricity-, and closeness-based measures were present in most of the presented shortlisted rankings, which suggests that centrality- and distance-based measures, obtained at the node level, are more informative predictors for the classifier.", "Surprisingly, measures describing the community in the most straightforward way, e.g., the community size or density, did not occur in the shortlisted rankings, usually taking place in the second half of the rankings.", "Furthermore, the macroscopic features, especially the network density, were important only when the history of the community was very short (1-2 states).", "Thus, when there were more historical data available, classifiers preferred past microscopic and mesoscopic features over the recent macroscopic features.", "What is more, the predictive features proposed by \u0130lhan et al. in [@bib:Ilhan:2016] were ranked rather low, except the IlhanAging feature, which was the most commonly used in case of the 1-state evolution chains (Tab. [@ref:LABEL:tab:topTenFeatures1s] ) and was usually also among the top 30 features in other rankings.", "\\newline </subsection> <subsection> <title> Reproducibility </title> Experiment described in this section has been implemented in the Python programming language.", "Existing implementations of the classification algorithms from scikit-learn [@bib:scikit-learn] and evolutionary algorithms from DEAP [@bib:DEAP_JMLR2012] have been used.", "Code sufficient to repeat the experiment has been made publicly available at , whereas the necessary data, especially its partitioning used during the experiment, has been provided at [@bib:harvard_data] .", "\\newline </subsection>  </section>"], ["<section> <title> Classifiers used in the experiments </title>  In this experimental study 15 different classifiers, implemented in WEKA Data Mining Software [@bib:hall2009weka] , were compared in term of the average F-measure value.", "They were gathered into six more general types.", "\\newline <subsection> <title> Rule classifiers </title> <list> \\ ZeroR is the simplest classification method, which relies on the target and ignores all predictors.", "ZeroR classifier simply classifies the majority category (class).", "Although there is no predictability power in ZeroR, it is useful for determining a baseline performance as a benchmark for other classification methods.", "\\newline \\ \\ RIPPER (JRip) is a propositional rule learner, also called Repeated Incremental Pruning to Produce Error Reduction (RIPPER), which was proposed by Cohen [@bib:cohen1995fast] .", "\\newline \\ \\ DecisionTable builds a simple decision table majority classifier [@bib:kohavi1995power] .", "It evaluates the feature subsets using a best-first search and can use a cross-validation for the evaluation.", "\\newline \\ </list> \\newline </subsection> <subsection> <title> Function classifier </title> <list> \\ Support Vector Machine (SVM) performs classification by finding the hyperplane that maximizes the margin between classes.", "The vectors (cases) that define the hyperplane are the support vectors [@bib:chang2011libsvm] .", "\\newline \\ </list> \\newline </subsection> <subsection> <title> Tree classifiers </title> <list> \\ REPTree is a fast decision tree learner, which builds a decision/regression tree using the information gain/variance and prunes it using a reduced-error pruning (", "with backfitting).", "It only sorts values for the numeric attributes once, and the missing values are dealt with by splitting the corresponding instances into pieces.", "\\newline \\ \\ RandomForest is a well-known classifier for constructing a forest of random trees [@bib:breiman2001random] .", "\\newline \\ \\ C4.5 (J48) is a classic classifier generating a pruned or unpruned C4.5 decision tree [@bib:quinlan2014c4] .", "\\newline \\ \\ SimpleCart is a classifier implementing the minimal cost-complexity pruning [@bib:breiman1984classification] .", "\\newline \\ </list> \\newline </subsection> <subsection> <title> Bayes classifiers </title> <list> \\ NaiveBayes is a simple classifier using estimator classes; numeric estimator precision values are chosen based on analysis of the training data [@bib:john1995estimating] .", "\\newline \\ \\ BayesNet is a factored representation of the probability distributions that generalize the naive Bayesian classifier and explicitly represent statements about independence [@bib:hall2009weka] .", "\\newline \\ </list> \\newline </subsection> <subsection> <title> Lazy classifiers </title> <list> \\ KNN (IBk) is a simple algorithm that stores all available cases and classifies new cases based on a similarity measure, e.g., distance functions [@bib:aha1991instance] .", "\\newline \\ \\ K* KStar is an instance-based classifier, that is the class of a test instance is based upon the class of those training instances similar to it, as determined by some similarity function.", "It differs from other instance-based learners in that it uses an entropy-based distance function [@bib:cleary1995k] .", "\\newline \\ </list> \\newline </subsection> <subsection> <title> Meta-classifiers </title> <list> \\ AdaBoost (with DecisionStump) is a classifier for boosting a nominal class classifier using the Adaboost M1 method [@bib:freund1996experiments] .", "DecisionStump [@bib:iba1992induction] performs the classification based on entropy; missing values are treated as a separate value.", "\\newline \\ \\ Bagging (with REPTree) bags a classifier to reduce the variance.", "Can do classification and regression depending on the base learner [@bib:breiman1996bagging] .", "\\newline \\ \\ MultiClassClassifier (with Logistic) is a meta-classifier for handling multi-class data sets with 2-class classifiers.", "This classifier is also capable of applying error correcting output codes for increased accuracy.", "Logistic is a classifier building a multinomial logistic regression model with a ridge estimator [@bib:le1992ridge] .", "\\newline \\ </list> \\newline </subsection> <subsection> <title> Statistical tests of classifiers </title> In order to statistically compare classifiers the Friedman test [@bib:Friedman:1937] with the Shaffer post-hoc multiple comparisons [@bib:Shaffer:1986] was utilized.", "The non-parametric statistical analysis was computed with the KEEL software tool [@bib:KEEL:2009] .", "The Friedman procedure was applied two times, once on the results obtained from the imbalanced data sets, and once on the results obtained from the data sets balanced with the equal size sampling technique."]], "target": "Tab. presents the average ranks obtained by applying the Friedman procedure. The test conducted on the imbalanced data sets produced p-value= $ 5.25*10^{-5} $ , while the test on the balanced data sets provided p-value= $ 1.1*10^{-3} $ . Since both p-values are much lower than 0.05, the results can be considered statistically significant."}, {"tabular": ["  TRUE CPTS  &  FOUND CPTS  &  ADJ. RAND ", " 120, 190, 310  &  120, 188, 310  &  0.992 ", " 70, 190, 310  &  66, 191, 310  &  0.980 ", " 120, 240, 430  &  118, 239, 423  &  0.9 49 ", " 190, 260, 380  &  93, 190, 260, 380  &  0.804 ", " 120, 240, 310  &  119, 243  &  0.757 ", " 120, 240, 310  &  297  &  0.506 ", " 70, 190, 380  &  380  &  0.363  "], "ref_sec": [["<section> <title> 1 Introduction </title>  The area of high-dimensional inverse covariance (or precision) matrix estimation has developed considerably over the past years.", "This is partly due to the off-diagonal entries of the precision matrix encoding un-scaled partial correlations and in the case of a multivariate normal distribution even conditional independence between two variables given all the others.", "The resulting graph, with variables as nodes and edges for nonzero off-diagonal entries is called a conditional independence graph or Gaussian graphical model (GGM), respectively [@bib:lauritzen] .", "\\newline In a lot of settings where the graphical structure of a set of observations is of interest, the data is in the form of a time series (or has another natural ordering, e.g. by space or genome location) and the underlying distribution might change over time.", "A lot of attention is given to the setting where there are structural breaks, so called change points, in between which the observations are identically distributed.", "Disregarding this structure and estimating a GGM for all observations leads to a fit of mixtures that does not model the true GGM well for any time point.", "In such cases to estimate the graphical structure, prior good estimation of the change points is key.", "\\newline Real world data sets often suffer from missing values.", "In the presence of change points and without prior knowledge of them, usual imputation methods are not expected to perform well as they require observations from a homogeneous distribution.", "However, some kind of imputation method is necessary in order to apply any of the current methods to find change points, between which the distribution can be assumed to be homogeneous, leading to a chicken and egg kind of problem.", "\\newline <subsection> <title> 1.1 Related Work </title> For homogeneous observations, [@bib:MeinsBuhl] proposed to use nodewise regression using the Lasso [@bib:lasso_original] to recover the conditional independence structure from data.", "[@bib:YuanLin] introduced an estimator for the precision matrix (and thus the GGM) via maximisation of the $ L_{1} $ -penalized Gaussian log-likelihood over the set of positive definite matrices.", "The graphical Lasso (glasso) algorithm of [@bib:glasso] with subsequent improvements ( [@bib:witten_glasso] ; [@bib:mazumder2012] ) gained popularity for computing such estimates such that the term glasso is now also associated with the corresponding estimator.", "Computational approaches for the estimator were also presented by [@bib:Banerjee_dAspremont] , theoretical properties of it were investigated by [@bib:YuanLin] , [@bib:Rothman] , [@bib:sparsistency] and [@bib:Ravikumar] .", "\\newline For the non-homogeneous case, [@bib:ZhouLaffertyWassermann] considered cases where the graph structure varies smoothly and [@bib:KolarXing] investigated under which conditions the graph structure can be recovered consistently.", "In a setting with abrupt structural breaks, [@bib:Kolar_Gauss_estim] proposed to estimate the locations of change points with a total variation penalty for consecutive observations either using nodewise regression or a penalized likelihood approach.", "[@bib:GibberdNelson] investigated group-fused and independent-fused graphical Lasso methods (with a Frobenius norm or an $ L_{1} $ -fusion penalty).", "Some statistical analysis of the former was provided by [@bib:Gibberd_Roy] .", "While [@bib:Kolar_Gauss_estim] used an accelerated gradient descent method, [@bib:GibberdNelson] proposed an ADMM algorithm to calculate the estimator, similarly to [@bib:Hallac_network] , who considered larger classes of fusion type penalties.", "Other computational approaches include an approximate majorize-minimize algorithm [@bib:Bybee_Atchade_JMLR] or a specific greedy search [@bib:Hallac_GGS] .", "More thorough statistical analysis of similar proposals was conducted by [@bib:Avanesov_theory] , [@bib:Wang_Yu_Rinaldo_theory] , [@bib:Dette_theory] and [@bib:RoyMichailidis] .", "\\newline In the presence of missing values, the maximisation of the $ L_{1} $ -penalized log-likelihood (see equation ( [@ref:LABEL:eq:loglikelihood_missing_1] ) later on) is no longer a convex problem, even for homogeneous observations.", "For this scenario of homogeneous observations with missing values, [@bib:missglasso] proposed to use an Expectation Maximisation algorithm coupled with the glasso to obtain an estimate of the precision matrix.", "The single example of the treatment of missing values in the context of change point detection we are aware was done by [@bib:changepoint_missing] .", "They however considered an online (sequential) setup and assumed that the observations lie close to a time-varying low-dimensional submanifold within the observation space.", "This assumption is appropriate in e.g. video surveillance, but it is unrealistic in the setting of GGMs, even if the underlying precision matrix is assumed to be sparse.", "\\newline </subsection> <subsection> <title> 1.2 Possible applications </title> Applications of change point detection within graphical models include the analysis of environmental measurements, biological data and financial time series, which potentially encounter the problem of missing values.", "One specific motivating example for our proposals was the shallow groundwater monitoring data set, which we will discuss later on.", "To mention further concrete examples, multivariate change point detection methods (in GGMs) could also be useful for example in detecting the signal of abrupt climate changes imprinted simultaneously into multiple climate proxy records, e.g. ice cores in Antarctica or speleothems, all facing missing values [@bib:s1] .", "\\newline So far, it is common practice to discard variables with too much missingness and to perform simple imputations on the rest [@bib:ecp] .", "Also, sometimes univariate methods are used to detect change points for each variable separately [@bib:s2] .", "These approaches are suboptimal.", "Discarding non-complete observations, especially with high-dimensional data and inhomogeneity of the missingness structure with respect to time, is impractical as it results in a significant loss in information.", "\\newline </subsection> <subsection> <title> 1.3 Our contribution </title> Our investigated setup is composed of three problems: change point detection, estimation of GGMs and the treatment of missing values.", "While there are many possible applications, there is currently no readily available method combining the three and thus capable of estimating change points in a GGM in the presence of missing values.", "We fill this gap and provide practitioners with practically usable, and in particular computationally tractable methods, which are implemented in an R -package (see the Supplementary material for the current version.", "The package is planned to be uploaded to CRAN after acceptance of the manuscript for publication).", "\\newline We investigate different scenarios of missingness (both missing completely at random and with structures resembling real world scenarios), discuss the resulting difficulties and propose viable estimation approaches.", "Their performance is evaluated in a simulation study and applied to environmental and financial data.", "\\newline </subsection>  </section>"], ["<section> <title> 2 Change point detection without missing values </title>  Consider a sequence of independent Gaussian random variables $ (X_{i})_{i=1}^{n}\\in{\\mathbb{R}}^{p} $ with means $ \\mu_{i} $ and covariance matrices $ \\Sigma_{i}=\\Omega_{i}^{-1} $ such that the map $ i\\mapsto(\\mu_{i},\\Sigma_{i}) $ is piecewise constant.", "Let \\newline <equation> $ \\alpha^{0}:=\\{0,n\\}\\cup\\{i:(\\mu_{i},\\Sigma_{i})\\neq(\\mu_{i+1},\\Sigma_{i+1})\\} $ </equation> be the set of segment boundaries.", "We label the elements of $ \\alpha^{0} $ by their natural order starting with zero such that consecutive pairs of elements in $ \\alpha^{0} $ define segments $ (\\alpha^{0}_{k-1},\\alpha^{0}_{k}],\\ k=1,\\dotsc,|\\alpha^{0}|-1 $ within which the $ X_{i} $ are i.i.d.", "For $ 0\\leq u<v\\leq n $ let $ X_{(u,v]} $ denote the matrix of the observations $ X_{u+1},\\ldots,X_{v} $ , denote with $ \\hat{\\mu}^{(u,v]} $ their mean and let $ S_{(u,v]}:=(X_{(u,v]}-\\hat{\\mu}^{(u,v]})^{T}(X_{(u,v]}-\\hat{\\mu}^{(u,v]})/(v-u) $ be the corresponding covariance matrix.", "\\newline For $ \\delta>0 $ define $ {\\cal A}_{n,\\delta} $ to be the family of possible sets of segment boundaries such that the minimal segment length is not smaller than $ \\delta n $ .", "If $ L_{n}((u,v]) $ is some normalized loss after fitting an adequate model to $ X_{(u,v]} $ and $ \\gamma>0 $ a penalty parameter for the number of segments, an estimator for $ \\alpha^{0} $ is \\newline <equation> $ \\hat{\\alpha}^{0}:=\\underset{\\alpha\\in{\\cal A}_{n,\\delta}}{\\operatorname{argmin% }}\\sum_{j=1}^{|\\alpha|-1}L_{n}((\\alpha_{j-1},\\alpha_{j}])+\\gamma.", "$ </equation> \\newline This estimator can be computed using dynamic programming with $ {\\cal O}(n^{2}) $ evaluations of $ L_{n} $ , see for example [@bib:hawkins1976point] .", "This is computationally infeasible if $ n $ is large, especially if the cost to evaluate $ L_{n} $ is significant.", "\\newline Binary Segmentation is a much faster greedy algorithm to estimate $ \\alpha^{0} $ .", "For this define the gains function of some segment $ (u,v] $ at some split point $ s $ to be \\newline <equation> $ G_{n}^{(u,v]}(s):=L_{n}((u,v])-L_{n}((u,s])-L_{n}((s,v]) $ </equation> and define \\newline <equation> $ \\hat{\\alpha}_{(u,v]}:=\\underset{s\\in\\{u+\\delta n,\\dotsc,v-\\delta n\\}}{% \\operatorname{argmin}}G_{n}^{(u,v]}(s).", "$ </equation> The search for a single change point in $ (X_{i})_{i=1}^{n} $ by solving ( [@ref:LABEL:eq:changepointestimator] ) breaks down to finding $ \\hat{\\alpha}_{(0,n]} $ and checking if $ G_{n}^{(0,n]}(\\hat{\\alpha}_{(0,n]})>\\gamma $ .", "For the multiple change point case Binary Segmentation (BS) finds an approximate solution to ( [@ref:LABEL:eq:changepointestimator] ) by recursively splitting segments using ( [@ref:LABEL:eq:singlesplitpoint] ) until the resulting segment length is smaller than $ 2\\delta n $ such that a split is no longer allowed or the corresponding gain is not bigger than $ \\gamma $ , the minimally required gain to split.", "BS typically requires asymptotically $ {\\cal O}(n\\log(n)) $ evaluations of $ L_{n} $ .", "\\newline This can still be prohibitive if the cost of evaluating $ L_{n} $ is large and $ n $ is big.", "Instead of evaluating $ G_{n}^{(u,v]}(s) $ at every possible split in a full grid search to find its maximum, one can find one of its local maxima with smartly chosen $ \\log(n) $ evaluations, see [@bib:OBS] .", "The expected gain curve for common losses (e.g. the squared error loss) is piecewise convex between the true underlying segment boundaries, such that in particular all local maxima correspond to change points.", "Hence, splitting at a local maximum instead of the global one does not induce a false discovery and the missed global maximum can still be found in a later step.", "Doing BS with this adaptive search is called Optimistic Binary Segmentation (OBS) [@bib:OBS] and approximately requires $ {\\cal O}(\\log(n)^{2}) $ evaluations of $ L_{n} $ .", "Optimism is needed in noisy scenarios, when the idealized piecewise convex structure is distorted.", "In an extremely noisy case the optimistic search strategy might fail while the full grid search would possibly still perform reasonably.", "We will see later on how this influences the applicability of OBS in scenarios with lots of missing data.", "\\newline [@bib:LeonBuhl] applied BS to a high-dimensional regression change point problem using the negative log-likelihood for Gaussian errors (sum of squared errors) resulting from a Lasso fit as a loss measure.", "They provided (under technical conditions) consistency results if the penalization parameter $ \\lambda $ for the Lasso is adjusted by the inverse of the square root of the relative segment length, i.e. by using $ \\lambda_{(u,v]}:=\\sqrt{(n/(v-u))}\\lambda_{0} $ for some fixed $ \\lambda_{0} $ for the segment $ (u,v] $ .", "\\newline In order to adapt this approach to the multivariate normal case, we set \\newline <equation> $ L_{n}(\\Omega;S_{(u,v]}):=\\frac{v-u}{n}\\left(\\operatorname{Tr}(\\Omega^{T}S_{(u,% v]})-\\log(|\\Omega|)\\right) $ </equation> and define \\newline <equation> $ \\hat{\\Omega}_{(u,v]}^{\\rm glasso}:=\\underset{{\\mathbb{R}}^{p\\times p}\\ni\\Omega% \\succ 0}{\\operatorname{argmin}}L_{n}(\\Omega;S_{(u,v]})+\\lambda_{(u,v]}\\|\\Omega% \\|_{1}. $ </equation> This way $ L_{n}(\\Omega;S_{(u,v]}) $ is (up to a constant) the negative log-likelihood of a Gaussian with precision matrix $ \\Omega $ given observations $ X_{(u,v]} $ that is scaled with segment length.", "Furthermore, $ \\hat{\\Omega}_{(u,v]}^{\\rm glasso} $ is the glasso estimator from [@bib:glasso] for the precision matrix of observations $ X_{(u,v]} $ with penalization parameter $ \\lambda_{(u,v]} $ .", "We prefer not to penalize the diagonal in $ \\|\\Omega\\|_{1} $ .", "We then use the in sample loss \\newline <equation> $ L_{n}((u,v]):=L_{n}(\\hat{\\Omega}_{(u,v]}^{\\rm glasso};S_{(u,v]}) $ </equation> after fitting the glasso in equation ( [@ref:LABEL:eq:gains_fun] ) as the loss when greedily searching for optimal splits with BS or OBS.", "\\newline We choose the graphical Lasso for the estimation of the precision matrix since some sparsity assumption seems crucial in high-dimensional scenarios.", "( [@bib:Avanesov_theory] also relied on the graphical Lasso (or similar procedures for sparse precision matrices) and [@bib:RoyMichailidis] also had a sparsity assumption.) Additionally, the change point detection is expected to be more powerful and reasonable when placing the sparsity assumption on the precision matrix rather than the covariance matrix, in particular when considering sparse changes between conditional dependencies among a few variables.", "For low-dimensional scenarios non-sparse (e.g. ridge type) estimators could also be reasonable, but differences in estimated change point locations compared to our glasso based approach are expected to be small.", "\\newline Overall the algorithms have three tuning parameters: $ \\delta $ for the minimal relative segment length, $ \\gamma $ to control for the number of segments and $ \\lambda_{0} $ for the sparsity of the precision matrices.", "Note that the procedure is similar to the one proposed by [@bib:Angelosante] , but as a crucial difference the penalty is scaled according to the segment length with $ \\lambda_{(u,v]} $ .", "\\newline  </section>"], ["<section> <title> 3 Adapting to missing data </title>  For non-complete data denote with $ x_{\\operatorname{obs},i} $ the observed part of the $ i $ -th observation and with $ \\Omega_{\\operatorname{obs},i} $ and $ \\mu_{\\operatorname{obs},i} $ the submatrix of $ \\Omega $ and the subvector of $ \\mu $ corresponding to the observed variables of $ x_{i} $ .", "Similarly denote with $ \\mu_{\\operatorname{mis},i} $ the subvector of $ \\mu $ corresponding to the variables of $ x_{i} $ with missing values.", "The normalized negative Gaussian log-likelihood of observations from a segment $ (u,v] $ is \\newline <equation> $ \\begin{split}\\ell(&\\mu,\\Omega,(x_{i})_{i=u+1}^{v})=\\frac{1}{2n}\\sum_{i=u+1}^{v% }\\Big{(}\\log(|2\\pi\\Omega_{\\operatorname{obs},i}|)-\\\\ &(x_{\\operatorname{obs},i}-\\mu_{\\operatorname{obs},i})^{T}\\Omega_{% \\operatorname{obs},i}(x_{\\operatorname{obs},i}-\\mu_{\\operatorname{obs},i})\\Big% {)}.\\end{split} $ </equation> Set $ \\hat{\\mu}^{(u,v]} $ to be the empirical mean of the observed part of $ X_{(u,v]} $ (discarding the missing values).", "Note that $ \\hat{\\mu}^{(u,v]} $ might have missing values itself if for some variable there is no observed value in the segment $ {(u,v]} $ .", "Let \\newline <equation> $ \\ell(\\Omega;(x_{i})_{i=u+1}^{v}):=\\ell(\\hat{\\mu}^{(u,v]},\\Omega;(x_{i})_{i=u+1% }^{v}).", "$ </equation> The $ L_{1} $ -penalized maximum likelihood estimator for observations $ X_{(u,v]} $ is then \\newline <equation> $ \\hat{\\Omega}_{(u,v]}=\\underset{{\\mathbb{R}}^{d\\times d}\\ni\\Omega\\succ 0}{% \\operatorname{argmin}}\\ell(\\Omega;(x_{i})_{i=u+1}^{v})+\\lambda_{(u,v]}\\sum_{u+% 1}^{v}\\|\\Omega_{\\operatorname{obs},i}\\|_{1}. $ </equation> Contrary to ( [@ref:LABEL:eq:glasso_estimator] ), this problem is no longer convex and cannot be solved efficiently with an update-based approach like the glasso.", "The Miss-Glasso algorithm proposed by [@bib:missglasso] combines the glasso and an Expectation Maximization (EM) algorithm to estimate the precision matrix in the presence of missing data.", "However, the algorithm needs complete observations for a good initialization, is computationally expensive due to a new glasso fit for each EM iteration and might get stuck in local optima.", "These features are especially critical in our setting of high-dimensional change point detection.", "High computational cost is prohibitive since we do a lot of evaluations of the loss function.", "More importantly even, for each split, Miss-Glasso would be initialised slightly differently and in some situations it could converge to a very different local optimum.", "This would result in jumps in the gain curve from equation ( [@ref:LABEL:eq:gains_fun] ) for some neighboring splits $ s $ .", "\\newline While an accurate estimate $ \\hat{\\Omega}_{(u,v]} $ is necessary for a good fit, this is not needed for change point detection, as it is sufficient to preserve the piecewise convex structure of the gains function ( [@ref:LABEL:eq:gains_fun] ).", "This key new idea helps to avoid the heavy computations and local optima of the EM algorithm when doing BS or OBS.", "In the following, we propose estimators $ \\tilde{S}_{(u,v]} $ that approximate $ S_{(u,v]} $ based on $ (x_{\\operatorname{obs},i})_{i=u+1}^{v} $ .", "We can then use $ \\tilde{S}_{(u,v]} $ in the glasso estimator ( [@ref:LABEL:eq:glasso_estimator] ) to obtain $ \\tilde{\\Omega}_{(u,v]}^{\\rm glasso} $ instead of $ \\hat{\\Omega}^{\\rm glasso}_{(u,v]} $ and use the resulting log-likelihood $ \\ell(\\tilde{\\Omega}^{\\rm glasso}_{(u,v]},(x_{i})_{i=u+1}^{v} $ ) as in equation ( [@ref:LABEL:eq:loglikelihood_missing_2] ) with minor modifications (see Section [@ref:LABEL:section:curve_smoothing] ) as a loss measure.", "\\newline <subsection> <title> 3.1 Missing value imputations </title> We propose three different estimators $ \\tilde{S}_{(u,v]} $ for data with missing values.", "These will lead to different results, computational costs and applicabilities.", "\\newline <paragraph> <title> The average imputation estimator </title> In a first attempt, we impute the missing values $ (x_{\\operatorname{mis},i})_{i=u+1}^{v} $ with the average value of the corresponding variables within the interval $ (u,v] $ .", "Thus define centered variables \\newline <equation> $ z_{\\operatorname{obs},i}^{(u,v]}:=x_{\\operatorname{obs},i}-\\hat{\\mu}^{(u,v]}_{% \\operatorname{obs},i}\\ \\textrm{and }\\ \\hat{z}^{(u,v]}_{i}:=(\\hat{z}^{(u,v]}_{% \\operatorname{obs},i},0) $ </equation> and estimate \\newline <equation> $ {\\tilde{S}}_{(u,v]}^{\\rm av}:=\\frac{1}{v-u}(\\hat{z}^{(u,v]}_{u+1},\\dotsc,\\hat{% z}^{(u,v]}_{v})^{T}(\\hat{z}^{(u,v]}_{u+1},\\dotsc,\\hat{z}^{(u,v]}_{v}).", "$ </equation> This will underestimate the variance and covariance of variables where values are missing.", "Nonetheless the average method serves as a baseline.", "\\newline </paragraph> <paragraph> <title> The Loh-Wainwright bias corrected estimator </title> We try to counteract the shortcomings of the average imputation method using the bias correction presented by [@bib:loh2012structure] .", "The authors show that if the $ j $ -th variable of an observation in $ X_{(u,v]} $ is discarded with probability $ \\rho_{j} $ , setting \\newline <equation> $ M_{i,j}:=\\begin{cases}\\frac{1}{(1-\\rho_{i})(1-\\rho_{j})}&i\\neq j\\\\ \\frac{1}{1-\\rho_{i}}&i=j\\end{cases}, $ </equation> the matrix $ \\tilde{S}_{(u,v]}^{\\rm av}\\circ M $ is an unbiased estimator of $ S_{(u,v]} $ .", "Here $ \\circ $ denotes the Hadamard (pointwise) product for matrices.", "In practice, we have to estimate the $ \\rho_{i} $ based on the proportion of missing observations, leading to $ \\hat{M} $ .", "Note that the resulting matrix $ \\tilde{S}_{(u,v]}^{\\rm av}\\circ\\hat{M} $ is not necessary positive semi-definite which is required for the glasso algorithm [@bib:glasso] to converge.", "We thus compute the closest positive semi-definite matrix to $ \\tilde{S}_{(u,v]}^{\\rm av}\\circ\\hat{M} $ with respect to the Frobenius norm using the Higham algorithm [@bib:higham2002computing] and take this as our final Loh-Wainwright (LW) bias corrected estimator $ \\tilde{S}_{(u,v]}^{\\rm LW} $ .", "Note that the Higham algorithm has an asymptotic complexity of $ {\\cal O}(p^{3}) $ similar to the glasso and thus evaluating the gain using the LW estimator is computationally more expensive than the average imputation method.", "\\newline </paragraph> <paragraph> <title> Pairwise covariance estimation </title> A third estimate can be based on pairwise covariance estimates, where the covariance between two variables is calculated from observations where both corresponding variables are available.", "Similar to the LW estimator, this gives a valid estimate of the variances and covariances of variables, even if the missingness structure in the data is not homogeneous.", "If there are less than two complete observations for a pair of variables in a segment, we set the covariance between these variables to be zero.", "Again, as with the LW approach, this might yield a matrix that is not positive semi-definite.", "We hence apply the Higham algorithm to compute the closest positive semi-definite matrix and denote the resulting estimator by $ \\tilde{S}_{(u,v]}^{\\rm pair} $ .", "\\newline </paragraph> </subsection> <subsection> <title> 3.2 Avoiding jumps in the gain curve </title> For all of the three proposals above, the estimation of the variance of a variable on a given segment requires at least two observations with non missing values.", "In order to obtain a meaningful estimate, more non-missing observations are necessary.", "As a consequence, with a lot of missing values or small segments, we might only be able to estimate a submatrix of the full covariance matrix.", "For such segments, the log-likelihood can then only be computed for a submodel of the entire multivariate Gaussian distribution.", "When evaluating the gains function ( [@ref:LABEL:eq:gains_fun] ) at some split point $ s $ , it might thus happen that the log-likelihood of the segment $ {(u,v]} $ is calculated based on a larger covariance matrix (and thus a model with more parameters) than for $ (u,s] $ or $ (s,v] $ .", "As the log-likelihoods of multivariate Gaussians of different dimensions are not easily comparable, this is especially problematic for split points $ s $ such that the estimated covariance matrix for the neighboring split $ s+1 $ has a different size.", "In such scenarios, the gains curve often has jumps between $ s $ and $ s+1 $ (see Figure [@ref:LABEL:fig:curve_smoothing] ).", "To alleviate this, we propose to restrict the log-likelihood of $ {(u,v]} $ to the dimensions available for $ (u,s] $ and $ (s,v] $ . To make this more concrete, let us introduce some notation.", "\\newline Denote for a segment $ {(u,v]} $ and some $ k\\geq 2 $ with $ j_{(u,v]}(k) $ the indices of the variables for which at least $ k $ values are observed in the segment $ {(u,v]} $ .", "For any imputation method $ *\\in\\{{\\rm av},{\\rm LW},{\\rm pair}\\} $ let $ {\\tilde{S}}_{(u,v]}^{*,k}:=({\\tilde{S}}_{(u,v]}^{*})_{j_{(u,v]}(k),j_{(u,v]}(k)} $ be the submatrix of $ {\\tilde{S}}_{(u,v]}^{*} $ where each variable has at least $ k $ observed values.", "Finally denote with $ \\tilde{\\Omega}^{\\rm glasso}_{(u,v],k}=\\tilde{\\Omega}^{\\rm glasso}_{(u,v]}({% \\tilde{S}}_{(u,v]}^{*,k}) $ the obtained glasso fit for the submatrix.", "In our simulations we set the minimal number of required observations for keeping a variable to be $ k=5 $ .", "\\newline A naive estimator for the gains function is \\newline <equation> $ \\begin{split}\\tilde{G}^{(u,v],k}_{n,{\\rm naive}}(s):=\\ &\\ell(\\tilde{\\Omega}^{% \\rm glasso}_{(u,v],k},(x_{i,j_{(u,v]}(k)})_{i=u+1}^{v})\\ -\\\\ &\\ell(\\tilde{\\Omega}^{\\rm glasso}_{(u,s],k},(x_{i,j_{(u,s]}(k)})_{i=u+1}^{s})% \\ -\\\\ &\\ell(\\tilde{\\Omega}^{\\rm glasso}_{(s,v],k},(x_{i,j_{(s,v]}(k)})_{i=s+1}^{v}).% \\end{split} $ </equation> This naive estimator might be comparing log-likelihoods of multivariate normal distributions of different dimensions at some possible split points $ s $ if $ j_{(u,s]}(k)\\subsetneq j_{(u,v]}(k) $ or $ j_{(s,v]}(k)\\subsetneq j_{(u,v]}(k) $ . See Figure [@ref:", "LABEL:fig:blocks_plot] for an illustrative example.", "Here $ j_{(u,s]}(2)=\\{1,2,3\\} $ , $ j_{(s,v]}(2)=\\{2,3,4\\} $ and $ j_{(u,v]}(2)=\\{1,2,3,4\\} $ .", "The log-likelihood $ \\ell(\\tilde{\\Omega}^{\\rm glasso}_{(u,v],2},(x_{i,j_{(u,v]}(2)})_{i=u+1}^{v}) $ of the full segment would be using the first variable of the (s+1)-st observation for evaluation, whereas the log-likelihood $ \\ell(\\tilde{\\Omega}^{\\rm glasso}_{(s,v],2},(x_{i,j_{(s,v]}(2)})_{i=s+1}^{v}) $ of the segment on the right would not.", "\\newline To avoid this, we propose to use the slightly different estimator \\newline <equation> $ \\begin{split}\\tilde{G}^{(u,v],k}_{n}(s):=\\ &\\ell(\\tilde{\\Omega}^{\\rm glasso}_{% (u,v],k},(x_{i,j_{(u,s]}(k)})_{i=u+1}^{s})\\ +\\\\ &\\ell(\\tilde{\\Omega}^{\\rm glasso}_{(u,v],k},(x_{i,j_{(s,v]}(k)})_{i=s+1}^{v})% \\ -\\\\ &\\ell(\\tilde{\\Omega}^{\\rm glasso}_{(u,s],k},(x_{i,j_{(u,s]}(k)})_{i=u+1}^{s})% \\ -\\\\ &\\ell(\\tilde{\\Omega}^{\\rm glasso}_{(s,v],k},(x_{i,j_{(s,v]}(k)})_{i=s+1}^{v}).% \\end{split} $ </equation> Here we only use the variables $ j_{(u,s]}(k) $ and $ j_{(s,v]}(k) $ in the calculation for the loss of the full segment $ {(u,v]} $ when splitting at $ s $ .", "Hence, slightly different losses are used for the full segment depending on the split point.", "As we are not primarily interested in a segments\u2019 own loss, but rather a fair estimate of the gain, this is a sensible approach.", "\\newline This does not increase the computational cost significantly, as for repeated evaluations of $ \\tilde{G}^{(u,v],k}_{n} $ we can keep the initial estimate $ \\tilde{\\Omega}^{\\rm glasso}_{(u,v]} $ .", "Without this mechanism the gain curve exhibits jumps at the boundaries of missing blocks, as illustrated in Figure [@ref:LABEL:fig:curve_smoothing] .", "This might prevent BS and OBS from correctly estimating the change points.", "The severity of this problem depends on the block size.", "When the missingness structure is homogeneous in time, the block size is small such that this is not a pronounced issue.", "However, in many applications one faces blockwise missing data, where such jumps would be a pronounced issue without our proposal.", "\\newline </subsection>  </section>"], ["<section> <title> 4 Model selection </title>  A good choice of tuning parameters is essential for accurate estimation results.", "The parameter $ \\lambda_{0} $ controls the form of the gain curve.", "When chosen too small, the glasso tends to overfit and the resulting gain curve has an inverse U shape independently of the underlying change points.", "When chosen too big, the glasso underfits, resulting in an almost constant gain curve.", "Even though we adjust the penalization ( $ \\lambda_{(u,v]} $ ) depending on the segment length, one global $ \\lambda_{0} $ might not be able to approximate the shape (piecewise convex structure) of the population version of the gain curve simultaneously in all possible segments encountered during BS or OBS.", "If the sparsity pattern of the underlying graphical model in the segments differs strongly, selecting a new $ \\lambda_{0} $ in each splitting step of BS or OBS is advocated to obtain good results.", "\\newline The parameters $ \\gamma $ (the penalty for the number of segments) and $ \\delta $ (the minimum relative segment size) on the other hand control the depth of the tree structure generated by BS and thus how many change points are found.", "A sufficiently large value of $ \\delta $ is also necessary to achieve stability of fits in high-dimensional scenarios.", "Often, overly small segments are uninterpretable and thus uninteresting for practitioners, such that $ \\delta $ can be set to some predetermined value (typically around 0.1).", "Thus, $ \\gamma $ is the key parameter to be chosen in order to avoid under- or oversegmentation.", "[@bib:LeonBuhl] proposed to choose values for $ \\lambda_{0} $ and $ \\gamma $ via 2-fold cross validation, where the test data is taken from an equispaced grid across the entire sample.", "Since change points for $ \\gamma $ can be regained from trees grown with smaller $ \\gamma^{\\prime}<\\gamma $ , it is only necessary to do one BS fit (with $ \\gamma=0 $ ) per fold and $ \\lambda_{0} $ .", "\\newline This approach did not yield satisfactory results in our settings even when only a small amount of values were missing.", "Often the value chosen for $ \\gamma $ would correspond to the correct segmentation of the test data, but would underfit on the whole data.", "This could be explained by the fact that while our covariance estimation methods approximately preserve the structure of the gain curve, they do not reliably preserve its magnitude and thus $ \\gamma $ might be incomparable between folds and different segments.", "\\newline We thus propose an alternative method as a stopping criterion for splits as well as for choosing $ \\lambda $ .", "This approach performed empirically much better than the one that was used by [@bib:LeonBuhl] and has the strong computational advantage of only requiring one single BS or OBS fit.", "For each investigated segment $ (u,v] $ we first apply 10-fold cross validation (taking the test data from an equispaced grid of all the observations in $ {(u,v]} $ ) to obtain an optimal value $ \\hat{\\lambda_{0}}({(u,v]}) $ corresponding to the minimal attained cross validated loss, which we denote by $ l_{{(u,v]}}(\\hat{\\lambda_{0}}({(u,v]})) $ .", "The loss that is minimized is the negative log-likelihood of the test data given the mean and the estimated precision matrix of the train data.", "We then use $ \\hat{\\lambda_{0}}({(u,v]}) $ for the evaluation of the gain curve for that segment.", "In the standard setting, one would then check if $ G_{n}^{(u,v]}(\\hat{\\alpha}_{(u,v]})>\\gamma $ to decide whether to split further at the found point $ \\hat{\\alpha}_{(u,v]} $ or not.", "Instead, we compare the cross-validated minimal loss on the full segment $ {(u,v]} $ to the sum of cross-validated minimal losses of the subsegments $ (u,\\hat{\\alpha}_{(u,v]}] $ and $ (\\hat{\\alpha}_{(u,v]},v] $ .", "We keep the split if there is a positive improvement, i.e. if \\newline <equationgroup> <equation> $  l_{{(u,v]}}(\\hat{\\lambda_{0}}({(u,v]}))-l_{(u,\\hat{\\alpha}_{(u,v% ]}]}(\\hat{\\lambda_{0}}((u,\\hat{\\alpha}_{(u,v]}])) $ $  l_{{(u,v]}}(\\hat{\\lambda_{0}}({(u,v]})) $ $ -l_{(u,\\hat{\\alpha}_{(u,v]}]}(\\hat{\\lambda_{0}}((u,\\hat{\\alpha}_{% (u,v]}])) $ </equation> <equation> $ -l_{(\\hat{\\alpha}_{(u,v]},v]}(\\hat{\\lambda_{0}}((\\hat{\\alpha}_{(u% ,v]},v]))>0.", "$ $ -l_{(\\hat{\\alpha}_{(u,v]},v]}(\\hat{\\lambda_{0}}((\\hat{\\alpha}_{(u% ,v]},v]))>0.", "$ </equation> </equationgroup> \\newline Note that our approach is not a proper cross-validation technique as the above described improvement at a candidate split $ \\hat{\\alpha}_{(u,v]} $ is evaluated on the same data as was used to find the split point.", "Hence, this procedure might be optimistic regarding the improvements and thus slightly biased towards finding too many change points.", "This would not be a big problem in practice, as finding too many change points is preferred to finding too few.", "In Section [@ref:LABEL:section:simulations] we investigate how our stopping criterion performs on simulated data both with and without change points.", "Contrary to expectations it does not tend to oversegment in scenarios without change points.", "\\newline  </section>"], ["<section> <title> 5 Simulations </title>  It seems to be hard to provide theoretical guarantees in the setting of change point detection in GGMs with missing values.", "We think that the only semi-realistic case to provide theory is the one with values missing completely at random, which seems to be far from realistic for most applications (see examples in Section [@ref:LABEL:section:applications] ).", "Moreover, keeping our tuning parameter $ \\lambda_{0} $ fixed would be one of our technical assumptions, which however is clearly suboptimal for real and simulated data (as discussed in Section [@ref:LABEL:section:model_selection] ).", "We thus focus on the practical performance of our methods, which we demonstrate with the following simulations.", "\\newline <subsection> <title> 5.1 Setup </title> We first discuss how we generated data, how we deleted values and we introduce the performance measure used to evaluate the results.", "\\newline <paragraph> <title> Generating covariance matrices </title> In our simulations we consider two methods to draw precision matrices for the segments.", "The first one is the random graph model [@bib:randomgraph] , which was used to simulate high-dimensional graphs [@bib:Kolar_Ising] .", "Here, the graph is generated by connecting nodes randomly with some probability $ q>0 $ , which we set to $ \\frac{5}{p} $ in the following to ensure sufficient sparsity.", "We create the corresponding precision matrix by assigning a constant value (taken here as $ 0.3 $ ) to the entries corresponding to the chosen edges and then adding the absolute value of the smallest eigenvalue of the resulting matrix plus some increment (here $ 0.1 $ ) to the diagonal.", "This is necessary to ensure positive definiteness of the constructed precision matrix.", "\\newline We used chain networks as a second model [@bib:fan2009_chain_network] .", "Here we set $ \\Sigma_{ij}:=\\exp{(\u2212a|s_{i}-s_{j}|)} $ , where $ a>0 $ , $ s_{1}<\\ldots<s_{p} $ and $ s_{i}-s_{i-1}\\sim\\operatorname{Unif}(0.5,1) $ for $ i=2,\\dotsc,p $ .", "In the simulations we set $ a=1/2 $ and additionally draw $ s_{1}\\sim\\operatorname{Unif}(0.5,1) $ .", "The inverse of the resulting matrix is tridiagonal.", "To generate precision matrices with differing sparsity patterns for different segments, we draw some permutation $ \\pi $ of $ 1,\\dotsc,p $ and set $ \\Sigma_{ij}=\\exp(\u2212a|s_{\\pi(i)}-s_{\\pi(j)}|) $ .", "This breaks the tridiagonal structure but keeps the sparsity.", "\\newline </paragraph> <paragraph> <title> Types of missingness </title> We consider two ways to delete values for the simulations.", "The first one is missing completely at random (MCAR), where a given percentage of values is discarded uniformly at random.", "The second one is inspired by the missingness structure of environmental monitoring data (see bottom of Figure [@ref:LABEL:fig:groundwater_final] ).", "Here a failure of a sensor leads to missing values over several consecutive observations, while replacement of them at multiple sampling locations might occur at the same time.", "Moreover, it is common that simultaneously several sites are newly installed or abandoned based on the available budget.", "This leads to blocks of observations missing, ranging over multiple variables as well as observations.", "In order to generate a similar blockwise missingness structure, we repeatedly select $ k\\sim\\operatorname{Poi}(\\frac{p}{20}) $ variables uniformly at random and delete for all of them a segment of length $ l\\sim\\operatorname{Exp}(\\frac{n}{8}) $ with the midpoint chosen uniformly between $ 1 $ and $ n $ .", "We repeat this procedure until the preset percentage of missing values is reached.", "An example with 30% missing values for $ n=200 $ and $ p=100 $ is shown at the bottom of Figure [@ref:LABEL:fig:curve_smoothing] .", "\\newline </paragraph> <paragraph> <title> Performance measures </title> We use the adjusted Rand Index [@bib:adjRand_Hubert] , a common measure to compare clusterings, to measure performance in our simulation study (see Table [@ref:LABEL:table:simulation_results] ).", "Given two partitions of $ n $ observations, the Rand Index [@bib:Rand] is the number of agreements (pairs of observations that are either in the same subset for both partitions or are in different subsets for both partitions) divided by the total number of pairs $ n\\choose{2} $ .", "The adjusted Rand Index is the difference between the Rand Index and its expectation when choosing partitions randomly, normalized by the difference between the maximum possible Rand Index and its expectation.", "The adjusted Rand Index is thus bounded by one and is expected to be zero when partitions are chosen randomly.", "We illustrate the estimation uncertainty of found change points corresponding to some adjusted Rand measures (taking true and estimated segments as the two partitions) via histograms in Figure [@ref:LABEL:fig:histograms] .", "\\newline </paragraph> <paragraph> <title> Setup of the main simulation study </title> We will illustrate the behavior of our methods on settings with $ n=500 $ observations of dimension $ p=100 $ with three change points with segments of sizes $ 70,120,120 $ and $ 190 $ .", "We randomly permute the order of the segments to avoid systematic effects.", "Note that in the smallest segment the number of observations is smaller than the number of variables, resulting in a truly high-dimensional setting when splitting.", "In each simulation, we generate a precision matrix (either random or chain network) for each segment and then draw observations independently from the corresponding centered multivariate normal distribution.", "The parameter $ \\delta $ is held fixed at $ 0.1 $ and we vary the proportion of missing data in steps of $ 10\\% $ between $ 10\\% $ and $ 50\\% $ .", "Note that in this setup in expectation there is less than one complete observation available per segment when deleting only $ 10\\% $ of the values completely at random.", "Therefore, discarding incomplete observations is clearly not a viable option and some kind of imputation method is necessary.", "\\newline </paragraph> </subsection> <subsection> <title> 5.2 Results </title> We analyze the estimation performance (using the model selection approach of Section [@ref:LABEL:section:model_selection] ) for our three methods (average, pairwise and LW, see Section [@ref:LABEL:section:imputation_methods] ) both using BS and OBS.", "We ran 100 simulations for each setting.", "The corresponding mean values of adjusted Rand Indices are displayed in Table [@ref:LABEL:table:simulation_results] along with their standard deviations in parenthesis."]], "target": "To aid the interpretability, we present the adjusted Rand Indices of a selection of estimation results together with the true change points in Table . Note that finding the correct number of change points with an accuracy of around two observations each leads to an adjusted Rand Index of around 0.95. Finding all true change points plus a false positive one leads to an adjusted Rand Index of around 0.8, similar to finding only two of the three change points."}, {"tabular": ["    &    &  RFID ", "  &    &  positive  &  negative ", " Video  &  positive  &  25,326  &  25,674 ", "  &  negative  &  6,086  &  196,025 ", "  &    &    &    "], "ref_sec": [["<section> <title> 1 Introduction </title>  Face-to-face social interactions are a central activity in human lives and the desire to socialize with others is a core motivation for human behavior [@bib:Baumeister1995] .", "Face-to-face interaction (or the lack thereof) have been linked to diverse outcomes such as psychological well-being, creativity, and success [@bib:Steger2010,Lechler2001,Kawachi2001,Perry-Smith2006,Reis2000a] .", "In many contexts, it is thus important to understand how often, under what circumstances, and with whom individuals engage in such social interactions.", "\\newline However, face-to-face interactions have been difficult to measure.", "Self assessments of interactions suffer from known biases such as duration neglect [@bib:Fredrickson1993] or recency effects [@bib:Greene1986] .", "Because of such shortcomings, [@bib:Baumeister2007] have advocated for direct observations of behavior.", "Direct behavioral observation studies can indeed overcome problems of individual biases but are typically limited to small social contexts and a short observation periods.", "Observational studies that make use of video recording and automated image recognition (possibly combined with automated speech recognition) hold great promise for scaling up observational studies [@bib:Haritaoglu2000] .", "Automated recordings through camera and speech capture a lot more information than merely face-to-face interactions, for example, about expression of emotions, conversational content, or about individuals who are not participating in a study.", "Where such measures are not of key interest, this raises ethical concerns and methodological challenges.", "Privacy and informed consent (of incidentally recorded individuals) are hard to achieve.", "This is in line with the observation of [@bib:Baumeister2007] that \u201csometimes, observations are unethical, unfeasible, or impossible\u201d.", "Smart-phone based measures are more suitable to only involve informed participants.", "They have been proposed to collect data of social interactions [@bib:Miller2012] .", "Built-in sensors such as GPS [@bib:Ashbrook2003] , WiFi [@bib:Sapiezynski2017] , or Bluetooth [@bib:Eagle2006] can help to identify the spatial co-location of individuals and electronic forms of interaction.", "However, the resolution of such technologies is too rough to allow identifying when people face each other in a social interaction, as they can capture at most who is in the same room.", "\\newline One of the most promising proposals for the collection of face-to-face interaction are sociometric badges [@bib:Pentland2008] that can be experimentally applied to collect data within bounded settings, such as within organizations, schools, or at conferences [@bib:Waber2010,Pachucki2014,Scholz2013,ElmerDSSI] .", "These sensors are worn by study participants and automatically record when two study participants face each other in close physical distance.", "A technology that has been used in many applied studies are sociometric badges based on Radio Frequency Identification [@bib:Cattuto2010,Lederman2017] .", "Figure [@ref:LABEL:RFIDpicture] shows a sketch of an RFID badge and its size.", "RFID badges are typically worn on the chest by study participants (possibly hidden under a name tag) and measure if another study participant\u2019s badge is in short proximity (up to 1.6 meters) and in an angle that indicates that those two people are facing each other (each badge scans an angle of about 65 degrees).", "The measurements of two RFID badges are recorded in real-time by stationary routers that can capture broadcast signals from badges within a certain radius (depending on the architectural layout); the space in which interactions are recorded thus needs to be defined and tested in advance.", "The interaction data are then stored on a database server.", "Figure [@ref:LABEL:illustration] illustrates the minimal setup of an RFID study.", "Section [@ref:LABEL:sec:rfid-badges] and earlier literature [@bib:Cattuto2010,Want2006] introduce additional technological details.", "\\newline RFID badges have been applied in diverse behavioral research studies, for example, to investigate social interaction patterns in a hospital [@bib:Isella2011a] , at conferences [@bib:Cattuto2010] , or to understand how social interactions are associated with well-being of a company\u2019s employees [@bib:Chancellor2017] or of school children [@bib:Pachucki2014] .", "The chief advantages of RFID badges as compared to more complex social sensor systems are that i) the collected data are minimal and do not capture video, speech or behavior of non-participants, reducing the risk of unnecessary privacy intrusion, ii) they are relatively cheap to assemble and thereby allow scaling up data collections to larger contexts and longer periods, iii) the technology is based on established industry standards which means that it can be considered more robust than purpose-built sensors, and iv) they can be employed in varying contexts in which face-to-face interactions are to be studied.", "The small scale of the badge permits that they can, for example, be integrated in a name tag.", "We think that this technology holds great promise in psychology and other fields of behavioral sciences, in particular due to recent advancements in statistical methodology for the study of time-stamped interaction data [@bib:StadtfeldBlock2017,Stadtfeld2017,Stadtfeld2011a,Pilny2016,Butts2008] .", "\\newline A crucial question, however, remains to be answered: Do RFID badges actually measure what they are expected to?", "In stark contrast to the increasing use of RFID badges in research studies, there is a lack of thorough validation studies.", "Some functional tests have been proposed [@bib:Cattuto2010,Isella2011a] that, however, mostly focus on technical functionality in lab settings.", "We replicate a number of those lab tests and provide guidelines that relate to the detection range, the detection angles, and the role of batteries on the technical validity in Section [@ref:LABEL:pretest] (Pretests).", "Measurement validity needs to be evaluated in the field as individual behavior has a direct effect on the measurement: The distance at which individuals communicate, their body angles, whether they are moving, how many people are interacting, hand gestures, or the presence of other objects (e.g., holding a glass of water) may all affect measurement quality.", "This paper closes this gap by proposing validity tests based on real-life data.", "It assesses two different types of validity.", "In the first study we assess the construct validity of RFID badges by comparing social interaction data gathered through RFID badges with human-coded video data of the same interactions in a small setting (N = 11 individuals; 76.7 minutes of data recorded).", "We first assess the overall construct validity of the RFID data (i.e., the overlap between video and RFID data).", "We then test how the validity can be improved by imputing missing data that stem from signal instability and provide practical guidelines on data preprocessing strategies.", "In the second study we test the criterion validity of RFID badges by assessing how social interactions measured with RFID badges correspond with self-report measures of social interactions.", "The second study is situated in a larger context and involves N = 73 individuals and 36.86 hours of interaction data.", "\\newline  </section>"], ["<section> <title> 2 Pretests </title>  Before validating the RFID badges in field experiments (Study 1 and Study 2), we conducted a number of tests assessing the geographical ranges in which the RFID badges and the RFID readers operate.", "All tests were carried out with the same set of five badges.", "We sought to answer three questions: (1) What is the badge and edge detection-range of the readers (i.e., the distance from the reader within which the presence of a badge is detected and the distance within the presence of a signal between to badges is detected)?", "As there were no signal differences between readers, we report only results of the tests conducted with one reader.", "When there was no object in between the badge and the reader (e.g., a wall or a person shielding the signal), badges were detected more than 50 meters away from the reader.", "The presence of a person between the badge and the reader reduced the detection-range to 26.8 meters (SD = 0.54).", "Walls that are in between the reader and badges reduce the range depending on wall thickness and construction material.", "Hence, we advise to test reception ranges within the spatial setting in which interactions should be recorded before the collecting data.", "(2) What is the edge detection-range between two RFID badges? To answer this question, we took five random pairs of badges and tested up to which distance and angle two badges would detect each other (i.e., measure a social interaction).", "On average, at up to 1.61 meters distance (SD = 0.35) edges between two badges were detected.", "Depending on the material that is placed on top of the RFID badge (e.g., a plastic name tag holder) this range is reduced.", "A single layer of paper (that can be used as a name tag)", "had no significant effect on the detection range.", "The angle between two RFID badges for an edge to be detected on average was 32.6 degrees (SD = 7.56) from the horizontal and vertical zero-axis (in total about 65 degrees towards all sides).", "We found no effect of the distance between the RFID badges and the reader on the edge detection-range.", "(3) Do battery properties affect the edge detection-range of two RFID badges?", "There is no effect of battery run-time on the edge detection-range (tested up to 72 hours).", "We have encountered lower detection-ranges of batteries (of type Panasonic coin lithium batteries CR2032) that had been used two months in advance and were stored properly in between.", "Such differences were not found for batteries that had only been used for a week.", "Hence, we recommend using temporally new batteries when collecting data.", "\\newline  </section>"], ["<section> <title> 3 Study 1 </title>  Study 1 aims at testing the construct validity of RFID badges by assessing how interactions measured with the RFID badges correspond to human-coded interactions of video data.", "Moreover, we evaluate if straightforward data processing strategies can enhance the validity of the RFID badges.", "Those strategies take into account that missing data are often systematic and, for example, are characterized by fluctuating stability of the signal within a dyadic interaction.", "In particular, we test three such strategies that relate to i) the duration of social interactions, ii) the time between two interactions and iii) triadic configurations.", "\\newline In some earlier studies, scholars have restricted themselves to analyzing time windows of a given length [@bib:Cattuto2010] without considering how long the signal was recorded for within that time window.", "The reasoning behind that threshold is that a sensor may pick up the signals of other sensors in situations that are not a face-to-face interactions, for example, when two interacting groups of individuals are standing in close proximity or when individuals pass each other while moving through the crowd.", "In the past, scholars have investigated how various cutoff-points of social interaction duration can be used to predict future interactions [@bib:Scholz2012] or self-reports of social interactions [@bib:Atzmueller2018,Smieszek2016] .", "To the best of our knowledge, no study yet has investigated how these cutoff-points affect the construct validity of the RFID badges to measure face-to-face interactions.", "Hence, in a first step, we test how variations of this threshold (rather than taking the ad-hoc threshold of 20 seconds) contribute to the validity.", "\\newline Second, we assess to what extent merging signals between two individuals, with respect to how long these interactions are apart, improve the validity.", "The reasoning behind this merging strategy is that even if individuals are involved in a longer face-to-face interaction, their body movements, or interfering objects such as other individuals passing by or drinking glasses may interrupt the signal at times.", "With this strategy, we make use of the continuous and fine-grained data to overcome such measurement biases.", "Merging two signals into one measure may thus increase the validity of the measure.", "We refer to this strategy as interpolation .", "Figure [@ref:LABEL:fig:functions] (left panel) illustrates this data processing strategy.", "\\newline Third, we test the contribution of adding missing ties in interaction triads.", "For instance, if individual A is interacting with B and C at the same time, then a tie between B and C is added for the time in which A is in interaction with B and C. Because social interactions are {unimodal} (i.e., individuals can only engage in one interaction at a time), we may assume that B and C also interacted with each other if A is interacting with both of them, even if there is no, or no stable signal between them.", "Due to the nature of the RFID technology, interactions are only observed if the individuals are facing each other.", "Hence, if two people (B and C) are standing next to each other because they are listening to A, a tie between B and C would not be detected.", "Furthermore, in larger groups, the narrow angle of the RFID badges might not allow the capturing of each pair of individuals involved.", "Closing triads might therefore improve the validity of the RFID badges.", "Figure [@ref:LABEL:fig:functions] (right panel) shows the triadic closure data processing strategy.", "\\newline <subsection> <title> 3.1 Methods Study 1 </title> <subsubsection> <title> 3.1.1 Design </title> Staff and students of a Swiss university were invited to the experiment, advertised as an after-work get-together event.", "11 individuals took part in the experiment.", "Three participants were female.", "A room of about $ 20m^{2} $ was set up with a camera (model: GoPro 4) covering the whole room and two RFID readers (devices to detect the signals between RFID badges in real time) situated in two opposite corners of the room.", "The density (individuals per square meter) was chosen to be similar to Study 2 (Section [@ref:LABEL:sec:study2] ).", "Upon arrival, each participant was equipped with an RFID badge and was instructed to wear it on the top layer of clothing at chest height.", "No further instructions were given to the participants.", "As expected, participants engaged in social interactions with other participants.", "During the event beverages and snacks were served.", "Figure [@ref:LABEL:screenshop] illustrates the setup of the experiment.", "60% of the pairs of participants knew each other beforehand.", "A total of 76.7 minutes of video and RFID-data were recorded.", "Summed over all pairs of individuals ( $ N_{\\text{pairs}}=\\frac{N(N-1)}{2}=55 $ ) , there are 55 * 76.7 minutes ( = 70.3 hours) of dyadic data recorded.", "To compare the video data to the RFID data, we then transformed this dyadic data structure to a linear time dimension for each pair of badges, indicating if for a given second an interaction was present or not (0 = no, 1 = yes).", "Further details on the comparison are given in Section [@ref:LABEL:sec:fit] .", "\\newline </subsubsection> <subsubsection> <title> 3.1.2 RFID badges </title> RFID badges were used to capture social interactions between the participants of the experiment.", "The firm- and software for the RFID badges and readers that are used in this article were taken from the OpenBeacon project (www.openbeacon.org).", "OpenBeacon is an open source software and hardware project.", "Similar technologies have been proposed in other projects and we expect those to behave similarly [@bib:Lederman2017,Cattuto2010] .", "Our version of the OpenBeacon software can be downloaded from www.osf.io/rrhxe .", "\\newline A set of 11 active 2.4 GHz RFID badges (nRF24L01P chipsets) that uses the proprietary Nordic Semiconductor radio protocol were used in this experiment.", "The OpenBeacon proximity firmware was used to track the location of the badge as well as interactions once a contact between two badges is established via the regularly transmitted beacon packets that the badge constantly sends.", "The packets containing the information about position and proximity of the badge are received by the nearest OpenBeacon Easyreader PoE II (for brevity called reader) which sends the information to the server infrastructure via LAN cable.", "Our experimental setup consisted of 2 readers, 11 RFID badges for the 11 participants and a computer which acts as a server.", "The readers were directly connected to the server computer, which collects and stores information received by the RFID readers on the level of a fifth of a second.", "The reader scans its environment five times every second.", "The server then receives information about which badge is detected by which reader and between which badges interactions are recorded.", "Badges can record multiple interactions at the same time.", "We then transformed these data into a time-stamped edgelist, of which the first 6 interactions are shown in Table [@ref:LABEL:data] .", "For instance, the first row of the table indicates that the badges with IDs 3 and 5 interacted with one another from 18:19:46 to 18:19:58.", "\\newline The firm- and software as well as the schematic and hardware design of the RFID badges are freely available on the website of the OpenBeacon project (www.openbeacon.org).", "Using this open source information, the badges can be assembled by interested research groups.", "Other developers of similar hard- and software also provide their source code online [@bib:Lederman2017] .", "More details on the RFID technology and its application to measure social interactions can be found elsewhere [@bib:Cattuto2010,Want2006] .", "\\newline </subsubsection> <subsubsection> <title> 3.1.3 Human-coded interactions </title> Goffman (1956, p. 18) [@bib:Goffman1956] defined a face-to-face social interaction as the \u201creciprocal influence of individuals upon on another\u2019s actions when in one another\u2019s immediate physical presence\u201d.", "For our setting, this definition is too broad as it, for example, may include physical presence in the same room.", "Hence, we narrowed this definition and coded a face-to-face interaction when two individuals were talking or listening to each other or when they were part of the same group conversation.", "More specifically, an interaction was coded when an individual directed his/her attention as indicated by the body movement (turning of head and/or rotating the body) to another person or group for more than 10 seconds.", "Briefly turning one\u2019s attention (< 10s) to someone else or another (interaction)-group was not coded as an interaction.", "Similarly, leaving the interaction for less than 10 seconds (e.g., to put down a drinking glass to the nearest table), was not considered as two separate interactions.", "In group conversations, every group member was coded as interacting with every other member, irrespective of the role in the group (i.e., speaker or listener).", "Interactions were coded to match the format of the RFID data, as shown in Table [@ref:LABEL:data] .", "\\newline Two confederates independently coded the interactions in the videos.", "An overlap of 13.5 minutes (18% of the total duration) was coded by both raters to compute the interrater reliability of the video coding.", "To evaluate the interrater reliability we computed Cohen\u2019s $ \\kappa $ [@bib:Cohen1960] , which has been proposed as a chance-corrected agreement between two raters [@bib:Hallgren2012] .", "Cohen\u2019s $ \\kappa $ was .96, indicating a very high interrater reliability [@bib:Landis1977] .", "We therefore can assume that the two raters were consistent in their understanding of what constitutes a social interaction.", "The interactions of both raters were merged so that both raters accounted for half of the time coded.", "\\newline </subsubsection> <subsubsection> <title> 3.1.4 Assessing the fit between the video and RFID data </title> When assessing the validity of a measure, the sensitivity and the specificity are the most prominent indices.", "We use the human-coded video data as the ground truth.", "Hence, in our case, the sensitivity is defined as the true positive rate.", "In other words, sensitivity is the proportion of human rated interactions that are correctly identified as such by the RFID badges.", "Specificity (the true negative rate) is the proportion of human-coded non-existent interaction that are correctly identified by the RFID badges.", "Formally, the sensitivity and the specificity are defined as $ \\frac{\\text{TP}}{\\text{TP}+\\text{TN}} $ and $ \\frac{\\text{TN}}{\\text{TN}+\\text{FN}} $ , respectively.", "The classification indices (true positives (TP), false negatives (FN), etc.) for our analysis are defined in equations [@ref:LABEL:equ:tp] to [@ref:LABEL:equ:tn] : \\newline <equation> $ \\text{TP}=\\sum_{d=1}^{D}\\sum_{i=1}^{S}I\\{R^{d}_{i}+V^{d}_{i}=2\\}\\\\ $ </equation> <equation> $ \\text{FP}=\\sum_{d=1}^{D}\\sum_{i=1}^{S}I\\{R^{d}_{i}-V^{d}_{i}=1\\}\\\\ $ </equation> <equation> $ \\text{FN}=\\sum_{d=1}^{D}\\sum_{i=1}^{S}I\\{R^{d}_{i}-V^{d}_{i}=-1\\}\\\\ $ </equation> <equation> $ \\text{TN}=\\sum_{d=1}^{D}\\sum_{i=1}^{S}I\\{R^{d}_{i}+V^{d}_{i}=0\\}\\\\ $ </equation> \\newline Vector $ R^{d} $ (RFID) is a dummy vector with the length of the total observation period in seconds $ S $ indicating whether an interaction of dyad $ d $ among all dyads $ D=\\frac{N(N-1)}{2} $ was recorded with the RFID badges at the respective second.", "Vector $ V^{d} $ (Video) is a dummy vector of the same length indicating whether an interaction of dyad $ d $ was coded in the video at the respective second.", "The elements $ i $ of the vector indicate an entry that relates to a specific second, $ S $ is the last recorded second and thus the vector length.", "$ I\\{A\\} $ denotes an indicator function for condition $ A $ and returns one if the condition is true and zero otherwise.", "\\newline For the process of finding optimal values for minimal duration , interpolation and the number of iterations for which triadic closure is performed, we use a single index that entails a combination of all classification indices called the accuracy .", "Accuracy ( $ a $ ) assesses the percentage of correctly identified instances (i.e., seconds) and is defined as: \\newline <equation> $ a=\\frac{\\text{TP}+\\text{TN}}{\\text{TP}+\\text{TN}+\\text{FN}+\\text{FP}} $ </equation> We choose to optimize this single index because one value can be optimized more easily and thereby weights every second equally compared to relative indices (such as sensitivity and specificity).", "Nevertheless, we also report the sensitivity and the specificity for a more detailed understanding of the validity.", "Alternative indices such as the sum of the sensitivity and specificity [@bib:Koepsell1985] do not consider each correctly/incorrectly specified second equally, but relatively to the size of other cells in the classification table.", "Hence, we do not focus on such relative measures.", "Nevertheless, we provide robustness analyses for these indices in Appendix [@ref:LABEL:app:S1_robust] .", "\\newline </subsubsection> </subsection> <subsection> <title> 3.2 Results Study 1 </title> <subsubsection> <title> 3.2.1 Description of the data </title> A total of 1,168 interactions with varying lengths were measured by the RFID badges.", "Figure [@ref:LABEL:hists] (left) shows the overall RFID signal over time.", "It can be seen that the number of interactions changes through time with a maximum of 35 interaction pairs recorded.", "The maximum number of 55 interactions ( $ \\frac{N(N-1)}{2} $ ) could have only been reached if all 11 participants had simultaneously interacted in one large group which never occurred.", "Figure [@ref:LABEL:hists] (right) shows the durations of each interaction measured by the RFID badges and the video-coding.", "The interactions captured with RFID badges tend to be much shorter than the the video-coded interactions -- this could be an indicator that the signals relating to one interaction tend to be unstable .", "For instance, while the video might record 5 minutes of an interaction between person A and person B, the RFID badge might record 5 unique 50-second-long signals of the same interaction between A and B. Because people tend to move their upper body during a conversation, the RFID signal might be interrupted from time to time (in this example: for 10 seconds every minute).", "We hope to reduce the flickering of the RFID signal with the interpolation processing or the transitive closure processing.", "When comparing the total duration of interactions (i.e., the sum of all interaction durations), the video-coded data records more interaction time (14.3 hours, 20.3% of the possible 70.3 hours of dyadic data) than the RFID badges (8.4 hours, 12.0%).", "\\newline </subsubsection> <subsubsection> <title> 3.2.2 Initial validity </title> In this step we assess the fit between the interactions recorded through the RFID devices and the video-coded interactions.", "Table [@ref:LABEL:initialstats] shows the classification table for this comparison.", "The classification table shows the number of seconds that were identified by the two methods (RFID and video) as positive or negative.", "The number of seconds that each of the two methods classified as a social interaction is denoted as positive in the classification table.", "Because the data is on a dyadic level, the number of seconds that need to be classified (as either positive or negative by the two methods) is the number of seconds that all dyads could have possibly interacted with one another (i.e., 55 dyads * 76.7 minutes, see Section [@ref:LABEL:sec:design] for details).", "For instance, if the RFID badge and the video both indicate at a specific second that person A and person B interacted, then this adds one to the count of the top left cell of the table (true positives).", "But if the RFID badge does not indicate an interaction for that given second and the video data does, a count of one is added to the top right cell of the table (false negatives).", "\\newline Based on the classification results of Table [@ref:LABEL:initialstats] the sensitivity is 49.7%, the specificity at 97.0%, and the accuracy at 87.5%, indicating that around 50% of the seconds of interactions were detected by the RFID badges and 97% of the seconds of non-interactions were correctly identified as such."]], "target": "This is a first promising observation because even if signals are unstable for a number of technical and behavior-related reasons, a signal that is captured by the RFID badges tends to be a reliable measure of an ongoing interaction and incidental measurements (false positives, the lower right cell of Table ) seem to be rare."}, {"tabular": ["  (a) Mean Predicted Rank ( $ \\hat{k}_{11} $ )  &    &  (b) Source Identification Error Rate ", " Dataset  &  MoE-NHP  &  NHP  &  MoE-RMTPP  &  RMTPP  &    &  Dataset  &  MoE-NHP  &  MoE-RMTPP  &  Bayes PP ", "  &  ", " Meme  &  225  &  283  &  143  &  159  &    &  Meme  &  5.04%  &  4.64%  &  9.18% ", " Reddit  &  19.4  &  35.2  &  20.0  &  35.6  &    &  Reddit  &  1.38%  &  2.02%  &  3.24% ", " Amazon  &  21.6  &  22.8  &  21.6  &  22.9  &    &  Amazon  &  8.34%  &  9.94%  &  12.88% ", " LastFM  &  2.02  &  2.04  &  2.01  &  2.04  &    &  LastFM  &  28.44%  &  33.90%  &  39.94%  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Event sequences in continuous time occur across many contexts, leading to a variety of data analysis applications such as forecasting consumer purchases, fraud detection in transaction data, and prediction in clinical medicine.", "In such data, each event is typically associated with one of $ K $ event types, also known as {marks} , and a timestamp.", "There has been significant amount of prior work in statistics for clustering [@bib:du2015dirichlet,xu2017dirichlet] , factorizing [@bib:schein2015bayesian] , and generative modeling of such data, typically under the framework of marked temporal point process (MTPP) models [@bib:daley2007introduction] .", "We are primarily interested in the third of these objectives.", "The multivariate Hawkes process [@bib:hawkes1971spectra,liniger2009multivariate] , Poisson-network [@bib:rajaram2005poisson] , piecewise-continuous conditional intensity model [@bib:gunawardana2011model] , and proximal graphic event model [@bib:bhattacharjya2018proximal] are some examples of the many different MTPP models previously explored.", "MTPP models characterize the instantaneous rate of occurrence of each event type, the so-called {intensity function} , conditioned on the history of past events.", "However, strong parametric assumptions in these traditional models limit their flexibility for modeling real-world phenomena.", "\\newline Recent work in machine learning has sought to address these limitations via the use of deep recurrent neural networks (RNNs).", "These models, such as [@bib:du2016recurrent] , use expressive representations for the intensity function, use event embeddings to avoid parameter explosion, and optimize the associated log-likelihood via stochastic gradient methods.", "A variety of approaches have been explored to address the complex mix of discrete events and continuous time that occur in real-world event sequences [@bib:mei2017neural,wang2017marked,zhang2019self,turkmen2019fastpoint] .", "In general, these neural-based MTPPs have been found empirically to provide systematically better predictions than their traditional counterparts, due to their more flexible representations for capturing the influence of past events on future ones (both their time stamps and their types), as well as being better able to handle the significant data sparsity associated with large event vocabularies.", "However, a common implicit assumption in these approaches is that all of the modeled sequences originate from the same source (or user), which is often not the case in real-world datasets such as online consumer data or medical history records.", "Sufficiently powerful neural-based MTPPs can internally adjust for this heterogeneity after conditioning on a significant portion of a history; however, they exhibit large predictive uncertainty at the beginning of sequences.", "Thus, it is important to develop techniques that {personalize} predictions to account for heterogeneity across users.", "\\newline To develop personalized MTPPs, we propose using variational autoencoders (VAEs) [@bib:KW2014] in conjunction with previous neural-based MTPPs.", "VAEs are well-suited to address the problem of personalization (e.g., [@bib:liang2018variational] ) since they distinguish between global and local parameters, which are treated differently during training/inference.", "In our setup, global model parameters capture properties that are common across all sequences regardless of associated user.", "By contrast, local parameters describe user-specific traits and preferences.", "They therefore have to be inferred from fewer, user specific data, motivating a Bayesian treatment by the VAE.", "We further employ a mixture-of-experts approach [@bib:shi2019variational] to account for heterogeneity within each user.", "We demonstrate that our proposed scheme yields systematic improvements in a variety of tasks on four large, real world datasets.", "\\newline  </section>"], ["<section> <title> 2 Personalized Event Sequences </title>  <paragraph> <title> Problem Statement </title> We consider the problem of modeling sequences of events $ (t,k) $ that occur at irregular times $ t $ .", "Each event carries a mark $ k $ corresponding to one of a finite number $ K $ of different possible event types.", "Since all our training sets are finite, each event sequence is bounded by some time horizon $ T>0 $ , i.e., it can be written as a finite history sequence of the form \\newline <equationgroup> <equation> $ \\mathcal{H}_{T}=\\big{(}(t_{1},k_{1}),(t_{2},k_{2}),\\ldots,(t_{|% \\mathcal{H}_{T}|},k_{|\\mathcal{H}_{T}|})\\big{)} $ $ \\mathcal{H}_{T}=\\big{(}(t_{1},k_{1}),(t_{2},k_{2}),\\ldots,(t_{|% \\mathcal{H}_{T}|},k_{|\\mathcal{H}_{T}|})\\big{)} $ </equation> </equationgroup> with times $ 0\\leq t_{1}<t_{2}<\\cdots<t_{|\\mathcal{H}_{T}|}\\leq T $ and marks $ k_{i}\\in\\{1,\\ldots,K\\}\\;\\forall i $ .", "For brevity, let $ \\mathcal{H}\\equiv\\mathcal{H}_{T} $ .", "\\newline Since our goal is personalization, we assume that each event sequence is associated with a {user} $ u $ .", "Our objective is to forecast (or evaluate the likelihood of) an event sequence for a given user $ u $ conditioned on three sources of information, illustrated in Figure [@ref:LABEL:fig:overview] : (i) a large {training set} of event sequences from many users, possibly including $ u $ (Figure [@ref:LABEL:fig:overview] , left); (ii) a smaller (possibly empty) set of {reference sequences} from the same user $ u $ , that may or may not be part of the training set (blue box in left part of Figure [@ref:LABEL:fig:overview] ); and (iii) a {prefix} , i.e., a (possibly empty) partial sequence $ \\mathcal{H}_{t}^{u} $ of events performed by user $ u $ just before the time $ t $ where we start predicting (solid circles in right part of Figure [@ref:LABEL:fig:overview] ).", "Conditioned on these three sources of information, we aim to predict the continuation of the full sequence $ \\mathcal{H}_{t+\\Delta}^{u} $ (half-transparent circles in Figure [@ref:LABEL:fig:overview] , right) for some remaining time span $ \\Delta $ .", "\\newline For example, in an online store, the training set (i) contains many shopping sessions by many users; the reference sequences (ii) are previous sessions of a given user $ u $ ; and the prefix (iii) is the already observed part of a currently ongoing session.", "This setup is quite general, covering many applications with recurring users, e.g., social media platforms, music streaming services, or e-commerce websites.", "\\newline The above enumeration arranges the three types of input information (i)-(iii) as nested subsets organized from global to local context.", "It thus reflects the assumption that the predicted event sequence $ \\mathcal{H}_{t+\\Delta}^{u} $ follows some general characteristics (e.g., similarities or incompatibilities between different event types) that can be learned from the entire data set (i).", "At the same time, we assume that $ \\mathcal{H}_{t+\\Delta}^{u} $ also exhibits some individual traits of the associated user $ u $ , which can therefore only be inferred from reference sequences (ii) from the same user.", "Finally, a user\u2019s current goal or mood may still vary somewhat over time and can therefore only be inferred from very recent observations in the prefix $ \\mathcal{H}_{t}^{u} $ (iii).", "\\newline While the relevance for the current prediction increases as we go from (i) to (iii), the data size shrinks from (i) to (iii).", "This motivates different treatments of the data sources (i)-(iii) in our models in terms of point estimated global model parameters, a user-specific Bayesian inference variable $ z^{u} $ , and the local state of a recurrent neural network, respectively.", "The rest of this section provides an overview over the proposed framework, deferring a more detailed discussion to Section [@ref:LABEL:sec:model] .", "\\newline </paragraph> <paragraph> <title> Overview of the Proposed Solution </title> Forecasting discrete event sequences amounts to both predicting an ordering of future event {types} $ k_{i} $ as well as their {time stamps} $ t_{i} $ .", "This is a challenging problem due to the strong correlations between these two data modalities.", "We consider a broad class of stochastic dynamics models\u2014 {neural marked temporal point processes} (neural MTPPs)\u2014that autoregressively generate events one after another.", "For the $ i^{\\text{th}} $ event, we draw its time stamp $ t_{i} $ and mark $ k_{i} $ conditioned on the hidden state $ h_{i} $ of a \u201cdecoder\u201d recurrent neural network (RNN).", "The RNN state $ h_{i} $ gets updated after each generated event, conditioned on the event it just generated, and on an embedding vector $ z^{u} $ that represents the user $ u $ .", "This leads to the following stochastic recursion: \\newline <equation> $ \\begin{gathered}(t_{i+1},k_{i+1})\\sim p_{\\theta}(t_{i+1},k_{i+1}\\,|\\,h_{i},z^{% u})\\\\ \\text{with}\\quad h_{i}=f_{\\text{Dec}}(h_{i-1},[\\mathbf{k}_{i};z^{u}],t_{i};% \\eta)\\quad\\text{and}\\quad h_{0}=\\tanh(W_{0}z^{u}+b_{0})\\end{gathered} $ </equation> \\newline where $ [\\,\\cdot\\,;\\cdot\\,] $ denotes vector concatenation, $ \\mathbf{k}_{i} $ is a learnable continuous vector embedding for the mark $ k_{i} $ of the $ i^{\\text{th}} $ event, and $ f_{\\text{Dec}} $ is the recurrent unit of the decoder neural network $ \\textsc{Dec}_{\\theta} $ with learnable parameters $ \\theta $ that include $ \\eta,W_{0}, $ and $ b_{0} $ .", "\\newline Apart from the user embedding $ z^{u} $ , which is specific to our personalization scheme, Eq. [@ref:LABEL:eq:stoch_rnn] covers several MTPP models in the literature.", "Section [@ref:LABEL:sec:model] summarizes models that fit into our framework.", "Note that we are not considering any side-information from users (e.g., age, location, gender, etc.); however, depending on the application these should be straightforward to incorporate into the framework.", "\\newline Eq. [@ref:LABEL:eq:stoch_rnn] models the generation of event sequences probabilistically: each successive event $ (t_{i+1},k_{i+1}) $ is sampled from $ p_{\\theta}(t_{i+1},k_{i+1}\\,|\\,h_{i},z^{u}) $ rather than being generated deterministically.", "Probabilistic models allow for the ability to estimate complex statistics, such as the expected time until next event of a specific type, how much more likely event A will come before event B, etc.", "Many of these questions would be hard or impossible to answer with a deterministic model.", "\\newline Eq. [@ref:LABEL:eq:stoch_rnn] further reflects our problem setting with diverse information sources (i)-(iii) discussed above.", "The decoder parameters $ \\theta $ are identical for all generated sequences and can thus be trained on the entire data set (i).", "The user embedding $ z^{u} $ stays constant within each event sequence but varies from user to user.", "Thus, $ z^{u} $ has to be inferred from reference sequences (ii) from the same user.", "By concatenating the user embedding to the mark embedding, we effectively create personalized representations of events for that user.", "Additionally, by computing the initial stochastic state $ h_{0} $ from $ z^{u} $ , we allow for personalized predictions across the entire time window from $ t=0 $ to $ t=T $ .", "Finally, when completing a partial sequence, the prefix (iii) can be encoded into the initial RNN state $ h_{i} $ by unrolling the RNN update (second line of Eq. [@ref:LABEL:eq:stoch_rnn] ) on the events in the prefix.", "\\newline </paragraph>  </section>"], ["<section> <title> 3 Model Parameterization and Inference </title>  This section specifies the details for representing and estimating user embedding $ z^{u} $ , the underlying data generating process for sequential event data, how existing neural MTPP models can be extended to become personalized by incorporating user embeddings, as well as the loss function being optimized.", "Figure [@ref:LABEL:fig:enc_dec_overview] shows operational diagrams of the encoding and decoding processes.", "\\newline <paragraph> <title> Encoding User Embeddings </title> The user embedding $ z^{u} $ in Eq. [@ref:LABEL:eq:stoch_rnn] allows us to personalize predictions for a given user $ u $ .", "$ z^{u} $ is a real-valued vector, and for our results the dimensionality ranges from 32 to 64 depending on the dataset (see supplement for more information).", "The vector $ z^{u} $ can be interpreted as the sequence and user-specific dynamics for a single history of events.", "We infer $ z^{u} $ from a reference set $ \\mathcal{R}^{u}=\\{\\mathcal{H}^{u,1},\\dots,\\mathcal{H}^{u,n^{u}}\\} $ of $ n^{u} $ sequences that we have already observed from the same user.", "This leads to two complications: first, the amount of data in each reference set $ \\mathcal{R}^{u} $ is much smaller than the whole training set of sequences from all users; second, learning an individual user embedding $ z^{u} $ for thousands of users would be expensive.", "We address both complications by an approximate Bayesian treatment of $ z^{u} $ via amortized variational inference (amortized VI) [@bib:KW2014,rezende2014stochastic,zhang2019advances] .", "\\newline The typically small amount of data in each reference set $ \\mathcal{R}^{u} $ motivates a Bayesian treatment via a probabilistic generative process with a prior $ p(z^{u}) $ and the likelihood in Eq. [@ref:LABEL:eq:stoch_rnn] .", "For simplicity, we assume a standard normal prior: $ z^{u}\\sim\\mathcal{N}(0,I) $ .", "Bayesian inference seeks the posterior probability $ p(z^{u}|\\mathcal{R}^{u}) $ .", "As finding the true posterior is computationally infeasible, VI approximates the posterior with a parameterized variational distribution $ q(z^{u}|\\mathcal{R}^{u}) $ by minimizing the Kullback-Leibler divergence from the true posterior to $ q $ .", "The inferred approximate posterior $ q(z^{u}|\\mathcal{R}^{u}) $ can then be used to sample a user embedding $ z^{u} $ for a personalized prediction, i.e., \\newline <equationgroup> <equation> $  z^{u}\\sim\\begin{cases}\\hidden@noalign\\textstyle\\mathcal{N}(0,I% )&\\text{for unconditional generation;}\\\\ \\hidden@noalign\\textstyle q(z^{u}\\,|\\,\\mathcal{R}^{u})&\\text{for % personalized prediction.}\\end{cases} $ $  z^{u} $ $ \\sim\\begin{cases}\\hidden@noalign\\textstyle\\mathcal{N}(0,I)&% \\text{for unconditional generation;}\\\\ \\hidden@noalign\\textstyle q(z^{u}\\,|\\,\\mathcal{R}^{u})&\\text{for % personalized prediction.}\\end{cases} $ </equation> </equationgroup> In principle, one could fit an individual variational distribution $ q(z^{u}|\\mathcal{R}^{u}) $ for each user $ u $ .", "As this would be expensive, we instead use amortized VI [@bib:KW2014] We first model $ q(z^{u}|\\mathcal{R}^{u}) $ by a mixture of experts [@bib:shi2019variational] where each expert $ q(z^{u}|\\mathcal{H}^{u}) $ is conditioned only on a single reference sequence $ \\mathcal{H}^{u}\\in\\mathcal{R}^{u} $ , \\newline <equationgroup> <equation> $  q(z^{u}\\,|\\,\\mathcal{R}^{u})=\\textstyle\\frac{1}{n^{u}}\\sum_{i=1}% ^{n^{u}}q(z^{u}\\,|\\,\\mathcal{H}^{u,i}).", "$ $  q(z^{u}\\,|\\,\\mathcal{R}^{u})=\\textstyle\\frac{1}{n^{u}}\\sum_{i=1}% ^{n^{u}}q(z^{u}\\,|\\,\\mathcal{H}^{u,i}).", "$ </equation> </equationgroup> $ q(z^{u}\\,|\\,\\mathcal{R}^{u}) $ represents the various modes of dynamics for a given user $ u $ as defined by their past sequences $ \\mathcal{R}^{u} $ .", "Further, each expert distribution $ q(z^{u}|\\mathcal{H}^{u}) $ is a fully factorized normal distribution where the means $ \\mu $ and variances $ \\sigma^{2} $ are further parameterized by an encoder neural network $ \\textsc{Enc}_{\\phi} $ with parameters $ \\phi $ that are shared across all users, \\newline <equationgroup> <equation> $  q(z^{u}\\,|\\,\\mathcal{H}^{u})=\\mathcal{N}\\big{(}z^{u};\\mu,\\text{% diag}(\\sigma^{2})\\big{)}\\qquad\\text{where}\\qquad(\\mu,\\log\\sigma)=\\textsc{Enc}_% {\\phi}(\\mathcal{H}^{u}).", "$ $  q(z^{u}\\,|\\,\\mathcal{H}^{u})=\\mathcal{N}\\big{(}z^{u};\\mu,\\text{% diag}(\\sigma^{2})\\big{)}\\qquad\\text{where}\\qquad(\\mu,\\log\\sigma)=\\textsc{Enc}_% {\\phi}(\\mathcal{H}^{u}).", "$ </equation> </equationgroup> $ \\textsc{Enc}_{\\phi} $ contains a bidirectional RNN (more specifically gated recurrent units) that takes embedded times and marks of the reference sequence as inputs.", "The mark embeddings are learned and the time embeddings are continuous versions of the fixed positional embeddings [@bib:cho2014properties,vaswani2017attention] .", "The last hidden states from both directions are concatenated and then linearly transformed to result in $ \\mu $ and $ \\log\\sigma $ .", "Precise details for this process can be found in the supplement.", "\\newline Eqs. [@ref:LABEL:eq:moe] - [@ref:LABEL:eq:z_expert] specify the variational family.", "We optimize over the variational parameters $ \\phi $ using standard methods for Black Box VI [@bib:blei2017variational,zhang2019advances] , i.e., by stochastic maximization of the evidence lower bound.", "\\newline </paragraph> <paragraph> <title> Distributions for Events </title> Marked temporal point processes (MTPP) are a broad class of processes used for modeling seqeunces of events $ \\mathcal{H} $ .", "A common method to fully characterize a MTPP is through an intensity function, \\newline <equation> $ \\lambda(t|\\mathcal{H}_{t})=\\lim_{\\delta\\downarrow 0}\\textstyle\\frac{1}{\\delta}% P\\big{(}|\\mathcal{H}_{t+\\delta}|-|\\mathcal{H}_{t}|=1\\;\\big{|}\\;\\mathcal{H}_{t}% \\big{)}, $ </equation> where $ |\\mathcal{H}_{t}| $ counts the number of events up to time $ t $ .", "The intensity function measures the instantaneous rate of occurrence for events at time $ t $ , conditioned on the history up until time $ t $ .", "Mark-specific intensity functions are defined as the product of the overall intensity function and the conditional categorical distribution over marks, $ \\lambda_{k}(t|\\mathcal{H}_{t})=p(k|t,\\mathcal{H}_{t})\\lambda(t|\\mathcal{H}_{t}) $ .", "We denote the vector of rates over all marks as $ \\vv{\\lambda}(t|\\mathcal{H}_{t}) $ .", "The log-likelihood of a sequence $ \\mathcal{H} $ works out to be \\newline <equation> $ \\log p(\\mathcal{H})=\\textstyle\\sum_{i=1}^{|\\mathcal{H}|}\\log\\lambda_{k_{i}}(t_% {i}|\\mathcal{H}_{t_{i}})-\\int_{0}^{T}\\lambda(t|\\mathcal{H}_{t})dt.", "$ </equation> Intuitively, the summation in the first term rewards the model when the intensity values are high for the actual observed marks within the history, whereas the negative integral term penalizes high overall intensity values when there is no event.", "\\newline Intensity functions have been parameterized in both simple forms for interpretability as well as with neural networks for flexibility.", "Our proposed approach can in principle be used to add personalization to most existing neural MTPP models.", "We selected two of the most well-known and widely-cited such models to serve as base architectures which we extend for personalization as described in Sec. 2: \\newline <list> \\ The {Recurrent Marked Temporal Point Process} (RMTPP) [@bib:du2016recurrent] , which parameterizes the intensity function explicitly as a piece-wise exponentially decaying rate: $ \\overrightarrow{\\lambda}^{\\text{RMTPP}}(t|\\mathcal{H}_{t})=\\exp\\{Wh_{i}+w(t-t_% {i})+b\\} $ , where $ t_{i}<t\\leq t_{i+1} $ , and $ W $ , $ w $ , and $ b $ are learnable parameters.", "For this model, $ f_{\\text{Dec}} $ from Eq. [@ref:LABEL:eq:stoch_rnn] is a gated recurrent unit (GRU).", "\\newline \\ \\ The {Neural Hawkes Process} (NHP) [@bib:mei2017neural] , which describes a procedure to obtain an interpolated hidden state $ h(t) $ , defines $ \\overrightarrow{\\lambda}^{\\text{NHP}}(t|\\mathcal{H}_{t})=\\text{softplus}(Wh_{i% }(t))", "$ where $ W $ is a learnable matrix with $ t_{i}<t\\leq t_{i+1} $ . and has $ f_{\\text{Dec}} $ from Eq. [@ref:LABEL:eq:stoch_rnn] be a continuous-time LSTM unit.", "\\newline \\ </list> By incorporating $ z^{u} $ as specified in Eq. [@ref:LABEL:eq:stoch_rnn] , $ \\overrightarrow{\\lambda}(t|\\mathcal{H}^{u}_{t}) $ becomes $ \\overrightarrow{\\lambda}(t|\\mathcal{H}^{u}_{t},z^{u}) $ .", "Note that by defining $ \\overrightarrow{\\lambda}(t|\\mathcal{H}^{u}_{t},z^{u}) $ and $ f_{\\text{Dec}} $ , we effectively define $ p(t_{i+1},k_{i+1}\\,|\\,h_{i},z^{u}) $ in Eq. [@ref:LABEL:eq:stoch_rnn] , as well as the general decoding process, $ \\textsc{Dec}_{\\theta} $ .", "\\newline All MTPP models can be sampled via a thinning procedure [@bib:ogata1981lewis] , if not directly.", "Similarly, the integral in Eq. [@ref:LABEL:eq:ll] can be computed by Monte-Carlo estimation, if not analytically.", "In our experiments, we perform the former for all models for consistency.", "More precise details on this can be found in the supplement.", "\\newline </paragraph> <paragraph> <title> Optimization </title> The objective function for the proposed personalized neural MTPP models is the $ \\beta-\\text{VAE} $ objective [@bib:higgins2017beta] which is defined for a single target sequence $ \\mathcal{H}^{u} $ as: \\newline <equationgroup> <equation> $ {\\cal L}_{\\beta}(\\phi,\\theta;\\mathcal{H}^{u})={\\mathbb{E}}_{q_{% \\phi}(z^{u}|{\\cal R}^{u})}[\\log p_{\\theta}({\\cal H}^{u}|z^{u})]-\\beta{\\rm KL}(% q_{\\phi}(z^{u}|{\\cal R}^{u})||p(z^{u})), $ $ {\\cal L}_{\\beta}(\\phi,\\theta;\\mathcal{H}^{u})={\\mathbb{E}}_{q_{% \\phi}(z^{u}|{\\cal R}^{u})}[\\log p_{\\theta}({\\cal H}^{u}|z^{u})]-\\beta{\\rm KL}(% q_{\\phi}(z^{u}|{\\cal R}^{u})||p(z^{u})), $ </equation> </equationgroup> which the right-hand side is a variant of what is known as the evidence lower bound (ELBO).", "The expectation is estimated with a Monte-Carlo estimate.", "During training, a single sample for the estimate turned out to be sufficient, whereas during testing we utilized 5 samples to reduce variance.", "\\newline </paragraph>  </section>"], ["<section> <title> 4 Experimental Results </title>  To measure the effectiveness of this framework in general, using the NHP and RMTPP base models we trained each in their standard configuration (i.e., a decoder-only setup) and in the proposed variational mixture-of-experts setup (referred to as MoE-NHP and MoE-RMTPP).", "We rated these models on their held-out log-likelihood values, next event predictions, and user/source identification capabilities as described below.", "Furthermore, all tests were conducted using sequences from new users to emphasize the added ability to adapt to new sources.", "\\newline Models were trained by minimizing Eq. [@ref:LABEL:eq:ll] and Eq. [@ref:LABEL:eq:ELBO] , averaged over training sequences, for the decoder-only and MoE variants respectively via the Adam optimizer with default hyperparameters [@bib:kingma2014adam] and a learning rate of 0.001.", "A linear warm-up schedule for the learning rate over the first training epoch was used as it led to more stable training across runs.", "We also performed cyclical annealing on $ \\beta $ in Eq. [@ref:LABEL:eq:ELBO] from 0 to $ 0.001 $ with a period of 20% of an epoch to help prevent the posterior distribution from collapsing to the prior [@bib:liu2019cyclical] .", "\\newline <subsection> <title> 4.1 Datasets </title> All models were trained and evaluated on four real-world datasets (see Table [@ref:LABEL:tab:datasets] ).", "The MemeTracker dataset [@bib:snapnets] relates to common phrases (memes).", "We defined the meme as the \u201cuser\u201d and the website it was posted to as the mark.", "The mark vocabulary is the set of top 5000 websites by volume of utterances.", "Sequences were defined as one-week-long chunks spanning August 2008 to April 2009, and event times were measured in hours.", "The Reddit comments dataset [@bib:baumgartner2020pushshift] relates to user-comments on posts in the social media site reddit.com .", "One month of data (October 2018) was used to extract user sequences, and the mark vocabulary was defined as the top 1000 communities (subredits) by comment volume.", "The month was divided into multiple sequences consisting of week-long windows per user, with event times in units of hours.", "Amazon Reviews [@bib:ni2019justifying] consists of timestamped product reviews between May 1996 and October 2018, with marks defined as 737 different product categories.", "User sequences were defined as 4-week windows with event times in units of days (with a small amount of uniformly distributed noise to avoid having multiple events co-occur).", "The 4th dataset, LastFM [@bib:Celma:Springer2010] , has time-stamped records of songs listened to (both artists and track names) for nearly 1,000 users on the last.fm website.", "Marks were defined as one of 15 possible genres for a song, via the discogs.com API.", "User sequences corresponded to 1 day of listening in units of hours.", "For all datasets event times were calculated relative to the start-time of a user sequence.", "All datasets were filtered to include sequences with at least five events and no more than 200.", "Training, validation, and test sets were split so that there were no users in common between them.", "\\newline </subsection> <subsection> <title> 4.2 Results </title> <paragraph> <title> Training Data Size Ablation </title> We first investigate differences in predictive performance between the two proposed Mixture of Experts (MoE) models and their decoder-only counterparts, as a function of the size of the training data.", "We therefore trained each model on various subsets of the training data, using $ 10\\% $ , $ 20\\% $ , $ 30\\% $ , $ 50\\% $ , $ 70\\% $ , $ 90\\% $ , and $ 100\\% $ of the full training set.", "For efficiency reasons, we generated these trained models using curriculum learning, i.e., we first trained each model on the $ 10\\% $ subset until convergence, then added $ 10\\% $ more training points and trained on the resulting $ 20\\% $ subset, and so on.", "Convergence on each subset was determined when validation log-likelihood improved by less than $ 0.1 $ .", "The training subsets were generated via random sampling of users.", "All models were evaluated on the same fixed-size test dataset.", "\\newline The results can be seen in Figure [@ref:LABEL:fig:performance] (a).", "The proposed MoE models (solid lines) systematically yield better predictions in terms of test log-likelihood over their non-MoE counterparts (dotted lines).", "This trend suggests that our personalization scheme could benefit most, if not all, neural MTPP models and that these benefits appear for even small amounts of training data.", "\\newline </paragraph> <paragraph> <title> Likelihood Over Time </title> Having seen that the proposed MoE models have better predictive log-likelihoods than their decoder-only counterparts, we now investigate where exactly they achieve these performance gains.", "Using $ \\lambda_{k}(t|\\mathcal{H}_{t})=p(k|t,\\mathcal{H}_{t})\\lambda(t|\\mathcal{H}_{t}) $ , we can factor Eq. [@ref:LABEL:eq:ll] as follows: \\newline <equationgroup> <equation> $ -\\log p(\\mathcal{H})=|\\mathcal{H}|\\left({\\text{SCE}}(\\mathcal{H})% +{\\text{PP}}^{+}(\\mathcal{H})\\right)+T\\;\\!{\\text{PP}}^{-}(\\mathcal{H}) $ $ -\\log p(\\mathcal{H})=|\\mathcal{H}|\\left({\\text{SCE}}(\\mathcal{H})% +{\\text{PP}}^{+}(\\mathcal{H})\\right)+T\\;\\!{\\text{PP}}^{-}(\\mathcal{H}) $ </equation> </equationgroup> where $ {\\text{SCE}}(\\mathcal{H}_{t})\\equiv\\frac{-1}{|\\mathcal{H}_{t}|}\\sum_{i=1}^{|% \\mathcal{H}_{t}|}\\log p(k_{i}|t_{i},\\mathcal{H}_{t_{i}}), $ is the average cross entropy of a sequential, non-continuous time based, classification model, and $ {\\text{PP}}^{+}(\\mathcal{H}_{t})\\equiv\\frac{-1}{|\\mathcal{H}_{t}|}\\sum_{i=1}^{% |\\mathcal{H}_{t}|}\\log\\lambda(t_{i}|\\mathcal{H}_{t_{i}}),{\\text{PP}}^{-}(% \\mathcal{H}_{t})\\equiv\\frac{1}{t}\\int_{0}^{t}\\lambda(\\tau|\\mathcal{H}_{\\tau})d\\tau $ respectively represent the average positive and negative evidence of a sequence, ignoring the associated marks (the two together make up the terms in the log-likelihood of a non-marked temporal point process).", "All of these terms can assist in identifying issues within MTPPs, especially when investigated as a function of $ t $ .", "We presume that most of the heterogeneity between sequences in datasets resides in the categorical distributions of marks.", "Here we focus our analysis on the SCE term\u2014see the supplementary material for discussion of other terms.", "\\newline Figure [@ref:LABEL:fig:performance] (b) shows average SCE values over time.", "The decoder-only models (dotted) tend to have high SCE values near the beginning of sequences (left side of x-axis), as the model adapts to the type of sequence and user it is making predictions for.", "In contrast, the MoE models (solid) have much lower SCE near the beginning of sequences, i.e., are making significantly better categorical predictions for marks early on.", "The decoder-only models gradually approach the performance of the MoE models over time, but never close the gap, indicating the user information (via $ z_{u} $ ) provides significant benefit in mark prediction that is difficult for an RNN decoder model to learn from the sequence itself.", "\\newline </paragraph> <paragraph> <title> Ranking of Next Event Predictions </title> One use case of MTPP models is to predict what a user will do next and when they will do it during an ongoing sequence.", "As an example scenario, we conditioned the models on a prefix $ \\mathcal{H}^{u}_{t_{10}} $ of the first $ 10 $ events in each test sequence and evaluated the predictive performance for the next event $ (t_{11},k_{11}) $ .", "Predicted times and marks were estimated by marginalizing over marks and times respectively to minimize Bayes risk, similar to [@bib:mei2017neural] \u2014see the supplement for details.", "The choice of $ 10 $ events in the prefix was made to simulate making predictions early in a sequence, where there is still a good deal of variability for the next event.", "\\newline The predicted marks were evaluated by the ranking of the true mark\u2019s predicted probability, averaged over all sequences in the test set for each dataset."]], "target": "Table (a) shows our results. MoE models achieve superior performance than the other models on all datasets, with particularly large gains for the Meme and Reddit data. The results for predicted times were not found to be consistently different between the MoE and non-personalized models. One possible reason for this might be that there is not a strong user-specific signal in event timing information that cannot already be detected in the sequence being decoded, thus causing the personalization models to focus more on event types than on times. In terms of predictive performance, it appears that the biggest benefit of personalization is more accurate predictions of marks rather than times. All results for predicted times can be found in the supplement."}, {"tabular": ["  Quadrants  &  Technique  &  Data Characteristics  &  Model ", " Partitioning  &  Storage  &  High dim.  &  Low dim.  &  High ins.  &  Low ins.  &  Multi-class  &  Deep tree ", " QD1  &  Horizontal  &  Column  &    &    &    &    &    &  ", " QD2  &  Horizontal  &  Row  &    &  \u2713  &  \u2713  &    &    &  ", " QD3  &  Vertical  &  Column  &  \u2713  &    &    &  \u2713  &    &  ", " QD4  &  Vertical  &  Row  &  \u2713  &    &  \u2713  &    &  \u2713  &  \u2713  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Gradient boosting decision tree (GBDT) [@bib:friedman2001greedy] is an ensemble model which uses decision tree as weak learner and improves model quality with a boosting strategy [@bib:friedman2000additive,Wang2012] .", "It has achieved superior performance in various workloads, such as prediction, regression, and ranking [@bib:li2012robust,tyree2011parallel,burges2010ranknet] .", "Not only the data scientists choose it as a favorite tool for data analytic competitions such as Kaggle, but also users from industry raise interests in deploying GBDT in production environments [@bib:he2014practical,zhou2017psmart,jiang2018dimboost] .", "\\newline With the rapid increase in data volume, distributed GBDT has been intensively studied to improve the performance.", "Recently, a range of distributed machine learning systems has been developed to train GBDT, such as XGBoost, LightGBM and DimBoost [@bib:chen2016xgboost,TencentBoost,zhou2017psmart,ponomareva2017tf,ke2017lightgbm,jiang2018dimboost] .", "However, in practical use, there is no such system able to outperform the others in all cases.", "We notice that these systems manage the training dataset in different ways.", "This motivates us to conduct a study of the data management in distributed GBDT.", "\\newline Consider the training dataset as a matrix, where each row represents one instance and each column refers to one dimension of feature.", "To make distributed machine learning possible, we need to partition the dataset among the workers in a cluster.", "Afterwards, each worker uses some storage structure to store the data partition.", "As a result, there are two orthogonal aspects in the data management of distributed GBDT \u2014 data partitioning and data storage.", "\\newline Data Partitioning.", "Since the dataset is a two-dimensional matrix, there are two different schemes to partition the dataset over the workers.", "Horizontal partitioning , which is the de facto choice of most distributed machine learning algorithms, horizontally partitions the dataset by instances (rows).", "Vertical partitioning is an alternative to horizontal partitioning.", "The workers partition the dataset by features (columns) and each worker stores a feature subset.", "\\newline Data Storage.", "After data partitioning, each worker has a portion of the training data, either a horizontal partition or a vertical partition.", "Without loss of generality, we assume the dataset is sparse.", "There are two avenues to store the data.", "Row-store is a popular choice in machine learning.", "Each instance is stored as a set of $ \\langle $ feature index, feature value $ \\rangle $ pairs, a.k.a. Compressed Sparse Row (CSR) format.", "Many algorithms follow a row-based training routine which supports scanning the training data sequentially.", "Column-store puts together one column (feature) of the partition, and stores each column as a set of $ \\langle $ instance index, feature value $ \\rangle $ pairs, a.k.a. Compressed Sparse Column (CSC) format.", "\\newline If we revisit the methods of data management, there are two data partitioning choices and two data storage choices, yielding four possible combinations.", "Using a quadrant-based manner, Figure [@ref:LABEL:fig:four_quadrants] summarizes four combinations into four quadrants.", "Interestingly, three quadrants have been explored by existing systems, but none of these works study which is the best combination.", "As a result, the researchers and engineers might be confused when they need to choose the platform for their specific workloads.", "To address this issue, we ask the question what are the advantages and disadvantages of different data management schemes, and how can we make a proper choice facing different scenarios? \\newline <subsection> <title> 1.1 Summary of Contributions </title> We list the main contributions of this work below.", "\\newline (Anatomy of existing systems) To answer the above questions, we first study how data management influences the performance of distributed GBDT.", "Specifically, we conduct a theoretical analysis of data partitioning and data storage.", "\\newline Anatomy of data partitioning.", "The data partitioning directly affects the communication and memory cost due to a data structure called gradient histogram, which summarizes gradient statistics for fast and accurate split finding in GBDT.", "We find that vertical partitioning is more suitable for a range of workloads, including high-dimensional features, deep trees, and multi-classification.", "The fundamental reason is that these factors could cause extreme large gradient histograms, and vertical partitioning helps avoid intensive communication and memory overhead.", "In contrast, horizontal partitioning works better for datasets with low dimensionality and a large number of instances.", "\\newline Anatomy of data storage.", "In GBDT, the training procedures, especially the construction of gradient histograms involve complex data access and indexing, and the efficiency is influenced by the data storage.", "We carefully investigate the computation efficiency of row- and column-store in terms of data access and indexing.", "We find that although column-store seems more natural for vertical partitioning, as adopted by database design, the computation overhead is rather undesirable.", "Row-store is superior to column-store given a large number of instances, achieving a higher computation efficiency.", "In short, our main finding is that row-store is almost always a wiser choice unless the dataset is high-dimensional and meanwhile contains very few instances.", "\\newline (Proposal of Vero) Unfortunately, although our study discovers that the fourth quadrant in Figure [@ref:LABEL:fig:four_quadrants] is suitable for a wide range of large-scale scenarios, including high-dimensional datasets, multi-classification tasks, and deep trees, it is never investigated by previous works.", "In this work, we propose Vero, an end-to-end distributed GBDT system that uses vertical partitioning and row-store.", "\\newline Horizontal-to-vertical transformation.", "We develop an efficient algorithm to transform the horizontally stored datasets to vertically partitioned.", "To reduce the network overhead, we compress both feature indices and feature values, without any loss of model accuracy.", "\\newline Training with Vertical Row-store.", "We redesign the training routine of GBDT to match the vertical partitioning and row-store policy.", "Specifically, we adapt the split finding and node splitting procedures to vertical partitioning, and adopts a node-to-instance index for row-store to construct the gradient histograms efficiently.", "\\newline (Comprehensive Evaluation) We implement distributed GBDT on top of Spark [@bib:zaharia2012resilient] , a popular distributed engine for large-scale data processing, and conduct extensive experiments to validate our analysis empirically.", "\\newline Breakdown comparison of data management.", "To fairly evaluate each candidate in data partitioning and data storage, we implement different partitioning schemes and storage patterns in the same code base, and compare them under different circumstances using a wide range of datasets.", "Our experimental results regarding computation, communication, and memory cost validate our theoretical anatomy.", "\\newline End-to-end evaluation.", "We compare Vero with other popular GBDT systems over extensive datasets, including public, synthetic, and industrial datasets.", "Empirical results show that our analytical comparison also holds for the state-of-the-art systems.", "Regarding the results, we provide suggestions on how to choose a proper platform for a given workload.", "\\newline </subsection>  </section>"], ["<section> <title> 2 Background </title>  <subsection> <title> 2.1 Preliminaries of GBDT </title> <subsubsection> <title> 2.1.1 Overview of GBDT </title> Gradient boosting decision tree is a boosting algorithm that uses decision tree as weak learner.", "Figure [@ref:LABEL:fig:gbdt] shows an illustration of GBDT.", "Given a training dataset with $ N $ instances and $ D $ features $ \\left\\{(\\bm{x}_{i},y_{i})\\right\\}_{i=1}^{N} $ , where $ \\bm{x}_{i}\\in\\mathbb{R}^{D} $ and $ y_{i}\\in\\mathbb{R} $ are the feature vector and label of an instance, GBDT trains a set of decision trees $ \\left\\{f_{t}(\\bm{x})\\right\\}_{t=1}^{T} $ , puts each instance onto one leaf node, and sums the leaf predictions of all trees as the final instance prediction: $ \\hat{y}_{i}=\\sum_{t=1}^{T}\\eta f_{t}(\\bm{x}_{i}) $ , where $ T $ denotes the total number of trees and $ \\eta $ is a hyper-parameter called learning rate (a.k.a. step size).", "\\newline GBDT trains the decision trees sequentially.", "For the $ t $ -th tree, it tries to minimize the loss given the predictions of prior trees, defined by the regularized objective function: \\newline <equation> $ \\small F^{(t)}\\text{=}\\sum l(y_{i},\\hat{y}_{i}^{(t)})+\\Phi(f_{t})\\text{=}\\sum l% (y_{i},\\hat{y}_{i}^{(t-1)}+f_{t}(\\bm{x}_{i}))+\\Phi(f_{t}), $ </equation> \\newline where $ l $ is usually a differentiable convex loss function that measures the loss given prediction and target, e.g., logistic loss or square loss.", "$ \\Phi $ is a regularization term to avoid over-fitting.", "We follow the popular choice in [@bib:chen2016xgboost,jiang2018dimboost] , which is $ \\Phi(f_{t})=\\gamma J_{t}+\\lambda||\\omega_{t}||_{2}^{2}/2 $ , where $ \\omega_{t} $ denotes the weight vector comprised of $ J_{t} $ leaf values in in the $ t $ -th tree.", "$ \\gamma $ and $ \\lambda $ are hyper-parameters that control the complexity of one tree.", "\\newline To quickly optimize the objective function, LogitBoost [@bib:friedman2000additive] proposes to approximate $ F^{(t)} $ with second-order Taylor expansion when training the $ t $ -th tree, i.e., \\newline <equation> $ \\small F^{(t)}\\approx\\sum\\big{[}l(y_{i},\\hat{y}_{i}^{(t-1)})+g_{i}f_{t}(\\bm{x}% _{i})+\\frac{1}{2}h_{i}f_{t}^{2}(\\bm{x}_{i})\\big{]}+\\Phi(f_{t}), $ </equation> where $ g_{i}=\\partial_{\\hat{y}_{i}^{(t-1)}}l(y_{i},\\hat{y}_{i}^{(t-1)}) $ and $ h_{i}=\\partial_{\\hat{y}_{i}^{(t-1)}}^{2}l(y_{i},\\hat{y}_{i}^{(t-1)}) $ are the first- and second-order gradients.", "Denote $ I_{j}=\\{i|\\bm{x}_{i}\\in{leaf}_{j}\\} $ as the set of instances classified onto the $ j $ -th leaf.", "Omitting the constant term, we should minimize \\newline <equation> $ \\small\\widetilde{F}^{(t)}=\\sum_{j=1}^{J_{t}}\\Big{[}\\big{(}\\sum_{i\\in{I_{j}}}g_% {i}\\big{)}\\omega_{j}+\\big{(}\\sum_{i\\in{I_{j}}}h_{i}+\\lambda\\big{)}\\omega_{j}^{% 2}\\Big{]}+\\gamma J_{t}. $ </equation> \\newline If the tree is not going to be expanded (no leaf to be split), we can obtain its optimal weight vector and minimal loss by \\newline <equation> $ \\small\\omega_{j}^{*}=-\\frac{\\sum_{i\\in{I_{j}}}g_{i}}{\\sum_{i\\in{I_{j}}}h_{i}+% \\lambda},\\widetilde{F}^{(t)*}=-\\frac{1}{2}\\sum_{j=1}^{J_{t}}\\frac{(\\sum_{i\\in{% I_{j}}}g_{i})^{2}}{\\sum_{i\\in{I_{j}}}h_{i}+\\lambda}+\\gamma J_{t}. $ </equation> \\newline Equation [@ref:LABEL:eq:criterion] can be reckoned as a measurement to evaluate the performance of a decision tree, which can be analogous to the impurity functions of decision tree algorithms, such as entropy for ID3 [@bib:quinlan1986induction] or Gini-index for CART [@bib:breiman2017classification] .", "To grow a tree w.r.t.", "minimizing the total loss, the common approach is to select a tree node (beginning with the root node) and find the best split (a split feature and a split value) that can achieve the maximal split gain.", "The split gain is defined as \\newline <equation> $ \\small Gain=\\frac{1}{2}\\big{[}\\frac{(\\sum_{i\\in{I_{L}}}g_{i})^{2}}{\\sum_{i\\in{% I_{L}}}h_{i}+\\lambda}+\\frac{(\\sum_{i\\in{I_{R}}}g_{i})^{2}}{\\sum_{i\\in{I_{R}}}h% _{i}+\\lambda}-\\frac{(\\sum_{i\\in{I}}g_{i})^{2}}{\\sum_{i\\in{I}}h_{i}+\\lambda}% \\big{]}-\\gamma, $ </equation> where $ I_{L} $ and $ I_{R} $ indicate the left and right child nodes after the splitting.", "After the current tree finishes, the predictions of all instances are updated, the gradient statistics are re-computed, and the algorithm will proceed to next tree.", "\\newline </subsubsection> <subsubsection> <title> 2.1.2 Histogram-based Algorithm </title> Histogram-based split finding.", "It is vital to find the optimal split of a tree node efficiently, as enumerating every possible split in a brute-force manner is impractical.", "Current works generally adopt a histogram-based algorithm for fast and accurate", "split finding, as illustrated in Figure [@ref:LABEL:fig:histogram] .", "The algorithm considers only $ q $ values for each feature $ f $ as candidate splits rather than all possible splits.", "The most common approach to propose the candidates is using the quantile sketch [@bib:greenwald2001space,karnin2016optimal,gan2018moment] to approximate the feature distribution.", "After candidate splits are prepared, we enumerate all instances on a tree node and accumulate their gradient statistics into two histograms, first- and second-order gradients, respectively.", "The histogram consists of $ q $ bins, each of which sums the first- or second-order gradients of instances whose $ f $ -th feature values fall into that range.", "In this way, each feature is summarized by two histograms.", "We find the best split of feature $ f $ upon the histograms by Equation [@ref:LABEL:eq:split_gain] , and the global best split is the best split over all features.", "\\newline Histogram subtraction technique.", "Another advantage of the histogram-based algorithm is that we can accelerate the algorithm by a histogram subtraction technique.", "The instances on two children nodes are non-overlapping and mutual exclusive, since an instance will be classified onto either left or right child node when the parent node gets split.", "Considering the basic operation of histogram is adding gradients, therefore, for feature $ f $ , the element-wise sum of first- or second-order histograms of children nodes equals to that of parent.", "Motivated by this, we can significantly accelerate training by first constructing the histograms of the one child node with fewer instances, and then getting those of the sibling node via histogram subtraction (histograms of parent node are persist in memory).", "By doing so, we can skip at least one half of the instances.", "Since histogram construction usually dominates the computation cost, such subtraction technique can speed up the training process considerably.", "\\newline </subsubsection> </subsection> <subsection> <title> 2.2 Data Management in GBDT </title> As aforementioned, the combinations of partitioning schemes and storage patterns together form four quadrants (QD).", "Although the four quadrants entail similar memory consumption to store the dataset in expectation, the manipulation (including computation, storing, and communication) of gradient histograms can be significantly different.", "\\newline <subsubsection> <title> 2.2.1 Data Partitioning in GBDT </title> Since gradient histograms can be reckoned as summaries of features, different partitioning choices affect the way we construct and exchange histograms.", "\\newline Since values of each feature are scattered among workers in horizontal partitioning, as presented in Figure [@ref:LABEL:fig:horizontal] , each worker needs to construct histograms for all features based on its data shard.", "Then the local histograms are aggregated into global histograms via element-wise summation, so that all values of each feature are correctly summarized.", "\\newline As shown in Figure [@ref:LABEL:fig:vertical] , each worker maintains one or several complete columns in vertical partitioning, therefore there is no need to aggregate the histograms.", "Each worker obtains the local best split regarding its feature subset, and then all workers exchange the local best splits and choose the global best one.", "Nevertheless, since the feature values of an instance are partitioned, its placement after node splitting, i.e., left or right child node, is only known by the worker who proposes the global best split.", "As a result, the placement of instances must be broadcast to all workers.", "\\newline </subsubsection> <subsubsection> <title> 2.2.2 Data Storage in GBDT </title> The most distinguished difference brought by storage pattern is the way we index and access the values during the construction of histograms, as shown in Figure [@ref:LABEL:fig:storage] .", "\\newline With row-store, each worker iterates the data shard row-by-row, and accumulates the gradient statistics to corresponding histograms.", "When processing one instance, the worker needs to update multiple histograms of different features.", "To accelerate the construction, each worker further maintains an indexing between tree nodes and instances.", "\\newline With column-store, as all values of one feature are held together, each worker constructs histograms one-by-one by processing the columns individually.", "However, the indexing between the values on a column and tree nodes must be maintained carefully.", "As we will discuss in Section [@ref:LABEL:sec:storage_pattern] , the data access and indexing might take extra efforts.", "\\newline </subsubsection> </subsection>  </section>"], ["<section> <title> 3 Anatomy of Quadrants </title>  In this section, we provide an in-depth study of the four quadrants when training a GBDT model distributedly.", "To formally describe the results, we assume there are $ W $ workers, and the GBDT model is comprised of $ T $ decision trees, where each of them has $ L $ layers.", "The number of candidate splits is denoted by $ q $ .", "For classification tasks, we denote $ C $ as the dimension of a gradient, where $ C $ equals 1 in binary-classification or the number of classes in multi-classification.", "\\newline <subsection> <title> 3.1 Analysis of Partitioning Scheme </title> Here we theoretically analyze the performance of horizontal and vertical partitioning schemes, including memory and communication cost.", "\\newline <subsubsection> <title> 3.1.1 Histogram Size </title> The core operation of GBDT is the construction and manipulation of gradient histograms.", "We first study the size of histograms, which is determined by three factors.", "(1) Feature dimension.", "Since two histograms are built for each feature (one first-order gradient histogram and one second-order gradient histogram), the total size is proportional to $ 2\\times D $ .", "(2) Number of candidate splits.", "The number of bins in one histogram equals to the number of candidate splits $ q $ , which makes the histogram size proportional to $ q $ .", "(3) Number of classes.", "In multi-classification tasks, the gradient is a vector of partial derivatives on all classes.", "The histogram size is therefore proportional to $ C $ .", "To sum up, the histogram size on one tree node, denoted by $ Size_{hist} $ , is $ 2\\times D\\times q\\times C\\times 8 $ bytes, where $ 8 $ bytes is the size of a double-precision floating-point number.", "\\newline </subsubsection> <subsubsection> <title> 3.1.2 Memory Cost </title> Obviously, the memory cost for both partitioning to store the dataset is similar.", "Nonetheless, the memory cost to store the gradient histograms is quite different.", "Here we focus on the memory consumed by storing the histograms.", "\\newline In order to perform histogram subtraction, we have to conserve the histograms of the parent nodes.", "The maximum number of histograms to be held in memory equals to the number of tree nodes in the last but one layer , which is $ 2^{L-2} $ .", "With horizontal partitioning, each worker needs to construct the histograms of all features, thus the memory cost of histograms is $ Size_{hist}\\times 2^{L-2} $ .", "Nevertheless, with vertical partitioning, each worker constructs the histograms of a portion of features.", "As a result, the expected memory cost is $ Size_{hist}\\times 2^{L-2}/{W} $ , which is significantly smaller than the horizontal partitioning counterpart.", "\\newline </subsubsection> <subsubsection> <title> 3.1.3 Communication Cost </title> The dominant communication cost in horizontal partitioning scheme is the aggregation of histograms.", "Despite the existence of different aggregation methods [@bib:thakur2005optimization] , such as map-reduce , all-reduce , and reduce-scatter , the minimal transferred data of each worker is the size of local histograms.", "Thus the total communication cost among the cluster building one tree is at least $ Size_{hist}\\times W\\times(2^{L-1}-1) $ .", "It is obvious that as the tree goes deeper, i.e., as $ L $ increases, the communication cost grows quadratically.", "\\newline Unlike horizontal partitioning scheme, vertical partitioning scheme does not need to aggregate the histograms since each worker holds all the values of a specific feature.", "However, as described in Section [@ref:LABEL:sec:bg] , after splitting a tree node, the placement of instances must be broadcast to all workers.", "Since the communication cost is only affected by the number of instances, the overhead in one tree layer remains the same as the tree goes deeper.", "As we will elaborate in Section [@ref:LABEL:sec:train_workflow] , the placement is encoded into a bitmap so that the communication overhead can be reduced sharply.", "To conclude, the communication cost for an $ L $ -layer tree is $ \\left\\lceil{N}/{8}\\right\\rceil\\times W\\times L $ bytes, where $ \\left\\lceil{N}/{8}\\right\\rceil $ bytes is the size of one bitmap.", "\\newline </subsubsection> <subsubsection> <title> 3.1.4 Summary of Analysis </title> Undoubtedly, the choice of partitioning scheme highly depends on $ Size_{hist} $ .", "Undoubtedly, horizontal partitioning works well for datasets with low dimensionality, since the resulting histograms are small.", "However, in both industry and academia, the following three cases become more and more popular \u2014 high dimensional features, deep trees, and multi-classification.", "In these cases, the histogram size can be very large.", "Therefore, vertical partitioning is far more memory- and communication-efficient than horizontal partitioning.", "Take an industrial dataset Age as an example, which is also used in our experimental study, we suppose running GBDT on 8 workers.", "The dataset contains 48M instances, 330K features and 9 classes.", "The decision trees have 8 layers and the number of candidate splits is 20.", "Then the estimated size of histograms on one tree node can be up to 906MB.", "Using the horizontal approach, the memory consumption would be 56.6GB and the total communication cost would be 900GB for merely one tree in the worst case.", "To the contrary, when the vertical scheme is applied, the expected memory cost of histograms is 7.08GB per tree and the communication cost is merely 366MB for one tree.", "\\newline </subsubsection> </subsection> <subsection> <title> 3.2 Analysis of Storage Pattern </title> In this section, we discuss the impact brought by different storage patterns.", "Although there exist various works discussing the different storage patterns in database designs, the conclusion cannot be transferred to distributed GBDT.", "\\newline The choice of storage pattern only influences the computation cost, rather than communication or memory cost.", "The most time-consuming computation in GBDT is histogram construction.", "However, the data access in GBDT is different from other ML models.", "Specifically, since GBDT conducts tree splitting in a top-to-bottom way, we need to create an index between tree nodes and training instances, and update the index during the training.", "Below, we discuss how to design the index with different storage patterns.", "\\newline <subsubsection> <title> 3.2.1 Choice of Index </title> To understand the computation complexity of histogram construction, we first illustrate the possible index choices used in GBDT training.", "As illustrated in Figure [@ref:LABEL:fig:indexes] , there are three commonly used indexes indicating the position of training instances in the tree.", "\\newline <list> \\ Node-to-instance index maps a tree node to the corresponding training instances, meaning that the key is a tree node and the value is the instances on the tree node.", "\\newline \\ \\ Instance-to-node index maps a training instance to the corresponding tree node.", "\\newline \\ \\ Column-wise node-to-instance index maintains a node-to-instance index for each feature column.", "\\newline \\ </list> \\newline </subsubsection> <subsubsection> <title> 3.2.2 Row-store </title> When building the gradient histogram with row-store, we adopt a row-wise access method to scan rows sequentially.", "Each row is an instance, which consists of the instance index and a list of nonzero $ \\langle $ feature id, feature value $ \\rangle $ pairs.", "\\newline Node-to-instance index is designed for row-store.", "We get the instance rows of one tree node from the index.", "For each row, we iterate the $ \\langle $ feature id, feature value $ \\rangle $ pairs.", "For each pair, we add the instance gradient to the histograms of that tree node.", "Furthermore, the node-to-instance index enables the histogram subtraction technique since we can directly get the instances of any tree node.", "If two tree nodes are siblings, we only build histogram for the tree node with fewer instances, and apply histogram subtraction for the other one.", "Consequently, combining the node-to-instance index and row-store can save large amount of data accesses.", "\\newline </subsubsection> <subsubsection> <title> 3.2.3 Column-store </title> When building the gradient histogram with column-store, a straight-forward way is to use a column-wise access method to scan the columns.", "Each column summarizes the values of one feature, which includes the feature id and a list of $ \\langle $ instance id, feature value $ \\rangle $ pairs.", "\\newline Instance-to-node index.", "Since the key of each pair in column-store is instance id, a natural idea is creating an instance-to-node index.", "As shown in Figure [@ref:LABEL:fig:indexes] , for each $ \\langle $ instance id, feature value $ \\rangle $ pair, we query the tree node it belongs to, and then update the corresponding histograms.", "Nonetheless, we find that using such method is not efficient in practice.", "The reason is that in many real cases, the dataset is often sparse (especially for high-dimensional datasets).", "By default, given an optimal node split with feature $ f $ , instances with missing value on $ f $ are classified to the same child node, causing imbalance sibling nodes.", "Histogram subtraction should be able to boost the performance, however, with instance-to-node index, we cannot directly get the instances of two child nodes without queries, i.e., we need to access all instances of the two nodes.", "Therefore, a lot of time is wasted on scanning unnecessary data, resulting in poor performance.", "\\newline Node-to-instance index.", "One solution to avoid scanning all instances is using node-to-instance index for column-store.", "However, there still exists a fatal drawback.", "Once obtaining an instance id from the index, we need to locate the feature values of the instance from column-store.", "To that end, we have to perform a binary search on all the feature columns, which brings in a $ \\log{(N)} $ computation complexity.", "When $ N $ is large, the overhead becomes unacceptable.", "\\newline Column-wise node-to-instance index.", "Another way to escape from both scanning unnecessary data and binary search is deploying an index on each column, which actually maintains a node-to-instance index for each column.", "When building histograms for one node, we can locate the $ \\langle $ instance id, feature value $ \\rangle $ pairs on all columns directly.", "Nevertheless, although locating the instances is fast, updating the index is expensive.", "As shown in Figure [@ref:LABEL:fig:update_index] , whenever we split some tree node, we have to update the indexes on all columns.", "The computation complexity of splitting tree nodes is about $ D $ times of the two indexes described above.", "As a result, the column-wise node-to-instance index is only applicable for low-dimensional datasets.", "\\newline </subsubsection> <subsubsection> <title> 3.2.4 Summary of Analysis </title> Here we summarize the computation complexity of different combinations by considering the number of accesses to dataset or other data structures.", "\\newline Cost of histogram construction.", "In histogram construction, since we need to access the feature values on the data shard, and the expected number of key-value pairs is $ Nd/W $ , where $ d $ is the average number of non-zeros of one instance, the complexity of histogram construction for one layer is at least $ O(Nd/W) $ .", "There are three combinations that can theoretically achieve the lowest complexity, which are row-store with node-to-instance index, column-store with instance-to-node index, and column-store with column-wise index.", "However, as discussed above, column-store with instance-to-node index cannot benefit from the histogram subtraction technique, and thereby spends more time than row-store with node-to-instance index in practice; while column-store with column-wise index entails a much higher complexity when node splitting although it works well for histogram construction.", "For the last combination, column-store with node-to-instance index, it incurs binary search on the feature columns whenever accessing an instance.", "In expectation, the complexity of binary search is approximately $ O(\\log Nd/WD) $ .", "Therefore, the overall complexity becomes $ O(Nd/W\\times\\log Nd/WD) $ .", "\\newline Cost of split finding and node splitting.", "Except for histogram construction, there are two other phases in GBDT, which are split finding and node splitting.", "To make the analysis self-contained, here we briefly analyze the computation cost in these two phases.", "For split finding, the algorithm needs to iterate all split candidates, causing a computation complexity of $ O(qD/W) $ , regardless of the partitioning scheme.", "For node splitting, we need to update the index described above.", "The computation on one tree layer for both store patterns is proportional to the number of instances, if we do not use the column-wise node-to-instance index .", "The complexity is $ O(N/W) $ for horizontal partitioning and $ O(N) $ for vertical partitioning.", "Obviously, both of the two phases have a significantly lower computation cost than histogram construction.", "Therefore, we should pay more attention to the impact of storage pattern on histogram construction.", "\\newline Summary.", "As analyzed, column-store is not efficient with different index structures.", "To the contrary, the combination of row-store and node-to-instance index can achieve minimal computation since it leverages histogram subtraction to reduce instance scanning and incurs the smallest cost of index update.", "As a result, unless the dataset contains very few instances so that the extra cost in indexing will not be large, we should choose row-store for distributed GBDT.", "\\newline </subsubsection> </subsection> <subsection> <title> 3.3 Take-away Results </title> We conclude the advantageous scenarios of different data management methods in Table [@ref:LABEL:tb:adv_summary] .", "Considering large-scale cases is becoming more and more ubiquitous, we have the following take-away results: \\newline <list> \\ Vertical partitioning is able to outperform horizontal partitioning for the high-dimensional features, deep trees and multi-classification tasks, since it is more memory- and communication-efficient, while horizontal partitioning is better the low-dimensional datasets.", "\\newline \\ \\ Row-store is better than column-store unless the number of instances is very small, since it can achieve minimal computation complexity and avoid redundant data accesses.", "\\newline \\ \\ Overall, the composition of vertical partitioning and row-store (QD4) achieves optimal performance under many real-world large-scale cases as aforementioned.", "In Section [@ref:LABEL:sec:eval] and [@ref:LABEL:sec:industrial] , we will validate this through extensive experiments.", "\\newline \\ </list> \\newline </subsection>  </section>"], ["<section> <title> 4 Representatives of Quadrants </title>  In this section, we first introduce the representatives of QD1-3, and then propose Vero, a brand new distributed GBDT system with vertical partitioning and row-store (QD4).", "\\newline <subsection> <title> 4.1 Taxonomy of Existing Systems </title> XGBoost (QD1, Horizontal & Column) .", "XGBoost [@bib:chen2016xgboost] is a popular GBDT system that achieves great success, and it chooses horizontal partitioning scheme and column-store pattern.", "In XGBoost, each worker maintains an instance-to-node indexing.", "To construct histograms of one layer, workers linearly scan the feature columns, accumulate the gradient statistics to corresponding histogram bins, and finally aggregate the histograms in an all-reduce manner.", "After aggregation, the histograms are owned by a leader worker.", "Then it finds the best split by enumerating the candidate splits in the histograms.", "In node splitting phase, each worker updates its own instance-to-node index.", "\\newline LightGBM and DimBoost (QD2, Horizontal & Row) .", "Both LightGBM [@bib:ke2017lightgbm] and DimBoost [@bib:jiang2018dimboost] belong to this quadrant.", "A node-to-instance indexing that maps tree nodes to instances is maintained.", "To construct the histograms of one node, the workers scan the feature vectors of instances on that node, accumulate the gradient statistics to corresponding histogram bins, and finally aggregate the histograms.", "LightGBM accomplishes the aggregation using reduce-scatter .", "Instead of aggregating all histograms on a single worker, each worker is responsible for a part of features.", "All workers then find splits on aggregated histograms and synchronize to obtain the global best one.", "While DimBoost, with parameter-server architecture [@bib:li2014scaling,jiang2017heterogeneity] , aggregates the histograms on parameter servers and enables server-side split finding.", "In either way we can avoid the single-point-bottleneck in communication.", "The node-to-instance indexing is also updated during node splitting.", "\\newline Yggdrasil (QD3, Vertical & Column) .", "Although Yggdrasil [@bib:abuzaid2016yggdrasil] is designed for vanilla decision tree algorithms instead of GBDT, it is the first work that introduces vertical partitioning into distributed decision tree.", "In Yggdrasil, each worker maintains several complete columns so that it can obtain the best split of its own feature (column) subset without histogram aggregation.", "All workers then exchange their local best splits and choose the global best with maximal split gain.", "In this way, the communication in split finding phase is far less than horizontal-based methods.", "When splitting the tree nodes, Yggdrasil encodes the placement of each instance into a bitmap.", "Further, Yggdrasil utilizes a column-wise node-to-instance index.", "Based on the bitmap, the index for each column is updated.", "However, it will bring in a large computation cost when feature dimensionality is high.", "\\newline </subsection> <subsection> <title> 4.2 Vero </title> As analyzed in Section [@ref:LABEL:sec:anatomy] , QD4 (Vertical & Row) is superior to the others under many large-scale scenarios but left unexplored.", "This drives us to develop a system, Vero, within the scope of QD4.", "Vero is built on top of Spark [@bib:zaharia2012resilient] and has been deployed in our industrial partner, Tencent Inc.. As shown in Figure [@ref:LABEL:fig:overview] , Vero follows the master-worker architecture.", "After loading horizontally partitioned dataset from distributed file systems, we perform an efficient transformation operation to vertically repartition the dataset accross workers.", "Then masters and workers iteratively train a set of decision trees upon the repartitioned dataset.", "\\newline <subsubsection> <title> 4.2.1 Horizontal-to-Vertical Transformation </title> Naturally, training datasets are often horizontally partitioned and stored in distributed file systems such as HDFS and S3, which is obviously unfit for vertical partitioning.", "To solve this problem, we need to repartition the datasets vertically.", "To address the potential network overhead for large datasets, we develop an efficient transformation method that compresses both feature indices and feature values, without any loss of model accuracy.", "There are five main steps, as shown in Figure [@ref:LABEL:fig:transform] and described below.", "\\newline <list> \\ Build quantile sketches.", "After loading the dataset, each worker builds a quantile sketch for each feature.", "Then the local sketches are repartitioned among all workers, i.e., the local sketches of one feature are sent to the same worker.", "Finally, the workers merge local sketches of the same feature into a global sketch.", "\\newline \\ \\ Generate candidate splits.", "The workers generate candidate splits for each feature from merged quantile sketch, using a set of quantiles, e.g., 0.1, 0.2, \u2026, 1.0.", "Then the master collects the candidate splits and broadcasts them to all workers for further use.", "\\newline \\ \\ Column grouping.", "Each worker changes the representation of its local data shard by putting those features to be assigned to the same worker into one group.", "(The strategy of feature assignment will be described in Section [@ref:LABEL:sec:transform_impl] .) The key-value pairs are encoded into a more compact form simultaneously.", "(i) For each feature, we assign a new feature id starting from 0 inside the column group.", "Suppose there are $ p $ features in one group, we use $ \\lceil\\log(p)\\rceil $ bytes to encode the new feature id. (ii) We encode feature values with histogram bin indexes, which indicates the range of two consecutive splits.", "Since the histograms stay unchanged, the model accuracy will not be harmed.", "As the number of histogram bins $ q $ is generally a small integer, we further encode bin indexes with $ \\lceil\\log(q)\\rceil $ bytes.", "After this operation, key-value pairs turn into $ \\langle $ new feature id, bin index $ \\rangle $ pairs.", "\\newline \\ \\ Repartition column groups.", "Similar to step 1, the column groups are repartitioned among workers.", "By doing so, each worker holds all values of its responsible features.", "Further, the ordering of instances should be the same on all workers, so that we can coalesce the instances with their labels.", "This can be done by sorting the received column groups w.r.t.", "the original worker ids.", "\\newline \\ \\ Broadcast instance labels.", "Master collects all instance labels and broadcasts them to all workers.", "Since the instance rows on each worker are ordered in step 4, we can therefore coalesce instance rows with instance labels.", "\\newline \\ </list> \\newline Network overhead.", "Step 1 and 2 prepare the candidate splits for step 3 to convert feature values into bin indexes.", "Quantile sketch is a widely-used data structure for approximate query [@bib:Li2018,Song2018] and is usually small in size [@bib:greenwald2001space,karnin2016optimal,gan2018moment] , so the network overhead is almost negligible.", "The communication bottleneck incurs in step 4.", "Nevertheless, by encoding feature id and feature value into smaller bytes, the size of a key-value pair is significantly decreased.", "According to our empirical results, it brings up to 4 $ \\times $ compression.", "The time cost of step 5 is not dominant as presented in the appendix of our technical report [@bib:1907.01882] .", "\\newline </subsubsection> <subsubsection> <title> 4.2.2 Training Workflow </title> To fit the data management strategy of QD4, we revise the traditional training procedure of GBDT.", "\\newline Histogram construction.", "Given tree node(s) to process, the master first obtains the number of instances on each node, then it decides on which node(s) we can perform histogram subtraction and sends the schema to all workers.", "Each worker constructs histograms based on its data shard.", "Since Vero stores data in row manner, we use the node-to-instance index to achieve the best performance in histogram construction.", "For each tree node, each worker obtains a list of row indexes, and each row represents an instance that is currently classified onto that tree node.", "Then the worker adds the gradient statistics to corresponding histograms.", "We also adopt the method proposed in [@bib:jiang2018dimboost] to handle instances with missing values.", "Finally, unlike horizontal-based works, Vero does not need to aggregate histograms among workers.", "\\newline Split finding.", "To obtain the best split for some tree node, each worker first calculates a split for each histogram by Equation [@ref:LABEL:eq:split_gain] , and proposes the one with maximal split gain as the local best split.", "Finally, master collects all local best splits and chooses the global best one.", "Note that, the obtained feature id is not the original one since we transform it in step 3 of Section [@ref:LABEL:sec:transform] .", "Hence, the master needs to recover the original feature afterwards.", "\\newline Node splitting.", "As aforementioned, since only one worker owns feature values of the best split, the placement of each instance (left or right child) after node splitting can only be computed by it.", "The master asks the worker who has proposed the global best split to compute and broadcast the instance placement.", "Since the placement of each instance has only two options, i.e., left or right child node, we use a bitmap to represent the instance placement, which can reduce the network overhead by 32 $ \\times $ .", "All workers then update the node-to-instance index based on the bitmap.", "\\newline </subsubsection> <subsubsection> <title> 4.2.3 Proposed Optimization </title> Load balance.", "There are various strategies for column grouping, such as round robin, hash-based, and range-bashed partition, yet these methods cannot guarantee exact load balance.", "We might suffer from the straggler problem if a worker contains far more key-value pairs than others.", "Therefore, we balance the workload on workers by averaging the total number of key-value pairs.", "In practice, the master collects the number of feature occurrences from global quantile sketches, then the problem becomes assigning the feature pairs to $ W $ groups so that the number of feature pairs in each group is as close as possible.", "This problem is obviously an NP-hard problem, we therefore use a greedy method to solve it [@bib:jiang2013predictive] .", "\\newline Blockify of column group.", "Although the network overhead is reduced by compression, the overhead of (de)serialization is probably large if we represent column groups with large amount of small vectors, since there are $ W $ times number of objects compared to the original dataset.", "To alleviate such overhead, we blockify the column groups before repartition, as shown in Figure [@ref:LABEL:fig:blocky] .", "Each block consists of three arrays, i.e., feature indexes, histogram bin indexes, and instance pointers.", "By default, the file split in Spark is 128MB, therefore, we can always put a partial column group into one block since the number of key-value pairs in one file split is far smaller than INT_MAX .", "We assign the index of file split to the $ W $ partial column groups.", "After repartition, each column group (the data sub-matrix of a worker) is comprised of several blocks, sorted by their file split indexes.", "\\newline Two-phase indexing and block merge.", "Since the data sub-matrix is now made up of a number of blocks, we adopt a two-phase index to access each instance.", "In initialization, the offset of instance (row) id of each block is recorded.", "Given an instance id, we first binary search the block that contains that instance, then the instance id inside the block is calculated by subtracting the offset of the block, finally we obtain the range of the instance by the instance pointers.", "Considering that the number of file splits can be very large, for instance, a 100GB dataset results in approximately 800 file splits, we merge the blocks when possible in order to reduce the data access time.", "In practice, the number of blocks after the merge operation is smaller than 5.", "Therefore, we can nearly omit the extra cost brought by two-phase indexing.", "\\newline </subsubsection> </subsection>  </section>"], ["<section> <title> 5 Evaluation </title>  In this section, we conduct experiments to empirically validate our analysis.", "We organize the experiments into two parts.", "In Section [@ref:LABEL:sec:quadrant_expr] , we implement different quadrants in the same code base and assess their performance over a range of synthetic datasets.", "In Section [@ref:LABEL:sec:end2end] , we compare Vero with other baselines over extensive public and synthetic datasets.", "For more experiments, including the efficiency of the horizontal-to-vertical transformation and scalability of Vero, please refer to the appendix of our technical report [@bib:1907.01882] .", "\\newline <subsection> <title> 5.1 Experimental Setup </title> Environment.", "We conduct the experiments on an 8-node laboratory cluster.", "Each machine is equipped with 32GB RAM, 4 cores and 1Gbps Ethernet.", "The maximum memory allowed for each run is limited to 30GB, and we use 4 threads to achieve parallel computation on each node.", "\\newline Hyper-parameters.", "In specific experiments, we vary some hyper-parameters to assess the change in performance.", "However, unless otherwise stated, we set $ T=100 $ (# trees), $ L=8 $ (# layers), and $ q=20 $ (# candidate splits).", "\\newline </subsection> <subsection> <title> 5.2 Assessment of Quadrants </title> In order to validate the analysis in Section [@ref:LABEL:sec:anatomy] , we evaluate the impact of partitioning scheme and storage pattern.", "For partitioning scheme, we compare Vero with QD2, in terms of communication and memory efficiency.", "For storage pattern, we compare Vero with QD3 in terms of computation efficiency.", "\\newline To achieve fair and thorough comparison, we implement two optimized baselines in QD2 and QD3 on top of Spark and compare them with Vero over a range of synthetic datasets, and report the mean and standard deviation of one tree.", "The synthetic datasets are generated from random linear regression models.", "Specifically, given dimensionality $ D $ , informative ratio $ p $ , and number of classes $ C $ , we first randomly initialize the weight matrix $ W $ with size $ D\\times C $ , and each row of $ W $ contains $ pD $ nonzero values.", "Then for each instance, the feature $ x $ is a randomly sampled $ D $ -dimensional vector with density $ \\phi $ , and its label $ y $ is determined by $ \\operatorname*{arg\\,max}x^{T}W $ .", "In our experiment, we set $ p=\\phi=20\\% $ .", "\\newline <subsubsection> <title> 5.2.1 Partitioning schemes </title> Impact of number of instances.", "We first assess the impact of number of instances $ N $ using low-dimensional datasets, and present the time cost per tree in Figure [@ref:LABEL:fig:dense_ins] .", "The computation time of QD2 and QD4 is close to each other since partitioning scheme does not have influence on computation, Nonetheless, the communication time varies.", "With $ D=100 $ , which is a fairly low dimensionality, the communication cost of QD2 is negligible since the size of gradient histograms is small.", "In contrast, QD4 takes nearly half of the training time on network transmission.", "Besides, when $ N $ grows larger, the communication cost of QD4 also becomes higher.", "This is because vertical partitioning has to broadcast the placement of instances after node splitting, which results in proportional network overhead w.r.t.", "$ N $ .", "Therefore, given a low-dimensional datasets containing a large amount of instances, horizontal partitioning is a properer choice.", "\\newline Impact of dimensionality.", "To assess the impact of feature dimensionality $ D $ , we train distributed GBDT over datasets with varying $ D $ , as shown in Figure [@ref:LABEL:fig:dimension] .", "The communication time of horizontal partitioning increases linearly w.r.t.", "$ D $ , since the histogram size grows linearly, while vertical partitioning gives almost the same communication time regardless of $ D $ .", "The result validates that vertical partitioning is more communication-efficient for the high-dimensional datasets.", "Theoretically speaking, the computation cost of QD2 and QD4 is similar, which matches the case when $ D=25K $ .", "However, when we use more features, the computation time of QD2 increases sharply while that of QD4 grows mildly.", "This is because when $ D $ gets higher, the histogram becomes larger and cannot fit in cache.", "Thus QD2 suffers from frequent cache miss, and therefore spends more time on histogram construction for larger $ D $ .", "QD4, instead, holds a much smaller histogram on each worker owing to vertical partitioning and has a slow-growth in computation time.", "\\newline Impact of tree depth.", "We then assess the impact of the number of tree layers by changing $ L $ .", "As shown in Figure [@ref:LABEL:fig:tree_depth] , when $ L $ increases from 8 to 9 and 10, the communication time of QD2 almost increases exponentially because the number of tree nodes becomes exponential.", "To the contrary, the communication time of QD4 increases linearly w.r.t $ L $ since the transmission on each layer remains the same.", "As for computation time, due to the histogram subtraction technique, the time to build histograms for a deep layer is very little.", "As a result, communication dominates when the decision tree goes deeper, and vertical partitioning reveals its superiority more for deep trees.", "\\newline Impact of multi-classes.", "We next assess the impact of the number of classes $ C $ in multi-classification tasks.", "The experiments are conducted on several synthetic datasets with different number of classes.", "Since QD2 encounters OOM (out-of-memory) error with $ D=100K $ and $ C=10 $ , we lower the dimensionality to 25K.", "The results are presented in Figure [@ref:LABEL:fig:multi-class] .", "The computation time of QD2 and QD4 shows similar increase when $ C $ increases from 3 to 5, and to 10.", "Nevertheless, the communication time of QD2 is approximately proportional to $ C $ , while that of QD4 remains unchanged.", "This validates our analysis that vertical partitioning is more suitable for multi-classification tasks than horizontal partitioning as it saves a lot of communication.", "\\newline Memory consumption.", "We record the memory consumption by monitoring the GC of JVM.", "As analyzed in Section [@ref:LABEL:sec:anatomy] , the vertical partitioning is more memory-efficient since each worker does not need to store the histograms of all features.", "Therefore, we breakdown the memory consumption into data and histogram.", "As shown in Figure [@ref:LABEL:fig:memory_dim] and Figure [@ref:LABEL:fig:memory_multi] , QD2 and QD4 incur similar memory cost to store dataset.", "QD4 allocates slightly more memory since it needs to store all instance labels.", "Nonetheless, the memory for histogram is much different.", "Compared to QD4, QD2 allocates approximately 6-8 $ \\times $ space to persist the histograms, showing that the memory cost of vertical partitioning can be alleviated given more workers.", "Moreover, in multi-classfication tasks, the memory consumption of histogram in QD2 dominates the overall memory cost, since the histogram size grows linearly against $ C $ while the size of dataset remains unchanged.", "QD4, to the contrary, is able to handle high-dimensional or multi-class datasets with limited memory resource.", "\\newline </subsubsection> <subsubsection> <title> 5.2.2 Storage patterns </title> Index plan.", "Since the column-wise node-to-instance index causes unacceptable overhead during update, we implement QD3 with a combination of node-to-instance and instance-to-node indexes.", "Specifically, when a column contains few number of values, we build histogram for it by linear scanning, otherwise, we perform binary search on the column.", "In the appendix of our technical report [@bib:1907.01882] , we compare our QD3 implementation with Yggdrasil to show that the combination of two indexes can achieve higher performance.", "\\newline Impact of dimensionality.", "We first study the performance on datasets with only a few instances but a high dimensionality.", "Although such datasets are seldom seen in practice, conducting the comparison helps make our assessment complete.", "The result is given in Figure [@ref:LABEL:fig:dim-storage] .", "Given a fixed $ N $ , the communication cost of QD3 and QD4 almost stays unchanged, due to the vertical partitioning they adopt.", "However, QD4 spends more time on computation than QD3 given a larger $ D $ .", "The reason is that QD3 stores the dataset column-by-column and constructs histograms one-by-one, thus it is more cache-friendly when writing on the histograms.", "While row-store constructs histograms for all features together, which will suffer from heavy cache miss when $ D $ is large.", "As a result, the experiment results match our analysis in Section [@ref:LABEL:sec:storage_pattern] that column-store performs better than row-store when the dataset is low-dimensional and meanwhile contains very few instances.", "\\newline Impact of number of instances.", "We then assess the impact of number of instances $ N $ .", "As shown in Figure [@ref:LABEL:fig:num_ins] , QD3 and QD4 have similar network time growing linearly against $ N $ , since both of them vertically partition the datasets and need to transmit the instance placement.", "The difference occurs in computation time.", "In general, QD3 spends 3-4 $ \\times $ on computation compared with QD4.", "Moreover, the computation time of QD3 oscillates heavily (high standard deviation of time per tree).", "This is because the binary searches on columns result in many CPU branch mispredictions.", "In contrast, when training with row-store, we iterate the feature vectors row-by-row, which escapes from heavy branch prediction penalty.", "In short, QD3 shares the same communication overhead of QD4, but QD3 is not as computation-efficient as QD4, owing to the column-store it adopts.", "\\newline </subsubsection> <subsubsection> <title> 5.2.3 Summary </title> The experiments above validate the analysis in Section [@ref:LABEL:sec:anatomy] , that (i) horizontal partitioning works better when dimensionality is low, while vertical partitioning is more memory- and communication-efficient under the high-dimensional, deep trees and multi-class cases; (ii) row-store is more efficient in computation than column-store except that the dataset is high-dimensional with few instances.", "In addition, we observe another two advantages of QD4 in practice, which are cache- and branch-friendly.", "As a result, the composition of vertical partitioning and row-store can achieve optimal performance under a wide range of workloads.", "\\newline </subsubsection> </subsection> <subsection> <title> 5.3 End-to-end Evaluation </title> Baselines.", "We choose three open source GBDT implementations as our baselines, which are XGBoost, LightGBM and DimBoost.", "XGBoost and LightGBM are favorite toolkits in data-analytic competitions, while DimBoost is optimized for large-scale GBDT workloads and is able to achieve the state-of-the-art performance.", "\\newline Datasets.", "We run Vero and the baselines on six public datasets and two synthetic datasets, as listed in Table [@ref:LABEL:tb:pub_dataset] .", "We categorize the datasets into low-dimensional dense (LD), high-dimensional sparse (HS), and multi-classification (MC) datasets, and discuss the overall performance of the systems on different kinds of datasets.", "All systems are tuned to achieve comparable accuracy.", "We present the convergence curve in Figure [@ref:LABEL:fig:pub_curve] and report the running time in Table [@ref:", "LABEL:tb:avg_time] .", "\\newline <paragraph> <title> Low-dimensional Dense Datasets </title> We first conduct end-to-end evaluation on four datasets with low dimensionality and fully dense data.", "We use five workers to run on these four datasets.", "Corresponding to the analysis in Section [@ref:LABEL:sec:anatomy] , low dimensionality results in small histogram size and hence the communication time of horizontal partitioning does not dominant.", "Therefore, LightGBM, which belongs to QD2, achieves the fastest speed in overall, since it is more computation-efficient than XGBoost (QD1) and communicates little compared to Vero (QD4).", "Vero suffers on extreme low-dimensional datasets, i.e., SUSY , Higgs , and Criteo , however, it catches up quickly and is comparable to LightGBM when the dimensionality gets higher, for instance the Epsilon dataset, which also matches our analysis.", "DimBoost (QD2) runs slower than XGBoost on three datasets, violating our analysis.", "The unsatisfactory performance of DimBoost is caused by two factors: 1) DimBoost is designed aiming at the high-dimensional case and always stores datasets as sparse matrices, which inevitably results in extra cost in data access and indexing; 2) DimBoost is implemented in Java, thus it is hard to achieve as good computation efficiency as the C++-based XGBoost and LightGBM.", "\\newline </paragraph> <paragraph> <title> High-dimensional Sparse Datasets </title> We then assess the systems on high-dimensional sparse datasets, RCV1 and Synthesis , with five and eight workers, respectively.", "In short, Vero runs the fastest, followed by DimBoost and LightGBM, while XGBoost is the slowest.", "XGBoost is about 18 $ \\times $ slower than Vero, due to the inefficiency in both computation and communication.", "The speedup of Vero w.r.t.", "DimBoost and LightGBM are 2-5.6 $ \\times $ .", "The relative performance of Vero on Synthesis is slower than RCV1 , since there is a large number of instances compared with the 330 thousand feature.", "However, it can still achieve the fastest speed, owing to the superiority of QD4 under high-dimensional cases.", "\\newline </paragraph> <paragraph> <title> Multi-classification Datasets </title> Finally we consider the performance on multi-classification datasets using eight workers.", "Since DimBoost does not support multi-classification, we do not discuss it in this experiment.", "XGBoost and LightGBM are 8.6 $ \\times $ and 7.4 $ \\times $ slower on the multi-class dataset RCV1-multi than the binary-class dataset RCV1 , due to the 53 $ \\times $ increment in network transmission.", "Vero, however, takes only 4 $ \\times $ more time on RCV1-mutli , since the network transmission of vertical partitioning does not increase w.r.t.", "the number of classes.", "Overall, Vero is 9.7 $ \\times $ and 34.7 $ \\times $ faster than LightGBM and XGBoost.", "The speedup of Vero on Synthesis-multi is smaller than Synthesis due to the lower dimensionality, however, Vero still outperforms XGBoost and LightGBM by 7.1 $ \\times $ and 3.3 $ \\times $ , respectively.", "The experiment results match our analysis that QD4 is more suitable for multi-classification tasks.", "\\newline </paragraph> <paragraph> <title> Summary </title> The end-to-end evaluation reveals that we should choose the proper system for a given workload.", "To summarize, LightGBM achieves the highest performance on low-dimensional datasets, while Vero is the best choice for high-dimensional or multi-classification datasets.", "\\newline </paragraph> </subsection>  </section>"], ["<section> <title> 6 Evaluation in the Real World </title>  ", "As aforementioned, Vero has been integrated into the production pipeline of Tencent.", "In this section, we present some use cases to validate the ability of Vero to handle large scale real-world workloads.", "\\newline Environment.", "The experiments are carried out on a productive cluster in Tencent.", "Each machine is equipped with 64GB RAM, 24 cores and 10Gbps Ethernet.", "Since the cluster is shared by other applications, the maximum resource for each Yarn container is restricted.", "Thus we use 20GB memory and 10 cores for each container.", "\\newline Datasets.", "We use three datasets in Tencent.", "All three datasets are used to train models to complete the user persona.", "Gender contains 122 million instances.", "Age classifies 48 million users into 9 age ranges.", "Both of them have 330 thousand features.", "Taste , with 10 million instances and 15 thousand features, describes the user taste with 100 tags.", "\\newline Hyper-parameters.", "We use 50 workers for Gender , 20 workers for Age and Taste .", "We set $ T=20 $ (# trees) and restrict the maximum running time to convergence as 1 hour.", "The other hyper-parameters are the same as in Section [@ref:LABEL:sec:eval] .", "\\newline Baselines.", "Prior to Vero, XGBoost and DimBoost are two candidates for GBDT in Tencent.", "As discussed in [@bib:jiang2018dimboost] , LightGBM is impractical for productive environments owing to the strict environment requirement and the lack of integration with the Hadoop ecosystem.", "Therefore, we choose XGBoost and DimBoost as our baselines in this section.", "\\newline <paragraph> <title> Gender dataset </title> We run the Gender dataset on all the three systems and present the results in Figure [@ref:LABEL:fig:industrial_curves] and Table [@ref:LABEL:tb:industrial_time] .", "Unfortunately, Vero spends 1.5 $ \\times $ to finish one tree compared with DimBoost.", "This is caused by two factors.", "First, the productive cluster has a 10 $ \\times $ higher network bandwidth compared to the laboratory cluster in Section [@ref:LABEL:sec:eval] , so the communication overhead is alleviated for DimBoost.", "Second, Gender contains an extreme large amount of instances, in which case horizontal partitioning can better distribute the workloads to workers.", "However, the time cost of Vero is comparable to that of DimBoost and can outperform XGBoost by 5.5 $ \\times $ , verifying that Vero can well support datasets with large number of instances and low dimensionality.", "\\newline </paragraph> <paragraph> <title> Age dataset </title> We next assess the performance of Vero and XGBoost on the large-scale multi-class dataset.", "Figure [@ref:LABEL:fig:industrial_curves] and Table [@ref:LABEL:tb:industrial_time] give the results.", "It takes 207 seconds for Vero to complete one tree, and it can get close to convergence within an hour.", "Nevertheless, XGBoost costs 1738 seconds for one tree, which is 8.3 $ \\times $ slower.", "In many real applications, the allowed time is usually restricted.", "For instance, daily recurring jobs need to commit within a reasonable period of time so that the jobs in downstream will not be affected.", "Obviously, XGBoost fails to converge within acceptable time on this dataset, whereas Vero can achieve better performance since it is more efficient in both communication and computation.", "\\newline </paragraph> <paragraph> <title> Taste dataset </title> Finally we conduct an experiment on a relatively small-scale multi-class dataset.", "As shown in Figure [@ref:LABEL:fig:industrial_curves] and Table [@ref:LABEL:tb:industrial_time] , Vero is 4.5 $ \\times $ faster than XGBoost.", "Although the feature dimensionality of Taste is low, Vero can still outperform XGBoost, showing that Vero is more suitable for the multi-classification tasks.", "\\newline </paragraph> <paragraph> <title> Summary </title> With the experimental results on three industrial datasets, we show that by careful investigation on the management of distributed datasets, we can achieve a better solution to solve a wide range of workloads.", "Currently Vero is designed for vertical partitioning and row-store, and is not able to achieve highest performance on all cases.", "How to determine an optimal dataset management strategy given the size of dataset (e.g., number of instances, feature dimensionality and number of classes) along with the application environment (e.g., network bandwidth, number of machines, number of cores) is remained unsolved.", "We believe this problem can bring insight to both the machine learning and database community and leave it as our future work.", "\\newline </paragraph>  </section>"], ["<section> <title> 7 Related Work </title>  A lot of works have implemented the algorithm, either in research interests or industrial needs.", "R-GBM and scikit-learn [@bib:ridgeway2007generalized,pedregosa2011scikit] are stand-alone packages so that they cannot handle large-scale datasets.", "MLlib [@bib:meng2016mllib,zhang2019mllib] is a machine learning package of Spark and implements GBDT.", "XGBoost [@bib:chen2016xgboost] achieves great success in various data analytics competitions, and is also widely-used in companies due to the distributed learning supported by DMLC.", "LightGBM [@bib:ke2017lightgbm] is developed in favor of data analytics.", "Although it supports parallel learning with MPI, LightGBM requires complex setup and is not a good fit for large scale workloads in commodity environment.", "Note that there is a feature-parallel version of LightGBM, which lets each worker process a feature subset like vertical partitioning does.", "However, it requires all workers to load the whole dataset into memory, i.e. dataset is never partitioned, which is impractical for large-scale workloads.", "In Appendix of our technical report [@bib:1907.01882] we conduct experiments on small datasets with the feature-parallel LightGBM and Vero.", "There is a surge of interests to introduce parameter-server architecture into industrial applications [@bib:jiang2017angel,zhou2017kunpeng,zhang2019ps2] .", "Notably, TencentBoost and PSMART [@bib:TencentBoost,zhou2017psmart] implement GBDT with parameter-server.", "DimBoost [@bib:jiang2018dimboost] further applies a series of optimization techniques and achieves the state-of-the-art performance.", "However, it only supports binary-classification.", "\\newline There exist many works discussing the impact on databases brought by data layout.", "Column-oriented databases [@bib:stonebraker2005c,abadi2006integrating] vertically partition the data and store them in columns and outperform row-oriented databases on database analytics workloads.", "[@bib:abadi2008column] discusses the performance difference in terms of row-store and column-store.", "There are also works that take advantages of both vertical partitioning and row representation [@bib:agrawal2004integrating,cui2010exploring] .", "Despite the extensive studies in database community, how does the way we manage the training datasets influence the performance of machine learning algorithms is few discussed.", "Yggdrasil [@bib:abuzaid2016yggdrasil] introduces vertical partitioning into the training of decision tree and showcases the reduction in network communication.", "Our work extends the analysis to both communication and memory overhead.", "In addition, Yggdrasil focuses on the case of deep decision tree.", "We further show that vertical partitioning combined with row-store benefits the high-dimensional and multi-classification cases.", "DimmWitted [@bib:zhang2014dimmwitted] analyzes the trade-off in access methods when training linear models under the NUMA architecture.", "However, instances are stored in row format without vertical partitioning in DimmWitted.", "In this work, we together discuss the data access and data index methods for both row-store and column-store data when training GBDT.", "\\newline The analysis in this work is applicable to many other tree-based algorithms beyond GBDT, such as AdaBoost, random forest, and gcForest [@bib:freund1997decision,breiman2001random,zhou2017deep] .", "However, there are also algorithms that our analysis fails to support.", "For instance, neural decision forest [@bib:rota2014neural,kontschieder2015deep] utilizes neural networks (randomized multi-layer perceptron or fully-connected layers concatenated with a deep convolutional network) as splitting criteria.", "There is a big difference between this algorithm and vanilla decision trees.", "To discuss the impact on performance brought by data management methods, we need thorough investigation on deep neural network training, such as the anatomy of data parallelism and model parallelism.", "Moreover, the qualitative study on how hardware environment influences the performance is remained undone.", "We leave these as future works and do not discuss them in this work.", "\\newline  </section>"], ["<section> <title> 8 Conclusion </title>  In this paper, we systematically study the data management methods in distributed GBDT."]], "target": "Specifically, we propose the four-quadrant categorization along partitioning scheme and storage pattern, analyze their pros and cons, and summarized their advantageous scenarios in Table . Based on the findings, we further propose Vero, a distributed GBDT implementation that partitions the dataset vertically and stores data in row manner. Empirical results on extensive datasets validate our analysis and provide suggestive guidelines on choosing a proper platform for a given workload."}, {"tabular": ["    &  No Supervision  &  Full Supervision  &  Weak Supervision ", " Dataset  &  Real  &  CycleGAN  &  BiGAN  &  Disc-CGAN  &  Cont-CGAN  &  DFI  &  PC-GAN ", " CACD  &  94.37( train) 49.00(val)  &  20.52  &  19.66  &  46.02  &  41.62  &  20.92  &  48.44 ", " UTK  &  98.19( train) 76.80(val)  &  19.46  &  20.50  &  71.44  &  59.16  &  22.90  &  63.88 ", " SCUT-FBP  &  100.00( train) 58.00(val)  &  19.75  &  20.38  &  29.63  &  46.25  &  22.69  &  40.00 ", " Average Rank  &  \u2013  &  5.67  &  5.33  &  2.00  &  2.33  &  4.00  &  1.67  "], "ref_sec": [["<section> <title> Introduction </title>  Generative adversarial networks (GAN) [@bib:goodfellow2014generative] have shown great success in producing high-quality realistic imagery by training a set of networks to generate images of a target distribution via an adversarial setting between a generator and a discriminator.", "New architectures have also been developed for adversarial learning such as conditional GAN (CGAN) [@bib:mirza2014conditional,odena2016conditional,han2018learning] which feeds a class or an attribute label for a model to learn to generate images conditioned on that label.", "The superior performance of CGAN makes it favorable for many problems in artificial intelligence (AI) such as image attribute editing.", "\\newline However, this task faces a major challenge from the lack of massive labeled images with varying attributes.", "Many recent works attempt to alleviate such problems using semi-supervised or unsupervised conditional image synthesis [@bib:lucic2019high] .", "These methods mainly focus on conditioning the model on categorical pseudo-labels using self-supervised image feature clustering.", "However, attributes are often continuous-valued, for example, the stroke thickness of MNIST digits.", "In such cases, applying unsupervised clustering would be difficult since features are most likely to be grouped by salient attributes (like identities) rather than any other attributes of interest.", "In this work, to disentangle the target attribute from the rest, we focus on learning from weak supervisions in the form of pairwise comparisons.", "\\newline Pairwise comparisons.", "Collecting human preferences on pairs of alternatives, rather than evaluating absolute individual intensities, is intuitively appealing, and more importantly, supported by evidence from cognitive psychology [@bib:furnkranz2010preference] .", "As pointed out by \\citeauthor yanpassive \\shortcite yanpassive, we consider relative attribute annotation because they are (1) easier to obtain than total orders, (2) more accurate than absolute attribute intensities, and (3) more reliable in application like crowd-sourcing.", "For example, it would be hard for an annotator to accurately quantify the attractiveness of a person\u2019s look, but much easier to decide which one is preferred given two candidates.", "Moreover, attributes in images are often subjective.", "Different annotators have different criteria in their mind, which leads to noisy annotations [@bib:xu2019deep] .", "\\newline Thus, instead of assigning an absolute attribute value to an image, we allow the model to learn to rank and assign a relative order between two images [@bib:yanpassive,furnkranz2010preference] .", "This method alleviates the aforementioned problem of lacking continuously valued annotations by learning to rank using pairwise comparisons.", "\\newline Weakly supervised GANs.", "Our main idea is to substitute the full supervision with the attribute ratings learned from weak supervisions, as illustrated in Figure [@ref:LABEL:fig:first] .", "To do so, we draw inspiration from the Elo rating system [@bib:elo1978rating] and design a Bayesian Siamese network to learn a rating function with uncertainty estimations.", "Then, for image synthesis, motivated by [@bib:thekumparampil2018robustness] we use \u201ccorrupted\u201d labels for adversarial training.", "The proposed framework can (1) learn from pairwise comparisons, (2) estimate the uncertainty of predicted attribute ratings, and (3) offer quantitative controls in the presence of a small portion of absolute annotations.", "Our contributions can be summarized as follows.", "\\newline <list> \\ We propose a weakly supervised generative adversarial network, PC-GAN, from pairwise comparisons for image attribute manipulation.", "To the best of our knowledge, this is the first GAN framework considering relative attribute orders.", "\\newline \\ \\ We use a novel attribute rating network motivated from the Elo rating system, which models the latent score underlying each item and tracks the uncertainty of the predicted ratings.", "\\newline \\ \\ We extend the robust conditional GAN to continuous-value setting, and show that the performance can be boosted by incorporating the predicted uncertainties from the rating network.", "\\newline \\ \\ We analyze the sample complexity which shows that this weakly supervised approach can save annotation effort.", "Experimental results show that PC-GAN is competitive with fully-supervised models, while surpassing unsupervised methods by a large margin.", "\\newline \\ </list> \\newline  </section>"], ["<section> <title> Related Work </title>  Learning to rank.", "Our work focuses on finding \u201cscores\u201d for each item (e.g. player\u2019s rating) in addition to obtaining a ranking.", "The popular Bradley-Terry-Luce (BTL) model postulates a set of latent scores underlying all items, and the Elo system corresponds to the logistic variant of the BTL model.", "Numerous algorithms have been proposed since then.", "To name a few, TrueSkill [@bib:herbrich2007trueskill] considers a generalized Elo system in the Bayesian view.", "Rank Centrality [@bib:negahban2016rank] builds on spectral ranking and interprets the scores as the stationary probability under the random walk over comparison graphs.", "However, these methods are not designed for amortized inference, i.e. the model should be able to score (or extrapolate) an unseen item for which no comparisons are given.", "Apart from TrueSkill and Rank Centrality, the most relevant work is the RankNet [@bib:burges2005learning] .", "Despite being amortized, RankNet is homoscedastic and falls short of a principled justification as well as providing uncertainty estimations.", "\\newline Weakly supervised learning.", "Weakly-supervised learning focuses on learning from coarse annotations.", "It is useful because acquiring annotations can be very costly.", "A close weakly supervised setting to our problem is [@bib:xiao2015discovering] which learns the spatial extent of relative attributes using pairwise comparisons and gives an attribute intensity estimation.", "However, most facial attributes like attractiveness and age are not localized features thus cannot be exploited by local regions.", "In contrast, our work uses this relative attribute intensity for attribute transfer and manipulation.", "\\newline Uncertainty.", "There are two uncertainty measures one can model: aleatoric uncertainty and epistemic uncertainty.", "The epistemic uncertainty captures the variance of model predictions caused by lack of sufficient data; the aleatoric uncertainty represents the inherent noise underlying the data [@bib:kendall2017uncertainties] .", "In this work, we leverage Bayesian neural networks [@bib:gal2016dropout] as a powerful tool to model uncertainties in the Elo rating network.", "\\newline Robust conditional GAN (RCGAN).", "Conditioning on the estimated ratings, a normal conditional generative model can be vulnerable under bad estimations.", "To this end, recent research introduces noise robustness to GANs.", "\\citeauthor bora2018ambientgan \\shortcite bora2018ambientgan apply a differentiable corruption to the output of the generator before feeding it into the discriminator.", "Similarly, RCGAN [@bib:thekumparampil2018robustness] proposes to corrupt the categorical label for conditional GANs and provides theoretical guarantees.", "Both methods have shown great denoising performance when noisy observations are present.", "To address our problem, we extend RCGAN to the continuous-value setting and incorporate uncertainties to guide the image generation.", "\\newline Image attribute editing.", "There are many recent GAN-style architectures focusing on image attribute editing.", "IPCGAN [@bib:wang2018face] proposes an identity preserving loss for facial attribute editing.", "\\citeauthor CycleGAN2017 \\shortcite CycleGAN2017 propose cycle consistency loss that can learn the unpaired translation between image and attribute.", "BiGAN/ALI [@bib:donahue2016adversarial,dumoulin2016adversarially] learns an inverse mapping between image-and-attribute pairs.", "\\newline There exists another line of research that is not GAN-based.", "Deep feature interpolation (DFI) [@bib:upchurch2017deep] relies on linear interpolation of deep convolutional features.", "It is also weakly-supervised in the sense that it requires two domains of images (e.g. young or old) with inexact annotations [@bib:zhou2017brief] .", "DFI demonstrates high-fidelity results on facial style transfer.", "While, the generated pixels look unnatural when the desired attribute intensity takes extreme values, we also find that DFI cannot control the attribute intensity quantitatively.", "\\citeauthor wang2018weakly \\shortcite wang2018weakly considers a binary setting and sets qualitatively the intensity of the attribute.", "Unlike prior research, our method uses weak supervision in the form of pairwise comparisons and leverages uncertainty together with noise-tolerant adversarial learning to yield a robust performance in image attribute editing.", "\\newline  </section>"], ["<section> <title> Pairwise Comparison GAN </title>  In this section, we introduce the proposed method for pairwise weakly-supervised visual attribute editing.", "Denote an image collection as $ I=\\{x_{1},\\cdots,x_{n}\\} $ and $ x_{i} $ \u2019s underlying absolute attribute values as $ \\Omega\\left(x_{i}\\right) $ .", "Given a set of pairwise comparisons $ C $ (e.g., $ {\\Omega\\left(x_{i}\\right)>\\Omega\\left(x_{j}\\right)} $ or $ {\\Omega\\left(x_{i}\\right)=\\Omega\\left(x_{j}\\right)} $ , where $ i,j\\in\\{1,\\cdots,n\\} $ ), our goal is to generate a realistic image quantitatively with a different desired attribute intensity, for example, from 20 years old to 50 years old.", "The proposed framework consists of an Elo rating network followed by a noise-robust conditional GAN.", "\\newline <subsection> <title> Attribute Rating Network </title> The designed attribute rating module is motivated by the Elo rating system [@bib:elo1978rating] , which is widely used to evaluate the relative levels of skills between players in zero-sum games.", "Elo rating from a player is represented as a scalar value which is adjusted based on the outcome of games.", "We apply this idea to image attribute editing by considering each image as a player and comparison pairs as games with outcomes.", "Then we learn a rating function.", "\\newline Elo rating system.", "The Elo system assumes the performance of each player is normally distributed.", "For example, if Player A has a rating of $ y_{A} $ and Player B has a rating of $ y_{B} $ , the probability of Player A winning the game against Player B can be predicted by $ P_{A}=\\frac{1}{1+10^{(y_{B}-y_{A})/400}} $ .", "We use $ S_{A} $ to denote the actual score that Player A obtains after the game, which can be valued as $ S_{A}(\\texttt{win})=1,S_{A}(\\texttt{tie})=0.5,S_{A}(\\texttt{lose})=0.", "$ After each game, the player\u2019s rating is updated according to the difference between the prediction $ P_{A} $ and the actual score $ S_{A} $ by $ y_{A}^{\\prime}=y_{A}+K(S_{A}-P_{A}) $ , where $ K $ is a constant.", "\\newline Image pair rating prediction network.", "Given an image pair $ (x_{A},x_{B}) $ and a certain attribute $ \\Omega $ , we propose to use a neural network for predicting the relative attribute relationship between $ \\Omega(x_{A}) $ and $ \\Omega(x_{B}) $ .", "This design allows amortized inference, that is, the rating prediction network can provide ratings for both seen and unseen data.", "The model structure is illustrated in Figure [@ref:LABEL:fig:elo_arch] .", "\\newline The network contains two input branches fed with $ x_{A} $ and $ x_{B} $ .", "For each image $ x $ , we propose to learn its rating value $ y_{x} $ by an encoder network $ \\mathcal{E}(x) $ .", "Assuming the rating value of $ x $ follows a normal distribution, that is $ y_{x}\\sim\\mathcal{N}\\left(\\mu(x),\\sigma^{2}(x)\\right) $ , we employ the reparameterization trick [@bib:kingma2013auto] , $ y_{x}=\\mu(x)+\\epsilon\\sigma(x) $ (where $ \\epsilon\\sim\\mathcal{N}(0,I) $ ).", "After obtaining each image\u2019s latent rating $ y_{A} $ and $ y_{B} $ , we formulate the pair-wise attribute comparison prediction as $ P_{A,y}(\\Omega(x_{A})>\\Omega(x_{B})|x_{A},x_{B},y_{A},y_{B})=\\text{sigm}(y_{A}% -y_{B}) $ where sigm is the sigmoid function.", "Then, the predictive probability of $ x_{A} $ winning $ x_{B} $ is obtained by integrating out the latent variables $ y_{A} $ and $ y_{B} $ , \\newline <equationgroup> <equation> $  P_{A}(\\Omega(x_{A})>\\Omega(x_{B})|x_{A},x_{B})=\\int{\\text{sigm}(% y_{A}-y_{B})dy_{A}dy_{B}}, $ $  P_{A}(\\Omega(x_{A})>\\Omega(x_{B})|x_{A},x_{B})=\\int{\\text{sigm}(% y_{A}-y_{B})dy_{A}dy_{B}}, $ </equation> </equationgroup> and $ P_{B}=1-P_{A} $ .", "The above integration is intractable, and can be approximated by Monte Carlo, $ P_{A}\\approx P_{A}^{MC}=\\frac{1}{M}\\sum_{m=1}^{M}{P_{A,y}} $ .", "We denote the ground-truth of $ P_{A} $ and $ P_{B} $ as $ S_{A} $ and $ S_{B} $ .", "The ranking loss $ \\mathcal{L}_{rank} $ can be formulated with a logistic-type function, that is \\newline <equationgroup> <equation> $ \\mathcal{L}_{rank}^{MC}=-\\mathbb{E}_{x_{A},x_{B}\\sim C}{\\left[S_{% A}\\log P_{A}^{MC}+S_{B}\\log P_{B}^{MC}\\right]}. $ $ \\mathcal{L}_{rank}^{MC}=-\\mathbb{E}_{x_{A},x_{B}\\sim C}{\\left[S_{% A}\\log P_{A}^{MC}+S_{B}\\log P_{B}^{MC}\\right]}. $ </equation> </equationgroup> Noticing that $ \\mathcal{L}_{rank}^{MC} $ is biased, an alternative unbiased upper bound can be derived as \\newline <equationgroup> <equation> $ \\mathcal{L}_{rank}^{UB}=-\\mathbb{E}_{x_{A},x_{B}\\sim C}{\\left[% \\frac{1}{M}\\sum_{m=1}^{M}{S_{A}\\log P_{A,y}+S_{B}\\log P_{B,y}}\\right]}. $ $ \\mathcal{L}_{rank}^{UB}=-\\mathbb{E}_{x_{A},x_{B}\\sim C}{\\left[% \\frac{1}{M}\\sum_{m=1}^{M}{S_{A}\\log P_{A,y}+S_{B}\\log P_{B,y}}\\right]}. $ </equation> </equationgroup> In practice, we find that $ \\mathcal{L}_{rank}^{UB} $ performs slightly better than $ \\mathcal{L}_{rank}^{MC} $ .", "\\newline We further consider a Bayesian variant of $ \\mathcal{E} $ .", "The Bayesian neural network is shown to be able to provide the epistemic uncertainty of the model by estimating the posterior over network weights in network parameter training [@bib:kendall2017uncertainties] .", "Specifically, let $ q_{\\theta}(w) $ be an approximation of the true posterior $ p(w|\\text{data}) $ where $ \\theta $ denotes the parameter of $ q $ , we measure the difference between $ q_{\\theta}(w) $ and $ p(w|\\text{data}) $ with the KL-divergence.", "The overall learning objective is the negative evidence lower bound (ELBO) [@bib:kingma2013auto,gal2016dropout] , \\newline <equationgroup> <equation> $ \\mathcal{L}_{\\mathcal{E}}=\\mathcal{L}_{rank}+\\underbrace{\\text{D}% _{KL}(q_{\\theta}(w)\\|p(w|\\text{data}))}_{{KL}}. $ $ \\mathcal{L}_{\\mathcal{E}}=\\mathcal{L}_{rank}+\\underbrace{\\text{D}% _{KL}(q_{\\theta}(w)\\|p(w|\\text{data}))}_{{KL}}. $ </equation> </equationgroup> \\citeauthor gal2016dropout \\shortcite gal2016dropout propose to view dropout together with weight decay as a Bayesian approximation, where sampling from $ q_{\\theta} $ is equivalent to performing dropout and the KL term in Equation [@ref:LABEL:eq:elbo] becomes $ L_{2} $ regularization (or weight decay) on $ \\theta $ .", "\\newline The predictive uncertainty of rating $ y $ for image $ x $ can be approximated using: \\newline <equationgroup> <equation> $ \\hat{\\sigma}^{2}(y)\\approx\\frac{1}{T}\\sum_{t=1}^{T}{\\mu_{t}^{2}}-% (\\frac{1}{T}\\sum_{t=1}^{T}{\\mu_{t}})^{2}+\\frac{1}{T}\\sum_{t=1}^{T}{\\sigma_{t}^% {2}} $ $ \\hat{\\sigma}^{2}(y)\\approx\\frac{1}{T}\\sum_{t=1}^{T}{\\mu_{t}^{2}}-% (\\frac{1}{T}\\sum_{t=1}^{T}{\\mu_{t}})^{2}+\\frac{1}{T}\\sum_{t=1}^{T}{\\sigma_{t}^% {2}} $ </equation> </equationgroup> with $ \\{\\mu_{t},\\sigma_{t}\\}_{t=1}^{T} $ a set of $ T $ sampled outputs: $ \\mu_{t},\\sigma_{t}=\\mathcal{E}(x) $ .", "\\newline Transitivity.", "Notice that the transitivity does not hold because of the stochasticity in $ y $ .", "If we fix $ \\sigma(\\cdot) $ to be zero and a non-Bayesian version is used, the Elo rating network becomes a RankNet [@bib:burges2005learning] , and transitivity holds.", "However, one can still maintain transitivity by avoiding reparameterization and modeling $ P_{A}=\\text{sigm}(\\frac{\\mu(x_{A})-\\mu(x_{B})}{\\sqrt{\\sigma^{2}(x_{A})+\\sigma^% {2}(x_{B})}}) $ .", "In practice, we find that reparameterization works better.", "\\newline </subsection> <subsection> <title> Conditional GAN with Noisy Information </title> We construct a CGAN-based framework for image synthesis conditioned on the learned attribute rating.", "The overall training procedure is shown in Figure [@ref:LABEL:fig:gan_overview] : given a pair of images $ x $ and $ x^{\\prime} $ , the generator $ \\mathcal{G} $ is trained to transform $ x $ into $ \\tilde{x}^{\\prime}=\\mathcal{G}(x,y^{\\prime}) $ , such that $ \\tilde{x}^{\\prime} $ possesses the same rating $ y^{\\prime}=\\mathcal{E}(x^{\\prime}) $ as $ x^{\\prime} $ .", "The predicted ratings can still be noisy, thus a robust conditional GAN is considered.", "While RCGAN [@bib:thekumparampil2018robustness] is conditioned on discrete categorical labels that are \u201ccorrupted\u201d by a confusion matrix, our model relies on the ratings that are continuous-valued and realizes the \u201ccorruption\u201d via resampling.", "\\newline Adversarial loss.", "Given image $ x $ , the corresponding rating $ y $ can be obtained from a forward pass of the pre-trained encoder $ \\mathcal{E} $ .", "Thus $ \\mathcal{E} $ defines a joint distribution $ p_{\\mathcal{E}}(x,y)=p_{data}(x)p_{\\mathcal{E}}(y|x) $ .", "Importantly, the output $ \\tilde{x}^{\\prime} $ of $ \\mathcal{G} $ is paired with a corrupted rating $ \\tilde{y}^{\\prime}=\\mathcal{T}(y^{\\prime}) $ , where $ \\mathcal{T} $ is a sampling process $ \\tilde{y}^{\\prime}\\sim\\mathcal{N}(y^{\\prime},\\hat{\\sigma}^{\\prime 2}) $ .", "The adversarial loss is \\newline <equationgroup> <equation> $ \\mathcal{L}_{CGAN}=\\mathbb{E}_{x,y\\sim p(x,y)}{\\log(\\mathcal{D}(x% ,y))}\\quad+ $ $ \\mathcal{L}_{CGAN}= $ $ \\mathbb{E}_{x,y\\sim p(x,y)}{\\log(\\mathcal{D}(x,y))}\\quad+ $ </equation> <equation> $ \\mathbb{E}_{x\\sim p(x),y^{\\prime}\\sim p(y^{\\prime}),\\tilde{y}^{% \\prime}\\sim\\mathcal{T}(y^{\\prime})}{\\log(1-\\mathcal{D}(\\mathcal{G}(x,y^{\\prime% }),\\tilde{y}^{\\prime}))}. $ $ \\mathbb{E}_{x\\sim p(x),y^{\\prime}\\sim p(y^{\\prime}),\\tilde{y}^{% \\prime}\\sim\\mathcal{T}(y^{\\prime})}{\\log(1-\\mathcal{D}(\\mathcal{G}(x,y^{\\prime% }),\\tilde{y}^{\\prime}))}. $ </equation> </equationgroup> \\newline The discriminator $ \\mathcal{D} $ is discriminating between real data $ (x,y) $ and generated data $ (\\mathcal{G}(x,y^{\\prime}),\\mathcal{T}(y^{\\prime})) $ .", "At the same time, $ \\mathcal{G} $ is trained to fool $ \\mathcal{D} $ by producing images that are both realistic and consistent with the given attribute rating.", "As such, the Bayesian variant of the encoder is required for considering robust conditional adversarial training.", "\\newline Mutual information maximization.", "Besides conditioning the discriminator, to further encourage the generative process to be consistent with ratings and thus learn a disentangled representation [@bib:chen2016infogan] , we add a reconstruction loss on the predictive ratings: \\newline <equationgroup> <equation> $ \\mathcal{L}_{rec}^{y}=\\mathbb{E}_{x\\sim p(x),y^{\\prime}\\sim p(y^{% \\prime})}{\\frac{1}{2\\hat{\\sigma}^{\\prime 2}}\\|\\mathcal{E}(\\mathcal{G}(x,y^{% \\prime}))-y^{\\prime}\\|^{2}_{2}+\\frac{1}{2}\\log{\\hat{\\sigma}^{\\prime 2}}}. $ $ \\mathcal{L}_{rec}^{y}=\\mathbb{E}_{x\\sim p(x),y^{\\prime}\\sim p(y^{% \\prime})}{\\frac{1}{2\\hat{\\sigma}^{\\prime 2}}\\|\\mathcal{E}(\\mathcal{G}(x,y^{% \\prime}))-y^{\\prime}\\|^{2}_{2}+\\frac{1}{2}\\log{\\hat{\\sigma}^{\\prime 2}}}. $ </equation> </equationgroup> The above reconstruction loss can be viewed as the conditional entropy between $ y^{\\prime} $ and $ \\mathcal{G}(x,y^{\\prime}) $ , \\newline <equationgroup> <equation> $ \\mathcal{L}_{rec}^{y}\\propto-\\mathbb{E}_{y^{\\prime}\\sim p(y^{% \\prime}),\\tilde{x}^{\\prime}\\sim\\mathcal{G}(x,y^{\\prime})}{\\left[\\log{p(y^{% \\prime}|\\tilde{x}^{\\prime})}\\right]} $ $ \\mathcal{L}_{rec}^{y} $ $ \\propto-\\mathbb{E}_{y^{\\prime}\\sim p(y^{\\prime}),\\tilde{x}^{% \\prime}\\sim\\mathcal{G}(x,y^{\\prime})}{\\left[\\log{p(y^{\\prime}|\\tilde{x}^{% \\prime})}\\right]} $ </equation> <equation> $ =-\\mathbb{E}_{y^{\\prime}\\sim p(y^{\\prime}),\\tilde{x}^{\\prime}\\sim% \\mathcal{G}(x,y^{\\prime})}{\\left[\\mathbb{E}_{y\\sim(y|\\tilde{x}^{\\prime})}{% \\left[\\log{(y|\\tilde{x}^{\\prime})}\\right]}\\right]} $ $ =-\\mathbb{E}_{y^{\\prime}\\sim p(y^{\\prime}),\\tilde{x}^{\\prime}\\sim% \\mathcal{G}(x,y^{\\prime})}{\\left[\\mathbb{E}_{y\\sim(y|\\tilde{x}^{\\prime})}{% \\left[\\log{(y|\\tilde{x}^{\\prime})}\\right]}\\right]} $ </equation> <equation> $ =\\text{H}(y^{\\prime}|\\mathcal{G}(x,y^{\\prime})).", "$ $ =\\text{H}(y^{\\prime}|\\mathcal{G}(x,y^{\\prime})).", "$ </equation> </equationgroup> Thus, minimizing the reconstruction loss is equivalent to maximizing the mutual information between the conditioned rating and the output image.", "\\newline <equationgroup> <equation> $ \\operatorname*{arg\\,min}_{\\mathcal{G}}{\\mathcal{L}_{rec}^{y}}=% \\operatorname*{arg\\,max}_{\\mathcal{G}}{-\\text{H}(y^{\\prime}|\\mathcal{G}(x,y^{% \\prime}))} $ $ \\operatorname*{arg\\,min}_{\\mathcal{G}}{\\mathcal{L}_{rec}^{y}} $ $ =\\operatorname*{arg\\,max}_{\\mathcal{G}}{-\\text{H}(y^{\\prime}|% \\mathcal{G}(x,y^{\\prime}))} $ </equation> <equation> $ =\\operatorname*{arg\\,max}_{\\mathcal{G}}{-\\text{H}(y^{\\prime}|% \\mathcal{G}(x,y^{\\prime}))+\\text{H}(y^{\\prime})} $ $ =\\operatorname*{arg\\,max}_{\\mathcal{G}}{-\\text{H}(y^{\\prime}|% \\mathcal{G}(x,y^{\\prime}))+\\text{H}(y^{\\prime})} $ </equation> <equation> $ =\\operatorname*{arg\\,max}_{\\mathcal{G}}{\\text{I}(y^{\\prime};% \\mathcal{G}(x,y^{\\prime}))}. $ $ =\\operatorname*{arg\\,max}_{\\mathcal{G}}{\\text{I}(y^{\\prime};% \\mathcal{G}(x,y^{\\prime}))}. $ </equation> </equationgroup> \\newline The cycle consistency constraint forces the image $ \\mathcal{G}(\\tilde{x}^{\\prime},y) $ to be close to the original $ x $ , and therefore helps preserve the identity information.", "Following the same logic, the cycle loss can be also viewed as maximizing the mutual information between $ x $ and $ \\mathcal{G}(x,y^{\\prime}) $ .", "\\newline Full objective.", "Finally, the full objective can be written as: \\newline <equationgroup> <equation> $ \\mathcal{L}(\\mathcal{G},\\mathcal{D})=\\mathcal{L}_{CGAN}+\\lambda_{% rec}\\mathcal{L}_{rec}^{y}+\\lambda_{cyc}\\mathcal{L}_{cyc}, $ $ \\mathcal{L}(\\mathcal{G},\\mathcal{D})=\\mathcal{L}_{CGAN}+\\lambda_{% rec}\\mathcal{L}_{rec}^{y}+\\lambda_{cyc}\\mathcal{L}_{cyc}, $ </equation> </equationgroup> where $ \\lambda $ s control the relative importance of corresponding losses.", "The final objective formulates a minimax problem where we aim to solve: \\newline <equationgroup> <equation> $ \\mathcal{G}^{*}=\\arg\\min_{\\mathcal{G}}{\\max_{\\mathcal{D}}{% \\mathcal{L}(\\mathcal{G},\\mathcal{D})}}. $ $ \\mathcal{G}^{*}=\\arg\\min_{\\mathcal{G}}{\\max_{\\mathcal{D}}{% \\mathcal{L}(\\mathcal{G},\\mathcal{D})}}. $ </equation> </equationgroup> \\newline Analysis of loss functions.", "\\citeauthor goodfellow2014generative \\shortcite goodfellow2014generative show that the adversarial training results in minimizing the Jensen-Shannon divergence between the true conditional and the generated conditional.", "Here, the approximated conditional will converge to the distribution characterized by the encoder $ \\mathcal{E} $ .", "If $ \\mathcal{E} $ is optimal, the approximated conditional will converge to the true conditional, we defer the proof in Supplementary.", "\\newline GAN training.", "In practice, we find that the conditional generative model trains better if equal-pairs (pairs with approximately equal attribute intensities) are filtered out and only different-pairs (pairs with clearly different intensities) are remained.", "Comparisons of training CGAN with or without equal-pairs can be found in Supplementary.", "\\newline </subsection> <subsection> <title> Pair Sampling </title> Active learning strategies such as OHEM [@bib:shrivastava2016training] can be incorporated in our Elo rating network.", "In hard example mining, only pairs with small rating differences are queried ( hard+diff/all in Table [@ref:LABEL:tab:online] ).", "In addition, to maximize the number of different-pairs we also try easy example mining ( easy+diff/all in Table [@ref:LABEL:tab:online] ).", "As shown, easy examples are inferior to hard examples in terms of both rating correlations and image qualities.", "The reason might be that easy example mining chooses pairs with drastic differences in attribute intensity, which makes the model hard to train.", "Hard examples help to learn a better rating function, however, provide less amount of different-pairs for the generative model to capture attribute transitions.", "We therefore augment hard examples with pseudo-pairs (easy examples but with predicted labels, listed as hard+pseudo-diff/all in Table [@ref:LABEL:tab:online] ).", "The augmentation strategy works well, but in following experiments we use randomly sampled pairs because (1) the random strategy is simple and performs equally well, and (2) pseudo-labels are less reliable than queried labels.", "\\newline Number of pairs.", "Suppose there are $ n $ images in the dataset, then the possible number of pairs is upper bounded by $ n(n-1)/2 $ .", "However, if $ \\mathcal{O}(n^{2}) $ pairs are necessary, there is no benefit of choosing pairwise comparisons over absolute label annotation.", "Using results from [@bib:radinsky2011ranking,wauthier2013efficient] , the following proposition shows that only $ \\mathcal{O}(n) $ comparisons are needed to recover an approximate ranking.", "\\newline <theorem> Proposition 0.1 .", "For a constant $ d $ and any $ 0<\\lambda<1 $ , if we measure $ dn/\\lambda^{2} $ comparisons chosen uniformly with repetition, the Elo rating network will output a permutation $ \\hat{\\pi} $ of expected risk at most $ (2/\\lambda)(n(n-1)/2) $ .", "\\newline </theorem> We also provide an empirical study in the Supplementary that supports the above proposition.", "\\newline </subsection>  </section>"], ["<section> <title> Experiments </title>  In this section, we first present a motivating experiment on MNIST.", "Then we evaluate the PC-GAN in two parts: (1) learning attribute ratings, and (2) conditional image synthesis, both qualitatively and quantitatively.", "\\newline Dataset.", "We evaluate PC-GAN on a variety of datasets for image attribute editing tasks: \\newline <list> \\ Annotated MNIST [@bib:kim2017mnist] provides annotations of stroke thickness for MNIST [@bib:lecun1998gradient] dataset.", "\\newline \\ \\ CACD [@bib:chen2014cross] is a large dataset collected for cross-age face recognition, which includes 2,000 subjects and 163,446 images.", "It contains multiple images for each person which cover different ages.", "\\newline \\ \\ UTKFace [@bib:zhifei2017cvpr] is also a large-scale face dataset with a long age span, ranging from 0 to 116 years.", "This dataset contains 23,709 facial images with annotations of age, gender, and ethnicity.", "\\newline \\ \\ SCUT-FBP [@bib:xie2015scut] is specifically designed for facial beauty perception.", "It contains 500 Asian female portraits with attractiveness ratings (1 to 5) labeled by 75 human raters.", "\\newline \\ \\ CelebA [@bib:liu2015faceattributes] is a standard large-scale dataset for facial attribute editing.", "It consists of over 200k images, annotated with 40 binary attributes.", "\\newline \\ </list> For the MNIST experiment, stroke thickness is the desired attribute.", "As illustrated in Figure [@ref:LABEL:fig:mnist] -a, the thickness information is still entangled. But in Figure [@ref:LABEL:fig:mnist] -b, the thickness is correctly disentangled from the rest attributes.", "\\newline We use CACD and UTK for age progression, SCUT-FBP and CelebA for attractiveness experiment.", "Since no true relatively labeled dataset is publically available, pairs are simulated from \u201cground-truth\u201d attribute intensity given in the dataset.", "The tie margins within which two candidates are considered equal are 10, 10, and 0.4 for CACD, UTK, and SCUT-FBP, respectively.", "This also simplifies the quantitative evaluation process since one can directly measure the prediction error for absolute attribute intensities.", "Notice that CelebA only provides binary annotations, from which pairwise comparisons are simulated.", "Interestingly, the Elo rating network is still able to recover approximate ratings from those binary labels.", "\\newline Furthermore, since CACD, UTKFace, SCUT-FBP, and CelebA are all human face dataset, we add an identity preserving loss term [@bib:wang2018face] to enforce identity preservation: $ \\mathcal{L}_{idt}=\\mathbb{E}_{x\\sim p(x),y\\sim p(y)}{\\|h(\\mathcal{G}(x,y))-h(x% )\\|^{2}_{2}} $ .", "Here, $ h(\\cdot) $ denotes a pre-trained convnet.", "\\newline Implementation.", "PC-GAN is implemented using PyTorch [@bib:paszke2017automatic] .", "Network architectures and training details are given in Supplementary.", "For a fair evaluation, the basic modules are kept identical across all baselines.", "\\newline <subsection> <title> Learning by Pairwise Comparison </title> Rating visualization.", "Figure [@ref:LABEL:fig:emb_vis] presents the predicted ratings learned from CACD, UTKFace, and SCUT-FBP from left to right.", "The ratings learned from pairwise comparisons highly correlate with the ground-truth labels, which indicates that the rating resembles the attribute intensity well.", "The uncertainties v.s. ground-truth labels is visualized in Figure [@ref:LABEL:fig:emb_std] .", "The plots show a general trend that the model is more certain about instances with extreme attribute values than those in the middle range, which matches our intuition.", "Additional attention-based visualizations are given in Supplementary.", "\\newline Noise resistance.", "As mentioned previously, not only does pairwise comparison require less annotating effort, it tends to yield more accurate annotations.", "Consider a simple setting: if all annotators (annotating the absolute attribute value) exhibit the same random noise with a tie margin $ M $ , then the corresponding pairwise annotation with the same tie margin would absorb the noise.", "We provide an empirical study of the noise resistance of pairwise comparisons in Supplementary.", "\\newline </subsection> <subsection> <title> Conditional Image Synthesis </title> Baselines.", "We consider two unsupervised baselines CycleGAN and BiGAN, two fully-supervised baselines Disc-CGAN and Cont-CGAN, and DFI in a similar weakly-supervised setting.", "\\newline <list> \\ CycleGAN [@bib:CycleGAN2017] learns an encoder (or a \u201cgenerator\u201d from images to attributes) and a generator between images and attributes simultaneously.", "\\newline \\ \\ ALI/BiGAN [@bib:donahue2016adversarial,dumoulin2016adversarially] learns the encoder (an inverse mapping) with a single discriminator.", "\\newline \\ \\ Disc-CGAN/IPCGAN [@bib:wang2018face] takes discretized attribute intensities (one-hot embedding) as supervision.", "\\newline \\ \\ Cont-CGAN uses the same CGAN framework as PC-GAN but ratings are replaced by true labels.", "It is an upper bound of PC-GAN.", "\\newline \\ \\ DFI [@bib:upchurch2017deep] can control the intensity of attribute intensity continuously, however, cannot change the intensity quantitatively.", "To transform $ x $ into $ \\tilde{x}^{\\prime} $ , we assume $ \\phi({\\tilde{x}^{\\prime}})=\\phi({x})+\\alpha{w} $ and compute $ y^{\\prime}={w}\\cdot\\phi({x^{\\prime}}) $ ( $ w $ is the attribute vector), then $ \\alpha $ is given by $ \\alpha=({y^{\\prime}-{w}\\cdot\\phi({x})})/{\\left\\lVert{w}\\right\\rVert_{2}^{2}} $ .", "\\newline \\ </list> \\newline Qualitative results.", "In Figure [@ref:LABEL:fig:baselines] , we compare our results with all baselines.", "For each row, we take a source and a target image as inputs and our goal is to edit the attribute value of the source image to be equal to that of the target image.", "PC-GAN is competitive with fully-supervised baselines while all unsupervised methods fail to change attribute intensities.", "\\newline More results are shown in Figure [@ref:LABEL:fig:results_cacd] , [@ref:LABEL:fig:results_scut] , [@ref:LABEL:fig:results_utkface] , where the target rating value is the average of (cluster mean) a batch of (10 to 50) labeled images.", "From Figure [@ref:LABEL:fig:results_cacd] , we see aging characteristics like receding hairlines and wrinkles are well learned.", "Figure [@ref:LABEL:fig:results_utkface] shows convincing indications of rejuvenation and age progression.", "Figure [@ref:LABEL:fig:results_scut] shows results for SCUT-FBP, which is inherently challenging because of the size of the dataset.", "Compared to datasets such as CACD, SCUT-FBP is significantly smaller, with only 500 images in total (from which we take 400 for training).", "Training on large datasets, as the CelebA experiment in Figure [@ref:LABEL:fig:results_celeba] shows, our model produces convincing results.", "We also find that the model is capable of learning important patterns that correspond to attractiveness, such as in the hairstyle and the shape of the cheek shown in Figure [@ref:LABEL:fig:results_scut] .", "(The result does not represent the authors\u2019 opinion of attractiveness, but only reflects the statistics of the annotations.)", "\\newline Quantitative results.", "For quantitative evaluations, we report in Table [@ref:LABEL:tab:baseline_acc] classification accuracy (Acc) evaluated on synthesized images.", "In our experiments, we train classifiers to predict attribute intensities of images into discrete groups (CACD $ 11-20 $ , $ 21-30 $ , up to $ >50 $ ; UTK $ 1-20 $ , $ 21-40 $ , up to $ >80 $ , SCUT-FBP $ 1-1.75 $ , $ 1.75-2.5 $ , up to $ >4 $ ).", "PC-GAN demonstrates comparable performance with fully-supervised baselines and are significantly better than unsupervised methods.", "Additional metrics are reported in the Supplementary.", "\\newline AMT user studies.", "We also conduct user study experiments.", "Workers from Amazon Mechanical Turk (AMT) are asked to rate the quality of each face (good or bad) and vote to which age group a given image belongs.", "Then we calculate the percentage of images rated as good and the classification accuracy.", "Table [@ref:LABEL:tab:user] shows that PC-GAN is on a par with the fully-supervised counterparts.", "We conduct hypothesis testing of PC-GAN and Disc-CGAN for image quality rating, $ p-\\text{value}=0.31 $ , which indicates they are not statistically different with $ 95\\% $ confidence level.", "\\newline </subsection> <subsection> <title> Ablation Studies </title> Supervision."]], "target": "First, the comparisons in Table serve as an ablation study of full, no, and weak supervision, where PC-GAN is on a par with fully-supervised and significantly better than unsupervised baselines."}, {"tabular": ["    &  $ N_{f} $  &  MAE  &  MAE _(c)  &  MAE _(p)  &  MAE _(w)  &  Acc  &  F1 _(c)  &  F1 _(p)  &  F1 _(w) ", " Intensity  &  50  &  $ 1.09\\pm 1.88 $  &  $ 0.77\\pm 0.68 $  &  $ 1.49\\pm 1.26 $  &  $ 6.20\\pm 5.68 $  &  $ 90.3 $  &  $ 95.1 $  &  $ 35.7 $  &  $ 83.6 $ ", " Registration  &  108  &  $ 1.32\\pm 2.35 $  &  $ 0.90\\pm 1.04 $  &  $ 2.10\\pm 2.71 $  &  $ 7.76\\pm 6.01 $  &  $ 90.0 $  &  $ 95.1 $  &  $ 31.5 $  &  $ 78.4 $ ", " Combined  &  158  &  $ 1.07\\pm 1.86 $  &  $ 0.76\\pm 0.65 $  &  $ 1.47\\pm 1.22 $  &  $ 6.12\\pm 5.64 $  &  $ 90.7 $  &  $ 95.4 $  &  $ 38.1 $  &  $ 84.4 $ ", " Combined-no pooling  &  8  &  $ 1.24\\pm 2.22 $  &  $ 0.85\\pm 0.73 $  &  $ 1.72\\pm 1.64 $  &  $ 7.39\\pm 6.62 $  &  $ 89.4 $  &  $ 94.8 $  &  $ 32.6 $  &  $ 79.1 $ ", " Combined+MD  &  178  &  $ 1.07\\pm 1.83 $  &  $ 0.76\\pm 0.65 $  &  $ 1.46\\pm 1.20 $  &  $ 5.95\\pm 5.59 $  &  $ 90.7 $  &  $ 95.4 $  &  $ 38.3 $  &  $ 84.5 $ ", " Combined (LR)  &  158  &  $ 1.86\\pm 2.03 $  &  $ 1.58\\pm 1.34 $  &  $ 2.47\\pm 2.21 $  &  $ 6.12\\pm 4.97 $  &  $ 77.3 $  &  $ 87.3 $  &  $ 17.0 $  &  $ 67.6 $ ", " Combined (NN)  &  158  &  $ 1.13\\pm 2.07 $  &  $ 0.74\\pm 0.70 $  &  $ 1.81\\pm 1.67 $  &  $ 7.08\\pm 5.88 $  &  $ 89.8 $  &  $ 95.0 $  &  $ 31.2 $  &  $ 79.6 $  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Image registration is the task of finding the optimal spatial transformation between two or more images.", "In most registration methods, no assessment of the registration quality is provided, and simply the result is returned.", "Evaluation of the registration is devolved to human experts, which is very time-consuming and prone to inter-observer errors as well as human fatigue [@bib:murphy2011evaluation] .", "Automatic quantitative error prediction of registration would decrease quality assessment time and can provide information about the registration uncertainty.", "Many medical pipelines are based on registered images and it is important to know the uncertainty of registration before continuing to a next phase in order to prevent accumulation of errors.", "For example, in online adaptive radiotherapy daily contouring of the tumor and organs-at-risk can be performed with the help of image registration [@bib:thornqvist2010propagation] .", "In this task, quality assessment (QA) is mandatory to ensure patient safety.", "In addition, the accumulation of delivered dose over several treatment fractions is also impacted by the quality of registration [@bib:murphy2012method,tilly2013dose,veiga2015toward] .", "Registration quality therefore has to be checked before the treatment starts.", "Visualizing the error of registration can also be directly helpful in medical applications before making a clinical decision.", "[@bib:smit2017pelvis] localized autonomic pelvic nerves by registering a pre-operative MRI scan to an atlas model that includes nerve information.", "These nerves are not visible in the MRI scans and are prone to be damaged during a surgical procedure.", "Utilizing registration uncertainty yield better visualization of the autonomic nerves.", "\\newline Refinement of registration is another important application of automatic error prediction.", "[@bib:muenzing2014dirboost] improved registration by focusing only on regions with high registration error and discarding pixels which are aligned correctly.", "Registration refinement can also be done with the feedback of human experts by manually adding several corresponding landmarks [@bib:gunay2017semi] .", "\\newline [@bib:schlachter2016visualization] did a comprehensive study on visualization of registration quality with the help of three radiation oncologists on the DIR-Lab-COPDgene data, which has a slice thickness of 2.5 mm.", "The [average, maximum] TRE of the landmarks that were rated to be of acceptable registration quality with the conventional visualization method (checkerboard visualization and color blended) was [2.3, 6.9] mm, while with the best visualization method (histogram intersection) [1.8, 3.3] mm was achieved.", "\\newline A few methods have been proposed to detect the misalignment of a pair of images with the purpose to refine the registration result.", "[@bib:rohde2003adaptive] proposed to use the gradient of the cost function to detect which region in the image pair is poorly registered and potentially can be improved.", "[@bib:schnabel2001generic] suggested to refine the registration by increasing the number of registration parameters in regions with high local entropy, or with high local variation in the intensity or with relatively steep cost function.", "In another work, analyzing the shape of the cost function around each voxel was used to estimate the confidence of registration [@bib:saygili2016confidence] .", "[@bib:park2004adaptive] used normalized local mutual information to find poorly aligned regions in order to increase the number of registration parameters.", "[@bib:forsberg2011improving] utilized the outer product of the intensity gradient as an uncertainty measure in multi-channel diffeomorphic Demons registration.", "Although the mentioned metrics can be used to improve the image registration, it has not been shown how these metrics are correlated with the image registration error.", "\\newline Several methods exploit continuous probabilistic image registration by utilizing Bayesian inference to achieve an intrinsic transformation uncertainty measure [@bib:risholm2013bayesian,simpson2015probabilistic] .", "However, it has been shown that there is no clear statistical correlation between transformation uncertainty and registration uncertainty [@bib:luo2017misdirected] .", "The transformation and corresponding label (of a pair of images) are two random variables and it is not possible to quantify the uncertainty of the corresponding label by the summary statistics of the transformation.", "Another downside of these methods is that they can only be used for the specific paradigm of Bayesian registration.", "\\newline Some methods are based on the consistency of multiple registrations between a group of images [@bib:datteri2012automatic,gass2015consistency] , but these methods cannot be used in pairwise registrations.", "\\newline In the stochastic approaches, [@bib:kybic2010bootstrap] suggested to perform multiple registrations with random sampling of pixels with replacement.", "He found a correlation between the true registration error and the variation of the 2D translational parameters.", "The method was not extended to 3D and to nonrigid registration.", "[@bib:hub2009stochastic] calculated the local mean square intensity difference multiple times by perturbing the B-spline grid.", "They showed that the maximum change of the dissimilarity metric in a local region is correlated with the registration error in that region.", "The drawback of this method is that it is not efficient in homogeneous areas [@bib:hub2013estimation] .", "In a related work they showed that the variance of the final deformation vector field (DVF) is related to the registration error [@bib:hub2013estimation] , using the Demons algorithm.", "However, to find large misalignment a large search region is needed.", "\\newline In this paper, we turn our attention to methods capable of {learning} the registration error allowing to take advantage of multiple features related to registration uncertainty within a single framework.", "[@bib:muenzing2012supervised] casted the registration assessment task to a classification problem with three categories (wrong, poor and correct registrations).", "In their method, they mostly utilize intensity-based features, except for the determinant of the Jacobian of the transformation.", "Although their training samples consist of manually selected landmarks, later they showed that assessing registration in all regions is possible by interpolation [@bib:muenzing2014dirboost] .", "\\newline In our paper, instead of casting the uncertainty estimation task to a classification problem, we formulate it as a regression problem.", "To the best of our knowledge, in the field of continuous prediction of 3D registration error, [@bib:lotfi2013improving] only tested their method on artificially deformed images.", "Recently [@bib:eppenhof2017supervised] estimated the registration error by utilizing convolutional neural networks.", "Only preliminary results were available for synthetic 3D data.", "\\newline We explore several features related to the uncertainty of the registration transformation as well as related to intensity.", "All features are calculated in physical units, i.e. mm, which makes the system independent of voxel size.", "Finally, features are combined by using regression forests.", "The proposed method is applied and evaluated on chest CT scans.", "This work is an extension of [@bib:sokooti2016accuracy] with updated methodology and substantially extended evaluation.", "\\newline  </section>"], ["<section> <title> 2 Methods </title>  <subsection> <title> 2.1 System overview </title> A block diagram of the proposed algorithm is shown in Fig. [@ref:LABEL:fig:BD] .", "The system has two inputs: a fixed image $ I_{F} $ and a moving image $ I_{M} $ .", "Several registration-based and intensity-based features are generated.", "A regression forests (RF) is then trained from all features to estimate the registration error.", "\\newline The proposed system is trained to predict residual distances $ y $ (registration errors) obtained from a set of semi-automatically established corresponding landmarks.", "During evaluation, the prediction result $ \\hat{y} $ is compared with errors obtained from an independent set of ground truth landmarks, using cross-validation.", "The proposed system therefore estimates registration errors in physical units, i.e. mm.", "More information about the ground truth is available in Section [@ref:LABEL:title:Materials] .", "Details of the features are elaborated in Section [@ref:LABEL:hd:Features] .", "\\newline </subsection> <subsection> <title> 2.2 Registration </title> Registration can be formulated as an optimization problem in which the cost function $ \\mathcal{C} $ is minimized with respect to $ \\bm{T} $ : \\newline <equationgroup> <equation> $ \\widehat{\\bm{T}}=\\text{arg}\\,\\underset{\\bm{T}}{\\text{min}}\\,% \\mathcal{C}\\big{(}\\bm{T};I_{F},I_{M}\\big{)}, $ $ \\widehat{\\bm{T}}=\\text{arg}\\,\\underset{\\bm{T}}{\\text{min}}\\,% \\mathcal{C}\\big{(}\\bm{T};I_{F},I_{M}\\big{)}, $ </equation> </equationgroup> where $ \\bm{T} $ denotes the transformation.", "The optimization is usually solved by an iterative method embedded in a multi-resolution setting.", "A registration can be initialized by an initial transform $ \\bm{T}^{\\mathrm{ini}} $ .", "\\newline </subsection> <subsection> <title> 2.3 Features and pooling </title> The features we used in our system, consist of several registration-based as well as intensity-based features.", "Some features are intrinsically capable to be calculated over differently sized local boxes, for others, a pool of features is created by computing local averages and maxima afterwards.", "The features used in this paper are listed in Table [@ref:LABEL:tb:Features] .", "We propose the following features: \\newline <subsubsection> <title> 2.3.1 Registration-based features </title> Variation of deformation vector field ( $ \\operatorname{\\mathrm{std}}{\\bm{T}} $ ): The final solution of an iterative optimization problem can be influenced by the initial parameters.", "If in a region the cost function has multiple local minima or is semi-flat, a slight change in the initial parameters can lead to a different solution.", "In contrast, in areas where the cost function is well-defined, variations in the initial state are expected to have much less effect on the final solution.", "A flow chart of the described feature is available in Fig. [@ref:LABEL:fig:StdCVH] .", "Given $ P $ random initial transformations $ \\bm{T}^{\\mathrm{ini}}_{i} $ , $ i\\in\\{1,\\ldots,P\\}, $ that are used as initializations of the registration algorithm from Eq. ( [@ref:LABEL:eq:reg] ), the variation in the final transformation results $ \\widehat{\\bm{T}}_{i} $ is a surrogate for the precision of the registration.", "We propose to use the standard deviation $ \\operatorname{\\mathrm{std}}{\\bm{T}} $ of those final transformations as a feature: \\newline <equationgroup> <equation> $ \\overline{\\bm{T}}=\\tfrac{1}{P}\\sum\\widehat{\\bm{T}}_{i}, $ $ \\overline{\\bm{T}} $ $ =\\tfrac{1}{P}\\sum\\widehat{\\bm{T}}_{i}, $ </equation> <equation> $ \\operatorname{\\mathrm{std}}{\\bm{T}}=\\sqrt{\\tfrac{1}{P-1}\\sum{\\|% \\widehat{\\bm{T}}_{i}-\\overline{\\bm{T}}\\|}^{2}}. $ $ \\operatorname{\\mathrm{std}}{\\bm{T}} $ $ =\\sqrt{\\tfrac{1}{P-1}\\sum{\\|\\widehat{\\bm{T}}_{i}-\\overline{\\bm{T}% }\\|}^{2}}. $ </equation> </equationgroup> In this work, the initial transformations $ \\bm{T}^{\\mathrm{ini}}_{i} $ are created by uniformly distributed offsets in the range $ [-2,2]\\, $ mm to all B-spline coefficients.", "The offset range is chosen to be relatively small in comparison to the B-spline grid spacing in order to avoid unrealistic deformation.", "An example of $ \\operatorname{\\mathrm{std}}{\\bm{T}} $ in a synthetically deformed image is given in Fig. [@ref:LABEL:fig:STD_Visual] .", "\\newline Instead of perturbing the initial state of the registration, it is also possible to first perform the registration without any manipulated initial state, resulting in a transformation $ \\bm{T}^{\\mathrm{b}} $ [@bib:klein2009adaptive] .", "Then, random offsets $ \\bm{T}^{\\mathrm{offset}}_{i} $ are added to $ \\bm{T}^{\\mathrm{b}} $ after which another registration is performed, resulting in $ \\widehat{\\bm{T}_{i}^{\\mathrm{L}}} $ .", "This is close to the work of [@bib:hub2013estimation] , and approximately measures the concavity of the cost function.", "The feature $ \\operatorname{\\mathrm{std}}{\\bm{T}^{\\mathrm{L}}} $ is then derived akin to Eq. ( [@ref:LABEL:eq:std] ): \\newline <equationgroup> <equation> $ \\overline{\\bm{T}^{\\mathrm{L}}}=\\tfrac{1}{P}\\sum\\widehat{\\bm{T}_{i% }^{\\mathrm{L}}}, $ $ \\overline{\\bm{T}^{\\mathrm{L}}} $ $ =\\tfrac{1}{P}\\sum\\widehat{\\bm{T}_{i}^{\\mathrm{L}}}, $ </equation> <equation> $ \\operatorname{\\mathrm{std}}{\\bm{T}^{\\mathrm{L}}}=\\sqrt{\\tfrac{1}{% P-1}\\sum{\\|\\widehat{\\bm{T}_{i}^{\\mathrm{L}}}-\\overline{\\bm{T}^{\\mathrm{L}}}\\|}% ^{2}}. $ $ \\operatorname{\\mathrm{std}}{\\bm{T}^{\\mathrm{L}}} $ $ =\\sqrt{\\tfrac{1}{P-1}\\sum{\\|\\widehat{\\bm{T}_{i}^{\\mathrm{L}}}-% \\overline{\\bm{T}^{\\mathrm{L}}}\\|}^{2}}. $ </equation> </equationgroup> It is expected that $ \\operatorname{\\mathrm{std}}{\\bm{T}^{\\mathrm{L}}} $ is small in regions where the cost function is concave, as by adding small offsets $ \\bm{T}^{\\mathrm{offset}}_{i} $ to the parameters, it can still move back to the previous optimal point.", "A flow chart of $ \\operatorname{\\mathrm{std}}{\\bm{T}^{\\mathrm{L}}} $ is shown in Fig [@ref:LABEL:fig:stdL] .", "$ \\operatorname{\\mathrm{std}}{\\bm{T}^{\\mathrm{L}}} $ is calculated using the same setting as $ \\operatorname{\\mathrm{std}}{\\bm{T}} $ , except that only one resolution is used.", "\\newline If the difference between $ \\overline{\\bm{T}} $ and $ \\bm{T}^{\\mathrm{b}} $ is relatively large, regions indicating a small $ \\operatorname{\\mathrm{std}}{\\bm{T}} $ are still potentially regions of low registration quality.", "We then consider the bias $ \\mathcal{E}(\\bm{T}) $ and $ \\mathcal{E}(\\bm{T}^{\\mathrm{L}}) $ as complementary features to $ \\operatorname{\\mathrm{std}}{\\bm{T}} $ and $ \\operatorname{\\mathrm{std}}{\\bm{T}^{\\mathrm{L}}} $ computed by: \\newline <equationgroup> <equation> $ \\mathcal{E}(\\bm{T})=\\|\\bm{T}^{\\mathrm{b}}-\\overline{\\bm{T}}\\|, $ $ \\mathcal{E}(\\bm{T}) $ $ =\\|\\bm{T}^{\\mathrm{b}}-\\overline{\\bm{T}}\\|, $ </equation> <equation> $ \\mathcal{E}(\\bm{T}^{\\mathrm{L}})=\\|\\bm{T}^{\\mathrm{b}}-\\overline{% \\bm{T}^{\\mathrm{L}}}\\|.", "$ $ \\mathcal{E}(\\bm{T}^{\\mathrm{L}}) $ $ =\\|\\bm{T}^{\\mathrm{b}}-\\overline{\\bm{T}^{\\mathrm{L}}}\\|.", "$ </equation> </equationgroup> \\newline Coefficient of variation of joint histograms (CVH) : Multiple registration results can be used to extract additional information from the matched intensity patterns of the images.", "Given a fixed image $ I_{F} $ and a registration sub-result $ I_{M}(\\bm{T}_{i}) $ , we calculate their joint histogram $ \\mathrm{H}_{i},\\forall i $ .", "For identical sub-registrations, all resulting joint histograms are equal.", "Variation in the joint histograms implies registration uncertainty as a surrogate for registration error.", "The coefficient of variation of the joint histograms is calculated by dividing the standard deviation of all joint histograms over the average, $ \\overline{\\mathrm{H}} $ , of them.", "This normalization is done to compensate for large differences between the elements of $ \\overline{\\mathrm{H}} $ .", "We obtain the CVH in histogram space as follows: \\newline <equationgroup> <equation> $ \\mathrm{CVH^{B\\times B}}=\\frac{\\operatorname{\\mathrm{std}}\\mathrm% {H}}{\\overline{\\mathrm{H}}+\\epsilon}, $ $ \\mathrm{CVH^{B\\times B}} $ $ =\\frac{\\operatorname{\\mathrm{std}}\\mathrm{H}}{\\overline{\\mathrm{H% }}+\\epsilon}, $ </equation> </equationgroup> where B is the number of histogram bins, and $ \\epsilon $ a constant to avoid division by zero.", "In the experiments we set $ \\epsilon $ to 5.", "The CVH $ ^{\\mathrm{B}\\times\\mathrm{B}} $ in histogram space is subsequently transferred to the spatial domain, by assigning voxels $ x $ with a particular intensity combination $ \\big{(}I_{F}(x),I_{M}(\\bm{T}^{\\mathrm{b}}(x))\\big{)} $ the corresponding value from CVH $ ^{\\mathrm{B}\\times\\mathrm{B}} $ , resulting in the final CVH feature with size equal to the fixed image.", "Note that the CVH can be used in a multi-modality setting, like the previous features.", "An example of the CVH on a synthetically deformed image is given in Fig. [@ref:LABEL:fig:CVH_Visual] .", "\\newline Determinant of the Jacobian (Jac) : Jac measures the relative local volume change.", "This can point to poor registration quality in case of very large ( $ \\mathrm{Jac}\\gg 1 $ ) or very small ( $ \\mathrm{Jac}\\ll 1 $ ) values, or discontinuous transformations in case of a negative value ( $ \\mathrm{Jac}<0 $ ).", "In the experiments, the determinant of the Jacobian of $ \\bm{T}^{\\mathrm{b}} $ is used.", "\\newline </subsubsection> <subsubsection> <title> 2.3.2 Intensity-based features </title> MIND : The Modality Independent Neighborhood Descriptor (MIND) was introduced by [@bib:heinrich2012mind] in order to register multi-modal images.", "In this local self-similarity metric, a patch is considered to compare intensities between fixed and moving images.", "Finally, the sum of absolute differences between the MIND vector of $ I_{F} $ and that of $ I_{M}(\\bm{T}^{\\mathrm{b}}) $ is computed.", "We calculate MIND with a sparse patch including 82 voxels inside a $ [7\\times 7\\times 3] $ box, which is approximately physically isotropic for the data used in the experiments (see Fig. [@ref:LABEL:fig:MIND3D] ).", "\\newline Local normalized mutual information : Mutual information is used as an entropy-based similarity measure of two images.", "Similar to [@bib:muenzing2012supervised] we use the following definitions for local normalized mutual information: \\newline <equationgroup> <equation> $ \\mathrm{NMI}=\\frac{H(I_{F})+H(I_{M}(\\bm{T}^{\\mathrm{b}}))}{H\\Big{% (}I_{F},(I_{M}(\\bm{T}^{\\mathrm{b}})\\Big{)}}, $ $ \\mathrm{NMI} $ $ =\\frac{H(I_{F})+H(I_{M}(\\bm{T}^{\\mathrm{b}}))}{H\\Big{(}I_{F},(I_{% M}(\\bm{T}^{\\mathrm{b}})\\Big{)}}, $ </equation> <equation> $ \\mathrm{PMI}=\\frac{MI\\Big{(}I_{F},I_{M}(\\bm{T}^{\\mathrm{b}})\\Big{% )}}{min\\Big{\\H(I_{F}),H(I_{M}(\\bm{T}^{\\mathrm{b}}))\\Big{\\}}}. $ $ \\mathrm{PMI} $ $ =\\frac{MI\\Big{(}I_{F},I_{M}(\\bm{T}^{\\mathrm{b}})\\Big{)}}{min\\Big{% \\H(I_{F}),H(I_{M}(\\bm{T}^{\\mathrm{b}}))\\Big{\\}}}. $ </equation> </equationgroup> Both metrics are calculated over 8 differently sized boxes: [5, 10, 15, 20, 25, 30, 35, 40] mm.", "Two strategies for the selection of the number of bins are used, one uses a constant value $ \\mathrm{B_{C}} $ , the other strategy depends on the number of samples $ \\mathrm{|B|}=log_{2}(n)+1 $ , in which $ n $ is the number of samples in each box.", "The notations $ \\mathrm{NMIS} $ and $ \\mathrm{PMIS} $ indicate mutual information calculated with the latter strategy.", "\\newline Modality-dependent features: In addition to the modality-independent features from above, we consider the use of several modality-dependent features.", "In the experiments we assess their contributed value.", "Similar to [@bib:muenzing2012supervised] the squared intensity difference (SID) and the gradient of intensity difference (GID) are computed using Gaussian (derivative) operators with standard deviations of [0.5, 1, 2, 4, 8, 16] mm.", "Normalized correlation (NC) is calculated within boxes of size [5, 10, 15, 20, 25, 30, 35, 40] mm akin to [@bib:muenzing2012supervised] .", "\\newline </subsubsection> <subsubsection> <title> 2.3.3 Pooling </title> In order to reduce discontinuities and improve interaction with other features, the total set of features is increased by generating a pool from those mother features by calculating averages and maxima over them using differently sized boxes.", "The features MI, SID, GID and NC are inherently computed over differently sized local regions.", "The features $ \\mathrm{MIND} $ , $ \\operatorname{\\mathrm{std}}\\bm{T} $ , $ \\operatorname{\\mathrm{std}}\\bm{T}^{\\mathrm{L}} $ , CVH, $ \\mathcal{E}(\\bm{T}) $ , $ \\mathcal{E}(\\bm{T}^{\\mathrm{L}}) $ and Jac are calculated in a voxel-based fashion, and then pooled afterwards.", "Average and maximum pooling is performed with box sizes of $ [2,5,10,15,20,25,30,35,40] $ mm.", "As a result, for each feature we obtain a pool of 18 features: 9 from box averages and 9 from box maxima.", "The average-pooling is done efficiently by the help of integral images introduced by [@bib:viola2004robust] .", "A list of the proposed mother features together with the number of derived features $ N_{f} $ are given in Table [@ref:LABEL:tb:Features] .", "\\newline </subsubsection> </subsection> <subsection> <title> 2.4 Regression forests </title> Random forests were introduced by [@bib:breiman2001random] by extending the idea of bagging.", "The forests consist of several weak learners (trees) which are combined in an efficient fashion.", "Each tree is started from a node and continues splitting until reaching certain criteria.", "In contrast to bagging, splitting is performed with a random subset of features which makes the training phase faster and reduces correlation between trees, consequently decreasing the forest error rate.", "The reason that we chose the random forest is that it can handle data without preprocessing.", "For instance rescaling of data, outlier removal and selection of features are not necessary in random forests.", "In addition, random forest are efficient to train and fast at runtime.", "\\newline Random forests have the capability to calculate the importance of each feature with a little additional computation, which shows the contribution of each feature to the forest.", "Training of each tree is based on a bootstrap of all samples, and the so-called out-of-bootstrap samples $ \\Omega $ are used to compute the importance of a feature $ x_{i} $ .", "Importance is then defined as the difference between the mean square error (MSE) before and after a permutation of this feature: \\newline <equationgroup> <equation> $ \\mathrm{Imp}(x_{i})=\\frac{1}{N_{t}}\\sum_{t=1}^{N_{t}}\\bigg{(}% \\underset{j\\in\\Omega}{\\mathrm{MSE}}\\Big{(}\\hat{y}_{\\pi_{i}j},y_{j}\\Big{)}-% \\underset{j\\in\\Omega}{\\mathrm{MSE}}\\Big{(}\\hat{y_{j}},y_{j}\\Big{)}\\bigg{)}, $ $ \\mathrm{Imp}(x_{i})=\\frac{1}{N_{t}}\\sum_{t=1}^{N_{t}}\\bigg{(}% \\underset{j\\in\\Omega}{\\mathrm{MSE}}\\Big{(}\\hat{y}_{\\pi_{i}j},y_{j}\\Big{)}-% \\underset{j\\in\\Omega}{\\mathrm{MSE}}\\Big{(}\\hat{y_{j}},y_{j}\\Big{)}\\bigg{)}, $ </equation> </equationgroup> where $ y_{j} $ is the real value, $ \\hat{y_{j}} $ the predicted value from the regression, $ \\hat{y}_{\\pi_{i}j} $ the predicted value when permuting feature $ i $ , and $ N_{t} $ the number of trees.", "\\newline In this work, random forests are trained with different combinations of the proposed features (see Table [@ref:", "LABEL:tb:Features] ).", "The dependent variable $ y $ is the registration error in mm, which is described in Section [@ref:LABEL:title:Materials] .", "\\newline </subsection>  </section>"], ["<section> <title> 3 Experiments and results </title>  <subsection> <title> 3.1 Materials and ground truth </title> The SPREAD [@bib:stolk2007progression] DIR-Lab-4DCT [@bib:castillo2009framework] and DIR-Lab-COPDgene [@bib:castillo2013reference] databases have been used in this study.", "In the SPREAD study, there are 21 pairs of 3D follow-up lung CT images.", "Each patient in this database has a baseline and a follow-up image (which is taken after 30 months) both in inhale phase.", "The age of the patients ranges from 49 to 78 years old.", "The average size of the images is $ 446\\times 315\\times 129 $ with an average voxel size of $ 0.78\\times 0.78\\times 2.50 $ mm.", "In each pair of images, about 100 well-distributed corresponding landmarks were previously selected [@bib:staring2014towards] semi-automatically on distinctive locations [@bib:murphy2011semi] .", "\\newline From the DIR-Lab-4DCT data, five cases (4DCT1 to 4DCT5) are selected with each five phases between maximum inhalation and exhalation.", "The average image size is $ 256\\times 256\\times 103 $ with an average voxel size of $ 1.10\\times 1.10\\times 2.50 $ mm.", "Each scan has 75 corresponding landmarks annotated.", "Ten cases with severe breathing disorders are available via the DIR-Lab-COPDgene database.", "The images are taken in inhale and exhale phases.", "In total, 300 landmarks are annotated.", "The average image size and the average voxel size are $ 512\\times 512\\times 120 $ and $ 0.64\\times 0.64\\times 2.50 $ mm, respectively.", "\\newline Accuracy of the registration can be defined as the residual Euclidean distance after registration between the corresponding landmarks: \\newline <equationgroup> <equation> $  y=\\|\\bm{T}^{\\mathrm{b}}(\\bm{x}_{F})-\\bm{x}_{M}\\|_{2}, $ $  y=\\|\\bm{T}^{\\mathrm{b}}(\\bm{x}_{F})-\\bm{x}_{M}\\|_{2}, $ </equation> </equationgroup> with $ \\bm{x}_{F} $ and $ \\bm{x}_{M} $ the corresponding landmark locations.", "Based on the idea that the registration error is smooth, we include voxels from a small local neighborhood around the landmarks to increase the total set of available landmarks.", "In this small neighborhood we assume that the registration error is equal to the error at the center of the neighborhood.", "This assumption seems reasonable for smooth transformations and within a small region.", "The neighborhood size is chosen as $ 10\\times 10\\times 7.5\\;\\mathrm{mm} $ , which is approximately equivalent to the final grid spacing of the B-spline registration (see Fig. [@ref:LABEL:fig:GT_a_GroundTruth] ).", "\\newline The core software is written in Python.", "The feature pooling is performed with a C++ program [@bib:glocker2014robust] and the regression forest is calculated with the help of the Scikit-learn package [@bib:scikit-learn] .", "All registrations are performed by elastix [@bib:klein2010elastix] .", "Detailed registration setting can be found in the elastix parameter file database ( http://elastix.bigr.nl/wiki/index.php/Parameter_file_database , entry par0049).", "The code is publicly available via https://github.com/hsokooti/regun .", "\\newline </subsection> <subsection> <title> 3.2 Evaluation measures </title> In the SPREAD database, we employ 10 cross-validations by randomly splitting the data in 15 image pairs for training and the remaining 6 pairs for testing.", "To evaluate the regression performance, the mean absolute error (MAE) of the real registration error $ y_{i} $ and the estimated one $ \\hat{y}_{i} $ is calculated over the neighborhood of the landmarks by: \\newline <equationgroup> <equation> $ \\mathrm{MAE}=\\frac{1}{N}\\sum_{i=1}^{N}|\\hat{y}_{i}-y_{i}|.", "$ $ \\mathrm{MAE} $ $ =\\frac{1}{N}\\sum_{i=1}^{N}|\\hat{y}_{i}-y_{i}|.", "$ </equation> </equationgroup> To further detail the regression performance, the MAE is subdivided into three categories: $ \\mathrm{MAE_{c}} $ , $ \\mathrm{MAE_{p}} $ and $ \\mathrm{MAE_{w}} $ with $ y $ in $ [0,3) $ , $ [3,6) $ and $ [6,\\infty) $ mm, corresponding to correct, poor and wrong registration, similar to [@bib:muenzing2012supervised] .", "We then do the same for $ \\hat{y}_{i} $ , and report the accuracy and F1 score for classifying the registration error in these three categories.", "\\newline </subsection> <subsection> <title> 3.3 Parameter selection </title> The RF is trained using 100 trees with a maximum tree depth of 9, while at least 5 samples remain in the leaf nodes.", "At each splitting node, $ m $ features are randomly selected.", "We set $ m $ to the square root of the total number of features in that experiment, which performed slightly better than $ m=\\text{(number of features)}/3 $ [@bib:liaw2002classification] .", "The total number of registrations $ P $ is chosen as 20 to ensure that the estimation of $ \\operatorname{\\mathrm{std}}\\bm{T} $ does not change considerably when increasing the number of registrations [@bib:sokooti2016accuracy] .", "\\newline </subsection> <subsection> <title> 3.4 Reference registration error set </title> For the SPREAD and the DIR-Lab-4DCT study, registrations are based on free-form deformations by B-splines [@bib:rueckert1999nonrigid] .", "The cost function is mutual information, which is optimized by adaptive stochastic gradient descent.", "We used three resolutions with a final B-spline grid spacing of $ [10,10,10] $ mm.", "We collect samples by performing four different registrations using 20, 100, 500 and 2000 iterations, respectively.", "All other registration settings remain the same in these registrations.", "By varying the number of iterations we increase the variation in the samples, as well as the training size.", "Table [@ref:LABEL:tb:Composition] gives the distribution of reference registration errors in each database.", "As expected, increasing the number of iterations shifts the distribution towards the \u201ccorrect\u201d registration category.", "The maximum registration error is 81.8 mm in the SPREAD database, 17.6 mm in the DIR-Lab-4DCT database.", "\\newline Since the a priori distribution of registration errors is imbalanced, with much more samples in the \u201ccorrect\u201d category, we perform the following balancing step during training.", "For landmarks that fall in the category \u201ccorrect\u201d, we only add samples from a smaller neighborhood of $ 5\\times 5\\times 2.5\\;\\mathrm{mm} $ instead of the $ 10\\times 10\\times 7.5\\;\\mathrm{mm} $ neighborhoods used for landmarks in the categories \u201cpoor\u201d and \u201cwrong\u201d.", "The distribution of reference registration errors of the training samples is shown in Table [@ref:LABEL:tb:CompositionTraining] .", "\\newline For the DIR-Lab-COPDgene study, more advanced settings of the registration are used.", "In this experiment, samples are taken only on the landmark locations.", "More details are given in Section [@ref:LABEL:sec:inter-database] .", "The maximum registration error in this data is 31.5 mm.", "\\newline </subsection> <subsection> <title> 3.5 Experiments </title> <subsubsection> <title> 3.5.1 Single feature performance in SPREAD </title> The proposed features are described in Section [@ref:LABEL:hd:Features] and summarized in Table [@ref:LABEL:tb:Features] .", "To investigate the strength of the individual features, we trained the random forest with only a single feature with pooling.", "By comparing the MAE results in Table [@ref:LABEL:tb:SpreadFeatureResult] , it can be seen that MIND, $ \\operatorname{\\mathrm{std}}\\bm{T}^{\\mathrm{L}} $ and SID $ \\& $ GID are the best single features in the categories Intensity, Registration and Modality-dependent, respectively.", "\\newline </subsubsection> <subsubsection> <title> 3.5.2 Combined features performance </title> Instead of using only a single feature, several combinations of features are used to build the RFs: \\newline <list> \\ Intensity: Combination of all modality-independent intensity features: $ \\mathrm{MIND} $ and MI (50 features).", "\\newline \\ \\ Registration: Combination of all registration features: $ \\operatorname{\\mathrm{std}}\\bm{T} $ , $ \\operatorname{\\mathrm{std}}\\bm{T}^{\\mathrm{L}} $ , CVH, $ \\mathcal{E}(\\bm{T}) $ , $ \\mathcal{E}(\\bm{T}^{\\mathrm{L}}) $ and Jac (108 features).", "\\newline \\ \\ Combined: Combination of both intensity and registration features (158 features).", "\\newline \\ </list> \\newline All results are available in Table [@ref:LABEL:tb:SpreadResult] .", "By combining features from both the registration and modality-independent intensity category, improvements were obtained in all evaluation measures.", "\\newline The result of the regression with combined features is detailed in Fig. [@ref:LABEL:fig:RegSort] (a), which shows the real error (solid blue line) against the predicted error, sorted from small to large.", "In Fig. [@ref:LABEL:fig:RegSort] (b) we grouped the real errors in the three categories, each category showing a box-plot of the predicted errors.", "Intuitively, a smaller overlap between the boxes represents a better regression.", "\\newline </subsubsection> <subsubsection> <title> 3.5.3 Including modality-dependent features </title> We consider adding the combination of three modality-dependent features to the combined feature set (Combined+MD): NC, SID and GID."]], "target": "In both databases, if we add the modality-dependent features (see Table ), negligible differences are observed. Therefore, to keep the feature set small and modality-independent, we select the \u201ccombined features\u201d class without the modality-dependent features as the final system in the remainder of this paper."}, {"tabular": ["  Method  &  aero  &  bike  &  bird  &  boat  &  bottle  &  bus  &  car  &  cat  &  chair  &  cow  &  table  &  dog  &  horse  &  mbike  &  person  &  plant  &  sheep  &  sofa  &  train  &  tv  &  mAP ", " Old Model  &  -  &  78.8  &  77.4  &  56.5  &  60.1  &  76.4  &  85.0  &  80.0  &  50.0  &  78.0  &  69.9  &  78.3  &  79.2  &  74.3  &  77.3  &  39.5  &  66.4  &  65.7  &  76.9  &  74.4  &  - ", " New Model  &  15.8  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  - ", " DMC  &  16.3  &  75.9  &  75.8  &  52.9  &  59.5  &  74.2  &  84.2  &  79.1  &  49.3  &  73.0  &  59.9  &  70.0  &  75.4  &  64.8  &  79.9  &  40.2  &  64.1  &  58.8  &  69.9  &  74.3  &  64.9 ", " Old Model  &  69.6  &  -  &  76.3  &  60.1  &  59.8  &  76.7  &  85.4  &  79.6  &  54.6  &  75.9  &  63.7  &  78.6  &  79.5  &  71.5  &  77.7  &  44.9  &  68.0  &  57.6  &  77.3  &  75.5  &  - ", " New Model  &  -  &  70.2  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  - ", " DMC  &  75.8  &  62.4  &  75.5  &  59.6  &  59.0  &  76.0  &  85.6  &  79.5  &  53.8  &  77.0  &  62.3  &  78.6  &  77.6  &  67.5  &  80.7  &  43.5  &  70.6  &  57.6  &  77.3  &  76.3  &  69.8 ", " Old Model  &  68.9  &  78.8  &  -  &  55.9  &  61.4  &  70.7  &  79.9  &  79.8  &  50.9  &  73.6  &  65.0  &  77.7  &  79.3  &  76.0  &  77.0  &  43.1  &  66.2  &  66.8  &  77.3  &  75.5  &  - ", " New Model  &  -  &  -  &  35  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  - ", " DMC  &  69.0  &  77.9  &  43.8  &  54.7  &  60.1  &  75.5  &  84.1  &  77.5  &  51.0  &  71.4  &  65.4  &  69.4  &  69.7  &  73.5  &  76.5  &  40.8  &  59.9  &  66.9  &  77.0  &  76.2  &  67.0 ", " Old Model  &  76.9  &  78.3  &  77.1  &  -  &  57.9  &  76.2  &  85.2  &  79.8  &  48.7  &  76.5  &  65.6  &  82.9  &  76.9  &  75.1  &  77.7  &  40.6  &  67.7  &  67.6  &  76.9  &  69.5  &  - ", " New Model  &  -  &  -  &  -  &  18.6  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  - ", " DMC  &  76.6  &  77.2  &  75.8  &  23.4  &  58.2  &  77.2  &  84.4  &  80.0  &  48.7  &  78.5  &  63.3  &  82.8  &  70.3  &  76.1  &  80.7  &  40.8  &  66.7  &  64.9  &  75.5  &  68.6  &  68.5 ", " Old Model  &  70.5  &  77.9  &  77.5  &  53.5  &  -  &  76.1  &  85.6  &  78.8  &  51.0  &  76.2  &  62.5  &  77.2  &  79.1  &  73.2  &  77.6  &  42.5  &  68.6  &  68.1  &  76.6  &  74.5  &  - ", " New Model  &  -  &  -  &  -  &  -  &  47.7  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  - ", " DMC  &  74.7  &  76.2  &  76.4  &  51.0  &  37.6  &  76.9  &  85.4  &  79.4  &  53.0  &  76.7  &  64.2  &  77.9  &  77.9  &  73.6  &  80.4  &  43.0  &  68.2  &  68.4  &  76.5  &  75.3  &  69.6 ", " Old Model  &  70.8  &  77.8  &  75.2  &  57.2  &  60.0  &  -  &  84.7  &  79.6  &  48.3  &  75.3  &  68.4  &  78.8  &  78.6  &  75.6  &  77.3  &  41.8  &  69.0  &  68.0  &  75.0  &  73.9  &  - ", " New Model  &  -  &  -  &  -  &  -  &  -  &  46  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  - ", " DMC  &  68.7  &  79.7  &  73.9  &  55.6  &  61.3  &  53.5  &  84.9  &  79.3  &  49.4  &  75.8  &  66.8  &  78.9  &  75.6  &  75.4  &  80.6  &  41.6  &  67.4  &  66.7  &  70.0  &  73.8  &  68.9 ", " Old Model  &  77.5  &  78.8  &  74.5  &  58.1  &  60.3  &  74.5  &  -  &  80.7  &  49.0  &  76.0  &  64.4  &  77.3  &  78.7  &  66.8  &  77.1  &  39.0  &  67.9  &  67.0  &  77.1  &  75.3  &  - ", " New Model  &  -  &  -  &  -  &  -  &  -  &  -  &  76.2  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  - ", " DMC  &  70.3  &  76.3  &  74.0  &  51.3  &  60.2  &  68.2  &  77.5  &  80.0  &  47.1  &  76.5  &  61.0  &  77.4  &  77.3  &  59.5  &  79.9  &  41.5  &  66.5  &  65.0  &  77.2  &  74.8  &  68.1 ", " Old Model  &  76.5  &  79.4  &  78.1  &  54.7  &  60.8  &  77.2  &  85.4  &  -  &  49.6  &  74.9  &  65.1  &  78.5  &  78.5  &  74.3  &  77.8  &  44.2  &  67.3  &  65.1  &  76.0  &  74.5  &  - ", " New Model  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  60.5  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  - ", " DMC  &  75.7  &  81.0  &  76.6  &  51.4  &  61.9  &  76.7  &  84.5  &  69.8  &  51.5  &  74.6  &  63.6  &  76.9  &  69.4  &  74.6  &  81.2  &  43.3  &  67.0  &  67.1  &  77.1  &  74.2  &  69.9 ", " Old Model  &  78.7  &  79.6  &  76.9  &  57.3  &  62.2  &  77.4  &  80.0  &  79.5  &  -  &  75.9  &  66.6  &  77.6  &  79.6  &  76.5  &  77.3  &  43.4  &  67.3  &  66.7  &  77.8  &  69.3  &  - ", " New Model  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  41.9  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  - ", " DMC  &  75.8  &  76.2  &  76.9  &  56.7  &  62.9  &  76.9  &  85.4  &  78.9  &  38.1  &  75.1  &  64.1  &  78.6  &  76.0  &  74.4  &  80.4  &  43.0  &  66.8  &  62.6  &  77.8  &  74.0  &  70.0 ", " Old Model  &  70.8  &  77.8  &  76.0  &  58.1  &  60.7  &  78.1  &  85.0  &  80.1  &  47.2  &  -  &  64.4  &  77.4  &  75.3  &  74.9  &  80.3  &  41.7  &  66.8  &  64.9  &  77.1  &  72.1  &  - ", " New Model  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  30.3  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  - ", " DMC  &  69.9  &  75.6  &  68.1  &  56.4  &  60.7  &  77.2  &  85.5  &  79.4  &  46.4  &  37.0  &  65.2  &  70.0  &  68.0  &  74.6  &  80.4  &  41.7  &  59.6  &  62.8  &  76.5  &  72.9  &  66.4 ", " Old Model  &  75.5  &  80.1  &  77.1  &  57.8  &  61.4  &  76.6  &  85.5  &  80.6  &  51.1  &  79.0  &  -  &  78.6  &  80.2  &  75.4  &  77.1  &  44.7  &  68.4  &  66.7  &  77.4  &  74.6  &  - ", " New Model  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  43.6  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  - ", " DMC  &  75.0  &  80.8  &  75.3  &  54.1  &  62.6  &  76.8  &  85.3  &  80.6  &  50.2  &  77.4  &  53.9  &  83.8  &  77.6  &  73.4  &  81.0  &  45.9  &  66.8  &  65.7  &  75.4  &  74.8  &  70.8 ", " Old Model  &  76.6  &  77.8  &  77.2  &  57.4  &  60.6  &  76.3  &  84.8  &  80.9  &  49.9  &  77.4  &  64.5  &  -  &  77.4  &  69.3  &  77.5  &  43.2  &  73.7  &  67.4  &  76.7  &  74.7  &  - ", " New Model  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  40.3  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  - ", " DMC  &  75.2  &  76.6  &  74.5  &  57.1  &  62.0  &  74.9  &  85.4  &  70.0  &  51.0  &  57.8  &  63.6  &  52.5  &  59.2  &  73.5  &  79.9  &  43.1  &  65.4  &  66.9  &  75.1  &  74.5  &  66.9 ", " Old Model  &  77.3  &  78.2  &  77.7  &  59.4  &  60.5  &  77.5  &  85.2  &  85.9  &  48.8  &  76.6  &  70.7  &  76.5  &  -  &  74.1  &  77.3  &  42.1  &  67.8  &  68.0  &  78.7  &  72.4  &  - ", " New Model  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  52.4  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  - ", " DMC  &  77.4  &  76.2  &  72.1  &  54.9  &  63.0  &  77.5  &  84.7  &  79.1  &  48.0  &  73.3  &  68.0  &  61.5  &  40.5  &  71.9  &  79.5  &  40.4  &  65.9  &  63.0  &  77.4  &  73.0  &  67.4 ", " Old Model  &  76.5  &  77.3  &  75.7  &  56.8  &  60.8  &  70.5  &  85.4  &  79.7  &  48.6  &  74.2  &  62.7  &  79.3  &  77.3  &  -  &  76.9  &  43.9  &  68.4  &  63.3  &  77.2  &  76.0  &  - ", " New Model  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  59.2  &  -  &  -  &  -  &  -  &  -  &  -  &  - ", " DMC  &  68.9  &  74.2  &  75.8  &  55.0  &  60.1  &  77.1  &  84.2  &  86.0  &  50.7  &  75.2  &  61.3  &  78.8  &  70.0  &  68.2  &  79.6  &  46.1  &  68.1  &  61.4  &  75.5  &  76.1  &  69.6 ", " Old Model  &  77.1  &  79.7  &  76.9  &  59.1  &  62.3  &  77.3  &  85.7  &  80.2  &  52.0  &  77.6  &  65.0  &  78.5  &  80.4  &  78.2  &  -  &  44.1  &  67.5  &  71.9  &  78.0  &  74.1  &  - ", " New Model  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  76.4  &  -  &  -  &  -  &  -  &  -  &  - ", " DMC  &  75.8  &  78.8  &  75.0  &  59.7  &  62.1  &  77.1  &  85.5  &  80.1  &  51.1  &  77.0  &  63.3  &  77.9  &  78.1  &  76.8  &  78.0  &  44.7  &  66.0  &  69.2  &  78.1  &  75.1  &  71.5 ", " Old Model  &  75.5  &  77.1  &  75.5  &  58.9  &  62.1  &  77.8  &  85.8  &  87.7  &  44.4  &  76.6  &  64.7  &  78.3  &  78.7  &  75.5  &  77.4  &  -  &  68.3  &  67.7  &  76.6  &  73.4  &  - ", " New Model  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  35.8  &  -  &  -  &  -  &  -  &  - ", " DMC  &  75.5  &  74.3  &  74.4  &  56.1  &  61.6  &  77.9  &  86.7  &  87.2  &  48.0  &  77.1  &  64.6  &  78.0  &  77.4  &  73.7  &  80.3  &  31.0  &  67.3  &  65.8  &  75.4  &  73.8  &  70.3 ", " Old Model  &  78.0  &  77.8  &  75.3  &  57.5  &  61.0  &  69.6  &  86.5  &  79.8  &  48.5  &  67.9  &  62.8  &  76.8  &  79.6  &  74.8  &  77.5  &  43.5  &  -  &  68.0  &  76.8  &  74.8  &  - ", " New Model  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  26  &  -  &  -  &  -  &  - ", " DMC  &  76.3  &  76.9  &  73.6  &  54.3  &  62.0  &  73.8  &  86.1  &  79.7  &  48.5  &  67.0  &  63.9  &  75.6  &  76.3  &  75.2  &  80.8  &  44.4  &  20.2  &  68.2  &  76.4  &  74.4  &  67.7 ", " Old Model  &  77.6  &  78.2  &  76.3  &  55.0  &  59.3  &  70.7  &  85.8  &  80.4  &  50.5  &  75.4  &  67.2  &  83.5  &  78.7  &  69.0  &  77.6  &  44.4  &  67.7  &  -  &  70.1  &  75.1  &  - ", " New Model  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  33.1  &  -  &  -  &  - ", " DMC  &  77.4  &  82.5  &  68.5  &  58.3  &  61.8  &  75.2  &  85.6  &  78.7  &  47.1  &  74.9  &  63.5  &  75.6  &  69.8  &  73.5  &  79.4  &  42.6  &  65.8  &  26.1  &  69.8  &  74.1  &  67.5 ", " Old Model  &  70.4  &  79.5  &  77.1  &  57.6  &  60.2  &  73.6  &  84.6  &  80.2  &  51.0  &  75.5  &  65.4  &  78.7  &  78.0  &  75.3  &  77.7  &  42.8  &  69.3  &  63.6  &  -  &  73.9  &  - ", " New Model  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  -  &  34.9  &  -  &  - ", " DMC  &  73.9  &  77.4  &  76.7  &  56.0  &  60.8  &  62.1  &  83.7  &  79.7  &  49.6  &  76.3  &  65.7  &  79.3  &  73.8  &  73.2  &  80.6  &  40.3  &  73.3  &  65.9  &  37.7  &  74.5  &  68.0  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Despite the recent success of deep learning in computer vision for a broad range of tasks [@bib:chen2016deeplab,huang2017densely,krizhevsky2012imagenet,lin2018focal] , classical training paradigm of deep models is ill-equipped for incremental learning (IL).", "Most deep neural networks can only be trained when the complete dataset is given and all classes are known prior to training.", "However, the real world is dynamic and new categories of interest can emerge over time.", "Re-training a model from scratch whenever a new class is encountered can be prohibitively expensive due to training data storage requirements and the computational cost of full retrain.", "Directly fine-tuning the existing model on only the data of new classes using stochastic gradient descent (SGD) optimization is not a better approach either, as this might lead to the notorious catastrophic forgetting problem [@bib:goodfellow2013empirical,mccloskey1989catastrophic] , which can result in severe performance degradation on old tasks.", "\\newline We consider a realistic, albeit strict and challenging, setting of class-incremental learning, where the system must satisfy the following constraints: 1) the original training data for old classes are no longer accessible when learning new classes \u2014 this could be due to a variety of reasons, \\eg , legacy data may be unrecorded, proprietary, too large to store, or subject to privacy constraint when training the model for a new task; this is a practical concern in various academic and industrial applications, where the model can be transferred from one party to another but data should be kept private, and a practitioner wants to augment the model to learn new classes; 2) the system should provide a competitive multi-class classifier for the classes observed so far, \\ie single-headed classification should be supported, which does not require any prior information of the test data; 3) the model size should remain relatively unchanged after learning new classes.", "\\newline Several attempts have been made to enable IL for DNNs, but none of them satisfies all of these constraints.", "Some recent works [@bib:castro2018end,chaudhry2019efficient,he2018exemplar,javed2018revisiting,lopez2017gradient,rebuffi2017icarl] that rely on the storage of partial old data have made impressive progress.", "They are arguably not memory efficient and storing data for the life time involves violate some practical constraints such as copyright or privacy issues, which is common in the domains like bio-informatics [@bib:samet2013incremental] .", "The performance of the existing methods that do not store any past data is yet unsatisfactory.", "Some of these methods rely on incrementally training generative models [@bib:kemker2018fearnet,shin2017continual] , which is a harder problem to solve; while others fine-tune the old model on the new data with certain regularization techniques to prevent forgetting [@bib:aljundi2018memory,chaudhry2018riemannian,kirkpatrick2017overcoming,li2017learning,shmelkov2017incremental,zenke2017continual,zhang2020regularize] .", "We argue that the ineffectiveness of these regularization-based methods is mainly due to the {asymmetric information} between old classes and new classes in the fine-tuning step.", "New classes have explicit and strong supervisory signal from the available labeled data, whereas the information for old classes is implicitly given in the form of a noisy regularization term.", "Moreover, if we over-regularize the model, the model will fail to adapt to the new task, which is referred to as {intransigence} [@bib:chaudhry2018riemannian] in the IL context.", "As a result, these methods have intrinsic bias towards either the old or the new classes in the final model, and it is extremely difficult to find a sweet spot considering that in practice we do not have a validation dataset for the old classes during incremental learning.", "\\newline As depicted in Fig. [@ref:LABEL:fig:overview] , we propose a novel paradigm for class-incremental learning called deep model consolidation (DMC), which first trains a separate model for the new classes using labeled data, and then combines the new and old models using publicly available unlabeled auxiliary data via a novel double distillation training objective.", "DMC eliminates the intrinsic bias caused by the information asymmetry or over-regularization in the training, as the proposed double distillation objective allows the final student model to learn from two teacher models (the old and new models) simultaneously.", "DMC overcomes the difficulty introduced by loss of access to legacy data by leveraging unlabeled auxiliary data, where the abundant transferable representations are mined to facilitate IL.", "Furthermore, using the auxiliary data rather than the training data of the new classes ensures the student model absorbs the knowledge transferred from the both teacher models in an unbiased way.", "\\newline Crucially, we do not require the auxiliary data share the class labels or generative distribution of the target data.", "The only requirement is that they are generic, diversified, and generally related to the target data.", "Usage of such unlabeled data incurs no additional dataset construction and maintenance cost since they can be crawled from the web effortlessly when needed and discarded once the IL of new classes is complete.", "Furthermore, note that the symmetric role of the two teacher models in DMC has a valuable extra benefit in the generalization of our method; it can be directly applied to combine any two arbitrary pre-trained models that can be downloaded from the Internet for easy deployment ( \\ie , only one model needs to be deployed instead of two), without access to the original training data.", "\\newline To summarize, our main contributions include: \\newline <list> \\ A novel paradigm for incremental learning which exploits external unlabeled data, which can be obtained at negligible cost.", "This is an illuminating perspective for IL, which bypasses the constraint of having old data stored by finding some cheap substitute that does not need to be stored.", "\\newline \\ \\ A new training objective function to combine two deep models into one single compact model to promote symmetric knowledge transfer.", "The two models can have different architectures, and they can be trained on data of distinct set of classes.", "\\newline \\ \\ An approach to extend the proposed paradigm to incrementally train modern one-stage object detectors, to which the existing methods are not applicable.", "\\newline \\ \\ Extensive experiments that demonstrate the substantial performance improvement of our method over existing approaches on large-scale image classification and object detection benchmarks in the IL setting.", "\\newline \\ </list> \\newline  </section>"], ["<section> <title> 2 Related work </title>  McCloskey \\etal [@bib:mccloskey1989catastrophic] first identified the catastrophic forgetting effect in the connectionist models, where the memory about the old data is overwritten when retraining a neural network with new data.", "Recently, researchers have been actively developing methods to alleviate this effect.", "\\newline Regularization methods.", "Regularization methods enforce additional constraints on the weight update, so that the new concepts are learned while retaining the prior memories.", "Goodfellow \\etal [@bib:goodfellow2013empirical] found that dropout [@bib:srivastava2014dropout] could reduce forgetting for multi-layer perceptrons sometimes.", "One line of work constrains the network parameters that are important to the old tasks to stay close to their old values, while looking for a solution to a new task in the neighborhood of the old one.", "EWC [@bib:kirkpatrick2017overcoming] and its variants [@bib:chaudhry2018riemannian,schwarz2018progress] use Fisher information matrix to estimate the weight importance; MAS [@bib:aljundi2018memory] uses the gradients of the network output; SI [@bib:zenke2017continual] uses the path integral over the optimization trajectory instead.", "RWalk [@bib:chaudhry2018riemannian] combines EWC [@bib:kirkpatrick2017overcoming] and SI [@bib:zenke2017continual] .", "Information about the old task and new task is not symmetric during learning in these methods; besides, the network may become stiffer and stiffer to adapt to the new task as it learns more tasks over time.", "Li and Hoiem [@bib:li2017learning] pursued another direction by proposing the Learning without Forgetting (LwF) method, which finetunes the network using the images of new classes with knowledge distillation [@bib:hinton2015distilling] loss, to encourage the output probabilities of old classes for each image to be close to the original network outputs.", "However, information asymmetry between old classes and new classes still exists.", "Image samples from new data may severely deviate from the true distribution of the old data, which further aggravates the information asymmetry.", "Instead, we assign two teacher models to one student network to guarantee the symmetric information flow from old- and new-class models into the final model.", "IMM [@bib:lee2017overcoming] first finetunes the network on the new task with regularization, and then blends the obtained model with the original model through moment matching.", "Though conceptually similar, our work is different from IMM [@bib:lee2017overcoming] in the following ways: 1) we do not use regularized-finetuning from old-class model when training the new model for the new classes, so we can avoid intrinsic bias towards the old classes and suboptimal solution for the new task; 2) we do not assume the final posterior distribution for all the tasks is Gaussian, which is a strong assumption for DNNs.", "\\newline Dynamic network methods.", "Dynamic network methods [@bib:mallya2018piggyback,mallya2018packnet,serra2018overcoming,yoon2018lifelong] dedicate a part of the network or a unique feed-forward pathway through neurons for each task.", "At test time, they require the task label to be specified to switch to the correct state of the network, which is not applicable in the class-IL where task labels are not available.", "\\newline Rehearsal and pseudo-rehearsal methods.", "In rehearsal methods [@bib:castro2018end,chaudhry2019efficient,javed2018revisiting,lopez2017gradient,nguyen2017variational,rebuffi2017icarl] , past information is periodically replayed to the model to strengthen memories it has already learned, which is done by interleaving data from earlier sessions with the current session data [@bib:robins1995catastrophic] .", "However, storage of past data is not resource efficient and may violate some practical constraints such as copyright or privacy issues.", "Pseudo-rehearsal methods attempt to alleviate this issue by using generative models to generate pseudopatterns [@bib:robins1995catastrophic] that are combined with the current samples.", "However, this requires training a generative model in the class-incremental fashion, which is an even harder problem to solve.", "Existing such methods do not produce competitive results [@bib:kemker2018fearnet,shin2017continual] unless supported by real exemplars [@bib:he2018exemplar] .", "\\newline Incremental learning of object detectors.", "Shmelkov \\etal [@bib:shmelkov2017incremental] adapted LwF for the object detection task.", "However, their framework can only be applied to object detectors in which proposals are computed externally, \\eg , Fast R-CNN [@bib:girshick2015fast] .", "In our experiments, we show that our method is applicable to more efficient modern single-shot object detection architectures, \\eg , RetinaNet [@bib:lin2018focal] .", "\\newline Exploiting external data.", "In computer vision, the idea of employing external data to improve performance of a target task has been explored in many contexts.", "Inductive transfer learning [@bib:csurka2017comprehensive,zhang2018fully] aims to transfer and reuse knowledge in labeled out-of-domain instances.", "Semi-supervised learning [@bib:chapelle2009semi,zhu2006semi] attempts to exploit the usefulness of unlabeled in-domain instances.", "Our work shares a similar spirit with self-taught learning [@bib:raina2007self] , where we use unlabeled auxiliary data but do not require the auxiliary data to have the same class labels or generative distribution as the target data.", "Such unlabeled data is significantly easier to obtain compared to typical semi-supervised or transfer learning settings.", "\\newline  </section>"], ["<section> <title> 3 Method </title>  Let\u2019s first formally define the class-incremental learning setting.", "Given a labeled data stream of sample sets $ X^{1},X^{2},\\cdots $ , where $ X^{y}=\\{x^{y}_{1},\\cdots x^{y}_{y_{n}}\\} $ denotes the samples of class $ y\\in\\mathbb{N}^{+} $ , we learn one class or group of classes at a time.", "During each learning session, we only have training data $ \\mathcal{D}_{new}=\\{X^{s+1},\\dots,X^{t}\\} $ of newly available classes $ s+1,\\cdots,t $ , while the training data of the previously learned classes $ \\{X^{1},\\dots,X^{s}\\} $ are no longer accessible.", "However, we have the model obtained in the previous session, which is an $ s $ -class classifier $ f_{old}(x;\\Theta_{old}) $ .", "Our goal is to train a $ t $ -class classifier $ f(x;\\Theta) $ without catastrophic forgetting on old classes or significant underperformance on the new classes.", "We assume that all models are implemented as DNNs where $ x $ and $ \\Theta $ denote the input and the parameters of the network, respectively.", "\\newline We perform IL in two steps: the first step is to train a $ (t-s) $ -class classifier using training data $ \\mathcal{D}_{new} $ , which we refer as the {new} model $ f_{new}(x;\\Theta_{new}) $ ; the second step is to consolidate the old model and the new model.", "\\newline The new class learning step is a regular supervised learning problem and it can be solved by standard back-propagation.", "The model consolidation step is the major contribution of our work, where we propose a method called Deep Model Consolidation (DMC) for image classification which we further extend to another classical computer vision task, object detection.", "\\newline <subsection> <title> 3.1 DMC for image classification </title> We start by training a new CNN model $ f_{new} $ on new classes using the available training data $ D_{new} $ with standard softmax cross-entropy loss.", "Once the new model is trained, we have two CNN models specialized in classifying either the old classes or the new classes.", "After that, the goal of the consolidation is to have a single compact model that can perform the tasks of both the old model and the new model simultaneously.", "Ideally, we have the following objective: \\newline <equation> $ f(x;\\Theta)[j]=\\begin{cases}f_{old}(x;\\Theta_{old})[j],&1\\leq j\\leq s\\\\ f_{new}(x;\\Theta_{new})[j],&s<j\\leq t\\end{cases},\\forall x\\in\\mathcal{I} $ </equation> where $ j $ denotes the index of the classification score associated with $ j $ -th class, and $ \\mathcal{I} $ denotes the joint distribution from which samples of class $ 1,\\cdots,t $ are drawn.", "We want the output of the consolidated model to approximate the combination of the network outputs of the old model and the new model.", "To achieve this, the network response of the old model and the new model is employed as supervisory signals in joint training of the consolidated model.", "\\newline Knowledge distillation (KD) [@bib:hinton2015distilling] is a popular technique to transfer knowledge from one network to another.", "Originally, KD was proposed to transfer knowledge from a cumbersome network to a light-weight network performing the same task, and no novel class was introduced.", "We generalize the basic idea in KD and propose a double distillation loss to enable class-incremental learning.", "Here, we define the {logits} as the inputs to the final softmax layer.", "We run a feed-forward pass of $ f_{old} $ and $ f_{new} $ for each training image, and collect the logits of the two models $ \\boldsymbol{\\hat{y}}_{old}=[\\hat{y}^{1},\\cdots,\\hat{y}^{s}] $ and $ \\boldsymbol{\\hat{y}}_{new}=[\\hat{y}^{s+1},\\cdots,\\hat{y}^{t}] $ , respectively, where the superscript is the class label associated with the neuron in the model.", "Then we minimize the difference between the logits produced by the consolidated model and the combination of logits generated by the two existing specialist models, according to some distance metric.", "We choose $ L_{2} $ loss [@bib:ba2014deep] as the distance metric because it demonstrates stable and good performance, see \u00a7 [@ref:LABEL:sssec:loss] for discussions.", "\\newline Due the absence of the legacy data, we cannot consolidate the two models using the old data.", "Thus some auxiliary data has to be used.", "If we assume that natural images lie on an ideal low-dimensional manifold, we can approximate the distribution of our target data via sampling from readily available unlabeled data from a similar domain.", "Note that the auxiliary data do not have to be stored persistently; they can be crawled and fed in mini-batches on-the-fly in this stage, and discarded thereafter.", "\\newline Specifically, the training objective for consolidation is \\newline <equation> $ \\min_{\\Theta}\\frac{1}{|\\mathcal{U}|}\\sum_{x_{i}\\in\\mathcal{U}}L_{dd}(% \\boldsymbol{y}_{i},\\boldsymbol{\\mathring{y}}_{i}), $ </equation> where $ \\mathcal{U} $ denotes the unlabeled auxiliary training data, and the double distillation loss $ L_{dd} $ is defined as: \\newline <equation> $ L_{dd}(\\boldsymbol{y},\\boldsymbol{\\mathring{y}})=\\frac{1}{t}\\sum_{j=1}^{t}% \\left(y^{j}-\\mathring{y}^{j}\\right)^{2}, $ </equation> in which $ y^{j} $ is the logit produced by the consolidated model for the $ j $ -th class, and \\newline <equation> $ \\mathring{y}^{j}=\\begin{cases}\\hat{y}^{j}-\\frac{1}{s}\\sum_{k=1}^{s}\\hat{y}^{k}% ,&1\\leq j\\leq s\\\\ \\hat{y}^{j}-\\frac{1}{t-s}\\sum_{k=s+1}^{t}\\hat{y}^{k},&s<j\\leq t\\\\ \\end{cases} $ </equation> where $ \\boldsymbol{\\hat{y}} $ is the concatenation of $ \\boldsymbol{\\hat{y}}_{old} $ and $ \\boldsymbol{\\hat{y}}_{new} $ .", "\\newline The regression target $ \\boldsymbol{\\mathring{y}} $ is the concatenation of normalized logits of the two specialist models.", "We normalize $ \\boldsymbol{\\hat{y}} $ by subtracting its mean over the class dimension (Eq. [@ref:LABEL:eq:normalize] ).", "This serves as a step of bias calibration for the two set of classes.", "It unifies the scale of logits produced by the two models, but retains the relative magnitude among the classes, so that the symmetric information flow can be enforced.", "\\newline Notably, to avoid the intrinsic bias toward either old or new classes, $ \\Theta $ should not be initialized from $ \\Theta_{old} $ or $ \\Theta_{new} $ ; we should also avoid the usage of training data for the new classes $ \\mathcal{D}_{new} $ in the model consolidation stage.", "\\newline </subsection> <subsection> <title> 3.2 DMC for object detection </title> We extend the IL approach given in Section [@ref:LABEL:ssec:classification] for modern one-stage object detectors, which are nearly as accurate as two-stage detectors but run much faster than the later ones.", "A single-stage object detector divides the input image into a fixed-resolution 2D grid (the resolution of the grid can be multi-level), where higher resolution means that the area corresponding to the image region ( {i.e.} , receptive field) of each cell in the grid is smaller.", "There are a set of bounding-box templates with fixed sizes and aspect ratios, called anchor boxes, which are associated with each spatial cell in the grid.", "Anchor boxes serve as references for the subsequent prediction.", "The class label and the bounding box location offset relative to the anchor boxes are predicted by the classification subnet and bounding boxes regression subnet, respectively, which are shared across all the feature pyramid levels [@bib:lin2016feature] .", "\\newline In order to apply DMC to incrementally train an object detector, we have to consolidate the classification subnet and bounding boxes regression subnet simultaneously.", "Similar to the image classification task, we instantiate a new detector whenever we have training data $ \\mathcal{D}_{new} $ for new object classes.", "After the new detector is properly trained, we then use the outputs of the two specialist models to supervise the training of the final model.", "\\newline Anchor boxes selection.", "In one-stage object detectors, a huge number of anchor boxes have to be used to achieve decent performance.", "For example, in RetinaNet [@bib:lin2018focal] , $ \\sim $ 100k anchor boxes are used for an image of resolution $ 800\\times 600 $ .", "Selecting a smaller number of anchor boxes speeds up forward-backward pass in training significantly.", "The naive approach of randomly sampling some anchor boxes doesn\u2019t consider the fact that the ratio of positive anchor boxes and negative ones is highly imbalanced, and negative boxes that correspond to background carry little information for knowledge distillation.", "In order to efficiently and effectively distill the knowledge of the two teacher detectors in the DMC stage, we propose a novel anchor boxes selection method to selectively enforce the constraint for a small set of anchor boxes.", "For each image sampled from the auxiliary data, we first rank the anchor boxes by the objectness scores.", "The objectness score ( $ os $ ) for an anchor box is defined as: \\newline <equation> $ os\\triangleq\\max\\{p^{1},\\cdots,p^{s},p^{s+1},\\cdots,p^{t}\\}, $ </equation> where $ p^{1},\\cdots,p^{s} $ are classification probabilities produced by the old-class model, and $ p^{s+1},\\cdots,p^{t} $ are from the new-class model.", "Intuitively, a high objectness score for a box implies a higher probability of containing a foreground object.", "The predicted classification probabilities of the old classes are produced by the old model, and new classes by the new model.", "We use the subset of anchor boxes that have the highest objectness scores and ignore the others.", "\\newline DMC for classification subnet.", "Similar to the image classification case in Sec. [@ref:LABEL:ssec:classification] , for each selected anchor box, we calculate the double distillation loss between the logits produced by the classification subnet of the consolidated model $ \\boldsymbol{y} $ and the normalized logits generated by the two existing specialist models $ \\boldsymbol{\\mathring{y}} $ .", "The loss term of DMC for the classification subnet $ L_{cls}(\\boldsymbol{y},\\boldsymbol{\\mathring{y}}) $ is identical to Eq. [@ref:LABEL:eq:cls_loss] .", "\\newline DMC for bounding box regression subnet.", "The output of the bounding box regression subnet is a tuple of spatial offsets $ \\boldsymbol{t}=(t_{x},t_{y},t_{h},t_{w}) $ , which specifies a scale-invariant translation and log-space height/width shift relative to an anchor box.", "For each anchor box selected, we need to set its regression target properly.", "If the class that has the highest predicted class probability is one of the old classes, we choose the old model\u2019s output as the regression target, otherwise, the new model\u2019s output is chosen.", "In this way, we encourage the predicted bounding box of the consolidated model to be closer to the predicted bounding box of the most probable object category.", "Smooth $ L_{1} $ loss [@bib:girshick2015fast] is used to measure the closeness of the parameterized bounding box locations.", "The loss term of DMC for the bounding box regression subnet is as follows: \\newline <equation> $ L_{loc}(\\boldsymbol{t},\\boldsymbol{\\hat{t}})=\\sum_{k={x,y,h,w}}smooth_{L_{1}}(% t_{k}-\\hat{t}_{k}), $ </equation> in which \\newline <equation> $ \\boldsymbol{\\hat{t}}=\\begin{cases}\\boldsymbol{\\hat{t}}_{old},&\\max_{1\\leq j% \\leq s}\\hat{y}^{j}>\\max_{s<j\\leq t}\\hat{y}^{j}\\\\ \\boldsymbol{\\hat{t}}_{new},&\\text{otherwise}\\end{cases}, $ </equation> \\newline Overall training objective.", "The overall DMC objective function for the object detection is defined as \\newline <equation> $ \\min_{\\Theta}\\frac{1}{|\\mathcal{U}|}\\sum_{x_{i}\\in\\mathcal{U}}L_{cls}(% \\boldsymbol{y}_{i},\\boldsymbol{\\mathring{y}}_{i})+\\lambda L_{loc}(\\boldsymbol{% t}_{i},\\boldsymbol{\\hat{t}}_{i}) $ </equation> where $ \\lambda $ is a hyper-parameter to balance the two loss terms.", "\\newline </subsection>  </section>"], ["<section> <title> 4 Experiments </title>  <subsection> <title> 4.1 Evaluation protocols </title> There are two evaluation protocols for incremental learning.", "In one setting, the network has different classification layers (multiple \u201cheads\u201d) for each task, where each head can differentiate the classes learned only in this task; it relies on an oracle to decide on the task at test time, which would result in a misleading high test accuracy [@bib:chaudhry2018riemannian,liu2018rotate] .", "In this paper, we adopt a practical yet challenging setting, namely \u201csingle-head\u201d evaluation, where the output space consists of all the $ t $ classes learned so far, and the model has to learn to resolve the confusion among the classes from different tasks, when task identities are not available at test time.", "\\newline </subsection> <subsection> <title> 4.2 Incremental learning of image classifiers </title> <subsubsection> <title> 4.2.1 Experimental setup </title> We evaluate our method on iCIFAR-100 benchmark as done in iCaRL [@bib:rebuffi2017icarl] , which uses CIFAR-100 [@bib:krizhevsky2009learning] data and learn all 100 classes in groups of $ g=5,10,20 $ or $ 50 $ classes at a time.", "The evaluation metric is the standard top-1 multi-class classification accuracy on the test set.", "For each experiment, we run this benchmark 5 times with different class orderings and then report the averages and standard deviations of the results.", "We use ImageNet32 $ \\times $ 32 dataset [@bib:chrabaszcz2017downsampled] as the source of auxiliary data in the model consolidation stage.", "The images are down-sampled versions of images from ImageNet ILSVRC [@bib:imagenet_cvpr09,ILSVRC15] training set.", "We exclude the images that belong to the CIFAR-100 classes, which results in 1,082,340 images.", "Following iCaRL [@bib:rebuffi2017icarl] , we use a 32-layer ResNet [@bib:he2016deep] for all experiments and the model weights are randomly initialized.", "\\newline </subsubsection> <subsubsection> <title> 4.2.2 Experimental results and discussions </title> We compare our method against the state-of-the-art exemplar-free incremental learning methods EWC++ [@bib:chaudhry2018riemannian,kirkpatrick2017overcoming] , LwF [@bib:li2017learning] , SI [@bib:zenke2017continual] , MAS [@bib:aljundi2018memory] , RWalk [@bib:chaudhry2018riemannian] and some baselines with $ g=5,10,20,50 $ .", "Finetuning denotes the case where we directly fine-tune the model trained on the old classes with the labeled images of new classes, without any special treatment for catastrophic forgetting.", "Fixed Representation denotes the approach where we freeze the network weights except for the classification layer (the last fully connected layer) after the first group of classes has been learned, and we freeze the classification weight vector after the corresponding classes have been learned, and only fine-tune the classification weight vectors of new classes using the new data.", "This approach usually underfits for the new classes due to the limited degree of freedom and incompatible feature representations of the frozen base network.", "Oracle denotes the upper bound results via joint training with all the training data of the classes learned so far.", "\\newline The results are shown in Fig. [@ref:LABEL:fig:cifar100] .", "Our method outperforms all the methods by a significant margin across all the settings consistently.", "We used the official code for [@bib:chaudhry2018riemannian] to get the results for EWC++ [@bib:chaudhry2018riemannian,kirkpatrick2017overcoming] , SI [@bib:zenke2017continual] , MAS [@bib:aljundi2018memory] and RWalk [@bib:chaudhry2018riemannian] .", "We found they are highly sensitive to the hyperparameter that controls the strength of regularization due to the asymmetric information between old classes and new classes, so we tune the hyperparameter using a held-out validation set for each setting separately, and report the best result for each case.", "The results of LwF [@bib:li2017learning] are from iCaRL [@bib:rebuffi2017icarl] and they are the second-best in all the settings.", "\\newline It can be also observed that DMC demonstrates a stable performance across different $ g $ , in contrast to other regularization-based methods, where the disadvantages of inherent asymmetric information flow reveal more, as we incrementally learn more sessions.", "They struggle in finding the good trade-off between forgetting and intransigence.", "\\newline Fig. [@ref:LABEL:fig:acc_on_1st_task] illustrates how the accuracy on the first group of classes changes as we learn more and more classes over time.", "While the previous methods [@bib:aljundi2018memory,chaudhry2018riemannian,kirkpatrick2017overcoming,li2017learning,zenke2017continual] all suffer from catastrophic forgetting on the first task, DMC shows considerably more gentle slop of the forgetting curve.", "Though the standard deviations seems high, which is due to the random class ordering in each run, the relative standard deviations (RSD) are at a reasonable scale for all methods.", "\\newline We visualize the confusion matrices of some of the methods in Fig. [@ref:LABEL:fig:cifar100-cm] .", "Finetuning forgets old classes and makes predictions based only on the last learned group.", "Fixed Representation is strongly inclined to predict the classes learned in the first group, on which its feature representation is optimized.", "The previous best performing method LwF does a better job, but still has many more non-zero entries on the recently learned classes, which shows strong evidence of information asymmetric between old classes and new classes.", "On the contrary, the proposed DMC shows a more homogeneous confusion matrix pattern and thus has visibly less intrinsic bias towards or against the classes that it encounters early or late during learning.", "\\newline Impact of the distribution of auxiliary data.", "Fig. [@ref:LABEL:fig:acc-vs-dataset] shows our empirical study on the impact of the distribution of the auxiliary data by using images from datasets of handwritten digits (MNIST [@bib:lecun1998gradient] ), house number digits (SVHN [@bib:netzer2011reading] ), texture (DTD [@bib:cimpoi14describing] ), and scenes (Places365 [@bib:zhou2017places] ) as the sources of the auxiliary data.", "Intuitively, the more diversified and more similar to the target data the auxiliary data is, the better performance we can achieve.", "Experiments show that usage of overparticular datasets like MNIST and SVHN fails to produce competitive results, but using generic and easily accessible datasets like DTD and Places365 can already outperform the previous state-of-the-art methods.", "In the applied scenario, one may use the prior knowledge about the target data to obtain the desired auxiliary data from a related domain to boost the performance.", "\\newline Choices of loss function.", "We compare some common distance metrics used in knowledge distillation in Table [@ref:LABEL:tab:distance] .", "We observe DMC is generally not sensitive to the loss function chosen, while $ L_{2} $ loss and KD loss [@bib:hinton2015distilling] with $ T=2 $ performs slightly better than others.", "As stated in [@bib:hinton2015distilling] , both formulations should be equivalent in the limit of a high temperature $ T $ , so we use $ L_{2} $ loss throughout this paper for its simplicity and stability over various training schedules.", "\\newline Effect of the amount of auxiliary data.", "Fig. [@ref:LABEL:fig:cifar100-data] illustrates the effect of the amount of auxiliary data used in consolidation stage.", "We randomly subsampled $ 2^{k}\\times 10^{3} $ images for $ k=0,\\cdots,9 $ from ImageNet32 $ \\times $ 32 [@bib:chrabaszcz2017downsampled] .", "We report the average of the classification accuracies over all steps of the IL (as in [@bib:castro2018end] , the accuracy of the first group is not considered in this average).", "Overall, our method is robust against the reduction of auxiliary data to a large extent.", "We can outperform the previous state-of-the-art by just using 8,000, 16,000 and 32,000 unlabeled images ( $ <3\\% $ of full auxiliary data) for $ g={10,20,50} $ , respectively.", "Note that it also takes less training time for the consolidated model to converge when we use less auxiliary data.", "\\newline Experiments with larger images.", "We additionally evaluate our method on CUB-200 [@bib:WahCUB_200_2011] dataset in IL setting with $ g=100 $ .", "The network architecture (VGG-16 [@bib:simonyan2014very] ) and data preprocessing are identical with REWC [@bib:liu2018rotate] .", "We use BirdSnap [@bib:berg2014birdsnap] as the auxiliary data source where we excluded the CUB categories.", "As shown in Table [@ref:LABEL:tab:cub] , DMC outperforms the previous state-of-the-art [@bib:liu2018rotate] by a considerable margin.", "This demonstrates that DMC generalizes well to various image resolutions and domains.", "\\newline </subsubsection> </subsection> <subsection> <title> 4.3 Incremental learning of object detectors </title> <subsubsection> <title> 4.3.1 Experimental setup </title> Following [@bib:shmelkov2017incremental] , we evaluate DMC for incremental object detection on PASCAL VOC 2007 [@bib:pascal-voc-2007] in the IL setting: there are 20 object categories in the dataset, and we incrementally learn $ 10+10 $ classes and $ 19+1 $ classes.", "The evaluation metric is the standard mean average precision (mAP) on the test set.", "We use training images from Microsoft COCO [@bib:lin2014microsoft] dataset as the source of auxiliary data for the model consolidation stage.", "Out of 80 object categories in the COCO dataset, we use the 98,495 images that contain objects from the 60 non-PASCAL categories.", "\\newline We perform all experiments using RetinaNet [@bib:lin2018focal] , but the proposed method is applicable to other one-stage detectors [@bib:law2018cornernet,liu2016ssd,redmon2016you,zhang2018single] with minor modifications.", "In the $ 10+10 $ experiment, we use ResNet-50 [@bib:he2016deep] as the backbone network for both 10-class models and the final consolidated 20-class model.", "In $ 19+1 $ experiment, we use ResNet-50 as the backbone network for the 19-class model as well as the final consolidated 20-class model, and ResNet-34 for the 1-class new model.", "In all experiments, the backbone networks were pretrained on ImageNet dataset [@bib:he2016deep] .", "\\newline </subsubsection> <subsubsection> <title> 4.3.2 Experimental results and discussions </title> We compare our method with a baseline method and with the state-of-the-art IL method for object detection by Shmelkov \\etal [@bib:shmelkov2017incremental] .", "In the baseline method, denoted by Inference twice , we directly run inference for each test image using two specialist models separately and then aggregate the predictions by taking the class that has the highest classification probability among all classes, and use the bounding box prediction of the associated model.", "The method proposed by Shmelkov \\etal [@bib:shmelkov2017incremental] is compatible only with object detectors that use pre-computed class-agnostic object proposals ( \\eg , Fast R-CNN [@bib:girshick2015fast] ), so we adapt their method for RetinaNet by using our novel anchor boxes selection scheme to determine where to apply the distillation, denoted by Adapted Shmelkov \\etal [@bib:shmelkov2017incremental] .", "\\newline Learning $ 10+10 $ classes.", "The results are given in Table [@ref:LABEL:tab:pascal_10] .", "Compared to Inference twice , our method is more time- and space-efficient since Inference twice scales badly with respect to the number of IL sessions, as we need to store all the individual models and run inference using each one at test time.", "The accuracy gain of our method over the Inference twice method might seem surprising, but we believe this can be attributed to the better representations that were inductively learned with the help of the unlabeled auxiliary data, which is exploited also by many semi-supervised learning algorithms.", "Compared to Adapted Shmelkov \\etal [@bib:shmelkov2017incremental] , our method exhibits remarkable performance improvement in detecting all classes.", "\\newline Learning $ 19+1 $ classes."]], "target": "The results are given in Table . We observe an mAP pattern similar to the $ 10+10 $ experiment. Adapted Shmelkov \\etal suffers from degraded accuracy on old classes. Moreover, it cannot achieve good AP on the \u201ctvmonitor\u201d class. Heavily regularized on 19 old classes, the model may have difficulty learning a single new class with insufficient training data. Our DMC achieves state-of-the-art mAP of all the classes learned, with only half of the model complexity and inference time of Inference twice . We also performed the addition of one class experiment with each of the VOC categories being the new class. The behavior for each class is very similar to the \u201ctvmonitor\u201d case described above. The mAP varies from 64.88% (for new class \u201caeroplane\u201d) to 71.47% (for new class \u201cperson\u201d) with mean 68.47% and standard deviation of 1.75%. Detailed results are in the supplemental material."}, {"tabular": ["  Method  &  $ \\theta $  &  1  &  2  &  3  &  4  &  5 ", "  &  $ \\theta_{1} $  &  -5.79  &  -6.59  &  17.43  &  0.99  &  -3.01 ", " SGLD  &  $ \\theta_{2} $  &  -2.42  &  -1.76  &  9.02  &  -1.36  &  -4.74 ", " \\hdas  &  $ \\theta_{1} $  &  9.22  &  14.73  &  23.19  &  11.39  &  -4.22 ", " SGHMC  &  $ \\theta_{2} $  &  1.27  &  6.23  &  11.03  &  2.65  &  -2.25 ", " \\hdas  &  $ \\theta_{1} $  &  1.27  &  -19.77  &  16.52  &  5.14  &  -9.08 ", " pSGLD  &  $ \\theta_{2} $  &  -2.22  &  -15.44  &  8.17  &  0.65  &  3.75 ", "  &  $ \\theta_{1} $  &  19.75  &  15.34  &  19.99  &  19.01  &  19.98 ", " ASGLD  &  $ \\theta_{2} $  &  9.99  &  9.29  &  9.92  &  9.66  &  9.99 ", " \\hdas  &  $ \\theta_{1} $  &  20.01  &  20.07  &  19.99  &  20.00  &  19.99 ", " MSGLD  &  $ \\theta_{2} $  &  9.99  &  10.00  &  9.99  &  9.99  &  9.99  "], "ref_sec": [["<section> <title> 1 Introduction </title>  During the past decade, deep learning has been the engine powering many successes of artificial intelligence (AI).", "However, the deep neural network (DNN), as the basic model of deep learning, still suffers from some fundamental issues, such as model uncertainty, model interpretability, and prediction bias, which pose a high risk on the safety of AI.", "In particular, the standard optimization algorithms such as stochastic gradient descent (SGD) produce only a point estimate for the DNN, where model uncertainty is completely ignored.", "The machine prediction/decision is blindly taken as accurate and precise, with which the automated system might become life-threatening to humans if used in real-life settings.", "The universal approximation ability of the DNN enables it to learn powerful representations that map high-dimensional features to an array of outputs.", "However, the representation is less interpretable, from which important features that govern the function of the system are hard to be identified, causing serious issues in human-machine trust.", "In addition, the DNN often contains an excessively large number of parameters.", "As a result, the training data tend to be over-fitted and the prediction tends to be biased.", "\\newline As advocated by many researchers, see e.g. [@bib:KendallGal2017] and [@bib:ChaoChen2018] , Bayesian deep learning offers a principled way to address above issues.", "Under the Bayesian framework, a sparse DNN can be learned by sampling from the posterior distribution formulated with an appropriate prior distribution, see e.g. [@bib:Liang2018BNN] and [@bib:polson2018posterior] .", "For the sparse DNN, interpretability of the structure and consistency of the prediction can be established under mild conditions, and model uncertainty can be quantified based on the posterior samples, see e.g. [@bib:Liang2018BNN] .", "However, due to the lack of efficient Monte Carlo algorithms for sampling from the posterior of DNNs, Bayesian deep learning has not yet powered our AI systems.", "\\newline Toward the goal of efficient Bayesian deep learning, a variety of stochastic gradient Markov chain Monte Carlo (SGMCMC) algorithms have been proposed in the literature, including stochastic gradient Langevin dynamics (SGLD) [@bib:Welling2011BayesianLV] , stochastic gradient Hamiltonian Monte Carlo (SGHMC) [@bib:Chen2014StochasticGH] , and their variants.", "One merit of the SGMCMC algorithms is that they are scalable, requiring at each iteration only the gradient on a mini-batch of data as in the SGD algorithm.", "Unfortunately, as pointed out in [@bib:Dauphin2014] , DNNs often exhibit pathological curvature and saddle points, rendering the first-order gradient based algorithms, such as SGLD, inefficient.", "To accelerate convergence, the second-order gradient algorithms, such as stochastic gradient Riemannian Langevin dynamics (SGRLD) [@bib:AhnKW2012,GirolamiG2011,PattersonTeh2013] and stochastic gradient Riemannian Hamiltonian Monte Carlo (SGRHMC) [@bib:Ma2015ACR] , have been developed.", "With the use of the Fisher information matrix of the target distribution, these algorithms rescale the stochastic gradient noise to be isotropic near stationary points, which helps escape saddle points faster.", "However, calculation of the Fisher information matrix can be time consuming, which makes these algorithms lack scalability necessary for learning large DNNs.", "Instead of using the exact Fisher information matrix, preconditioned SGLD (pSGLD) [@bib:Li2016PreconditionedSG] approximates it by a diagonal matrix adaptively updated with the current gradient information.", "\\newline [@bib:Ma2015ACR] provides a general framework for the existing SGMCMC algorithms (see Section [@ref:LABEL:recipe] ), where the stochastic gradient of the energy function (i.e., the negative log-target distribution) is restricted to be unbiased.", "However, this restriction is unnecessary.", "As shown in the recent work, see e.g., [@bib:DalalyanK2017] , [@bib:SongLiang2020] , and [@bib:bhatia2019bayesian] , the stochastic gradient of the energy function can be biased as long as its mean squared error can be upper bounded by an appropriate function of $ \\theta_{t} $ , the current sample of the stochastic gradient Markov chain.", "On the other hand, a variety of adaptive SGD algorithms, such as momentum [@bib:Qian1999] , Adagrad [@bib:Duchietal2011] , RMSprop [@bib:TielemanH2012] , and Adam [@bib:KingmaB2015] , have been proposed in the recent literature for dealing with the saddle point issue encountered in deep learning.", "These algorithms adjust the moving direction at each iteration according to the current gradient as well as the past ones.", "It was shown in [@bib:StaibRK2019] that, compared to SGD, these algorithms escape saddle points faster and can converge faster overall to the second-order stationary points.", "\\newline Motivated by the two observations above, we propose a class of adaptive SGLD algorithms, where a bias term is included in the drift function to enhance escape from saddle points and accelerate the convergence in the presence of pathological curvatures.", "The bias term can be adaptively adjusted based on the path of the sampler.", "In particular, we propose to adjust the bias term based on the past gradients in the flavor of adaptive SGD algorithms [@bib:Ruder2016] .", "We establish the convergence of the proposed adaptive SGLD algorithms under mild conditions, and demonstrate via numerical examples that the adaptive SGLD algorithms can significantly outperform the existing SGMCMC algorithms, such as SGLD, SGHMC and pSGLD.", "\\newline  </section>"], ["<section> <title> 2 A Brief Review of Existing SGMCMC Algorithms </title>  Let $ {X}_{N}=(X_{1},X_{2},\\ldots,X_{N}) $ denote a set of $ N $ independent and identically distributed samples drawn from the distribution $ f(x|\\theta) $ , where $ N $ is the sample size and $ \\theta $ is the vector of parameters.", "Let $ p({X}_{N}|\\theta)=\\prod_{i=1}^{N}f(X_{i}|\\theta) $ denote the likelihood function, let $ \\pi(\\theta) $ denote the prior distribution of $ \\theta $ , and let $ U(\\theta)=-\\log p({X}_{N}|\\theta)-\\log\\pi(\\theta) $ denote the energy function of the posterior distribution.", "If $ \\theta $ has a fixed dimension and $ U(\\theta) $ is differentiable with respect to $ \\theta $ , then the SGLD algorithm can be used to simulate from the posterior, which iterates by \\newline <equation> $ \\theta_{t+1}=\\theta_{t}-\\epsilon_{t+1}\\nabla_{\\theta}\\tilde{U}(\\theta_{t})+% \\sqrt{2\\epsilon_{t+1}\\tau}\\eta_{t+1},\\ \\ \\eta_{t+1}\\sim N(0,I_{d}), $ </equation> where $ d $ is the dimension of $ \\theta $ , $ I_{d} $ is an $ d\\times d $ -identity matrix, $ \\epsilon_{t+1} $ is the learning rate, $ \\tau $ is the temperature, and $ \\nabla_{\\theta}\\tilde{U}(\\theta) $ denotes an estimate of $ \\nabla_{\\theta}U(\\theta) $ based on a mini-batch of data.", "The learning rate can be kept as a constant or decreasing with iterations.", "For the former, the convergence of the algorithm was studied in [@bib:Sato2014ApproximationAO] and [@bib:DalalyanK2017] .", "For the latter, the convergence of the algorithm was studied in [@bib:teh2016consistency] .", "\\newline The SGLD algorithm has been extended in different ways.", "As mentioned previously, each of its existing variants can be formulated as a special case of a general SGMCMC algorithm given in [@bib:Ma2015ACR] .", "Let $ \\xi $ denote an augmented state, which may include some auxiliary components.", "For example, SGHMC augments the state to $ \\xi=(\\theta,v) $ by including an auxiliary velocity component denoted by $ v $ .", "Then the general SGMCMC algorithm is given by \\newline <equation> $ \\theta_{t+1}=\\theta_{t}-\\epsilon_{t+1}[D(\\xi)+Q(\\xi)]\\nabla_{\\xi}\\tilde{H}(\\xi% )+\\Gamma(\\xi)+\\sqrt{2\\epsilon_{t+1}\\tau}Z_{t+1}, $ </equation> where $ Z_{t+1}\\sim N(0,D(\\xi_{t})) $ , $ H(\\xi) $ is the energy function of the augmented system, $ \\nabla_{\\xi}\\tilde{H}(\\xi) $ denotes an unbiased estimate of $ \\nabla_{\\xi}H(\\xi) $ , $ D(\\xi) $ is a positive semi-definite diffusion matrix, $ Q(\\xi) $ is a skew-symmetric curl matrix, and $ \\Gamma_{i}(\\xi)=\\sum_{j=1}^{d}\\frac{\\partial}{\\partial\\xi_{j}}(D_{ij}(\\xi)+Q_{% ij}(\\xi)) $ .", "The diffusion $ D(\\xi) $ and curl $ Q(\\xi) $ matrices can take various forms and the choice of the matrices will affect the rate of convergence of the sampler.", "For example, for the SGHMC algorithm, we have $ H(\\xi)=U(\\theta)+\\frac{1}{2}v^{T}v $ , $ D(\\xi)=\\begin{pmatrix}0&0\\\\ 0&C\\end{pmatrix} $ for some positive semi-definite matrix $ C $ , and $ Q(\\xi)=\\begin{pmatrix}0&-I\\\\ I&0\\end{pmatrix} $ .", "For the SGRLD algorithm, we have $ \\xi=\\theta $ , $ H(\\xi)=U(\\theta) $ , $ D(\\xi)=G(\\theta)^{-1} $ , $ Q(\\xi)=0 $ , where $ G(\\theta) $ is the Fisher information matrix of the posterior distribution.", "By rescaling the parameter updates according to geometry information of the manifold, SGRLD generally converges faster than SGLD.", "However, calculating the Fisher information matrix and its inverse can be time consuming when the dimension of $ \\theta $ is high and the total sample size $ N $ is large.", "To address this issue, pSGLD approximates $ G(\\theta) $ using a diagonal matrix and sequentially updates the approximator using the current gradient information.", "To be more precise, it is given by \\newline <equation> $ \\begin{split} G(\\theta_{t+1})&={\\rm diag}(1\\oslash(% \\lambda\\bf{1}+\\sqrt{V(\\theta_{t+1})})),\\\\  V(\\theta_{t+1})&=\\beta V(\\theta_{t})+(1-\\beta)% \\nabla_{\\theta}\\tilde{U}(\\theta_{t})\\odot\\nabla_{\\theta}\\tilde{U}(\\theta_{t}),% \\end{split} $ </equation> where $ \\lambda $ denotes a small constant, $ \\odot $ and $ \\oslash $ represent element-wise vector product and division, respectively.", "\\newline  </section>"], ["<section> <title> 3 Stochastic Gradient Langevin Dynamics with Adaptive Drifts </title>  Motivated by the observations that the stochastic gradient $ \\nabla_{\\theta}\\tilde{U}(\\theta) $ used in SGLD is not necessarily unbiased and that the past gradients can be used to enhance escape from saddle points for SGD, we propose a class of adaptive SGLD algorithms, where the past gradients are used to accelerate the convergence of the sampler by forming a bias to the drift at each iteration.", "A general form of the adaptive SGLD algorithm is given by \\newline <equation> $ \\theta_{t+1}=\\theta_{t}-\\epsilon_{t+1}(\\nabla_{\\theta}\\tilde{U}(\\theta_{t})+aA% _{t})+\\sqrt{2\\epsilon_{t+1}\\tau}\\eta_{t+1}, $ </equation> where $ A_{t} $ is the adaptive bias term, $ a $ is called the bias factor, and $ \\eta_{t+1}\\sim N(0,I_{d}) $ .", "Two adaptive SGLD algorithms are given in what follows.", "In the first algorithm, the bias term is constructed based on the momentum algorithm [@bib:Qian1999] ; and in the second algorithm, the bias term is constructed based on the Adam algorithm [@bib:KingmaB2015] .", "\\newline <subsection> <title> 3.1 Momentum SGLD </title> It is known that SGD has trouble in navigating ravines, i.e., the regions where the energy surface curves much more steep in one dimension than in another, which are common around local energy minima [@bib:Ruder2016,Sutton1986] .", "In this scenario, SGD oscillates across the slopes of the ravine while making hesitant progress towards the local energy minima.", "To accelerate SGD in the relevant direction and dampen oscillations, the momentum algorithm [@bib:Qian1999] updates the moving direction at each iteration by adding a fraction of the moving direction of the past iteration, the so-called momentum term, to the current gradient.", "By accumulation, the momentum term increases updates for the dimensions whose gradients pointing in the same directions and reduces updates for the dimensions whose gradients change directions.", "As a result, the oscillation is reduced and the convergence is accelerated.", "\\newline <float> MSGLD \\ Input: Data $ \\{x_{i}\\}_{i=1}^{N} $ , subsample size $ n $ , smoothing factor $ 0<\\beta_{1}<1 $ , bias factor $ a $ , temperature $ \\tau $ , and learning rate $ \\epsilon $ ; \\ \\ Initialization: $ \\theta_{0} $ from an appropriate distribution, and $ m_{0}=0 $ .", "\\ \\ for $ i=1,2,\\dots, $ do \\ \\ Draw a mini-batch of data $ \\{x_{j}^{*}\\}_{j=1}^{n} $ , and calculate \\ \\ $ \\theta_{t+1}=\\theta_{t}-\\epsilon(\\nabla\\tilde{U}(\\theta_{t})+am_{t})+e_{t+1} $ , \\ \\ $ m_{t}=\\beta_{1}m_{t-1}+(1-\\beta_{1})\\nabla\\tilde{U}(\\theta_{t-1}) $ , where $ e_{t+1}\\sim N(0,2\\tau\\epsilon I_{d}) $ , and $ d $ is the dimension of $ \\theta $ .", "\\ \\ end for \\ </float> \\newline As an analogy of the momentum algorithm in stochastic optimization, we propose the so-called momentum SGLD (MSGLD) algorithm, where the momentum is calculated as an exponentially decaying average of past stochastic gradients and added as a bias term to the drift of SGLD.", "The resulting algorithm is depicted in Algorithm [@ref:LABEL:alg:example] , where a constant learning rate $ \\epsilon $ is considered for simplicity.", "However, as mentioned in the Appendix, the algorithm also works for the case that the learning rate decays with iterations.", "The convergence of the algorithm is established in Theorem [@ref:LABEL:them:1] , whose proof is given in the Appendix.", "\\newline <theorem> Theorem 3.1 (Ergodicity of MSGLD) Suppose the conditions (A.1)-(A.5) hold (given in Appendix), $ \\beta_{1}\\in(0,1] $ is a constant, and the learning rate $ \\epsilon $ is sufficiently small.", "Then for any smooth function $ \\phi(\\theta) $ , \\newline <equation> $ \\frac{1}{L}\\sum_{k=1}^{L}\\phi(\\theta_{k})-\\int_{\\Theta}\\phi(\\theta)\\pi_{*}(% \\theta)d\\theta\\stackrel{{\\scriptstyle p}}{{\\to}}0,\\quad\\mbox{as $L\\to\\infty$}, $ </equation> where $ \\pi_{*} $ denotes the posterior distribution of $ \\theta $ , and $ \\stackrel{{\\scriptstyle p}}{{\\to}} $ denotes convergence in probability.", "\\newline </theorem> Algorithm [@ref:LABEL:alg:example] contains a few parameters, including the subsample size $ n $ , smoothing factor $ \\beta_{1} $ , bias factor $ a $ , temperature $ \\tau $ , and learning rate $ \\epsilon $ .", "Among these parameters, $ n $ , $ \\tau $ and $ \\epsilon $ are shared with SGLD and can be set as in SGLD.", "Refer to [@bib:Nagapetyan2017] and [@bib:NemethF2019] for more discussions on their settings.", "The smoothing factor $ \\beta_{1} $ is a constant, which is typically set to 0.9.", "The bias factor $ a $ is also a constant, which is typically set to 1 or a slightly large value.", "\\newline </subsection> <subsection> <title> 3.2 Adam SGLD </title> The Adam algorithm [@bib:KingmaB2015] has been widely used in deep learning, which typically converges much faster than SGD.", "Recently, [@bib:StaibRK2019] showed that Adam can be viewed as a preconditioned SGD algorithm, where the preconditioner is estimated in an on-line manner and it helps escape saddle points by rescaling the stochastic gradient noise to be isotropic near stationary points.", "\\newline <float> ASGLD \\ Input: Data $ \\{x_{i}\\}_{i=1}^{N} $ , subsample size $ n $ , smoothing factors $ \\beta_{1} $ and $ \\beta_{2} $ , bias factor $ a $ , temperature $ \\tau $ , and learning rate $ \\epsilon $ ; \\ \\ Initialization: $ \\theta_{0} $ from appropriate distribution, $ m_{0}=0 $ and $ V_{0}=0 $ ; \\ \\ for $ i=1,2,\\dots, $ do \\ \\ Draw a mini-batch of data $ \\{x_{j}^{*}\\}_{j=1}^{n} $ , and calculate \\ \\ $ \\theta_{t+1}=\\theta_{t}-\\epsilon(\\nabla\\tilde{U}(\\theta_{t})+am_{t}\\oslash% \\sqrt{V_{t}+\\lambda{\\bf 1}})+e_{t+1}, $ \\ \\ $ m_{t}=\\beta_{1}m_{t-1}+(1-\\beta_{1})\\nabla\\tilde{U}(\\theta_{t-1}) $ , \\ \\ $ V_{t}=\\beta_{2}V_{t-1}+(1-\\beta_{2})\\nabla\\tilde{U}(\\theta_{t-1})\\odot\\nabla% \\tilde{U}(\\theta_{t-1}) $ , where $ \\lambda $ is a small constant added to avoid zero-divisors, $ e_{t+1}\\sim N(0,2\\tau\\epsilon I_{d}) $ , and $ d $ is the dimension of $ \\theta $ .", "\\ \\ end for \\ </float> \\newline Motivated by this result, we propose the so-called Adam SGLD (ASGLD) algorithm.", "Ideally, we would construct the adaptive bias term as follows: \\newline <equation> $ \\begin{split} m_{t}&=\\beta_{1}m_{t-1}+(1-\\beta_{1})% \\nabla\\tilde{U}(\\theta_{t-1}),\\\\ \\tilde{V}_{t}&=\\beta_{2}\\tilde{V}_{t-1}+(1-\\beta_{2}% )\\tilde{U}(\\theta_{t-1})\\tilde{U}(\\theta_{t-1})^{T},\\\\ \\tilde{A}_{t}&=\\tilde{V}_{t}^{-1/2}m_{t},\\end{split} $ </equation> where $ \\beta_{1} $ and $ \\beta_{2} $ are smoothing factors for the first and second moments of stochastic gradients, respectively.", "Since $ \\tilde{V}_{t} $ can be viewed as an approximator of the true second moment matrix $ E(\\nabla_{\\theta}\\tilde{U}(\\theta_{t-1})\\nabla_{\\theta}\\tilde{U}(\\theta_{t-1})% ^{T}) $ at iteration $ t-1 $ , $ \\tilde{A}_{t} $ can viewed as the rescaled momentum which is isotropic near stationary points.", "If the bias factor $ a $ is chosen appropriately, ASGLD is expected to converge very fast.", "In particular, the bias term may guide the sampler to converge to a global optimal region quickly, similar to Adam in optimization.", "However, when the dimension of $ \\theta $ is high, calculation of $ \\tilde{V}_{t} $ and $ \\tilde{V}_{t}^{-1/2} $ can be time consuming.", "To accelerate computation, we propose to approximate $ \\tilde{V}_{t} $ using a diagonal matrix as in pSGLD.", "This leads to Algorithm [@ref:LABEL:alg:example2] .", "The convergence of the algorithm is established in Theorem [@ref:LABEL:them:2] , whose proof is given in the Appendix.", "\\newline <theorem> Theorem 3.2 (Ergodicity of ASGLD) Suppose the conditions (A.1)-(A.5) hold (given in Appendix), $ \\beta_{1}^{2}<\\beta_{2} $ are two constants between 0 and 1, and the learning rate $ \\epsilon $ is sufficiently small.", "Then for any smooth function $ \\phi(\\theta) $ , \\newline <equation> $ \\frac{1}{L}\\sum_{k=1}^{L}\\phi(\\theta_{k})-\\int_{\\Theta}\\phi(\\theta)\\pi_{*}(% \\theta)d\\theta\\stackrel{{\\scriptstyle p}}{{\\to}}0,\\quad\\mbox{as $L\\to\\infty$}, $ </equation> where $ \\pi_{*} $ denotes the posterior distribution of $ \\theta $ , and $ \\stackrel{{\\scriptstyle p}}{{\\to}} $ denotes convergence in probability.", "\\newline </theorem> Compared to Algorithm [@ref:LABEL:alg:example] , ASGLD contains one more parameter, $ \\beta_{2} $ , which works as the smoothing factor for the second moment term and is suggested to take a value of 0.999 in this paper.", "\\newline </subsection> <subsection> <title> 3.3 Other Adaptive SGLD Algorithms </title> In addition to the Momentum and Adam algorithms, other optimization algorithms, such as AdaMax [@bib:KingmaB2015] and Adadelta [@bib:AdaDelta2012] , can also be incorporated into SGLD to accelerate its convergence.", "Other than the bias term, the past gradients can also be used to construct an adaptive preconditioner matrix in a similar way to pSGLD.", "Moreover, the adaptive bias and adaptive preconditioner matrix can be used together to accelerate the convergence of SGLD.", "\\newline </subsection>  </section>"], ["<section> <title> 4 Illustrative Examples </title>  Before applying the adaptive SGLD algorithms to DNN models, we first illustrate their performance on three low-dimensional examples.", "The first example is a multivariate Gaussian distribution with high correlation values.", "The second example is a multi-modal distribution, which mimics the scenario with multiple local energy minima.", "The third example is more complicated, which mimics the scenario with long narrow ravines.", "\\newline <subsection> <title> 4.1 A Gaussian distribution with high correlation values </title> Suppose that we are interested in drawing samples from $ \\pi(\\theta) $ , a Gaussian distribution with the mean zero and the covariance matrix $ \\Sigma=\\begin{pmatrix}1&0.9\\\\ 0.9&1\\end{pmatrix} $ .", "For this example, we have $ \\nabla_{\\theta}U(\\theta)=\\Sigma^{-1}\\theta $ , and set $ \\nabla\\tilde{U}(\\theta)=\\nabla U(\\theta)+e $ in simulations, where $ \\theta=(\\theta_{1},\\theta_{2})^{T}\\in\\mathbb{R}^{2} $ and $ e\\sim N(0,I_{2}) $ .", "For ASGLD, we set $ \\tau=1 $ , $ a=0.1 $ , $ \\epsilon=0.1 $ , $ \\beta_{1}=0.9 $ and $ \\beta_{2}=0.999 $ .", "For MSGLD, we set $ \\tau=1 $ , $ a=0.01 $ , $ \\beta_{1}=0.9 $ and $ \\epsilon=0.1 $ .", "For comparison, SGLD was also run for this example with the same learning rate $ \\epsilon=0.1 $ .", "Figure [@ref:LABEL:correlated] shows that both ASGLD and MSGLD work well for this example, where the left panel shows that they can produce the same accurate estimate as SGLD for the covariance matrix as the number of iterations becomes large.", "\\newline </subsection> <subsection> <title> 4.2 A multi-modal distribution </title> The target distribution is a 2-dimensional 5-component mixture Gaussian distribution, whose density function is given by $ \\pi(\\theta)=\\sum_{i=1}^{5}\\frac{1}{10\\pi}\\exp(-\\|\\theta-\\mu_{i}\\|^{2}) $ , where $ \\mu_{1}=(-3,-3)^{T},\\mu_{2}=(-3,0)^{T},\\mu_{3}=(0,0)^{T},\\mu_{4}=(3,0)^{T},\\mu% _{5}=(3,3)^{T} $ .", "For this example, we considered the natural gradient variational inference (NGVI) algorithm [@bib:Kahn2019] , which is known to converge very fast in the variational inference field, as the baseline algorithm for comparison.", "\\newline For adaptive SGLD method, both ASGLD and MSGLD were applied to this example.", "We set $ \\nabla_{\\theta}\\tilde{U}(\\theta)=\\nabla U(\\theta)+e $ , where $ e\\sim N(0,I_{2}) $ and $ U(\\theta)=-\\log\\pi(\\theta) $ .", "For a fair comparison, each algorithm was run in 6.0 CPU minutes.", "The numerical results were summarized in Figure [@ref:LABEL:multimodal1] , which shows the contour of the energy function and its estimates by NGVI, MSGLD and ASGLD.", "The plots indicate that MSGLD and ASGLD are better at exploring the multi-modal distributions than NGVI.", "\\newline </subsection> <subsection> <title> 4.3 A distribution with long narrow energy ravines </title> Consider a nonlinear regression \\newline <equation> $ y=f_{\\theta}(x)+\\epsilon,\\quad\\epsilon\\sim N(0,1), $ </equation> where $ x\\sim Unif[-2,4] $ , $ \\theta=(\\theta_{1},\\theta_{2})^{T}\\in\\mathbb{R}^{2} $ , and $ f_{\\theta}(x)=(x-1)^{2}+2\\sin(\\theta_{1}x)+\\frac{1}{30}\\theta_{1}+\\cos(\\theta_% {2}x-1)-\\frac{1}{20}\\theta_{2} $ .", "As $ \\theta $ increases, the function $ f_{\\theta}(x) $ fluctuates more severely.", "Figure [@ref:LABEL:ravine1] depicts the regression, where we set $ \\theta_{1}=20 $ and $ \\theta_{2}=10 $ .", "Since the random error $ \\epsilon $ is relatively large compared to the local fluctuation of $ f_{\\theta}(x) $ , i.e., $ 2\\sin(\\theta_{1}x)+\\frac{1}{30}\\theta_{1}+\\cos(\\theta_{2}x-1)-\\frac{1}{20}% \\theta_{2} $ , identification of the exact values of $ (\\theta_{1},\\theta_{2}) $ can be very hard, especially when the subsample size $ n $ is small.", "\\newline From this regression, we simulated 5 datasets with $ (\\theta_{1},\\theta_{2})=(20,10) $ independently.", "Each dataset consists of 10,000 samples.", "To conduct Bayesian analysis for the problem, we set the prior distribution: $ \\theta_{1}\\sim N(0,1) $ and $ \\theta_{2}\\sim N(0,1) $ , which are a priori independent.", "This choice of the prior distribution makes the problem even harder, which discourages the convergence of the posterior simulation to the true value of $ \\theta $ .", "Instead, it encourages to estimate $ f_{\\theta}(x) $ by the global pattern $ (x-1)^{2} $ .", "\\newline Both ASGLD and MSGLD were run for each of the 5 datasets.", "Each run consisted of 30,000 iterations, where the first 10,000 iterations were discarded for the burn-in process and the samples generated from the remaining 20,000 iterations were averaged as the Bayesian estimate of $ \\theta $ .", "In the simulations, we set the subsample size $ n=100 $ .", "The settings of other parameters are given in the Appendix."]], "target": "Table shows the Bayesian estimates of $ \\theta $ produced by the two algorithms in each of the five runs. The MSGLD estimate converged to the true value in all five runs, while the ASGLD estimates converged to the true value in four of five runs. For comparison, SGLD, SGHMC and pSGLD were also applied to this example with the settings given in the Appendix."}, {"tabular": ["  criterion  &  no regularization  &  regular- $ \\ell_{1} $  &  reweighted- $ \\ell_{1} $ ", " SDR $ {}_{S} $  &  23.5  &  20.9  &  25.8 ", " SIR $ {}_{S} $  &  64.9  &  25.7  &  35.4 ", " SNR $ {}_{S} $  &  23.5  &  37.0  &  30.6 ", " SAR $ {}_{S} $  &  51.1  &  22.9  &  28.5  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Multichannel data are often encountered in scientific fields as different as geophysics, remote sensing, astrophysics or biomedical signal processing.", "In astrophysics for instance, the data are usually made of non-negative spectra measured at different locations.", "Each of these spectra is a mixture of several elementary source spectra which are characteristic of specific physical entities or sources.", "Recovering these sources is essential in order to identify the underlying components.", "Still, both the sources and the way they are mixed up together may be unknown.", "The aim of non-negative blind source separation (BSS) or non-negative matrix factorization (NMF) is to recover both the spectra and the mixtures.", "\\newline <subsection> <title> 1.1 Notations </title> The following notations will be used throughout the article: \\newline <list> \\ $ m $ is the number of measurements.", "\\newline \\ \\ $ n $ is the number of samples of the spectra/sources.", "\\newline \\ \\ $ r $ is the number of sources.", "\\newline \\ \\ $ \\mathbf{X} $ and all bold capital letters are matrices.", "The value of element $ (i,j) $ is called $ \\mathbf{X}_{i,j} $ , row $ i $ is $ \\mathbf{X}_{i,\\cdot} $ and column $ j $ is $ \\mathbf{X}_{\\cdot,j} $ .", "\\newline \\ \\ $ \\mathbf{Y}\\in\\mathbb{R}^{m\\times n} $ is the data matrix in which each row is a measurement.", "\\newline \\ \\ $ \\mathbf{S}\\in\\mathbb{R}^{r\\times n} $ the unknown source matrix in which each row is a spectrum/source.", "\\newline \\ \\ $ \\mathbf{A}\\in\\mathbb{R}^{m\\times r} $ the unknown mixing matrix which defines the contribution of each source to the measurements.", "\\newline \\ \\ $ \\mathbf{Z}\\in\\mathbb{R}^{m\\times n} $ is an unknown noise matrix accounting for instrumental noise and/or model imperfections.", "\\newline \\ \\ $ \\|\\mathbf{X}\\|_{p}=\\sqrt[p]{\\sum_{i,j}|\\mathbf{X}_{i,j}|^{p}} $ (Frobenius norm for $ p=2 $ ).", "\\newline \\ \\ $ \\odot $ and $ \\oslash $ are respectively the elementwise matrix multiplication (Hadamard product) and division.", "\\newline \\ \\ $ \\mathbf{X}\\geq\\mathbf{Y} $ means $ \\mathbf{X}_{i,j}\\geq\\mathbf{Y}_{i,j},\\forall(i,j) $ .", "\\newline \\ \\ $ i_{\\mathcal{C}} $ is the characteristic function of the set $ \\mathcal{C} $ .", "It is defined as follows: \\newline <equationgroup> <equation> $  i_{\\mathcal{C}}:x\\mapsto\\begin{cases}\\hidden@noalign\\textstyle 0% \\text{if }x\\in\\mathcal{C},\\\\ \\hidden@noalign\\textstyle+\\infty\\text{otherwise}.\\end{cases} $ $  i_{\\mathcal{C}}:x\\mapsto $ $ \\begin{cases}\\hidden@noalign\\textstyle 0\\text{if }x\\in\\mathcal% {C},\\\\ \\hidden@noalign\\textstyle+\\infty\\text{otherwise}.\\end{cases} $ </equation> </equationgroup> \\newline \\ \\ $ \\mathbf{W}\\in\\mathbb{R}^{p\\times n} $ is a matrix transform from $ \\mathbb{R}^{n} $ to $ \\mathbb{R}^{p} $ , $ p $ being the dimension of the transformed domain.", "In this paper, we use transforms with $ p\\geq n $ such as orthonormal and redundant wavelets.", "\\newline \\ \\ Signals in the transformed domain are marked with the subscript $ w $ .", "Since the sources in $ \\mathbf{S} $ are row vectors, their transforms are provided by $ \\mathbf{S}_{w}=\\mathbf{S}\\mathbf{W}^{T} $ .", "When several subscripts are necessary, they are separated by the symbol $ | $ , for instance, the $ j^{\\text{th}} $ element of $ x_{w} $ is denoted $ x_{w|j} $ .", "\\newline \\ </list> \\newline </subsection> <subsection> <title> 1.2 Non-negative Matrix Factorization </title> In BSS, the instantaneous linear mixture model assumes that the measurements are linear mixtures of sources plus some noise.", "With the above notations, it can be written in the following matrix form: \\newline <equation> $ \\mathbf{Y}=\\mathbf{A}\\mathbf{S}+\\mathbf{Z}. $ </equation> Yet, it is common to have some prior information about the sources $ \\mathbf{S} $ and the mixing matrix $ \\mathbf{A} $ .", "In the context of Non-negative Matrix Factorization (NMF, [@bib:Paatero_94_Positivematrixfactorization,Lee_99_Learningpartsobjects] ), the entries of both the mixture coefficients $ \\mathbf{A} $ and the sources $ \\mathbf{S} $ are assumed to be non-negative.", "This assumption arises naturally in many applications such as mass-spectrometry [@bib:Dubroca_12_WeightedNMFhigh] , text mining [@bib:Berry_05_EmailSurveillanceUsing] , clustering [@bib:Kim_08_SparseNonnegativeMatrix] , audio processing [@bib:Fevotte_09_Nonnegativematrixfactorization] or hyperspectral imaging [@bib:Jia_09_ConstrainedNonnegativeMatrix] .", "Indeed, spectra are often measured as intensities (electromagnetic spectra for instance) or in terms of a whole number of elements (molecules in mass-spectrometry) which are necessarily non-negative.", "The mixture coefficients are usually function of the relative concentrations of the observed physical entities, which are necessarily non-negative as well.", "Under an i.i.d.", "Gaussian noise assumption, the NMF problem is formulated as: \\newline <equation> $ \\underset{\\mathbf{A}\\geq\\mathbf{0},\\mathbf{S}\\geq\\mathbf{0}}{\\text{argmin}}% \\|\\mathbf{Y}-\\mathbf{A}\\mathbf{S}\\|_{2}^{2}. $ </equation> The most well-known NMF algorithms are the multiplicative updates [@bib:Lee_99_Learningpartsobjects,Lee_01_Algorithmsnonnegative] and the alternated least square (ALS, [@bib:Paatero_94_Positivematrixfactorization] ).", "\\newline </subsection> <subsection> <title> 1.3 Additional Priors in NMF </title> Finding an optimal solution for ( [@ref:LABEL:eq:NMF] ) is very complex since this problem is NP-Hard [@bib:Vavasis_09_ComplexityNonnegativeMatrix] .", "Because there can be many local minima, and because the mixture model may be imperfect, adding other priors is usually beneficial.", "Indeed, they can help privileging minima with desired properties.", "A source such as the NMR (Nuclear Magnetic Resonance) spectrum displayed in figure [@ref:LABEL:fig:lactose] shows some structural features which have been exploited in several NMF algorithms.", "\\newline <paragraph> <title> Continuity of the sources </title> In [@bib:Zdunek_07_BlindImageSeparation] , Zdunek & Cichocki proposed to recover smooth and therefore continuous sources by adding a smoothing term to the problem in Equation ( [@ref:LABEL:eq:NMF] ): \\newline <equation> $ \\underset{\\mathbf{A}\\geq\\mathbf{0},\\mathbf{S}\\geq\\mathbf{0}}{\\text{argmin}}% \\|\\mathbf{Y}-\\mathbf{A}\\mathbf{S}\\|_{2}^{2}+\\alpha U_{\\delta}(\\mathbf{S}), $ </equation> where $ U_{\\delta} $ is defined as the Green potential function: \\newline <equation> $ U_{\\delta}(\\mathbf{S})=\\delta\\sum_{i=1}^{r}\\sum_{j=2}^{n}\\text{log}\\left(\\text% {cosh}\\left(\\frac{\\mathbf{S}_{i,j}-\\mathbf{S}_{i,j-1}}{\\delta}\\right)\\right).", "$ </equation> The minimization is then carried out using multiplicative updates.", "The regularization penalizes large differences between a sample and its neighbors and therefore tends to privilege smooth estimates of the sources.", "Still, tuning the parameters $ \\delta $ and $ \\alpha $ can be cumbersome and this regularization is not appropriate for spiky signals, such as the spectrum in figure [@ref:LABEL:fig:lactose] .", "A toolbox implementing this algorithm is available online .", "Other types of smoothness regularizations have also been studied, such as the squared differences such as such as in [@bib:Virtanen_07_MonauralSoundSource] .", "\\newline </paragraph> <paragraph> <title> Sparsity of the sources </title> In the wide sense, a sparse signal is a signal which concentrates its energy into only a few large non-zero coefficients, or can be well approximated in such a way.", "In many applications sources can be both sparse and non-negative, such as in mass or nuclear magnetic resonance (NMR) spectrometry for instance.", "The source in figure [@ref:LABEL:fig:lactose] is indeed sparse since it is composed of few large coefficients and many close to null coefficients.", "Algorithms have then been designed to recover such signals in NMF and stressed that sparsity could indeed help perform more relevant factorizations [@bib:Kim_08_SparseNonnegativeMatrix,Eggert_04_Sparsecodingand,Hoyer_02_Nonnegativesparse] .", "\\newline In [@bib:Hoyer_02_Nonnegativesparse,Rapin_13_SparseandNon,Cichocki_07_HierarchicalALSAlgorithms] , sparsity is enforced by further constraining the $ \\ell_{1} $ norm of the sources as follows: \\newline <equation> $ \\underset{\\mathbf{A}\\geq\\mathbf{0},\\mathbf{S}\\geq\\mathbf{0}}{\\text{argmin}}% \\|\\mathbf{Y}-\\mathbf{A}\\mathbf{S}\\|_{2}^{2}+\\lambda\\|\\mathbf{S}\\|_{1}. $ </equation>", "In [@bib:Hoyer_02_Nonnegativesparse] , Hoyer uses a gradient descent for $ \\mathbf{A} $ and a multiplicative update procedure for $ \\mathbf{S} $ .", "In sparse HALS [@bib:Cichocki_07_HierarchicalALSAlgorithms,Cichocki_09_NonnegativeMatrixand] columns of $ \\mathbf{A} $ and rows of $ \\mathbf{S} $ are updated one by one, which leads to simple and efficient updates.", "A recent accelerated implementation of HALS [@bib:Gillis_12_AcceleratedMultiplicativeUpdates,Gillis_12_SparseandUnique] has been introduced.", "In this version of HALS, the parameter $ \\lambda $ is automatically handled in order to obtain a user-defined sparsity rate \u2014defined as the ratio of coefficients smaller than $ 10^{-6} $ times the largest one; it is available online .", "In [@bib:Virtanen_07_MonauralSoundSource] , the authors also used this regularization along with a Kullback-Leibler divergence as data fidelity term.", "In non-negative Generalized Morphological Component Analysis (nGMCA, [@bib:Rapin_13_SparseandNon] ), the authors used proximal techniques in order to alternately and optimally estimate $ \\mathbf{A} $ and $ \\mathbf{S} $ , with an automated parameter tuning.", "This work stands for the basis of the current paper and is further described in Section \u00a7 [@ref:LABEL:sec:transformed_nGMCA] .", "An implementation of the nGMCA algorithm is available online .", "\\newline Other forms of regularizations have also been explored to enforce the sparsity of the sources in the direct domain.", "In [@bib:Kim_08_SparseNonnegativeMatrix] and [@bib:Zdunek_07_Nonnegativematrixfactorization] , the authors have proposed the use of the penalization $ \\sum_{j=1}^{n}\\|\\mathbf{S}_{\\cdot,j}\\|_{1}^{2} $ .", "This penalization tends to favor solutions where a single source dominates at each sample.", "In [@bib:Hoyer_04_Nonnegativematrix] , Hoyer proposed to constrain a level of sparseness for each row of $ \\mathbf{S} $ .", "For a vector $ x\\in\\mathbb{R}^{n} $ , the sparseness value goes from 1 when $ x $ is perfectly sparse \u2014only 1 active coefficient\u2014 to 0 when all coefficients are active, with the same value.", "It is defined as follows: \\newline <equation> $ \\text{sparseness}(x)=\\frac{\\sqrt{n}-\\frac{\\|x\\|_{1}}{\\|x\\|_{2}}}{\\sqrt{n}-1}. $ </equation> \\newline If these algorithms are able to deal with spiky data, they do not take into account the continuity of source [@ref:LABEL:fig:lactose] .", "None of the aforementioned NMF algorithms is therefore able to use all the prior information about the sources.", "In order to better model this kind of signals, one can express sparsity in a different domain.", "Indeed, the sparsity of a signal depends on the basis or dictionary of waveforms in which it is expressed (see [@bib:Elad_10_SparseandRedundant] ).", "In a nutshell, bases that best capture the geometric structure of a signal will yield sparser representations of this signal.", "Sparsity-enforcing priors in transformed domains have been used with success to solve a very wide range of inverse problems (see [@bib:Starck_10_SparseImageand] and references therein).", "In NMF however, few algorithms have been proposed to enforce sparsity in a different basis or dictionary, because of the difficulty in dealing with two different priors in two different domains.", "To our knowledge, only [@bib:Jiang_12_Bregmaniterationalgorithm] has attempted to impose sparsity in a transformed domain.", "However this study is limited to imposing sparsity in an orthonormal basis.", "Furthermore, the estimation of $ \\mathbf{S} $ is not carried out in an optimal way, which can clearly lead to sub-optimal performances as advocated in [@bib:Rapin_13_SparseandNon] .", "\\newline </paragraph> </subsection> <subsection> <title> 1.4 Contribution </title> The aim of this article is to introduce a novel NMF algorithm enforcing the sparsity of the sources in a transformed domain, based on the nGMCA framework introduced in [@bib:Rapin_13_SparseandNon] and the preliminary works in [@bib:Rapin_13_SparseRedundantFormulations,Rapin_13_SparseRegularizationsand] .", "The nGMCA framework, which will be detailed in Section \u00a7 [@ref:LABEL:sec:nGMCA] , has been shown to yield efficient separation performance while providing an effective rule of thumb on how to set the sparsity parameter.", "However, it was so far limited to imposing sparsity in the direct domain.", "\\newline In Section \u00a7 [@ref:LABEL:sec:transformed_nGMCA] , the nGMCA algorithm is extended to tackle sparsity in general transformed domains, either in orthonormal or redundant dictionary of waveforms.", "We further tackle the most common types of sparse priors in a transformed domain, namely the synthesis and the analysis formulations which, to the best of our knowledge, have never been compared in the context of NMF.", "Numerical comparisons with state-of-the-art NMF algorithms on noisy mixtures of simulated NMR spectra are carried out.", "\\newline $ \\ell_{1} $ -type priors yield estimation biases which can generally be neglected when the sources to be retrieved are very sparse ( e.g. NMR and mass spectra).", "However for mildly sparse signals, such as natural images, the estimation bias related to the use of the $ \\ell_{1} $ norm hampers dramatically the performance.", "To alleviate this major issue, Section \u00a7 [@ref:LABEL:sec:reweighted-L1] presents an extension of the nGMCA algorithm which handles reweighted sparse priors [@bib:Candes_07_EnhancingSparsityby] .", "Numerical experiments are carried out on natural images which show that the proposed algorithm yields enhanced separation performance.", "\\newline </subsection>  </section>"], ["<section> <title> 2 Presentation of nGMCA </title>  <float> : standard nGMCA \\ $ \\mathbf{Y} $ , $ K $ .", "\\ \\ initialize $ \\mathbf{A}^{(0)} $ , $ \\mathbf{S}^{(0)} $ and $ \\mathbf{\\Lambda}^{(1)} $ .", "\\ \\ for $ k\\leftarrow 1,K $ do \\ \\ Normalize the columns of $ \\mathbf{A}^{(k-1)} $ .", "\\ \\ $ \\mathbf{S}^{(k)}\\leftarrow\\underset{\\mathbf{S}\\geq\\mathbf{0}}{\\text{argmin}}{% }\\frac{1}{2}\\|\\mathbf{Y}-\\mathbf{A}^{(k-1)}\\mathbf{S}\\|_{2}^{2}+\\|\\mathbf{% \\Lambda}^{(k)}\\odot\\mathbf{S}\\|_{1} $ .", "\\ \\ $ \\mathbf{A}^{(k)}\\leftarrow\\underset{\\mathbf{A}\\geq\\mathbf{0}}{\\text{argmin}}{% }\\frac{1}{2}\\|\\mathbf{Y}-\\mathbf{A}\\mathbf{S}^{(k)}\\|_{2}^{2} $ .", "\\ \\ Select $ \\mathbf{\\Lambda}^{(k+1)}\\leq\\mathbf{\\Lambda}^{(k)} $ .", "\\ \\ end for \\ \\ return $ \\mathbf{A}^{(K)},\\mathbf{S}^{(K)} $ .", "\\ </float> \\newline <subsection> <title> 2.1 Framework </title> nGMCA [@bib:Rapin_13_SparseandNon] was designed as an extension of GMCA [@bib:Bobin_07_Sparsityandmorphological,Bobin_08_BlindSourceSeparation] to tackle NMF as formulated in problem ( [@ref:LABEL:eq:sparseNMF] ).", "The main steps of the algorithm are provided in Algorithm [@ref:LABEL:alg:nGMCA] .", "Each subproblem (lines 4 and 5) is solved at optimality, since it was observed through extensive experiments that optimally managing the priors enhances the separation performances (see [@bib:Rapin_13_SparseandNon] ).", "\\newline An important feature of this algorithm is the decreasing $ \\ell_{1} $ regularization strategy.", "This kind of technique, inspired from simulated annealing, is also used in NMF with a decreasing $ \\ell_{2} $ or $ \\ell_{1,2} $ regularizations [@bib:Zdunek_07_Nonnegativematrixfactorization,Cichocki_07_RegularizedAlternatingLeast] .", "In nGMCA, it consists in starting with large thresholds $ \\mathbf{\\Lambda} $ so that the algorithm first estimates the mixing matrix from the entries of the sources which have the highest amplitude.", "Assuming that these large coefficients are likely to belong to only one source, they can indeed provide a descent separation.", "Next, the thresholds are decreased at each iteration in order to refine the solution.", "The final thresholds are set independently for each source at $ \\tau_{\\sigma}^{\\infty}\\sigma^{\\text{grad}}_{i} $ , where $ \\sigma^{\\text{grad}}_{i} $ is an online estimate of the noise level in the $ i^{\\text{th}} $ row of the gradient.", "This prevents most of the noise from altering the solution.", "The decrease of the thresholds is chosen to be linear, decreasing each threshold by a close to constant amount down to $ \\tau_{\\sigma}^{\\infty}\\sigma^{\\text{grad}}_{i} $ .", "\\newline </subsection> <subsection> <title> 2.2 Convergence Analysis </title> In [@bib:Rapin_13_SparseandNon] , in order to allow the convergence of the algorithm, $ \\mathbf{\\Lambda} $ is kept fixed during the last iterations.", "An additional constraint is also added to the update of $ \\mathbf{A} $ (line 5 of Algorithm [@ref:LABEL:alg:nGMCA] ) in order to thwart the scale indeterminacy: \\newline <equation> $ \\text{5:}\\mathbf{A}^{(k)}\\leftarrow\\underset{\\mathbf{A}\\geq% \\mathbf{0},\\|\\mathbf{A}_{\\cdot,j}\\|^{2}_{2}\\leq 1,\\forall j}{\\text{argmin}}% \\frac{1}{2}\\|\\mathbf{Y}-\\mathbf{A}\\mathbf{S}^{(k)}\\|_{2}^{2}. $ </equation> \\newline The full cost function of the problem it aims at solving is then: \\newline <equation> $ F(\\mathbf{A},\\mathbf{S})=\\|\\mathbf{Y}-\\mathbf{A}\\mathbf{S}\\|_{2}^{2}+i_{\\|% \\mathbf{A}_{\\cdot,j}\\|^{2}_{2}\\leq 1,\\forall j}(\\mathbf{A})+i_{\\cdot\\geq% \\mathbf{0}}(\\mathbf{A})+\\|\\mathbf{\\Lambda}\\odot\\mathbf{S}\\|_{1}+i_{\\cdot\\geq% \\mathbf{0}}(\\mathbf{S}).", "$ </equation> The minimization of this cost function is carried out here using block coordinate descent, i.e. minimizing alternately the subproblems in $ \\mathbf{A} $ and $ \\mathbf{S} $ .", "For this type of algorithm, Tseng [@bib:Tseng_01_ConvergenceBlockCoordinate] provided convergence conditions when the cost function is not differentiable.", "\\newline One of the conditions is that the levelsets of the cost function must be compact.", "This is the case for $ F $ thanks to the additional constraint, indeed: \\newline <list> \\ the level sets of $ F $ are closed, as the inverse images of closed sets of a continuous function.", "\\newline \\ \\ they are also bounded in $ \\mathbf{S} $ thanks to the $ \\ell_{1} $ regularization, and in $ \\mathbf{A} $ thanks to the norm constraint on the columns of $ \\mathbf{A} $ .", "\\newline \\ </list> Hence, as closed and bounded sets of a finite space, they are compact.", "Also, the data fidelity term $ (\\mathbf{A},\\mathbf{S})\\mapsto\\|\\mathbf{Y}-\\mathbf{A}\\mathbf{S}\\|_{2}^{2} $ is differentiable on its domain, its domain is open, $ F $ is continuous, and the subproblem in $ \\mathbf{A} $ is pseudoconvex (since it is convex).", "This permits to use theorem 4.1(b) of [@bib:Tseng_01_ConvergenceBlockCoordinate] which proves that the coordinate descent method with the cyclic rule converges to a stationary point of $ F $ .", "More details are provided in Example 6.4 of [@bib:Tseng_01_ConvergenceBlockCoordinate] which is closely related to the present settings.", "\\newline </subsection> <subsection> <title> 2.3 Optimization Procedures - Proximal Splitting </title> In order to solve the subproblems at lines 4 and 5, nGMCA makes use of a proximal splitting method, namely the forward-backward algorithm [@bib:Combettes_05_Signalrecoveryby] .", "This algorithm is able to tackle problems which take the following form: \\newline <equation> $ \\underset{x}{\\text{argmin}}f(x)+g(x), $ </equation> where $ f $ is a convex and differentiable function; and $ g $ is a non-differentiable proper convex and lower semi-continuous function.", "It alternates between local minimization of $ f $ and of $ g $ until convergence, which occurs under mild assumptions.", "To do so, the algorithm requires the gradient of $ f $ and the proximal operator of $ g $ .", "The proximal operator of a proper convex lower semi-continuous function $ g $ is defined as: \\newline <equation> $ \\text{prox}_{g}(x)=\\underset{y}{\\text{argmin}}\\frac{1}{2}\\|y-x\\|_{2}^{2}+g(% y).", "$ </equation> Proximal operators take a closed-form expression for a wide range of functions $ g $ ; Table [@ref:LABEL:tab:operators_1] further features the expression of the proximal operators of interest in this paper.", "\\newline In the case of the update of $ \\mathbf{S} $ , $ f(\\mathbf{S})=\\frac{1}{2}\\|\\mathbf{Y}-\\mathbf{A}\\mathbf{S}\\|_{2}^{2} $ is the data fidelity term; and $ g(\\mathbf{S})=i_{\\cdot\\geq\\mathbf{0}}(\\mathbf{S})+\\lambda\\|\\mathbf{S}\\|_{1} $ accounts for the sparse prior and the non-negativity constraint.", "Its proximal operator is called non-negative soft-thresholding and is given by proximal # [@ref:LABEL:prox:L1pos] of table [@ref:LABEL:tab:operators_1] .", "The subproblem in $ \\mathbf{A} $ is solved similarly, with proximal operator # [@ref:LABEL:prox:pos] , or with proximal operator # [@ref:LABEL:prox:constr_pos] in the norm-constrained case of problem ( [@ref:LABEL:eq:A_const_update] ) (derivation of this operator is provided in appendix [@ref:LABEL:app:norm_constrained_prox] ).", "\\newline </subsection>  </section>"], ["<section> <title> 3 Transformed non-negative GMCA </title>  In the context of BSS, sparsity has been shown to provide more diversity or contrast between the sources which greatly help improving their separation [@bib:Zibulevsky_99_BlindSourceSeparation,Li_03_Sparserepresentationand,Bobin_07_Sparsityandmorphological] .", "Enforcing sparsity in a transformed domain makes possible the separation of sources with complex geometrical structures (see [@bib:Bobin_07_Sparsityandmorphological] ).", "The aim of this section is to explore extensions of the nGMCA algorithm to tackle NMF problems with sparsity imposed in a transformed domain.", "It has to be noticed that, in contrast to current sparse constraints in the direct domain, dealing with two priors \u2014non-negativity and sparsity\u2014 expressed in different domains is challenging.", "In the sequel, we will particularly focus on two formulations of sparse regularization in a transformed domain: synthesis and analysis.", "To the best of our knowledge, this is the first study of an analysis regularization in the context of source separation.", "\\newline <subsection> <title> 3.1 Synthesis and Analysis Formulations </title> In a transformed domain, sparsity can be enforced in two different ways, namely synthesis and analysis formulations.", "\\newline With $ \\mathbf{W}\\in\\mathbb{R}^{p\\times n} $ , minimizing a function $ f:\\mathbb{R}^{n}\\rightarrow\\mathbb{R} $ with a synthesis regularization is expressed in the following way: \\newline <equation> $ \\underset{x_{w}\\in\\mathbb{R}^{p}}{\\text{argmin}}f(\\mathbf{W}^{T}x_{w})+% \\lambda\\|x_{w}\\|_{1}. $ </equation> In this formulation, the unknown of the minimization is not directly the signal but sparse coefficients in the transformed space $ \\hat{x}_{w}\\in\\mathbb{R}^{p} $ .", "Denoting $ \\mathbf{D}=\\mathbf{W}^{T} $ , the aim is to reconstruct the sought signal $ \\hat{x} $ as a sparse linear combination of columns of $ \\mathbf{D} $ \u2014i.e.", "using as few columns of $ \\mathbf{D} $ as possible\u2014: \\newline <equation> $ \\hat{x}=\\mathbf{W}^{T}\\hat{x}_{w}=\\sum_{j=1}^{p}\\hat{x}_{w|j}D_{.,j}.\\vspace{-% 0.3cm} $ </equation> $ \\mathbf{D} $ is consequently called a dictionary and its columns are called atoms.", "This is a generative model, hence the name \u201csynthesis\u201d: one builds the sought-after signal using bricks of the signal space, the atoms.", "\\newline Still, it is essential to notice that the fact that $ \\hat{x}_{w} $ is sparse does not mean that $ \\mathbf{W}\\hat{x}=\\mathbf{W}\\mathbf{W}^{T}\\hat{x}_{w} $ is necessarily sparse, since usually $ \\mathbf{W}\\mathbf{W}^{T}\\neq\\mathbf{I} $ .", "In practice, this means that the synthesis formulation finds a solution which has a sparse representation in the transformed domain, but not that the transform of the solution is sparse.", "In the analysis formulation, one therefore directly carries out the minimization in the direct/signal domain in order to find a solution which is sparse when multiplied by $ \\mathbf{W} $ .", "This is expressed as follows: \\newline <equation> $ \\underset{x\\in\\mathbb{R}^{n}}{\\text{argmin}}f(x)+\\lambda\\|\\mathbf{W}x\\|_{1}% .\\vspace{-0.15cm} $ </equation> \\newline The term $ \\lambda\\|\\mathbf{W}x\\|_{1} $ penalizes correlations between $ x $ and the atoms/columns of $ \\mathbf{D}=\\mathbf{W}^{T} $ .", "In other words, while in the synthesis formulation the signal was expressed as a sum of a limited number of atoms, the aim in the analysis formulation is to obtain a signal which is strongly correlated with only a few atoms of $ \\mathbf{D} $ and which is weakly correlated with the other atoms.", "\\newline When $ \\mathbf{W} $ is orthonormal, the synthesis and the analysis formulations are strictly equivalent [@bib:Selesnick_09_SignalRestorationwith] .", "Indeed, the change of variables $ x_{w}=\\mathbf{W}x $ lets us obtain one formulation from the other, since $ \\mathbf{W} $ is invertible in this case.", "Still, one may want to use redundant dictionaries, with $ p>n $ , since they were shown to enhance signal recoveries [@bib:Coifman_95_Translationinvariantde] .", "The advantage of redundant dictionaries comes from the larger number of atoms available to sparsely represent signals.", "In redundant wavelets for instance, this allows translation invariance [@bib:Coifman_95_Translationinvariantde] .", "With such redundant transforms, analysis and synthesis formulations were then shown to have very different behaviors.", "Indeed, since $ p\\neq n $ , the minimization spaces in the synthesis and analysis formulations are necessarily different.", "In the field of inverse problems, the latter was observed to be more flexible and better adapted to natural signals, which cannot generally be synthesized from a few atoms [@bib:Elad_07_AnalysisVersusSynthesis,Selesnick_09_SignalRestorationwith,Nam_13_CosparseAnalysisModel] .", "\\newline </subsection> <subsection> <title> 3.2 Synthesis nGMCA </title> In order to extend the nGMCA algorithm to use a sparse synthesis regularization, lines 4 and 5 of Algorithm [@ref:LABEL:alg:nGMCA] have to be updated as follows: \\newline <equationgroup> <equation> $ \\text{4:}\\mathbf{S}_{w}^{(k)}\\leftarrow\\underset{\\mathbf{S}_{w% }\\mathbf{W}\\geq\\mathbf{0}}{\\text{argmin}}\\frac{1}{2}\\|\\mathbf{Y}-\\mathbf{A}% ^{(k-1)}\\mathbf{S}_{w}\\mathbf{W}\\|_{2}^{2}+\\|\\mathbf{\\Lambda}^{(k)}\\odot% \\mathbf{S}_{w}\\|_{1}. $ $ \\mathbf{S}_{w}^{(k)}\\leftarrow\\underset{\\mathbf{S}_{w}\\mathbf{% W}\\geq\\mathbf{0}}{\\text{argmin}}\\frac{1}{2}\\|\\mathbf{Y}-\\mathbf{A}^{(k-1)}% \\mathbf{S}_{w}\\mathbf{W}\\|_{2}^{2}+\\|\\mathbf{\\Lambda}^{(k)}\\odot\\mathbf{S}_{w}% \\|_{1}. $ </equation> <equation> $ \\text{5:}\\mathbf{A}^{(k)}\\leftarrow\\underset{\\mathbf{A}\\geq% \\mathbf{0}}{\\text{argmin}}\\frac{1}{2}\\|\\mathbf{Y}-\\mathbf{A}\\mathbf{S}^{(k)% }_{w}\\mathbf{W}\\|_{2}^{2}.\\vspace{-0.4cm} $ $ \\mathbf{A}^{(k)}\\leftarrow\\underset{\\mathbf{A}\\geq\\mathbf{0}}{% \\text{argmin}}\\frac{1}{2}\\|\\mathbf{Y}-\\mathbf{A}\\mathbf{S}^{(k)}_{w}\\mathbf% {W}\\|_{2}^{2}.\\vspace{-0.4cm} $ </equation> </equationgroup> \\newline Since the variable is now $ \\mathbf{S}_{w} $ and not $ \\mathbf{S} $ , one must also provide $ \\mathbf{S}_{w}^{(0)} $ instead of $ \\mathbf{W}^{(0)} $ at the beginning and set $ \\mathbf{S}^{(K)}=\\mathbf{S}_{w}^{(K)}\\mathbf{W} $ at the end.", "\\newline Although the update of $ \\mathbf{A} $ is only slightly modified, the additional transform $ \\mathbf{W} $ provides a new difficulty for the update of $ \\mathbf{S} $ .", "Indeed, there is no convenient way to compute the proximal operator of $ g(\\mathbf{S}_{w})=\\|\\mathbf{\\Lambda}\\odot\\mathbf{S}_{w}\\|_{1}+i_{\\cdot\\mathbf{% W}\\geq\\mathbf{0}}(\\mathbf{S}_{w}) $ and it is therefore not practical to use the forward-backward algorithm in this case.", "\\newline Instead, one can apply the generalized forward-backward algorithm (GFB) [@bib:Raguet_13_GeneralizedForwardBackward] , which considers $ g $ as the sum of two convex lower semi-continuous functions $ g_{1}(\\mathbf{S}_{w})=\\|\\mathbf{\\Lambda}\\odot\\mathbf{S}_{w}\\|_{1} $ and $ g_{2}(\\mathbf{S}_{w})=i_{\\cdot\\mathbf{W}\\geq\\mathbf{0}}(\\mathbf{S}_{w}) $ .", "This algorithm also requires their proximal operators.", "The proximal operator of $ g_{1} $ is proximal # [@ref:LABEL:prox:L1] from table [@ref:LABEL:tab:operators_1] but the proximal operator of $ g_{2} $ is not always analytic.", "If $ \\mathbf{W} $ is orthonormal, the operator admits a closed form and is provided as proximal # [@ref:LABEL:prox:wavePosOrth] from table [@ref:LABEL:tab:operators_2] .", "In the experiments, such settings are used in the algorithm coined \u201corthonormal nGMCA\u201d with an orthonormal wavelet transform.", "\\newline As stated previously, redundant transforms were shown to improve reconstructions.", "In the particular case of transforms $ \\mathbf{W}\\in\\mathbb{R}^{p\\times n} $ with $ p>n $ and such that $ \\mathbf{W}^{T}\\mathbf{W}=\\mathbf{I} $ (tight frames), the proximal operator is still analytic.", "It is provided as proximal # [@ref:LABEL:prox:wavePos] in table [@ref:LABEL:tab:operators_2] and is derived in appendix [@ref:LABEL:app:synProx] .", "This proximal operator generalizes proximal operator # [@ref:LABEL:prox:wavePosOrth] which could only handle orthonormal, and therefore non-redundant, transforms.", "The pseudo-code of the synthesis update step is provided in Algorithm [@ref:LABEL:alg:synthesis_update] of appendix [@ref:LABEL:app:syn_update] .", "In the experiments, this algorithm is then coined \u201csynthesis nGMCA\u201d and is used with a redundant wavelet transform.", "\\newline For even more general transforms $ \\mathbf{W} $ , the proximal operator of $ g_{2} $ does not admit a closed-form expression anymore.", "In this case, it would be more convenient to use an algorithm such as Chambolle-Pock [@bib:Chambolle_10_firstorderprimal] , as will be the case for the analysis formulation below.", "\\newline </subsection> <subsection> <title> 3.3 Analysis nGMCA </title> In order to adapt the nGMCA algorithm to use a sparse analysis regularization in a transformed domain, line 4 of Algorithm [@ref:LABEL:alg:nGMCA] has to be updated as follows: \\newline <equationgroup> <equation> $ \\text{4:}\\mathbf{S}^{(k)}\\leftarrow\\underset{\\mathbf{S}\\geq% \\mathbf{0}}{\\text{argmin}}\\frac{1}{2}\\|\\mathbf{Y}-\\mathbf{A}^{(k-1)}\\mathbf% {S}\\|_{2}^{2}+\\|\\mathbf{\\Lambda}^{(k)}\\odot(\\mathbf{S}\\mathbf{W}^{T})\\|_{1}. $ $ \\mathbf{S}^{(k)}\\leftarrow\\underset{\\mathbf{S}\\geq\\mathbf{0}}{% \\text{argmin}}\\frac{1}{2}\\|\\mathbf{Y}-\\mathbf{A}^{(k-1)}\\mathbf{S}\\|_{2}^{2% }+\\|\\mathbf{\\Lambda}^{(k)}\\odot(\\mathbf{S}\\mathbf{W}^{T})\\|_{1}. $ </equation> </equationgroup> \\newline In [@bib:Rapin_13_SparseRedundantFormulations] and [@bib:Rapin_13_SparseRegularizationsand] , the authors use redundant wavelet transforms and carry the minimization in the same way as in the synthesis formulation, but with proximal # [@ref:LABEL:prox:pos] and # [@ref:LABEL:prox:analysis] instead of proximal # [@ref:LABEL:prox:wavePos] and # [@ref:LABEL:prox:L1] .", "Yet, proximal # [@ref:LABEL:prox:analysis] , which is derived in appendix [@ref:LABEL:app:anaProx] , is no more analytic and needs to be computed through a subroutine (using the FB algorithm with proximal # [@ref:LABEL:prox:Linf] for instance).", "It therefore requires intensive computations.", "Several other optimization schemes are however possible in order to avoid the need of a subroutine.", "In Appendix [@ref:LABEL:app:analysis_chambolle] we show how to use the Chambolle-Pock algorithm [@bib:Chambolle_10_firstorderprimal] for the resolution of ( [@ref:LABEL:eq:ana_update] ) with any transform $ \\mathbf{W} $ and provide the pseudo-code ( Algorithm [@ref:LABEL:alg:analysis_update] ).", "This approach is the one used for the \u201canalysis nGMCA\u201d in the experiments, with a redundant wavelet transform.", "\\newline </subsection> <subsection> <title> 3.4 Numerical Complexity </title> Each iteration of the updates of $ \\mathbf{S} $ involves a matrix multiplication, a forward and a backward transform, and linear steps such as the thresholding, the projections on the non-negative orthant and linear combinations.", "The matrix multiplication involves an $ r\\times r $ matrix and $ \\mathbf{S} $ , and has therefore a complexity of $ \\mathcal{O}(r^{2}n) $ .", "With $ \\phi(n) $ the complexity of the transform on a signal of length $ n $ , the complexity of the transformations is in $ \\mathcal{O}(r\\phi(n)) $ , which yields an overall complexity of the order of $ \\mathcal{O}(r\\phi(n)+r^{2}n) $ .", "\\newline In this article, we mostly use redundant wavelet transforms which have a complexity of $ \\phi(n)=n\\text{log}_{2}(n) $ [@bib:Coifman_95_Translationinvariantde] .", "The numerical complexity is therefore linearithmic in the number of samples $ n $ of each source (i.e. in $ n\\text{log}_{2}(n) $ ) because of the transform, and quadratic in the number of sources $ r $ because of the matrix multiplication.", "\\newline Note that, in any case, the number of observations $ m $ does not appear at all in the complexity of the update of $ \\mathbf{S} $ .", "The number of observations indeed only appears \u2014linearly\u2014 in the update of $ \\mathbf{A} $ , which has complexity of $ \\mathcal{O}(r^{2}m) $ because of the matrix multiplication.", "\\newline </subsection> <subsection> <title> 3.5 Experiments </title> <subsubsection> <title> 3.5.1 Experimental settings and Evaluation </title> In physical applications, a molecule can be identified by its specific Nuclear Magnetic Resonance (NMR) spectrum.", "In this section, we evaluate the algorithms on simulated data made of mixtures of realistic NMR spectra: \\newline <list> \\ the mixing matrix $ \\mathbf{A} $ is drawn as the absolute value of an i.i.d.", "Gaussian random matrix.", "\\newline \\ \\ the spectra in $ \\mathbf{S} $ come from the Spectral Database for Organic Compounds, SDBS .", "In order to account for the acquisition imperfections, the spikes were convoluted with a Laplacian kernel of 4-samples width at half-maximum (width-4 Laplacian kernel).", "Some of the obtained sources are shown in figure [@ref:LABEL:fig:NMRspectra] .", "\\newline \\ \\ the data matrix $ \\mathbf{Y} $ is generated as $ \\mathbf{Y}=\\mathbf{A}\\mathbf{S}+\\mathbf{Z} $ where $ \\mathbf{Z} $ is a Gaussian noise matrix.", "In the experiments, it gathers $ m=32 $ measurements of $ n=1024 $ samples.", "An example of mixture is provided in figure [@ref:LABEL:fig:appli_mixture] .", "\\newline \\ </list> \\newline The sources are naturally non-negative and already significantly sparse in the direct domain.", "They can however benefit from wavelet-sparsity since they are close to piecewise polynomial.", "In the following, we consider $ \\mathbf{W} $ to be 3-level wavelets (Symmlets-4).", "The orthonormal version uses Wavelab and the redundant ones a homemade reimplementation of the Rice wavelet toolbox (see Section \u00a7 [@ref:LABEL:sec:software] ).", "Both satisfy $ \\mathbf{W}^{T}\\mathbf{W}=\\mathbf{I} $ (tight frames) after adequate renormalization when necessary.", "With these settings, the mean sparseness (as defined in equation ( [@ref:LABEL:eq:HoyerSparseness] )) is 0.78 in the direct domain and 0.89 in the orthonormal wavelet domain.", "All the nGMCA-based algorithms are left running for 300 iterations.", "$ \\tau^{\\infty}_{\\sigma}=1 $ for nGMCA and the orthonormal version and 2 for the analysis and synthesis versions.", "\\newline These algorithms are compared with smooth NMF [@bib:Zdunek_07_BlindImageSeparation] and the accelerated sparse HALS [@bib:Gillis_12_SparseandUnique] , which are described in Section \u00a7 [@ref:LABEL:sec:priors_NMF] , and are left running until convergence.", "In each simulation, sparse HALS is provided with a sparsity level which is pre-computed from the actual reference sources.", "Since there is no straightforward way to tune the smoothness parameter $ \\alpha $ in problem ( [@ref:LABEL:eq:smoothNMF] ) for smooth NMF, we keep the best reconstruction out of 12 different value of the parameter $ \\alpha $ (logarithmically distributed between $ 10^{-5} $ and $ 1 $ ).", "In this sense, both these algorithms are provided with close to optimal parameters while the nGMCA based algorithms are not.", "\\newline In order to evaluate the outputs of BSS algorithms, Vincent et al. [@bib:Vincent_06_Performancemeasurementin] have proposed to decompose the estimated sources into the sum of several contributions through a sequence of projections: \\newline <equation> $ s^{\\text{est}}=s_{\\text{target}}+s_{\\text{interf}}+s_{\\text{noise}}+s_{\\text{% artifacts}}, $ </equation> with the following interpretations for the terms: \\newline <list> \\ $ s_{\\text{target}} $ is the projection of $ s^{\\text{est}} $ on the target (ground-truth) source.", "In other words, it is the one part of this decomposition which corresponds to what needs to be recovered.", "The other ones are residues.", "\\newline \\ \\ $ s_{\\text{interf}} $ accounts for interferences due to other sources.", "\\newline \\ \\ $ s_{\\text{noise}} $ is the part of the reconstruction which is due to noise.", "\\newline \\ \\ $ s_{\\text{artifacts}} $ stands for the remaining artifacts which are neither due to interferences nor noise.", "\\newline \\ </list> \\newline Using this decomposition, the authors designed scale-invariant SNR-type energy ratios in order to evaluate the detrimental influence of interferences (through an SIR criterion), of noise (SNR), and of artifacts (SAR) in the results.", "They also designed a more global criterion named Source to Distortion Ratio (SDR): \\newline <equation> $ \\text{SDR}(s^{\\text{est}})=10\\text{log}_{10}\\left(\\frac{\\|s_{\\text{target}}% \\|_{2}^{2}}{\\|s_{\\text{interf}}+s_{\\text{noise}}+s_{\\text{artifacts}}\\|_{2}^{2% }}\\right).", "$ </equation> All these criteria increase for better recoveries.", "The latter criterion is intensively used below in order to evaluate the algorithms since it takes into account all the aspects of a good reconstruction (low interferences, noise and artifacts).", "In the experiments it is computed through Monte-Carlo simulations.", "The number of simulations is provided in each figure\u2019s caption.", "\\newline </subsubsection> <subsubsection> <title> 3.5.2 Convolutive model </title> In this section, the sources are modeled as sparse spike trains convoluted with a Laplacian kernel.", "The sources can therefore be decomposed as a non-negative linear combination of non-negative atoms.", "In this case, the problem of the update of $ \\mathbf{S} $ can be greatly simplified since non-negativity and sparsity can be expressed in the same domain: \\newline <equation> $ \\mathbf{S}^{(k)}\\leftarrow\\underset{\\mathbf{S}_{w}}{\\text{argmin}}\\frac{% 1}{2}\\|\\mathbf{Y}-\\mathbf{A}^{(k-1)}\\mathbf{S}_{w}\\mathbf{W}\\|_{2}^{2}+\\|% \\mathbf{\\Lambda}^{(k)}\\odot\\mathbf{S}_{w}\\|_{1}+i_{\\cdot\\geq\\mathbf{0}}(% \\mathbf{S}_{w}).", "$ </equation> The advantage of this formulation is that function $ g(\\mathbf{S}_{w})=\\|\\mathbf{\\Lambda}\\odot\\mathbf{S}_{w}\\|_{1}+i_{\\cdot\\geq% \\mathbf{0}}(\\mathbf{S}_{w}) $ has an analytic proximal operator and the minimization can be carried with the FB algorithm such as in standard nGMCA.", "In the sequel, we use a convolution matrix $ \\mathbf{W} $ , such that for a column vector $ x $ , $ \\mathbf{W}x=f\\ast x $ , with $ f $ a convolutive kernel.", "This version of nGMCA is coined \u201cconvolutive nGMCA\u201d.", "The convolutive kernel of convolutive nGMCA is set to a width-4 Laplacian kernel.", "When the sources are indeed composed of non-negative spikes convoluted with such kernel, this approach should lead the best separation performances; it will therefore play the role of a reference method in this section.", "\\newline </subsubsection> <subsubsection> <title> 3.5.3 Comparison of the formulations </title> Figures [@ref:LABEL:fig:noise_nmr] , [@ref:LABEL:fig:m_nmr] and [@ref:LABEL:fig:r_nmr] show the performances of the nGMCA-based algorithms compared to other methods, respectively with varying noise levels, number of measurements $ m $ and number of sources $ r $ .", "The results generally indicate a common trend: smooth NMF does not perform as well as sparsity-enforcing methods (nGMCA, sparse HALS) for this type of sources as it is not well adapted to cope with singularities, such as the peaks which compose the sources.", "Wavelets are better suited for this goal [@bib:Mallat_92_Singularitydetectionand] and imposing sparsity in an orthonormal wavelets consequently yields increased performance of about a couple of dB. As expected, redundant wavelets, which are translation-invariant, whether used in the synthesis formulation or in the analysis formulation, yield enhanced separation results.", "As emphasized previously, the sources to be retrieved can be exactly modeled as a non-negative and sparse mixture of atoms of $ \\mathbf{W} $ ( i.e. convolutive model).", "The nGMCA algorithm based on the convolutive model performs best in this case.", "It is important to notice that, in the nGMCA-based algorithms, the regularization parameter is set automatically.", "This is not the case for the other algorithms which often turn to be more difficult to parameterize.", "In particular, it is not clear how the parameter of smooth NMF must be tuned.", "In the experiments, smooth NMF are optimally tuned so that they lead to the best reconstructions based on the knowledge of the sought after sources.", "In sparse HALS, the parameter is set to the sparsity level of the true sources.", "Obviously, this would be unavailable in practice.", "\\newline As expected, convolutive nGMCA yields the best results as generative convolutive model is exact in this particular case.", "This information is however usually unknown or is even not reliable in practice; this will be discussed later on.", "Smooth NMF is not able to recover the sources properly: while it is well adapted to recover smooth geometric structures, it is not well suited to recover singularities such as the peaks of the sources.", "nGMCA and sparse HALS perform slightly better since the sources are mildly sparse in the direct domain.", "Still, as stated above, the sources are sparser in the orthonormal wavelet domain (sparseness of 0.89 compared to 0.78 in the direct domain), which explains the couple of additional dB provided by orthonormal nGMCA.", "The translation invariance of redundant wavelets is also significantly beneficial as shown with analysis nGMCA and synthesis nGMCA which perform from 2 to 4 dB even better, with a neat advantage for the analysis formulation.", "This corroborates the results in [@bib:Elad_07_AnalysisVersusSynthesis,Selesnick_09_SignalRestorationwith] for natural signals: the sources can not be exactly synthesized from a few coefficients in $ \\mathbf{W} $ .", "In this case, the analysis-based regularization is generally more robust and yields better reconstruction results.", "\\newline Figure [@ref:LABEL:fig:appli_reconstruction_example] shows an example of reconstruction for analysis nGMCA, sparse HALS and smooth NMF and confirms our analysis.", "Indeed, the smoothing effect of smooth NMF is clearly illustrated with the peaks being smoothed out.", "It also highlights that the sparse regularization in the direct domain is not completely adapted since it does not capture the smooth structure; it essentially tends to bias the sources towards $ 0 $ .", "Wavelets have the ability to sparsely represent local singularities \u2014peaks\u2014 as well as smooth and large-scale geometric structures.", "Enforcing sparsity in the wavelet domain allows for a better recovery of both the sharp peaks and the large-scale structures of the signals.", "\\newline It is also very instructive to have a look at the importance of the peaks width.", "In figure [@ref:LABEL:fig:width_nmr] , the width at half-maximum of the peaks is modified compared to the previous cases where it was fixed to $ 4 $ .", "This highly impacts the model, since the smaller the width, the spikier the data.", "Unsurprisingly, smooth NMF does not perform well at recovery spiky data.", "Conversely, standard nGMCA performs best for extremely spiky spectra.", "Its performances with respect to synthesis nGMCA and analysis nGMCA decrease when the peaks\u2019 width increases.", "Finally and most interestingly, the convolutive kernel of convolutive nGMCA is left unchanged in this experiment.", "It is then clearly visible that the performances of the algorithm decrease very quickly when the kernel is no more perfectly tuned to the data (which is the case only at width $ 4 $ ).", "One should definitely establish a parallel between these observations and figure [@ref:LABEL:fig:sparseness_width] which provides the mean sparseness of the sources in the direct domain, in the wavelet domain, and after an inversion of the width-4 Laplacian kernel, for several kernel widths.", "When sparseness in the direct domain is a valid assumption, standard nGMCA performs better than wavelet sparse nGMCA versions.", "Conversely, the versions of nGMCA in the wavelet domain outperform standard nGMCA when the data are sparser in the wavelet domain.", "The convolutive nGMCA algorithm appears to be much more sensitive to the accuracy of the model.", "\\newline </subsubsection> <subsubsection> <title> 3.5.4 Summary </title> Through these experiments, we have seen that the additional structural information provided by the domain transform is helpful for the reconstruction of sources with complex geometrical structures which cannot be correctly tackled by smooth NMF or standard sparse NMF methods.", "This is especially true in difficult settings such as in the low measurement case or when the number of sources is large.", "Compared to the $ \\ell_{2} $ -based smoothness regularization, sparsity in a well-chosen domain \u2014here the wavelet domain\u2014 also has the advantage of preserving the peaks while correctly reconstructing large-scale smooth components.", "Lastly, the automatic and straightforward strategy used to handle the sparsity parameters in the nGMCA-based algorithms is efficient for a wide range of settings.", "To the best of our knowledge, these experiments also present the first comparison of synthesis and analysis-based regularizations in the scope of blind source separation and NMF.", "As already emphasized in the context of linear inverse problems [@bib:Elad_07_AnalysisVersusSynthesis,Selesnick_09_SignalRestorationwith] , analysis-based problems are generally more robust to model mismatch as, in contrast to the synthesis-based regularization, does not assume that the signals to be retrieved are decomposed into a few non-zero entries in $ \\mathbf{W} $ .", "\\newline </subsubsection> </subsection>  </section>"], ["<section> <title> 4 Reweighted-L1 in BSS </title>  In this section, we observe the limitations of the $ \\ell_{1} $ regularization and explain how it is possible to bypass it.", "This approach is then validated on noisy mixtures of images.", "\\newline <subsection> <title> 4.1 Bias and Interferences induced by the \u2113 1 Regularization </title> In article [@bib:Rapin_13_SparseandNon] , the authors discussed the pros and cons of the customarily used $ \\ell_{1} $ regularization in the context of non-negative BSS.", "More specifically, while this regularization can achieve superior separation performances, it is well known to produce a bias which can hamper the separation performances.", "\\newline If the bias induced by the $ \\ell_{1} $ regularization can be neglected for very sparse sources ( i.e. the number of active entries in the sources is very low), it is hardly the case for more complex data which are rather modeled as approximately sparse signals.", "In that case, all the entries of the sources are non-zero but only a few take a significant amplitude.", "For instance, natural images are good examples of approximately sparse signals in the wavelet domain.", "In this setting, the $ \\ell_{1} $ regularization may not be as effective.", "Figure [@ref:LABEL:fig:4_mixtures_2D] shows 4 out of 32 noisy mixtures of the 4 sources displayed in figure [@ref:LABEL:fig:4_sources_2D] (namely: Lena, peppers, a boat and Barbara), the mixture coefficients being the absolute value of a Gaussian matrix.", "Figure [@ref:LABEL:fig:lena_inversion_regular] shows the recovery of Lena after solving problem ( [@ref:LABEL:eq:S_analysis] ) with the ground truth mixing matrix $ \\mathbf{A} $ .", "One can observe strong interferences: some parts of the peppers and Barbara\u2019s head being visible on the picture.", "\\newline In the framework of standard inverse problems, the $ \\ell_{1} $ regularization is customarily substituted with the $ \\ell_{0} $ regularization which generally produce a lower estimation bias.", "In the context of sparse NMF [@bib:Rapin_13_SparseandNon] , the authors observed that an $ \\ell_{0} $ penalization do not exhibit similar interferences, but does not perform as well as the $ \\ell_{1} $ regularization.", "This is especially the case in difficult separation instances ( e.g. when the number of sources to be retrieved is large).", "The correct separation of approximately sparse signals \u2014such as natural images\u2014 therefore requires a special treatment by taking the best of the $ \\ell_{1} $ and $ \\ell_{0} $ penalizations.", "\\newline </subsection> <subsection> <title> 4.2 Balancing between \u2113 1 to \u2113 0 </title> In the context of regularized linear inverse problems, several techniques have been designed so as to overcome the bias produced by the $ \\ell_{1} $ penalization.", "In [@bib:Gao_97_Waveshrinkwith] , the authors have introduced a mixture of the soft- and hard-thresholding named firm-thresholding.", "In [@bib:Voronin_13_newiterativefirm] , the authors have proposed to iteratively alter the penalization from soft- to firm thresholding ; this strategy makes profit of the convexity of the $ \\ell_{1} $ regularization at the beginning of the algorithm.", "This allows to uniquely get a first estimate of the solution which is assumed to be close to the signal to be retrieved.", "\\newline In this article, we opt for an alternative called reweighted- $ \\ell_{1} $ [@bib:Candes_07_EnhancingSparsityby] .", "This method consists in choosing the coefficients of the regularization matrix $ \\mathbf{\\Lambda} $ according to the amplitude of the corresponding coefficients of the transform of $ \\mathbf{S} $ .", "The entries of the transform of $ \\mathbf{S} $ with the largest amplitudes will be less penalized than the small amplitude entries.", "This is usually done by iteratively solving a sequence of weighted $ \\ell_{1} $ -regularized problem.", "At each step of the sequence, the weights $ \\mathbf{\\Lambda} $ are re-estimated from the current estimate of the sources $ \\mathbf{S} $ .", "The main advantage of this method is that, although it globally requires solving a non-convex problem, each step remains convex.", "\\newline Several reweighting strategies have been proposed [@bib:Candes_07_EnhancingSparsityby] .", "In the current paper, the weight matrix $ \\mathbf{\\Lambda} $ will be updated as follows: \\newline <equation> $ \\mathbf{\\Lambda}^{\\text{rew.}}_{\\tau}=\\mathbf{\\Lambda}_{\\tau}\\oslash\\left(% \\mathbf{1}+\\left(\\mathbf{S}_{\\text{inv}|w}\\oslash\\mathbf{\\Sigma}\\right)^{2}% \\right), $ </equation> where the square is applied elementwise, and $ \\mathbf{S}_{w|\\text{inv}} $ is the least-square estimate of the sources using the current estimate of $ \\mathbf{A} $ : \\newline <equation> $ \\mathbf{S}_{w|\\text{inv}}=(\\mathbf{A}^{T}\\mathbf{A})^{-1}\\mathbf{A}^{T}\\mathbf% {Y}\\mathbf{W}^{T}. $ </equation>", "The matrix $ \\mathbf{\\Sigma} $ contains the noise standard deviation of the sources in the transform domain.", "In practice, it is evaluated by using a robust empirical estimator of the noise standard deviation based on the MAD (Median Absolute Deviation) of $ \\mathbf{S}_{w|\\text{inv}} $ .", "\\newline Applied to the same mixture of natural images, the reweighted $ \\ell_{1} $ regularization is used to estimate the sources assuming $ \\mathbf{A} $ is known; one of the sources is displayed in Figure [@ref:LABEL:fig:lena_inversion_reweighted] .", "For the sake of evaluation, we use the same criteria as defined in Section [@ref:LABEL:sec:settings_eval] ."]], "target": "These quantities are provided in Table in the following settings: i) no regularization is applied (non-negative least-square estimate), ii) standard $ \\ell_{1} $ regularization and iii) reweighted $ \\ell_{1} $ regularization. In comparison to a simple least-square estimate, the use of the $ \\ell_{1} $ regularization obviously helps removing noise contamination \u2014high SNR\u2014 but at the cost of more interferences and artifacts (lower SIR and SAR). As featured in the last column, the reweighted- $ \\ell_{1} $ penalization provides a good balance between denoising and separation efficiency, since the SNR slightly decreases but the SIR greatly increases."}, {"tabular": ["  KB  &  Predicate  &  $ \\# $ Facts  &  Examples ", " DBpedia  &  Category  &  $ 35152 $  &  ( Wii ,Category,VideoGameConsole) ", " ConceptNet  &  RelatedTo  &  $ 79789 $  &  ( Horse ,RelatedTo, Zebra ) , ( Wine ,RelatedTo,Goblet) ", " AtLocation  &  $ 13683 $  &  (Bikini,AtLocation, Beach ) , (Tap,AtLocation, Bathroom ) ", " IsA  &  $ 6011 $  &  ( Broccoli ,IsA,GreenVegetable) ", " CapableOf  &  $ 5837 $  &  ( Monitor ,CapableOf,DisplayImages) ", " UsedFor  &  $ 5363 $  &  ( Lighthouse ,UsedFor,SignalingDanger) ", " Desires  &  $ 3358 $  &  ( Dog ,Desires,PlayFrisbee) , ( Bee ,Desires,Flower) ", " HasProperty  &  $ 2813 $  &  ( Wedding ,HasProperty,Romantic) ", " HasA  &  $ 1665 $  &  ( Giraffe ,HasA,LongTongue) , ( Cat ,HasA,Claw) ", " PartOf  &  $ 762 $  &  (RAM,PartOf, Computer ) , (Tail,PartOf, Zebra ) ", " ReceivesAction  &  $ 344 $  &  ( Books ,ReceivesAction,bought at a bookshop) ", "  &  CreatedBy  &  $ 96 $  &  ( Bread ,CreatedBy,Flour) , ( Cheese ,CreatedBy,Milk) ", " WebChild  &  Smaller , Better ,  &  $ 38576 $  &  ( Motorcycle ,Smaller, Car ) , ( Apple ,Better,VitaminPill) , ", " Slower , Bigger ,  &  ( Train ,Slower, Plane ) , (Watermelon,Bigger, Orange ) , ", " Taller , $ \\dots $  &  ( Giraffe ,Taller,Rhino)  "], "ref_sec": [["<section> <title> I Introduction </title>  Visual Question Answering (VQA) can be seen as a proxy task for evaluating a vision system\u2019s capacity for deeper image understanding.", "It requires elements of image analysis, natural language processing, and a means by which to relate images and text.", "Distinct from many perceptual visual tasks such as image classification, object detection and recognition [@bib:krizhevsky2012imagenet,lin2014microsoft,deng2009imagenet,simonyan2014very] , however, VQA requires that a method be prepared to answer a question that has never seen before.", "In object detection the set of objects of interest are specified at training time, for example, whereas in VQA the set of questions which may be asked inevitably extend beyond those in the training set.", "\\newline The set of questions that a VQA method is able to answer are one of its key features, and limitations.", "Asking a method a question that is outside its scope will lead to a failure to answer, or worse, to a random answer.", "Much of the existing VQA effort has been focused on questions which can be answered by the direct analysis of the question and image, on the basis of a large training set [@bib:antol2015vqa,malinowski2014towards,gao2015you,Yu_2015_ICCV,ren2015image,zhu2015visual7w] .", "This is a restricted set of questions, which require only relatively shallow image understanding to answer.", "It is possible, for example, to answer \u2018How many giraffes are in the image?\u2019 without understanding anything about giraffes.", "\\newline The number of VQA datasets available has grown as the field progresses [@bib:antol2015vqa,malinowski2014towards,gao2015you,Yu_2015_ICCV,ren2015image,zhu2015visual7w] .", "They have contributed valuable large-scale data for training neural-network based VQA models and introduced various question types, and tasks, from global association between QA pairs and images [@bib:antol2015vqa,malinowski2014towards,ren2015image] to grounded QA in image regions [@bib:zhu2015visual7w] ; from free-from answer generation [@bib:antol2015vqa,gao2015you,ren2015image,zhu2015visual7w] to multiple-choice picking [@bib:antol2015vqa,malinowski2014towards] and blank filling [@bib:Yu_2015_ICCV] .", "For example, The questions defined in DAQUAR [@bib:malinowski2014towards] are almost exclusively \u201cVisual\u201d questions, referring to \u201ccolor\u201d, \u201cnumber\u201d and \u201cphysical location of the object\u201d.", "In the Toronto-QA dataset [@bib:ren2015image] , questions are generated automatically from image captions which describe the major visible content of the image.", "\\newline The VQA dataset in [@bib:antol2015vqa] , for example, has been very well studied, yet only 5.5% of questions require adult-level (18+) knowledge (28.4% and 11.2% questions require older child (9-12) and teenager (13-17) knowledge).", "This limitation means that this is not a truly \u201cAI-complete\u201d problem, because this is not a realistic test for human beings.", "Humans inevitably use their knowledge to answer questions, even visual ones.", "For example, to answer the question given in Fig. [@ref:LABEL:fig:t_figure] , one not only needs to visually recognize the \u2018red object\u2019 as a \u2018fire hydrant\u2019, but also to know that \u2018 a fire hydrant can be used for fighting fires \u2019.", "\\newline Developing methods that are capable of deeper image understanding demands a more challenging set of questions.", "We consider here the set of questions which may be answered on the basis of an external source of information, such as Wikipedia.", "This reflects our belief that reference to an external source of knowledge is essential to general VQA.", "This belief is based on the observation that the number of $ \\{$ image-question-answer $ \\} $ training examples that would be required to provide the background information necessary to answer general questions about images would be completely prohibitive.", "The number of concepts that would need to be illustrated is too high, and scales combinatorially.", "\\newline In contrast to previous VQA datasets which only contain question-answer pairs for an image, we additionally provide a supporting-fact for each question-answer pair.", "The supporting-fact is a structural representation of information that is necessary for answering the given question.", "For example, given an image with a cat and a dog, and the question \u2018Which animal in the image is able to climb trees?", "\u2019 , the answer is \u2018cat\u2019 .", "The required supporting fact for answering this question is <Cat,CapableOf,ClimbingTrees> , which is extracted from an existing knowledge base.", "By providing supporting facts, the dataset supports answering complex questions, even if all of the information required to answer the question is not depicted in the image.", "Moreover, it supports explicit reasoning in visual question answering, {i.e} ., it gives an indication as to how a method might derive an answer.", "This information can be used in answer inference, to search for other appropriate facts, or to evaluate answers which include an inference chain.", "\\newline In demonstrating the value of the dataset in driving deeper levels of image understanding in VQA, we examine the performance of the state-of-the-art LSTM (Long-Short Term Memory) models [@bib:antol2015vqa,malinowski2014towards,ren2015image] on our FVQA dataset.", "We find that there are a number of limitations with this approach.", "The first is that there is no explicit reasoning process in these methods.", "This means that it is impossible to tell whether the method is answering the question based on image information or merely the prevalence of a particular answer in the training set.", "The second problem is that, because the model is trained on individual question-answer pairs, the range of questions that can be accurately answered is limited.", "It can only answer questions about concepts that have been observed in the training set, and there are millions of possible concepts and hundreds of millions relationships between them.", "Capturing this amount of information would require an implausibly large LSTM, and a completely impractical amount of training data.", "\\newline Our main contributions are as follows.", "A new VQA dataset (FVQA) with additional supporting facts is introduced in Sec. [@ref:LABEL:dataset] , which requires and supports deeper reasoning.", "In response to this observed limitation of the current LSTM-based approach, we propose a method which is based on explicit reasoning about the visual concepts detected from images in Sec. [@ref:LABEL:method] .", "The proposed method first detects relevant content in the image, and relates it to information available in a pre-constructed knowledge base (we combine several publicly available large-scale knowledge bases).", "A natural language question is then automatically classified and mapped to a query which runs over the combined image and knowledge base information.", "The response of the query leads to the supporting fact, which is then processed so as to form the final answer to the question.", "We achieve the state-of-the-art performance with 56.91% in Top-1 accuracy (see Sec. [@ref:LABEL:expe] ).", "\\newline  </section>"], ["<section> <title> II Related Work </title>  <subsection> <title> II-A Visual Question Answering Datasets </title> Several datasets designed for Visual Question Answering have been proposed.", "The DAQUAR [@bib:malinowski2014towards] dataset is the first small benchmark dataset built upon indoor scene RGB-D images, which is mostly composed of questions requiring only visual knowledge.", "Most of the other datasets [@bib:antol2015vqa,gao2015you,Yu_2015_ICCV,ren2015image,zhu2015visual7w] represent question-answer pairs for Microsoft COCO images [@bib:lin2014microsoft] , either generated automatically by NLP tools [@bib:ren2015image] or written by human workers [@bib:antol2015vqa,gao2015you] .", "The Visual Genome dataset [@bib:krishnavisualgenome] contains 1.7 million questions, which are asked by human workers based on region descriptions.", "The MadLibs dataset [@bib:Yu_2015_ICCV] provides a large number of template based text descriptions of images, which are used to answer multiple choice questions about the images.", "Visual 7W [@bib:zhu2015visual7w] established a semantic link-between textual descriptions and image regions by object-level grounding and the questions are asked based on groundings.", "\\newline </subsection> <subsection> <title> II-B Visual Question Answering Methods </title> Malinowski {et al} .", "[@bib:malinowski2014multi] were the first to study the VQA problem.", "They proposed a method that combines image segmentation and semantic parsing with a Bayesian approach to sampling from nearest neighbors in the training set.", "This approach requires human defined predicates, which are inevitably dataset-specific.", "Tu {et al} .", "[@bib:tu2014joint] built a query answering system based on a joint parse graph from text and videos.", "Geman {et al} .", "[@bib:geman2015visual] proposed an automatic \u2018query generator\u2019 that is trained on annotated images and produces a sequence of binary questions from any given test image.", "\\newline The current dominant trend within VQA is to combine Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) to learn the mapping from input images and questions, to answers.", "Both Gao {et al} .", "[@bib:gao2015you] and Malinowski {et al} . [@bib:malinowski2015ask] used RNNs to encode the question and renerate the answer.", "Whereas", "Gao {et al} . [@bib:gao2015you] used two networks, a separate encoder and decoder, Malinowski {et al} .", "[@bib:malinowski2015ask] used a single network for both encoding and decoding.", "Ren {et al} .", "[@bib:ren2015image] focused on questions with a single-word answer and formulated the task as a classification problem using an LSTM.", "Inspired by Xu {et al} .", "[@bib:xu2015show] who encoded visual attention in the Image Captioning, authors of [@bib:zhu2015visual7w,Chen2015ABC,Jiang2015compositional,andreas2015deep,yang2015stacked] proposed to use the spatial attention to help answer visual questions.", "[@bib:yang2015stacked,noh2015dppnet] formulated the VQA as a classification problem and restrict the answer only can be drawn from a fixed answer space.", "In other words, they can not generate open-ended answers.", "Zhu {et al} .", "[@bib:zhu2015uncovering] investigated the video question answering problem using \u2018fill-in-the-blank\u2019 questions.", "However, either an LSTM or a GRU (Gated Recurrent Unit, similar to an LSTM) is still applied in these methods to model the questions.", "Irrespective of the finer details, we label this the LSTM approach.", "\\newline </subsection> <subsection> <title> II-C Knowledge-bases and VQA </title> Answering general questions posed by humans about images inevitably requires reference to information not contained in the image itself.", "To an extent this information may be provided by an existing training set such as ImageNet [@bib:deng2009imagenet] , or MS COCO [@bib:lin2014microsoft] as class labels or image captions.", "There are a number of forms of such auxilliary information, including, for instance, question/answer pairs which refer to objects that are not depicted ( {e.g} ., which reference people waiting for a train, when the train is not visible inn the image) and provide external knowledge that cannot be derived directly from the image ( {e.g} ., the person depicted is Mona Lisa).", "\\newline Large-scale structured Knowledge Bases (KBs) [@bib:auer2007dbpedia,banko2007open,bollacker2008freebase,carlson2010toward,chen2013neil,mahdisoltani2014yago3,vrandevcic2014wikidata] in contrast, offer an explicit, and typically larger-scale, representation of such external information.", "In structured KBs, knowledge is typically represented by a large number of triples of the form (arg1,rel,arg2) , where arg1 and arg2 denote two concepts in the KB and rel is a predicate representing the relationship between them.", "A collection of such triples form a large interlinked graph.", "Such triples are often described according to a Resource Description Framework [@bib:rdf2014resource] (RDF) specification, and housed in a relational database management system (RDBMS), or triple-store, which allows queries over the data.", "The information in KBs can be accessed efficiently using a query language.", "In this work we use SPARQL Protocol [@bib:prud2008sparql] to query the OpenLink Virtuoso [@bib:erling2012virtuoso] RDBMS.", "\\newline Large-scale structured KBs are constructed either by manual annotation ( {e.g} ., DBpedia [@bib:auer2007dbpedia] , Freebase [@bib:bollacker2008freebase] and Wikidata [@bib:vrandevcic2014wikidata] ), or by automatic extraction from unstructured/semi-structured data ( {e.g} ., YAGO [@bib:hoffart2013yago2,mahdisoltani2014yago3] , OpenIE [@bib:banko2007open,etzioni2011open,fader2011identifying] , NELL [@bib:carlson2010toward] , NEIL [@bib:chen2013neil,chen2014enriching] , WebChild [@bib:tandon2014acquiring,tandon2014webchild] , ConceptNet [@bib:liu2004conceptnet] ).", "The KB that we use here is the combination of DBpedia, WebChild and ConceptNet, which contains structured information extracted from Wikipedia and unstructured online articles.", "\\newline In the NLP and AI communities, there is an increasing interest in the problem of natural language question answering using structured KBs (referred to as KB-QA) [@bib:berant2013semantic,bordes2014question,cai2013large,fader2014open,kolomiyets2011survey,kwiatkowski2013scaling,yao2014information,liang2013learning,unger2012template] .", "However, VQA systems exploiting KBs are still relatively rare.", "Zhu {et al} .", "[@bib:zhu2015building] used a KB and RDBMS to answer image-based queries.", "However, in contrast to our approach, they build a KB for the purpose, using an MRF model, with image features and scene/attribute/affordance labels as nodes.", "The links between nodes represent mutual compatibility relationships.", "The KB thus relates specific images to specified image-based quantities, which are all that exists in the database schema.", "This prohibits question answering that relies on general knowledge about the world.", "Most recently, Wu {et al} .", "[@bib:wu2015ask] encoded text mined from DBpedia to a vector with the Word2Vec model which they combined with visual features to generate answers using an LSTM model.", "However, their proposed method only extracts discrete pieces of text from the knowledge base, thus ignoring the power of its structural representation.", "Neither [@bib:zhu2015building] nor [@bib:wu2015ask] are capable of explicit reasoning, in contrast to the method we propose here.", "\\newline The approach closest to that we propose here is that of Wang {et al} .", "[@bib:wang2015explicit] , as it is capable of reasoning about an image based on information extracted from a knowledge base.", "However, their method largely relies on the pre-defined template, which only accepts questions in a pre-defined format.", "Our method does not suffer this constraint.", "Moreover, their proposed model used only a single manually annotated knowledge source whereas the method we propose uses this plus two additional two automatically-learned knowledge bases.", "This is critical because manually constructing such KBs does not scale well, and using automatically generated KBs thus enables the proposed method to answer more general questions.", "\\newline </subsection>  </section>"], ["<section> <title> III Creating the FVQA Dataset </title>  Different from previous VQA datasets [@bib:antol2015vqa,gao2015you,Yu_2015_ICCV,ren2015image,zhu2015visual7w] that only ask annotators to provide question-answer pairs without any restrictions, we want the questions in our dataset only can be asked and answered after the annotator knowing some commonsense knowledge.", "This means that we can not simply distribute only images to questioners like others [@bib:antol2015vqa,zhu2015visual7w] .", "We need to provide a large number of supporting facts (commonsense knowledge) which are related to the visual concepts in the image.", "We build our own on-line question collection system and allow users to choose images, visual concepts and candidate supporting facts freely.", "Then the user can ask questions based on his/her previous choices (all choices will be recorded).", "We give each annotator a tutorial and restrict them to ask questions that only to be answered with both visual concept in the image and the provided external commonsense knowledge.", "Following sections provide more details about images, visual concepts, knowledge bases and our question collection system and procedures.", "We also compare with other VQA datasets with some data statistics.", "\\newline <subsection> <title> III-A Images and Visual Concepts </title> We sample $ 2190 $ images from the MS COCO [@bib:lin2014microsoft] validation set and ImageNet [@bib:deng2009imagenet] test set for collecting questions.", "Images from MS COCO can provide more context because they have more complicated scenes.", "Scenes of ImageNet images are much simpler but there are more object categories (200 in ImageNet vs. 80 in MS COCO).", "\\newline Three types of visual concept extractors are applied to each image: \\newline Object Detector: Two Fast-RCNN [@bib:girshick2015fast] models are trained by the authors on MS COCO $ 80 $ -object (train split) and ImageNet $ 200 $ -object datasets (train+val split) respectively.", "After combination, there are in total $ 234 $ classes of objects which can be detected in each image (see Appendix).", "\\newline Scene Classifier: The scene classifier trained on MIT Places $ 205 $ [@bib:zhou2014learning] dataset is adopted, which assigns each image with scene labels from $ 205 $ classes.", "\\newline Attribute Classifier: The image attributes for training are obtained from the ground truth captions of MS COCO images, which are made up of $ 24 $ actions, $ 92 $ objects (without bounding box information) and $ 25 $ scenes (see Appendix).", "A deep model is trained by Wu {et al} .", "[@bib:qi2015caption] on these training data and incorporated in this work.", "These $ 92 $ object and $ 25 $ scene classes are different from the concepts extracted using the above object detectors and scene classifiers, and they are combined together.", "\\newline In summary, there are in total $ 326 $ object, $ 221 $ scene and $ 24 $ action classes to be extracted.", "These visual concepts are further linked to a variety of external knowledge, as shown in the next section.", "\\newline </subsection> <subsection> <title> III-B Knowledge Bases </title> The knowledge about each visual concept is extracted from a range of existing structured knowledge bases, including DBpedia [@bib:auer2007dbpedia] , ConceptNet [@bib:liu2004conceptnet] and WebChild [@bib:tandon2014acquiring,tandon2014webchild] .", "\\newline DBpedia: The structured information stored in DBpedia is extracted from Wikipedia by crowd-sourcing.", "In this KB, concepts are linked to their categories and super-categories based on the SKOS Vocabulary .", "In this work, the categories and super-categories of all aforementioned visual concepts are extracted transitively.", "\\newline ConceptNet: This KB is made up of several commonsense relations, such as UsedFor , CreatedBy and IsA .", "Much of the knowledge is automatically generated from the sentences of the Open Mind Common Sense (OMCS) project .", "We adopt 11 common relations (predicates) in ConceptNet to generate questions and answers.", "\\newline WebChild: The work in [@bib:tandon2014acquiring] considered a form of commonsense knowledge being overlooked by most of existing KBs, which involves comparative relations such as Faster , Bigger and Heavier .", "In [@bib:tandon2014acquiring] , this form of information is extracted automatically from the Web.", "\\newline The predicates (relations) which we extract from each KB and the corresponding number of facts can be found in Table [@ref:LABEL:tab:predicates] .", "All the aforementioned structured information are stored in the form of RDF triples and can be accessed using Sparql queries.", "\\newline </subsection> <subsection> <title> III-C Question Collection </title> In this work, we focus on collecting visual questions which need to be answered with the help of supporting-facts.", "To this end, we designed a specialized system, in which the procedure of asking questions is conducted in the following steps: \\newline <list> \\ Selecting Concept: Annotators are given an image and a number of visual concepts (object, scene and action).", "They need to choose one of the visual concepts which is related to this image.", "\\newline \\ \\ Selecting Fact: Once a visual concept is selected, the associated facts are demonstrated in the form of sentences with the two entities underlined.", "For example, the fact (Train,Slower,Plane) is expressed as \u2018 Train is slower than plane \u2019.", "Annotators should select a correct and relevant fact by themselves.", "\\newline \\ \\ Asking Question and Giving Answer: The Annotators are required to ask a question, answering which needs the information from both of the image and the selected fact.", "The answer is limited to the two concepts in the supporting-fact.", "In other words, the source of the answer can be either the visual concept in the image (underlined in Table [@ref:LABEL:tab:predicates] ) or the concept in the KB.", "\\newline \\ </list> \\newline </subsection> <subsection> <title> III-D Data Statistics </title> <paragraph> <title> Dataset size and other statistics </title> In total, $ 5826 $ questions (corresponding to $ 4216 $ unique facts) are collected collaboratively by $ 38 $ individuals.", "In order to report significant statistics, we create 5 random splits of the dataset.", "In each split, we have $ 1100 $ training images and $ 1090 $ test images.", "Each split provides roughly $ 2927 $ and $ 2899 $ questions for training and test respectively.", "These questions can be categorized according to the type of visual concept being asked (Object, Scene or Action), the source of the answer (Image or KB) and the knowledge base of the supporting-fact (DBpedia, ConceptNet or Webchild).", "\\newline Table [@ref:LABEL:tab:trntst] shows the number of training/test questions falling into each of the above categories.", "We can see that most of the questions are related to the objects in the images and most of the answers are visual concepts (\u2018Answer-source\u2019 is \u2018Image\u2019).", "As for knowledge bases, $ 80\\% $ of the collected questions rely on the supporting-facts from ConceptNet.", "Answering $ 14\\% $ and $ 6\\% $ questions depends on the knowledge from DBpedia and Webchild respectively.", "\\newline Table [@ref:LABEL:tab:datalen] shows summary statistics of the dataset, such as the number of question categories, average question/answer length {etc} .", "We have totally 32 question types (see Section [@ref:LABEL:subsec:QQ_Maping] for more details).", "Compared to VQA-real [@bib:antol2015vqa] and Visual Genome [@bib:krishnavisualgenome] , our FVQA dataset provides longer questions, with average length $ 9.5 $ words.", "\\newline </paragraph> <paragraph> <title> Predicates distribution </title> The distributions of collected questions and facts over different types of predicates are shown in Figure [@ref:LABEL:fig:predicates] .", "The comparative predicates in WebChild are considered as one type and there are in total $ 13 $ types of predicates."]], "target": "We can see that the questions and facts are evenly distributed over the predicates of Category , UsedFor , IsA , RelatedTo , CapableOf , AtLocation , HasProperty and HasA , although these predicates differ significantly in the total numbers of extracted facts (see Table )."}, {"tabular": ["  Source  &  Estimated emission rate [ton/yr] ", " $ q_{\\textit{eng},1} $  &  35 ", " $ q_{\\textit{eng},2} $  &  80 ", " $ q_{\\textit{eng},3} $  &  5 ", " $ q_{\\textit{eng},4} $  &  5  "], "ref_sec": [["<section> <title> 1 Introduction </title>  This article presents a methodology for simultaneously estimating pollutant emission rates and calibrating atmospheric dispersion models using far-field measurements of particulate deposition.", "We use a Gaussian process (GP) emulator to efficiently approximate a relatively expensive partial differential equation (PDE) model for atmospheric dispersion which is then coupled with a Bayesian framework for source inversion and uncertainty quantification.", "\\newline Source identification (or inversion) problems are prevalent in various areas of environmental monitoring [@bib:kim2007advanced] and forensics [@bib:mudge2008environmental] .", "These problems are often difficult to solve due to the scarcity of data and the complexity of physical processes that obscure the true nature of sources.", "Traditionally, source identification problems are solved by a combination of empirical techniques such as chemical analysis [@bib:morrison2000application] , remote sensing methods like thermal imaging [@bib:matson1981identification] , and statistical tools such as principle component analysis [@bib:mudge2007multivariate] .", "Owing to the prevalence of measurement methods and chemical analysis in the forensics literature [@bib:colbeck2009,hesterharrison2008,spikmans2019forensics] , the application of mathematical models and numerical simulations is relatively under-developed.", "This is in part due to complexity of certain mathematical models, uncertainty in values of tuning parameters, and general difficulty in assessing confidence in simulations. And even when the errors and uncertainties in contaminant measurements may be well-known or controlled, the effect of those errors when they are used as inputs for a source inversion model is much less well understood.", "It is therefore crucial to quantify the effect of measurement errors on emissions estimates and obtain uncertainty bounds in order to make reliable and defensible claims in forensics applications.", "\\newline In the context of atmospheric pollutant dispersion, numerous mathematical models are available that provide approximations to the actual physical processes driving dispersion of particulates and other substances within the atmosphere [@bib:chatwin1982use,lewellen1989meteorological] .", "A common challenge in dispersion modelling is to maintain accuracy since many models suffer from sizable errors and large uncertainties in parameters.", "In some cases, these inaccuracies can be addressed by increasing the model complexity to account for physical processes that have been neglected, in the hope that the resulting more complex model yields correspondingly higher accuracy and more realistic simulations.", "However, in many practical applications, such extensions lead to no significant improvement in the solution because the model errors are far outweighed by the uncertainty in values of the model parameters.", "This difficulty is further exacerbated by the fact that many models contain a large number of unknown model parameters.", "Some of these parameters have a clear physical basis, such as diffusion coefficients, particulate density and settling velocities, whereas others are mathematical (or fitting) parameters such as the Monin-Obukhov length, atmospheric stability classes, or terrain roughness length.", "\\newline Direct measurements of many physical and mathematical parameters are often problematic or even infeasible; for example, eddy diffusion coefficients are typically difficult to estimate in practice [@bib:seinfeld1998atmospheric] .", "One is therefore often forced to deal with significant uncertainties in the true value of model parameters, even when complex models are employed that under ideal circumstances could potentially simulate results very accurately.", "Because large errors in model parameters can severely contaminate simulations, it is therefore essential when simulating atmospheric dispersion scenarios to simultaneously understand and control the parameter uncertainty.", "Sources of uncertainty are diverse and can be classified roughly into one of three types [@bib:rao2005uncertainty] : \\newline <list> \\ Data uncertainty: when the empirical measurements or model parameter values are inaccurate; \\newline \\ \\ Model uncertainty: where the model does not capture all physical processes of interest; or \\newline \\ \\ Stochastic uncertainty: relating to the inherent unpredictability or randomness in physical processes, such as atmospheric turbulence.", "\\newline \\ </list> In this work we focus primarily on dealing with the first case of data uncertainty appearing in the context of atmospheric source inversion problems.", "\\newline Despite the difficulty of obtaining accurate simulations, there is a growing need to develop more accurate and computationally efficient models for practical atmospheric dispersion applications [@bib:leelHossy2014dispersion] .", "The necessity for computational efficiency comes from the fact that models for atmospheric transport are usually expressed as systems of partial differential equations that are computationally expensive to solve at the typical resolutions required, which is a particular limitation for real-time applications.", "Efficiency is of even greater importance in the context of source inversion problems, since a single solution of the inverse problem may require a large number of evaluations of the forward dispersion model.", "One of the goals of this work is therefore to demonstrate how to use computationally demanding forward models to solve atmospheric source inversion problems in an efficient manner.", "\\newline <subsection> <title> 1.1 Atmospheric dispersion modelling </title> We model the dispersion of pollutants in the atmosphere using the advection-diffusion PDE \\newline <equationgroup> <equation> $ \\frac{\\partial C(\\textbf{x},t)}{\\partial t}+\\nabla\\cdot(\\bar{% \\textbf{v}}C(\\textbf{x},t)-\\textbf{D}\\nabla C(\\textbf{x},t))=f(\\textbf{x},t), $ </equation> </equationgroup> where $ C(\\textbf{x},t) $ denotes the concentration of pollutant at location $ \\textbf{x}=(x,y,z)\\in\\mathbb{R}^{3} $ , $ t $ is time, $ \\bar{\\textbf{v}} $ is the wind velocity field, D is the diffusivity tensor, and $ f(\\textbf{x},t) $ is a pollutant source term.", "Throughout this paper we always consider ( [@ref:LABEL:eqnModelIntro] ) with zero initial condition $ C(\\textbf{x},0)=0 $ , so that no pre-existing transient concentrations exist.", "We make this assumption for reasons of simplicity, and because in practice it is often very difficult to measure these pre-existing concentrations.", "We focus on the case of a finite collection of $ n $ point sources each having an emission rate that is constant in time, which allows $ f $ to be written as \\newline <equationgroup> <equation> $  f(\\textbf{x},t)=\\sum_{j=1}^{n}q_{j}\\delta(\\textbf{x}-\\textbf{x}_% {j}), $ </equation> </equationgroup> where $ \\textbf{q}=(q_{1},q_{2},\\ldots,q_{n})^{T}\\in\\mathbb{R}^{n} $ represent emission rates, $ \\{\\textbf{x}_{j}\\}_{j=1}^{n} $ are the locations of the sources, and $ \\delta(\\textbf{x}-\\textbf{x}_{j}) $ are Dirac delta functions representing point sources at the locations $ \\textbf{x}_{j} $ .", "The wind velocity field $ \\bar{\\textbf{v}} $ and diffusivity tensor D are often difficult to measure and so are replaced using simpler mathematical approximations that depend upon empirical parameters describing the variation of $ \\bar{\\textbf{v}} $ and D with time and space.", "Common examples of such parameters include roughness length, Monin-Obukhov length and Pasquill stability class [@bib:seinfeld1998atmospheric] .", "We combine all empirical parameters together into a vector $ \\boldsymbol{\\theta}=(\\theta_{k})\\in\\mathbb{R}^{m} $ , and then denote the linear operator $ \\nabla\\cdot(\\textbf{v}+\\textbf{D}\\nabla) $ on the left hand side of $ \\eqref{eqnModelIntro} $ by $ \\textbf{L}(\\boldsymbol{\\theta}) $ to make explicit the dependence of the operator on the parameter vector $ \\boldsymbol{\\theta} $ , noting that the dependence of L on $ \\boldsymbol{\\theta} $ can still be nonlinear.", "Then we rewrite ( [@ref:LABEL:eqnModelIntro] ) as \\newline <equationgroup> <equation> $ \\frac{\\partial C(\\textbf{x},t)}{\\partial t}+\\textbf{L}(% \\boldsymbol{\\theta})C(\\textbf{x},t)=\\sum_{j=1}^{n}q_{j}\\delta(\\textbf{x}-% \\textbf{x}_{j}).", "$ </equation> </equationgroup> The task of finding the concentration $ C(\\textbf{x},t) $ given q and $ \\boldsymbol{\\theta} $ , supplemented by suitable boundary and initial conditions, is referred to as the forward problem in the context of atmospheric pollutant transport.", "\\newline </subsection> <subsection> <title> 1.2 Atmospheric source inversion </title> The goal of atmospheric source inversion is to estimate the source term $ f(\\textbf{x},t) $ on the right hand side of ( [@ref:LABEL:eqnModelIntro] ) from indirect measurements of the concentration $ C(\\textbf{x},t) $ .", "We consider equation ( [@ref:LABEL:eqnParametric] ) with a set of given point sources at known locations, but with unknown constant emission rates.", "Our aim is then to estimate the emission rates $ q_{j} $ from indirect measurements of $ C(\\textbf{x},t) $ .", "To this end, the source inversion problem is the reverse of the forward problem ( [@ref:LABEL:eqnParametric] ) and is thus an inverse problem .", "\\newline We assume that measurements of concentration can be treated in terms of the action of bounded linear operators on $ C $ .", "For example, a common measurement in particulate dispersion studies is the total accumulated deposition of pollutants in a region $ R\\subset\\mathbb{R}^{2} $ of the ground surface after some time $ T $ has elapsed.", "Such a measurement can be written as \\newline <equationgroup> <equation> $ \\int_{R}\\int_{0}^{T}C(x,y,0,t)v_{\\textit{set}}\\,dt\\,dx\\,dy, $ </equation> </equationgroup> where $ v_{\\textit{set}} $ is the vertical settling velocity at the ground surface for the pollutant of interest.", "The class of all possible linear measurements is large and includes many commonly used methods in practice ranging from short time average measurements such as Xact ambient metal monitors [@bib:cooper-environmental-2015] and Andersen high-volume air samplers [@bib:thermo-scientific-2015] , as well as averaged long-time measurements accumulated in dustfall jars.", "\\newline Suppose now that field measurements of $ C $ are taken at $ d $ locations in space and collected in a vector $ \\textbf{w}\\in\\mathbb{R}^{d} $ .", "Since the measurements are linear, we can write \\newline <equationgroup> <equation> $ \\textbf{w}=\\mathcal{A}(\\boldsymbol{\\theta})\\,\\textbf{q}, $ </equation> </equationgroup> where $ \\mathcal{A}(\\boldsymbol{\\theta}) $ is a $ d\\times n $ matrix that represents the solution map of the PDE ( [@ref:LABEL:eqnParametric] ) and depends nonlinearly on the model parameters $ \\boldsymbol{\\theta} $ .", "Source inversion requires finding q given w , and it is well known that this problem is ill-posed in the sense of Hadamard [@bib:enting1990inverse,isakov1990inverse] ; that is, small variations in the inputs ( w ) result in large variations in the solution ( q ).", "This is the case even if the true value of $ \\boldsymbol{\\theta} $ is known exactly.", "\\newline A variety of different approaches have been proposed in the literature to solve source inversion problems [@bib:haupt-young-2008,rao-2007] .", "Lin and Chang [@bib:lin2002relative] used an air trajectory statistical approach to estimate the strength of different sources of volatile organic compounds of anthropogenic origin.", "Stockie and Lushi [@bib:lushi2010inverse] used a Gaussian plume approximation to the governing PDEs to estimate ground-level deposition of zinc from a lead-zinc smelter, using linear least-squares to perform the source inversion.", "Skiba [@bib:skiba2003method] solved the adjoint equation for the advection-diffusion equation and used penalized least-squares to invert the sources.", "\\newline All of the methods just mentioned yield point estimates for the source strengths but provide no direct measure of uncertainty in the estimated parameters.", "This drawback is overcome by the use of probabilistic methods such as the Bayesian approach for solving inverse problems.", "Such methods provide a robust setting for solving the inverse problem and quantifying the uncertainties associated with the solution.", "Sohn et al. [@bib:sohn2002rapidly] developed an algorithm to obtain estimates and uncertainties for the location and strength of pollutant sources in buildings using data obtained from a COMIS simulation.", "Hosseini and Stockie [@bib:hosseini2016bayesian] used a Gaussian plume model combined with experimental data to estimate and quantify the uncertainty of airborne fugitive emissions.", "In a follow-up publication [@bib:hosseini2016airborne] , the same authors coupled a Bayesian approach with a finite volume solver to estimate and quantify the strength of airborne contaminants from a fixed number of point sources at known locations.", "Keats et al. [@bib:keats2007bayesian] obtained probability distributions for source strengths and locations using data from the standard \u201cMuck Urban Setting Test\u201d experiment.", "\\newline The central contribution of this work is in proposing a method that deals with the calibration parameters $ \\boldsymbol{\\theta} $ as unknowns.", "We infer $ \\boldsymbol{\\theta} $ along with the vector of source strengths q , which results in a nonlinear inverse problem that is solved within the Bayesian framework.", "The problem of estimating the true value of the parameters $ \\boldsymbol{\\theta} $ is referred to as model calibration .", "Traditionally, the process of tuning parameters in atmospheric dispersion models is done empirically using Pasquill stability classes [@bib:turner1994workbook,seinfeld1998atmospheric] that are often chosen heuristically.", "Instead, we automatically estimate these parameters using the information contained in the measured data w .", "\\newline </subsection> <subsection> <title> 1.3 Outline </title> The remainder of this article is organized as follows: In Section [@ref:LABEL:sec:emulation] we introduce GP emulators for approximation of computationally expensive models.", "Section [@ref:LABEL:sec:bayesianframework] is dedicated to the Bayesian framework for simultaneous calibration of the model and solution of the source inversion problem.", "In Section [@ref:LABEL:secIndustrialCase] we apply our framework for emulation and calibration to an industrial case study involving air-borne particulate emissions from a lead-zinc smelter in Trail, British Columbia, Canada and compare our results with previous studies and engineering estimates.", "\\newline </subsection>  </section>"], ["<section> <title> 2 Emulation of atmospheric dispersion models </title>  In this section we introduce a framework for emulation of atmospheric dispersion models using GPs.", "Equation ( [@ref:LABEL:eqnParametric] ) captures the linear relationship between source strengths $ \\textbf{q}\\in\\mathbb{R}^{n} $ and concentration $ C(\\textbf{x},t) $ .", "Under the further assumption that the data $ \\textbf{w}\\in\\mathbb{R}^{d} $ also depends linearly on concentration $ C(\\textbf{x},t) $ , we can write the map $ \\textbf{q}\\mapsto\\textbf{w} $ in the linear form ( [@ref:LABEL:eqnLinear] ), although we note that in general, $ \\mathcal{A}(\\boldsymbol{\\theta})\\in\\mathbb{R}^{d\\times n} $ may depend nonlinearly on $ \\boldsymbol{\\theta}\\in\\mathbb{R}^{m} $ .", "Therefore, the map $ (\\textbf{q},\\boldsymbol{\\theta})\\mapsto\\textbf{w} $ can be split into two parts: for fixed values of $ \\boldsymbol{\\theta} $ the map $ (\\cdot,\\boldsymbol{\\theta})\\mapsto\\textbf{w} $ is linear, whereas for a fixed q the mapping $ (\\textbf{q},\\cdot)\\mapsto\\textbf{w} $ is nonlinear.", "We will exploit this structure in the design of our source inversion algorithm, using the fact that the linear map $ (\\cdot,\\boldsymbol{\\theta})\\mapsto\\textbf{q} $ can be dealt with efficiently, but that we will need to approximate the nonlinear map $ (\\textbf{q},\\cdot)\\mapsto\\textbf{w} $ .", "\\newline To this end, we approximate the matrix \\newline <equationgroup> <equation> $ \\mathcal{A}(\\boldsymbol{\\theta})=[\\mathfrak{a}_{ij}(\\boldsymbol{% \\theta})]\\in\\mathbb{R}^{d\\times n}, $ </equation> </equationgroup> with another matrix \\newline <equationgroup> <equation> $  A(\\boldsymbol{\\theta})=[a_{ij}(\\boldsymbol{\\theta})]\\in\\mathbb{R% }^{d\\times n}, $ </equation> </equationgroup> where each entry $ \\mathfrak{a}_{ij}:\\mathbb{R}^{m}\\mapsto\\mathbb{R} $ of $ \\mathcal{A} $ is approximated by the map $ a_{ij}:\\mathbb{R}^{m}\\mapsto\\mathbb{R} $ .", "For this purpose, we make use of GP emulators of [@bib:kennedy2001bayesian] .", "Emulation with GPs is a well-established method in dynamic computer experiments and machine learning and we refer the reader to [@bib:rasmussen2006gaussian,kennedy2001bayesian,o2006bayesian,conti2009gaussian] and the references within for an introduction to this subject.", "Here, we outline our method for approximating $ \\mathcal{A} $ and will not discuss the theory of GP emulators with the exception of a few crucial definitions and results.", "\\newline <theorem> Definition 1 A GP on $ \\mathbb{R}^{m} $ is a collection of real-valued random variables $ \\{g(\\mathbf{x})\\}_{\\mathbf{x}\\in\\mathbb{R}^{m}} $ , any finite collection of which have a joint Gaussian distribution.", "\\newline </theorem> We denote a GP using the notation \\newline <equationgroup> <equation> $  g\\sim\\mathcal{GP}(\\bar{g},\\kappa), $ </equation> </equationgroup> where the mean of the GP is \\newline <equationgroup> <equation> $ \\bar{g}(\\boldsymbol{\\theta})=\\mathbb{E}\\>g(\\boldsymbol{\\theta})% \\qquad\\forall\\boldsymbol{\\theta}\\in\\mathbb{R}^{m}, $ </equation> </equationgroup> and $ \\kappa $ is a positive semi-definite kernel with \\newline <equationgroup> <equation> $ \\kappa(\\boldsymbol{\\theta},\\boldsymbol{\\theta}^{\\prime})=\\mathbb{% E}\\>(g(\\boldsymbol{\\theta})-\\bar{g}(\\boldsymbol{\\theta}))(g(\\boldsymbol{\\theta% }^{\\prime})-\\bar{g}(\\boldsymbol{\\theta}^{\\prime}))\\qquad\\forall\\boldsymbol{% \\theta},\\boldsymbol{\\theta}^{\\prime}\\in\\mathbb{R}^{m}. $ </equation> </equationgroup> We are primarily interested in isotropic kernels that satisfy \\newline <equationgroup> <equation> $ \\kappa(\\boldsymbol{\\theta},\\boldsymbol{\\theta}^{\\prime})=\\kappa(|% \\boldsymbol{\\theta}-\\boldsymbol{\\theta}^{\\prime}|), $ </equation> </equationgroup> from which it follows that if $ \\bar{g} $ is continuous and $ \\kappa $ is continuous at zero, then the GP is also mean square continuous [@bib:rasmussen2006gaussian] .", "\\newline Let $ \\{\\boldsymbol{\\theta}_{k}\\}_{k=1}^{K} $ be a collection of design points in the parameter space $ \\mathbb{R}^{m} $ for some fixed $ K>0 $ , and let $ \\{\\mathbf{e}_{j}\\}_{j=1}^{n} $ be the unit coordinate basis vectors in $ \\mathbb{R}^{n} $ .", "Then for each index pair $ (i,j) $ define a GP \\newline <equationgroup> <equation> $  g_{ij}\\sim\\mathcal{GP}(\\bar{g}_{ij},\\kappa_{ij}), $ </equation> </equationgroup> subject to the constraint \\newline <equationgroup> <equation> $  g_{ij}(\\boldsymbol{\\theta}_{k})=\\mathfrak{a}_{ij}(\\boldsymbol{% \\theta}_{k})=(\\mathcal{A}(\\boldsymbol{\\theta}_{k})\\mathbf{e}_{j})_{i}\\qquad% \\text{for }k=1,\\ldots,K. $ </equation> </equationgroup> That is, each $ g_{ij} $ interpolates the $ \\mathfrak{a}_{ij} $ at points $ \\{\\boldsymbol{\\theta}_{k}\\}_{k=1}^{K} $ .", "We can now identify $ g_{ij} $ using well-known identities for conditioning of Gaussian random variables [@bib:rasmussen2006gaussian] .", "Let $ \\Theta:=(\\boldsymbol{\\theta}_{1},\\ldots,\\boldsymbol{\\theta}_{K})^{T} $ and define the following matrices and vectors \\newline <equationgroup> <equation> $  G_{ij}(\\Theta,\\Theta)\\in\\mathbb{R}^{K\\times K},\\qquad $ $  G_{ij}(\\Theta,\\Theta)\\in\\mathbb{R}^{K\\times K},\\qquad $ $ [G_{ij}(\\Theta,\\Theta)]_{k\\ell}:=\\kappa_{ij}(\\boldsymbol{\\theta}_% {k},\\boldsymbol{\\theta}_{\\ell}), $ $ [G_{ij}(\\Theta,\\Theta)]_{k\\ell}:=\\kappa_{ij}(\\boldsymbol{\\theta}_% {k},\\boldsymbol{\\theta}_{\\ell}), $ </equation> <equation> $  G_{ij}(\\boldsymbol{\\theta},\\Theta)\\in\\mathbb{R}^{1\\times K},\\qquad $ $  G_{ij}(\\boldsymbol{\\theta},\\Theta)\\in\\mathbb{R}^{1\\times K},\\qquad $ $ [G_{ij}(\\boldsymbol{\\theta},\\Theta)]_{\\ell}:=\\kappa_{ij}(% \\boldsymbol{\\theta},\\boldsymbol{\\theta}_{\\ell}), $ $ [G_{ij}(\\boldsymbol{\\theta},\\Theta)]_{\\ell}:=\\kappa_{ij}(% \\boldsymbol{\\theta},\\boldsymbol{\\theta}_{\\ell}), $ </equation> <equation> $  G_{ij}(\\Theta,\\boldsymbol{\\theta})\\in\\mathbb{R}^{K\\times 1},\\qquad $ $  G_{ij}(\\Theta,\\boldsymbol{\\theta})\\in\\mathbb{R}^{K\\times 1},\\qquad $ $ [G_{ij}(\\Theta,\\boldsymbol{\\theta})]_{k}:=\\kappa_{ij}(\\boldsymbol% {\\theta}_{k},\\boldsymbol{\\theta}),", "$ $ [G_{ij}(\\Theta,\\boldsymbol{\\theta})]_{k}:=\\kappa_{ij}(\\boldsymbol% {\\theta}_{k},\\boldsymbol{\\theta}), $ </equation> <equation> $ \\mathbf{g}_{ij}\\in\\mathbb{R}^{K\\times 1},\\qquad $ $ \\mathbf{g}_{ij}\\in\\mathbb{R}^{K\\times 1},\\qquad $ $ [\\mathbf{g}_{ij}]_{k}=\\mathfrak{a}_{ij}(\\boldsymbol{\\theta}_{k}), $ $ [\\mathbf{g}_{ij}]_{k}=\\mathfrak{a}_{ij}(\\boldsymbol{\\theta}_{k}), $ </equation> </equationgroup> for $ k,\\ell=1,\\ldots,K $ .", "Then we have \\newline <equationgroup> <equation> $  g_{ij}(\\boldsymbol{\\theta})\\sim\\mathcal{GP}(\\bar{g}_{ij}(% \\boldsymbol{\\theta}),\\sigma_{ij}(\\boldsymbol{\\theta})), $ </equation> </equationgroup> where \\newline <equationgroup> <equation> $ \\bar{g}_{ij}(\\boldsymbol{\\theta})=G_{ij}(\\boldsymbol{\\theta},% \\Theta)G_{ij}(\\Theta,\\Theta)^{-1}\\mathbf{g}_{ij}, $ $ \\bar{g}_{ij}(\\boldsymbol{\\theta}) $ $ =G_{ij}(\\boldsymbol{\\theta},\\Theta)G_{ij}(\\Theta,\\Theta)^{-1}% \\mathbf{g}_{ij}, $ </equation> <equation> $ \\sigma_{ij}(\\boldsymbol{\\theta})=\\kappa_{ij}(\\boldsymbol{\\theta},% \\boldsymbol{\\theta})-G_{ij}(\\boldsymbol{\\theta},\\Theta)\\,\\left[G_{ij}(\\Theta,% \\Theta)^{-1}\\right]G_{ij}(\\Theta,\\boldsymbol{\\theta}), $ $ \\sigma_{ij}(\\boldsymbol{\\theta}) $ $ =\\kappa_{ij}(\\boldsymbol{\\theta},\\boldsymbol{\\theta})-G_{ij}(% \\boldsymbol{\\theta},\\Theta)\\,\\left[G_{ij}(\\Theta,\\Theta)^{-1}\\right]G_{ij}(% \\Theta,\\boldsymbol{\\theta}), $ </equation> </equationgroup> for all $ \\boldsymbol{\\theta}\\in\\mathbb{R}^{m} $ .", "Since the mean $ \\bar{g}_{ij} $ interpolates the data $ \\mathfrak{a}_{ij}(\\boldsymbol{\\theta}_{k}) $ , it is also a good candidate for approximating $ \\mathfrak{a}_{ij} $ , and so we take \\newline <equationgroup> <equation> $  a_{ij}(\\boldsymbol{\\theta})=\\bar{g}_{ij}(\\boldsymbol{\\theta})% \\qquad\\forall\\boldsymbol{\\theta}\\in\\mathbb{R}^{m}. $ </equation> </equationgroup> The advantage of using this approach for interpolation is that it is possible to assess the uncertainty and quality of the emulator via the covariance operator $ \\sigma(\\boldsymbol{\\theta}) $ .", "\\newline The variance at a point $ \\boldsymbol{\\theta}_{i} $ is given by the term $ \\sigma_{ii}(\\boldsymbol{\\theta}) $ and is strongly influenced by the spatial distribution of the points $ \\{\\boldsymbol{\\theta}_{k}\\}_{k=1}^{K} $ [@bib:johnson1990minimax] .", "Thus, in order to emulate $ \\mathcal{A}(\\boldsymbol{\\theta}) $ , it is crucial to choose the points $ \\boldsymbol{\\theta}_{k} $ in such a way that the uncertainty of the emulator is minimized.", "A popular method for choosing the design points is known as a space-filling design [@bib:johnson1990minimax] , instances of which include the maximum entropy design [@bib:maxEntDesign] , uniform design [@bib:Fang] , and Latin Hypercube design (LHD) [@bib:LHD] .", "Following Jones et al. [@bib:jones] we use a combination of the LHD and maximin designs, which is introduced in [@bib:johnson1990minimax] and shown to outperform most space-filling design methods for GP interpolation.", "\\newline We now briefly outline our space-filling design procedure.", "The main idea in the LHD is to distribute design points such that low-dimensional projections of the points do not overlap.", "One issue with LHD is that it does not have desirable space-filling properties and so leads to large uncertainties in the emulator in high dimensions.", "Thus, LHD is often used as an initial condition for other space-filling design methodologies and so here we complement the LHD with an approximate maximin design [@bib:johnson1990minimax] .", "\\newline The idea behind the maximin design is as follows. Let $ T\\subset\\mathbb{R}^{n} $ be the subset of parameter space in which we wish to construct our design points and consider all subsets $ S $ of $ T $ with finite (fixed) cardinality, say $ |S|=k $ .", "A maximin design $ S^{o} $ is a set of points that satisfies \\newline <equationgroup> <equation> $ \\max_{S\\subset T,\\text |S|=k}\\;\\min_{s,s^{\\prime}\\in S}d(s,s^{% \\prime})=\\min_{s,s^{\\prime}\\in S^{o}}d(s,s^{\\prime}), $ </equation> </equationgroup> where $ d $ is the Euclidean metric.", "The optimization problem in equation ( [@ref:LABEL:eqnmaximin] ) is not easily solvable, which is why we resort to metaheuristic optimization procedures.", "In particular, we use the particle swarm algorithm [@bib:arora2015optimization] , initiated with an LHD.", "We then apply a number of iterations of particle swarm that is chosen depending on our available computational budget.", "In Figure [@ref:LABEL:figSpaceFilling] we show an example of the final design after 10,000 steps of a particle swarm algorithm.", "\\newline  </section>"], ["<section> <title> 3 The Bayesian inversion framework </title>  We introduce the Bayesian framework for calibration and solution of inverse problems in this section.", "The Bayesian approach combines the data w together with prior knowledge to give a posterior probability distribution on the source strengths q and calibration parameters $ \\boldsymbol{\\theta} $ .", "Following Bayes\u2019 rule, the posterior distribution of $ (\\boldsymbol{\\theta},\\textbf{q}) $ is given by \\newline <equationgroup> <equation> $ \\mathbb{P}_{\\textit{post}}(\\boldsymbol{\\theta},\\textbf{q}|\\textbf% {w})=\\frac{\\mathbb{P}_{\\textit{like}}(\\textbf{w}|\\boldsymbol{\\theta},\\textbf{q% })\\,\\mathbb{P}_{\\textit{prior}}(\\boldsymbol{\\theta},\\textbf{q})}{Z(\\textbf{w})}, $ </equation> </equationgroup> where $ \\mathbb{P}_{\\textit{like}}(\\textbf{w}|\\boldsymbol{\\theta},\\textbf{q}) $ is the likelihood probability of w given both $ \\boldsymbol{\\theta} $ and q , which represents the probability of observing w given fixed values q and $ \\boldsymbol{\\theta} $ .", "The probability distribution $ \\mathbb{P}_{\\textit{prior}}(\\boldsymbol{\\theta},\\textbf{q}) $ is called the prior probability that expresses prior knowledge of the possible values of q and $ \\boldsymbol{\\theta} $ , before observing any experimental data.", "Finally, $ Z(\\textbf{w}) $ is a constant that normalizes the posterior probability so that it integrates to one, leading to the requirement that \\newline <equationgroup> <equation> $  Z(\\textbf{w})=\\int\\mathbb{P}_{\\textit{like}}(\\textbf{w}|% \\boldsymbol{\\theta},\\textbf{q})\\,\\mathbb{P}_{\\textit{prior}}(\\boldsymbol{% \\theta},\\textbf{q})\\,d\\boldsymbol{\\theta}\\,d\\textbf{q}. $ </equation> </equationgroup> \\newline We next assume that the linearity requirement ( [@ref:LABEL:eqnLinear] ) holds for physical measurements up to some additive Gaussian measurement noise, so that \\newline <equationgroup> <equation> $ \\textbf{w}=\\mathcal{A}(\\boldsymbol{\\theta})\\textbf{q}+\\epsilon% \\quad\\text{with}\\quad\\epsilon\\sim\\mathcal{N}(0,\\Sigma).", "$ </equation> </equationgroup> Here, $ \\epsilon $ is a normally distributed random vector with mean zero and covariance $ \\Sigma\\in\\mathbb{R}^{d\\times d} $ , which is assumed positive-definite.", "The measurement noise $ \\epsilon $ models the deviations in the measurements w due to missing physics and uncertainty in measurements.", "Under this assumption, it can be readily shown that [@bib:Somersalo] \\newline <equationgroup> <equation> $ \\mathbb{P}_{\\textit{like}}(\\textbf{w}|\\boldsymbol{\\theta},\\textbf% {q})=\\frac{1}{(2\\pi\\text{det}\\Sigma)^{\\frac{1}{2}}}\\exp\\left(-\\frac{1}{2}\\left% \\|\\Sigma^{-1/2}(\\mathcal{A}(\\boldsymbol{\\theta})\\textbf{q}-\\textbf{w})\\right\\|% ^{2}\\right).", "$ </equation> </equationgroup> \\newline The choice of the prior distribution depends on previous knowledge about the model parameters and so is problem specific.", "For atmospheric dispersion models, the parameter $ \\boldsymbol{\\theta} $ often depends on atmospheric conditions, whereas the emission rates in the vector q depend on the physical processes that generated the emissions.", "Consequently, it is reasonable to assume a priori that q and $ \\boldsymbol{\\theta} $ are statistically independent, so that \\newline <equationgroup> <equation> $ \\mathbb{P}_{\\textit{prior}}(\\boldsymbol{\\theta},\\textbf{q})=% \\mathbb{P}_{\\textit{prior}}(\\boldsymbol{\\theta})\\,\\mathbb{P}_{\\textit{prior}}(% \\textbf{q}).", "$ </equation> </equationgroup> In most cases, one chooses a prior for q that imposes a positivity constraint on the emission rates, whereas priors on $ \\boldsymbol{\\theta} $ typically reflect acceptable ranges of calibration parameters.", "Beyond these assumptions, the choice of the prior density for $ \\boldsymbol{\\theta} $ and q must be made on a case by case basis.", "In Section [@ref:LABEL:secIndustrialCase] , we present a particular prior distribution for $ (\\boldsymbol{\\theta},\\textbf{q}) $ in the context of an industrial case study.", "\\newline A key step in our source inversion approach is approximating the posterior probability $ \\mathbb{P}_{\\textit{post}} $ through an approximation for the map $ \\mathcal{A} $ .", "Let $ A $ be the GP emulator for $ \\mathcal{A} $ as outlined in Section [@ref:LABEL:sec:emulation] , then we can approximate the likelihood $ \\mathbb{P}_{\\textit{like}} $ in ( [@ref:LABEL:eqnLike] ) using \\newline <equationgroup> <equation> $ \\widehat{\\mathbb{P}_{\\textit{like}}}(\\textbf{w}|\\boldsymbol{% \\theta},\\textbf{q})=\\frac{1}{(2\\pi\\text{det}\\Sigma)^{\\frac{1}{2}}}\\exp\\left(-% \\frac{1}{2}\\left\\|\\Sigma^{-1/2}({A}(\\boldsymbol{\\theta})\\textbf{q}-\\textbf{w})% \\right\\|^{2}\\right).", "$ </equation> </equationgroup> Substituting this expression into Bayes\u2019 rule ( [@ref:LABEL:eqnBayesChp4] ) yields the approximate posterior \\newline <equationgroup> <equation> $ \\widehat{\\mathbb{P}_{\\textit{post}}}(\\boldsymbol{\\theta},\\textbf{% q}|\\textbf{w})=\\frac{\\widehat{\\mathbb{P}_{\\textit{like}}}(\\textbf{w}|% \\boldsymbol{\\theta},\\textbf{q})\\,\\mathbb{P}_{\\textit{prior}}(\\boldsymbol{% \\theta},\\textbf{q})}{\\widehat{Z}(\\textbf{w})}, $ </equation> </equationgroup> where the constant $ \\widehat{Z} $ is defined similar to ( [@ref:LABEL:eqnPropConst] ).", "If the map $ A $ approximates $ \\mathcal{A} $ closely, then we expect $ \\widehat{\\mathbb{P}_{\\textit{post}}} $ to be close to $ \\mathbb{P}_{\\textit{post}} $ .", "We refer the reader to [@bib:stuart2018posterior] and references therein for a detailed analysis of the errors introduced through GP emulation of forward maps in Bayesian inverse problems.", "\\newline With $ \\widehat{\\mathbb{P}_{\\textit{post}}} $ in hand we may now compute point value estimators for the parameters $ \\boldsymbol{\\theta} $ and source strengths q .", "Common choices of point estimates are [@bib:Somersalo] : \\newline <equationgroup> <equation> $ (\\boldsymbol{\\theta},\\textbf{q})_{\\textit{MAP}}=\\mathop{\\mathrm{% argmax}}_{\\boldsymbol{\\theta},\\textbf{q}}\\,\\widehat{\\mathbb{P}_{\\textit{post}}% }(\\textbf{w}|\\boldsymbol{\\theta},\\textbf{q}), $ $ (\\boldsymbol{\\theta},\\textbf{q})_{\\textit{MAP}} $ $ =\\mathop{\\mathrm{argmax}}_{\\boldsymbol{\\theta},\\textbf{q}}\\,% \\widehat{\\mathbb{P}_{\\textit{post}}}(\\textbf{w}|\\boldsymbol{\\theta},\\textbf{q}), $ </equation> <equation> $ (\\boldsymbol{\\theta},\\textbf{q})_{\\textit{CM}}=\\int(\\boldsymbol{% \\theta},\\textbf{q})\\,\\widehat{\\mathbb{P}_{\\textit{post}}}(\\boldsymbol{\\theta},% \\textbf{q}|\\textbf{w})\\,d\\boldsymbol{\\theta}\\,d\\textbf{q}, $ $ (\\boldsymbol{\\theta},\\textbf{q})_{\\textit{CM}} $ $ =\\int(\\boldsymbol{\\theta},\\textbf{q})\\,\\widehat{\\mathbb{P}_{% \\textit{post}}}(\\boldsymbol{\\theta},\\textbf{q}|\\textbf{w})\\,d\\boldsymbol{% \\theta}\\,d\\textbf{q}, $ </equation> <equation> $ (\\boldsymbol{\\theta},\\textbf{q})_{\\textit{ML}}=\\mathop{\\mathrm{% argmax}}_{\\boldsymbol{\\theta},\\textbf{q}}\\,\\widehat{\\mathbb{P}_{\\textit{post}}% }(\\boldsymbol{\\theta},\\textbf{q}|\\textbf{w}).", "$ $ (\\boldsymbol{\\theta},\\textbf{q})_{\\textit{ML}} $ $ =\\mathop{\\mathrm{argmax}}_{\\boldsymbol{\\theta},\\textbf{q}}\\,% \\widehat{\\mathbb{P}_{\\textit{post}}}(\\boldsymbol{\\theta},\\textbf{q}|\\textbf{w}).", "$ </equation> </equationgroup> The uncertainty in the choice of point estimate $ (\\boldsymbol{\\theta}^{\\ast},\\textbf{q}^{\\ast}) $ can be assessed by computing the covariance matrix \\newline <equationgroup> <equation> $ \\int\\left((\\boldsymbol{\\theta},\\textbf{q})-(\\boldsymbol{\\theta}^{% \\ast},\\textbf{q}^{\\ast})\\right)\\otimes\\left((\\boldsymbol{\\theta},\\textbf{q})-(% \\boldsymbol{\\theta}^{\\ast},\\textbf{q}^{\\ast})\\right)\\,\\widehat{\\mathbb{P}_{% \\textit{post}}}(\\boldsymbol{\\theta},\\textbf{q}|\\textbf{w})\\,d\\boldsymbol{% \\theta}\\,d\\textbf{q}. $ </equation> </equationgroup> The above estimators may of course also be computed using the true posterior $ {\\mathbb{P}_{\\textit{post}}} $ , but if $ \\widehat{\\mathbb{P}_{\\textit{post}}} $ is close to $ \\mathbb{P}_{\\textit{post}} $ in an appropriate sense (such as the total variation metric) then one expects the point estimators under $ \\widehat{\\mathbb{P}_{\\textit{post}}} $ to approximate their counterparts under $ \\mathbb{P}_{\\textit{post}} $ [@bib:stuart2018posterior] .", "\\newline In general, the integrals involved in computing point estimates or covariances are not analytically tractable and so it is necessary to resort to numerical methods for their estimation.", "Since these are high-dimensional integrals, quadrature-based approaches are unsuitable, thus it is necessary to use Markov chain Monte Carlo (MCMC) integration techniques.", "In this paper we use the adaptive MCMC algorithm of [@bib:haario2001] , which is outlined below in Algorithm [@ref:LABEL:algMH] .", "Specific values of the algorithmic parameters ( $ \\beta_{1} $ , $ \\gamma_{1} $ , $ \\gamma_{2} $ , $ \\gamma_{3} $ ) that are tailored to our case study are provided later in Section [@ref:LABEL:sec:source-inversion] .", "\\newline <float> Adaptive Metropolis-Hastings Algorithm.", "\\ Choose $ (\\boldsymbol{\\theta}_{1},\\textbf{q}_{1})\\in\\mathbb{R}^{d} $ in the support of $ \\mathbb{P}_{\\textit{post}}(\\boldsymbol{\\theta},\\textbf{q}|\\textbf{w}) $ and fixed parameters $ \\beta\\in(0,1) $ , $ \\gamma_{1},\\gamma_{2},\\gamma_{3}\\in(0,\\infty) $ , $ N\\in\\mathbb{N} $ .", "\\ \\ for $ j=2:N $ do \\ \\ if $ j\\leq 2d $ then \\ \\ Draw $ u $ from $ \\mathcal{N}\\left((\\boldsymbol{\\theta}_{j},\\textbf{q}_{j}),\\frac{\\gamma_{1}}{d}% I_{d\\times d}\\right) $ .", "\\ \\ else \\ \\ Estimate the empirical covariance matrix $ \\Sigma_{j} $ using $ \\{(\\boldsymbol{\\theta}_{k},\\textbf{q}_{k})\\}_{k=1}^{j} $ .", "\\ \\ Draw $ u $ from $ (1-\\beta)\\,\\mathcal{N}\\left((\\boldsymbol{\\theta}_{j},\\textbf{q}_{j}),\\frac{% \\gamma_{2}}{d}\\Sigma_{j}\\right)+\\beta\\mathcal{N}\\left((\\boldsymbol{\\theta}_{j}% ,\\textbf{q}_{j}),\\frac{\\gamma_{3}}{d}I_{d\\times d}\\right) $ .", "\\ \\ end if \\ \\ Propose $ (\\tilde{\\boldsymbol{\\theta}}_{j},\\tilde{\\textbf{q}}_{j})=(\\boldsymbol{\\theta}_% {j-1},\\textbf{q}_{j-1})+u $ .", "\\ \\ Compute $ \\delta=\\min\\left(1,\\frac{\\widehat{\\mathbb{P}_{\\textit{post}}}(\\boldsymbol{% \\theta}_{j},\\textbf{q}_{j}|\\textbf{w})}{\\widehat{\\mathbb{P}_{\\textit{post}}}(% \\boldsymbol{\\theta}_{j-1},\\textbf{q}_{j-1}|\\textbf{w})}\\right) $ .", "\\ \\ Draw $ w $ from $ U([0,1]) $ .", "\\ \\ if $ w<\\delta $ then \\ \\ $ (\\boldsymbol{\\theta}_{j},\\textbf{q}_{j})=(\\tilde{\\boldsymbol{\\theta}}_{j},% \\tilde{\\textbf{q}}_{j})\\qquad\\qquad $ (Accept the move) \\ \\ else \\ \\ $ (\\boldsymbol{\\theta}_{j},\\textbf{q}_{j})=(\\boldsymbol{\\theta}_{j-1},\\textbf{q}% _{j-1})\\qquad $ (Reject the move) \\ \\ end if \\ \\ end for \\ </float> \\newline  </section>"], ["<section> <title> 4 An industrial case study </title>  In this section we apply our Bayesian framework to the study of dispersion of airborne zinc particles from four point sources located within the area surrounding a lead-zinc smelter in Trail, British Columbia, Canada.", "In Section [@ref:LABEL:sec:sensitivity-analysis] we perform a sensitivity analysis that reveals which parameters are most informed by the data.", "Section [@ref:LABEL:sec:construct-emulator] is dedicated to validating the emulator while Section [@ref:LABEL:sec:source-inversion] contains the main results for the industrial case study including comparisons with previous studies.", "Finally, Sections [@ref:LABEL:sec:effect-prior-choice] and [@ref:LABEL:sec:effect-emul-qual] provide further validation of our source inversion results and study the dependence of emission estimates and uncertainties on the choice of the priors and quality of the emulator respectively.", "The methodology of this section was validated in [@bib:garcia2018parameter] for a synthetic example, and the dependence of the posterior on the number of measurements and choice of the prior distribution was studied in detail.", "\\newline Our ultimate goal is to estimate the contribution that each source makes to the total zinc released into the atmosphere by the smelting operation.", "We begin by outlining the details of our model and the parameters to be calibrated.", "We have access to monthly cumulative measurements of zinc particulate depositions at nine separate locations as well as horizontal wind field velocity data at a meteorological station located near the sources.", "We also have access to engineering estimates of the yearly-averaged emission rates obtained from independent engineering studies based on process control arguments.", "An aerial photograph of the industrial site, showing the locations of all sources and measurement devices, is provided in Figure [@ref:LABEL:figAerial] .", "The sources are labelled $ q_{1} $ to $ q_{4} $ , and deposition measurements are designated $ R_{1} $ to $ R_{9} $ .", "This same emission scenario has been studied using a linear least squares approach based on a Gaussian plume approximation [@bib:lushi2010inverse] , and also by performing a finite volume discretization of the governing equation ( [@ref:LABEL:eqnParametric] ) [@bib:hosseini2016airborne] .", "\\newline We apply the atmospheric dispersion model ( [@ref:LABEL:eqnParametric] ), as adapted in [@bib:hosseini2016airborne] for this specific zinc smelter site with $ n=4 $ sources: \\newline <equationgroup> <equation> $ \\frac{\\partial C(\\textbf{x},t)}{\\partial t}+\\textbf{L}(p,z_{0},z_% {i},L,z_{\\textit{cut}})C(\\textbf{x},t)=\\sum_{j=1}^{4}q_{j}\\delta(\\textbf{x}-% \\textbf{x}_{j}).", "$ </equation> </equationgroup> The differential operator L depends non-linearly on five parameters as we shall explain next.", "The parameter $ p $ comes from the assumption of a power-law distribution in the vertical component of the wind profile v ; that is, if $ z $ denotes the height above ground level $ (x,y,0) $ , then the two horizontal velocity components $ v_{x} $ and $ v_{y} $ are assumed to be function of $ z $ and $ t $ only and satisfy \\newline <equationgroup> <equation> $ \\|(v_{x}(z,t),v_{y}(z,t))\\|_{2}=v_{r}(t)\\left(\\frac{z}{z_{r}}% \\right)^{p}, $ </equation> </equationgroup> where $ v_{r}(t) $ is the wind speed at some reference height $ z_{r} $ .", "Note that the Euclidean norm appears on the left hand side since the power law describes the magnitude of the horizontal wind field.", "The exponent $ p $ depends on factors such as surface roughness and atmospheric stability class.", "For more details about the power law model for the wind velocity the reader is referred to [@bib:seinfeld1998atmospheric] .", "The other four parameters are related to the entries in the diagonal diffusivity matrix $ \\textbf{D}=\\operatorname{diag}(D_{11},D_{22},D_{33}) $ in equation ( [@ref:LABEL:eqnParametric] ).", "Following [@bib:seinfeld1998atmospheric] , the vertical diffusion coefficient satisfies to a good approximation \\newline <equationgroup> <equation> $  D_{33}=\\frac{\\kappa v_{\\ast}z}{\\phi(z/L)}, $ </equation> </equationgroup> where $ \\kappa $ is the von K\u00e1rm\u00e1n constant whose value can be set to $ 0.4 $ in practical scenarios.", "The function $ \\phi $ in the denominator is taken to be a piecewise continuous function \\newline <equationgroup> <equation> $ \\phi\\left(\\frac{z}{L}\\right)=\\left\\{\\begin{array}[]{ll}% \\hidden@noalign1+4.7\\frac{z}{L},&\\mbox{if }\\frac{z}{L}\\geq 0,\\\\ \\hidden@noalign(1-15\\frac{z}{L})^{-\\frac{1}{2}},&\\mbox{if }\\frac{z}{L}<0,% \\end{array}\\right.", "$ </equation> </equationgroup> where $ L $ is called the Monin-Obukhov length .", "The parameter $ v_{\\ast} $ is known as the friction velocity and is represented by \\newline <equationgroup> <equation> $  v_{\\ast}(t)=\\frac{\\kappa v_{r}(t)}{\\ln(\\frac{z_{r}}{z_{0}})}, $ </equation> </equationgroup> where $ v_{r}(t) $ is the wind velocity at some reference height.", "The variable $ z_{0} $ is called the roughness length and depends on both terrain and surface type.", "The remaining horizontal diffusion coefficients satisfy $ D_{11}=D_{22} $ and are assumed to be independent of height $ z $ .", "A correlation that is commonly employed for these parameters is [@bib:seinfeld1998atmospheric] \\newline <equationgroup> <equation> $  D_{11}=D_{22}\\approx\\frac{v_{\\ast}z_{i}^{\\frac{3}{4}}(-\\kappa L)% ^{-\\frac{1}{3}}}{10}, $ </equation> </equationgroup> where the parameter $ z_{i} $ is called the mixing layer height .", "\\newline The governing PDE ( [@ref:LABEL:eqnParametricFinal] ) is complemented with boundary conditions defined over the space-time domain $ \\mathbb{R}^{2}\\times[0,\\infty)\\times(0,T) $ for some fixed $ T\\in\\mathbb{R} $ .", "For this purpose, we impose the following conditions at infinity \\newline <equationgroup> <equation> $  c(\\textbf{x},t)\\rightarrow 0\\qquad\\text{as }\\|\\textbf{x}\\|% \\rightarrow\\infty, $ </equation> </equationgroup> along with a flux (or Robin) boundary condition at the ground surface \\newline <equationgroup> <equation> $ \\left.\\left(v_{\\textit{set}}c-D_{33}\\frac{\\partial c}{\\partial z}% \\right)\\right\\rvert_{z=0}=\\left.v_{\\textit{dep}}c\\right\\rvert_{z=0}, $ </equation> </equationgroup> where $ v_{\\textit{set}}=0.0027\\;m/s $ is the settling velocity of zinc particles computed using Stokes\u2019 law [@bib:seinfeld1998atmospheric] and $ v_{\\textit{dep}}=0.005\\;m/s $", "is the corresponding deposition velocity.", "Observe that at the bottom boundary $ z=0 $ , the vertical diffusivity satisfies $ D_{33}(0)=0 $ from ( [@ref:LABEL:eqnEddyVertical] ) which leads to an inconsistency in the Robin boundary condition; therefore, we define a cut-off length $ z_{\\textit{cut}}\\gtrapprox 0 $ below which $ D_{33} $ is set to the non-zero constant value $ D_{33}(z_{\\textit{cut}}) $ .", "\\newline Equation ( [@ref:LABEL:eqnParametricFinal] ) is solved numerically using the finite volume algorithm described [@bib:hosseini2016airborne] .", "The code takes as input values of the wind speed $ v_{r}(t) $ , parameters $ p,z_{0},z_{i},L,z_{\\textit{cut}} $ , and source strengths $ q_{j} $ , and returns as output the zinc concentration at any point $ (x,y,z) $ and time $ 0<t<T $ .", "However, as mentioned earlier, we do not have experimental measurements of concentration but rather total depositions at the nine sites $ R_{1},\\ldots,R_{9} $ (see Figure [@ref:LABEL:figAerial] ).", "We model the depositions using the integral \\newline <equationgroup> <equation> $  w(x,y,T)=\\int_{0}^{T}c(x,y,0,t)\\,v_{{\\textit{s}et}}\\,dt.", "$ </equation> </equationgroup> Since the nine deposition measurements $ R_{i} $ were obtained from roughly cylindrical dustfall jar collectors, we can readily approximate the total deposition over the time interval $ (0,T] $ at site $ i=1,\\ldots,9 $ using \\newline <equationgroup> <equation> $  w_{i}=\\int_{\\textit{jar}}w(x,y,T)\\,dx\\,dy\\approx w(x_{i},y_{i},T% )\\Delta A, $ </equation> </equationgroup> where $ \\Delta A\\approx 0.0206\\;m^{2} $ is the cross-sectional area of each dustfall jar.", "We then collect the zinc deposition measurements into a vector $ \\textbf{w}=(w_{i})^{T} $ and from now on, we assume that the time interval $ T $ over which particulates are allowed to accumulate in the dustfall jars is one month.", "\\newline With the industrial case fully specified our source inversion framework can be implemented.", "We make the following observations: \\newline <list> \\ The vector w is composed of $ d=9 $ measurements, one from each jar, so that $ \\textbf{w}\\in\\mathbb{R}^{9} $ .", "\\newline \\ \\ The number of model parameters is $ m=5 $ , which are represented by the vector $ \\boldsymbol{\\theta}=(p,z_{0},z_{i},L,z_{\\textit{cut}})^{T} $ .", "\\newline \\ \\ There are $ n=4 $ sources stored in the vector $ \\textbf{q}=(q_{1},q_{2},q_{3},q_{4})^{T} $ .", "\\newline \\ </list> Each measurement in the vector w may then be viewed as a map \\newline <equationgroup> <equation> $  w_{i}:\\mathbb{R}^{5}\\times\\mathbb{R}^{4}\\rightarrow[0,\\infty).", "$ </equation> </equationgroup> In other words, the number $ w_{i}(\\boldsymbol{\\theta}^{\\ast},\\textbf{q}^{\\ast}) $ is the deposition at site $ R_{i} $ predicted by the finite volume solver described in [@bib:hosseini2016airborne] , given a particular choice of parameters $ \\boldsymbol{\\theta}^{\\ast} $ and source strengths $ \\textbf{q}^{\\ast} $ .", "In the framework of Section [@ref:LABEL:sec:emulation] (namely, equations ( [@ref:LABEL:eqnLinear] ) and ( [@ref:LABEL:script-A-def] )) we write \\newline <equationgroup> <equation> $  w_{i}(\\boldsymbol{\\theta}^{\\ast},\\textbf{q}^{\\ast})=\\sum_{j=1}^{% 4}\\mathfrak{a}_{ij}(\\boldsymbol{\\theta}^{\\ast})\\,q^{\\ast}_{j}, $ </equation> </equationgroup> where each of the nonlinear functions $ \\mathfrak{a}_{ij}(\\boldsymbol{\\theta}^{\\ast}) $ can be approximated using a GP emulator $ a_{ij}(\\boldsymbol{\\theta}^{\\ast}) $ .", "\\newline <subsection> <title> 4.1 Sensitivity analysis </title> Before solving the source inversion problem, we first perform a sensitivity analysis in order to check whether the dimensionality of the parameter space can be reduced.", "The goal of a sensitivity analysis is to assess the relative importance of each of the variables in a model [@bib:saltelli2000sensitivity] .", "In this paper, the sensitivity measure we employ is known as the Sobol total index [@bib:sobol1993sensitivity,sullivan2015introduction,saltelli2000sensitivity] which captures the variance of the model outputs due to changes in each of its inputs and is a measure of the relative importance of each input.", "More specifically, the Sobol total index ranges from a lower limit of $ 0 $ , denoting a variable that has no effect on the output, to an upper limit of $ 1 $ , indicating that all variability in the model is explained by the variable in hand.", "\\newline We perform our sensitivity analysis using the R package sensitivity [@bib:sensitivity] , which uses GPs as surrogates for the function of interest.", "In order to account for the variability introduced by using different isotropic kernels (see Definition [@ref:LABEL:dfnGP] ), we calculate Sobol indices using the following choices of the kernel $ \\kappa $ : \\newline <list> \\ Exponential: $ \\kappa(|\\boldsymbol{\\theta}-\\boldsymbol{\\theta}^{\\prime}|)=r_{1}\\exp\\left(-% \\frac{|\\boldsymbol{\\theta}^{\\prime}-\\boldsymbol{\\theta}|}{r_{2}}\\right) $ , \\newline \\ \\ Squared exponential: $ \\kappa(|\\boldsymbol{\\theta}-\\boldsymbol{\\theta}^{\\prime}|)=r_{1}\\exp\\left(-% \\frac{|\\boldsymbol{\\theta}-\\boldsymbol{\\theta}^{\\prime}|^{2}}{2r_{2}}\\right), $ \\newline \\ \\ Mat\u00e9rn $ \\frac{3}{2} $ : $ \\kappa(|\\boldsymbol{\\theta}-\\boldsymbol{\\theta}^{\\prime}|)=r_{1}\\left(1+\\frac{% \\sqrt{3}|\\boldsymbol{\\theta}-\\boldsymbol{\\theta}^{\\prime}|}{r_{2}}\\right)\\exp% \\left(-\\frac{\\sqrt{3}|\\boldsymbol{\\theta}-\\boldsymbol{\\theta}^{\\prime}|}{r_{2}% }\\right) $ , \\newline \\ \\ Mat\u00e9rn $ \\frac{5}{2} $ : $ \\kappa(|\\boldsymbol{\\theta}-\\boldsymbol{\\theta}^{\\prime}|)=r_{1}\\left(1+\\frac{% \\sqrt{5}|\\boldsymbol{\\theta}-\\boldsymbol{\\theta}^{\\prime}|}{r_{2}}+\\frac{5}{3}% \\left(\\frac{|\\boldsymbol{\\theta}-\\boldsymbol{\\theta}^{\\prime}|}{r_{2}}\\right)^% {2}\\right)\\exp\\left(-\\frac{\\sqrt{5}|\\boldsymbol{\\theta}-\\boldsymbol{\\theta}^{% \\prime}|}{r_{2}}\\right) $ .", "\\newline \\ </list> In the above, $ r_{1},r_{2}\\in\\mathbb{R} $ are tuning parameters.", "These kernels are commonly used in GP regression and are readily implemented in the R packages sensitivity and DiceKriging .", "For other possible choices of kernels see [@bib:rasmussen2006gaussian] \\newline The sensitivity indices computed using the four different kernels are summarized in the boxplots shown in Figure [@ref:LABEL:figPaperSensitivity] .", "The size of each box represents the interquartile range (IQR).", "The upper bar attached to each box is at the value \\newline <equationgroup> <equation> $ \\min\\left\\{\\max(S),E_{3}+\\frac{3}{2}IQR\\right\\}, $ </equation> </equationgroup> and the lower bar is located at \\newline <equationgroup> <equation> $ \\max\\left\\{\\min(S),E_{1}-\\frac{3}{2}IQR\\right\\}, $ </equation> </equationgroup> where $ S $ is the set of the four indices (corresponding to the four kernels) calculated for each $ w_{i} $ for $ i\\in\\{1,\\ldots,9\\} $ , and $ E_{1} $ and $ E_{3} $ are the first and third quartiles of $ S $ respectively [@bib:boxplot] .", "\\newline From these results it is clear that the variability in output of each map $ w_{i} $ is captured in large part by the two parameters $ p $ and $ z_{0} $ .", "Although the sensitivity index for $ L $ is relatively small, we still retain this parameter because it is known to be closely related to $ z_{0} $ [@bib:seinfeld1998atmospheric] .", "The remaining \u201cunimportant\u201d parameters, $ z_{i} $ and $ z_{\\textit{cut}} $ , may then be fixed at suitable constant values (we used $ z_{i}=100 $ and $ z_{\\textit{cut}}=2 $ , following [@bib:hosseini2016airborne] ).", "This reduces the dimensionality of the parameter space from $ 5 $ to $ 3 $ and allows us to redefine our parameter vector as \\newline <equationgroup> <equation> $ \\boldsymbol{\\theta}:=(p,z_{0},L).", "$ </equation> </equationgroup> We highlight that the negative values of the total Sobol index for $ z_{\\textit{cut}} $ appearing in Figure [@ref:LABEL:figPaperSensitivity] are not physical but rather arise due to numerical errors in the Monte Carlo integration method used in the sensitivity package.", "\\newline We next identify the support of the prior distribution, which consists simply of the interval of allowable values for each unknown parameter.", "Every emission rate must be a non-negative number, so that \\newline <equationgroup> <equation> $  q_{j}\\in[0,\\infty),\\qquad\\text{for }j=1,2,3,4.", "$ </equation> </equationgroup> For the remaining parameters $ p,z_{0},L $ , we use the physically-motivated ranges listed in Table [@ref:LABEL:tabNewRanges] , which are slightly larger than the suggested ranges typically cited in the literature (see e.g., [@bib:seinfeld1998atmospheric] ) to allow for more flexibility.", "Consequently, each map $ w_{i}(\\boldsymbol{\\theta},\\textbf{q}) $ has a domain \\newline <equationgroup> <equation> $ \\text{dom}(w_{i})=[0,0.6]\\times[0,3]\\times[-600,0]\\times[0,\\infty% )^{4}. $ </equation> </equationgroup> With this information in hand, we are now in a position to create a space-filling design needed to construct the GP emulator as explained in Section [@ref:LABEL:sec:emulation] .", "Due to computational budget constraints, we choose 64 points to construct our emulators.", "We display 2D projections of the corresponding maximin space-filling design for the three relevant parameters in Figure [@ref:LABEL:figSpaceFilling] .", "\\newline </subsection> <subsection> <title> 4.2 Construction and validation of the emulator </title> We now proceed as outlined in Section [@ref:LABEL:sec:emulation] to construct the emulator for maps $ \\mathfrak{a}_{ij} $ using GPs.", "The 64 different combinations of parameters $ p,z_{0},L $ obtained from the space-filling design in the previous section are used to train the GP.", "To create the GPs for each of the 36 maps $ \\mathfrak{a}_{ij}(p,z_{0},L) $ , we used the R package DiceKriging [@bib:dupuy2015dicedesign] .", "Unlike the sensitivity analysis in the previous sections where four different kernels were computed, the GPs here are constructed using only the isotropic squared exponential kernel.", "\\newline The DiceKriging package chooses a maximum likelihood estimate for the tuning parameters $ r_{1},r_{2} $ for each map $ \\mathfrak{a}_{ij} $ .", "To assess the quality of each emulator we perform a \u201cleave one out\u201d cross validation (LOOCV) [@bib:murphy2012machine] on each of the nine sites $ R_{1},R_{2},\\ldots,R_{9} $ for the 64 design points shown in Figure [@ref:LABEL:figSpaceFilling] ; that is, we run the finite volume solver 64 times and save the predicted deposition value for each sites, yielding a total of $ 64\\times 9 $ points or predictions from the finite volume solver.", "For each point \u201cleft out\u201d in the LOOCV, we plot in Figure [@ref:LABEL:figGPTrained] the deposition obtained from the finite volume solver versus the predicted value from the corresponding trained GP.", "This figure shows that the output of the GP is closely matched to the output of the finite volume solver at most design points, with the exception of a small number of outliers.", "\\newline </subsection> <subsection> <title> 4.3 Source inversion </title> The GP emulator may now be employed to estimate the emission rates $ q_{1},\\ldots,q_{4} $ , for the actual physical dataset which consists of dustfall jar measurements at the nine locations marked $ R_{1},\\ldots,R_{9} $ in Figure [@ref:LABEL:figAerial] .", "Our first task is to specify the prior distribution for $ \\boldsymbol{\\theta} $ and q .", "Following ( [@ref:LABEL:eqnPrior] ), we take the prior for $ p,z_{0},L $ to be independent of the prior on q .", "Since we do not have any prior information about the values of the parameters $ p,z_{0},L $ (other than an acceptable range), we choose a uniform distribution for each parameter \\newline <equationgroup> <equation> $ \\mathbb{P}_{\\textit{prior}}(p)\\propto\\mathbf{1}_{[0,0.6]}(p),% \\qquad\\mathbb{P}_{\\textit{prior}}(z_{0})\\propto\\mathbf{1}_{[0,3]}(z_{0}),% \\qquad\\mathbb{P}_{\\textit{prior}}(L)\\propto\\mathbf{1}_{[-600,0]}(L), $ </equation> </equationgroup> where $ \\mathbf{1}_{E} $ is the indicator function for the interval set $ E $ ."]], "target": "For the source strengths q , we have the engineering estimates from previous independent studies shown in Table which can be applied along with a non-negativity constraint to construct a suitable prior. In particular, we propose the following prior for source strengths based on a gamma distribution:"}, {"tabular": ["  Beef  &  Pork  &  Bread ", " sliced beef  &  sirloin, rare beef  &  roasted pork  &    &  flat bread, wheat ", " stewed  &    &    &    &  toasted ", "  &    &    &  pieces, slices  &  ", "  &  black pepper  &  spicy sauce  &    &  buttery  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Taxonomy is an essential form of knowledge representation and plays an important role in a wide range of applications [@bib:Zhang2014TaxonomyDF,Yang2017EfficientlyAT,Meng2020HierarchicalTM] .", "A taxonomy constructed from a large corpus organizes a set of concepts into a hierarchy, making it clear for people to understand relations between concepts.", "\\newline Most existing taxonomy construction methods organize hypernym-hyponym entity pairs into a tree structure to form an instance taxonomy.", "However, a \u201cuniversal\u201d taxonomy so constructed cannot cater to user\u2019s specific needs.", "For example, a user might want to learn about concepts in a certain aspect (e.g., food or research areas ) from a corpus.", "Generic taxonomy has two noteworthy limitations: (1) Countless irrelevant terms and fixed \u201cis-a\u201d relations dominate the instance taxonomy, failing to capture user\u2019s interested aspects and relations, and (2) each node is represented by a single word without considering term correlation, limiting people\u2019s understanding due to low semantic coverage, not to mention that synonyms could appear at multiple nodes.", "\\newline We study the problem of seed-guided topical taxonomy construction, where user provides a seed taxonomy as guidance, and a more complete topical taxonomy is generated from text corpus, with each node represented by a cluster of terms (topics).", "As shown in Figure [@ref:LABEL:fig:output] , a user provides a seed taxonomy and wants to generate a more complete food taxonomy from a given corpus.", "Such a more complete topical taxonomy can be hopefully constructed by expanding various types of food both in width and depth, with a cluster of descriptive terms for each concept node as a topic.", "\\newline To fulfill this, we propose a framework CoRel , which approaches the problem with two modules: (i) A relation transferring module learns the specific relation preserved in seed taxonomy and attaches new concepts to existing nodes to complete the taxonomy structure.; and (ii) a concept learning module captures user-interested aspects and enriches the semantics of each concept node.", "Two challenges are met in the course: (1) Fine-grained concept names can be close in the embedding space, and enriching the concepts might result in relevant but not distinctive terms (e.g., \u201csugar\u201d is relevant to both \u201ccake\u201d and \u201cice-cream\u201d); and (2) with minimal user input, it is nontrivial to directly apply weakly supervised relation extraction methods to expand the taxonomy structure.", "Overall, noisy terms may harm the quality of new topics found.", "\\newline To address these challenges, the relation transferring module first captures the relation preserved in seed parent-child pairs and transfers it upwards and downwards for finding the first-layer topics and subtopics, attached by a co-clustering technique to remove inconsistent subtopics.", "The concept learning module learns a discriminative embedding space by jointly embedding the taxonomy with text and separating close concepts in the embedding space.", "\\newline We demonstrate the effectiveness of our framework through a series of experiments on two real-world datasets, and show that CoRel outperforms all the baseline methods in multiple metrics.", "We also provide qualitative analysis to demonstrate the high quality of our generated topical taxonomy and its advantages over other methods.", "\\newline Our contribution can be summarized as follows: (1) A novel framework for seed-guided topical taxonomy construction.", "(2) A relation transferring module that passes the user-interested relation along multiple paths in different directions for taxonomy structure completion.", "(3) A concept learning module that enriches the semantics for a taxonomy of words by extracting distinctive terms.", "(4) Comprehensive experiments on real-world data with qualitative and quantitative studies that prove the effectiveness of CoRel .", "\\newline  </section>"], ["<section> <title> 2 related work </title>  Unsupervised Taxonomy Construction.", "\\newline Most existing taxonomy construction algorithms perform a two-step approach: Hypernym-hyponym pairs are first extracted from a corpus and then organized into a tree structure.", "The task of hypernym-hyponym extraction traditionally relies on pattern-based methods which utilize Hearst patterns [@bib:Hearst1992AutomaticAO] like \u201cNP such as NP\u201d to acquire parent-child pairs that satisfy the \u201cis-a\u201d relation.", "Later, researchers design more lexical patterns [@bib:Navigli2010LearningWL,Nakashole2012PATTYAT] or extract such patterns automatically [@bib:Snow2004LearningSP,Shwartz2016ImprovingHD] in a bootstrapping method.", "These pattern-based methods suffer from low recall due to the diversity of expressions.", "Distributional methods alleviate the problem of sparsity by representing each word as a low-dimensional vector to capture their semantic similarity.", "There exist approaches [@bib:Weeds2004CharacterisingMO,Chang2017DistributionalIV] inspired by Distributional Inclusion Hypothesis [@bib:ZhitomirskyGeffet2005TheDI] (the context of a hyponym should be the subset of that of a hypernym) to detect hypernym-hyponym pairs without supervision.", "On the end of term organization, graph-based methods [@bib:Kozareva2010ASM,Navigli2011AGA,Velardi2013OntoLearnRA] are used to remove conflicts that form loops in the taxonomy.", "The aforementioned algorithms are not suitable for constructing a topical taxonomy, since they treat each word as a single node instead of forming topics with relevant terms for people to comprehend.", "\\newline As another line of work, clustering-based taxonomy construction is closer to our problem setting.", "Clustering-based taxonomy construction methods first learn a representation space for terms, then perform clustering to separate terms into different topics by different measures [@bib:Cimiano2004ComparingCD,Liu2012AutomaticTC,Wang2013APM,Yang2009AMF] .", "A recent method TaxoGen [@bib:Zhang2018TaxoGenUT] finds fine-grained topics by spherical clustering and local-corpus embedding.", "Hierarchical topic modeling algorithms [@bib:Blei2003HierarchicalTM,Mimno2007MixturesOH] are comparable to these methods, since they organize terms to form a taxonomy of topics, each represented by a word distribution.", "\\newline The above methods do not require supervision in taxonomy construction.", "They suffer from two disadvantages: (1) Without user input seed terms, they cannot capture users\u2019 specific interest in certain aspects of the corpus (e.g., \u201cfood\u201d or \u201cresearch areas\u201d), thus the final output may include a large number of irrelevant terms; and (2) these methods either capture generic \u201cis-a\u201d patterns or do not enforce specific relations in children finding (clustering-based methods), thus cannot cater to user-interested relations.", "\\newline Seed-Guided Taxonomy Construction.", "\\newline For seed-guided taxonomy construction, HiExpan [@bib:Shen2018HiExpanTT] integrates the above two-step approach into a tree expansion process by width and depth expansion of the original seed taxonomy.", "Specifically, for width expansion that adds sibling nodes to those sharing the same parent, the method uses a set expansion algorithm [@bib:Shen2017SetExpanCS] that leverages skip-gram features to calculate similarity between terms.", "For depth expansion that attaches children nodes to new node (e.g., attaching \u201coyster\u201d to \u201cseafood\u201d in Figure [@ref:LABEL:fig:output] ), they use word analogy [@bib:Mikolov2013DistributedRO] to capture relations between parent-child pairs.", "However, in our setting of constructing topical taxonomy, HiExpan suffers from two drawbacks: (1) the set expansion algorithm is not good at expanding concepts; and (2) word analogy is only locally preserved in the Word2Vec space [@bib:Fu2014LearningSH] .", "\\newline Weakly Supervised Relation Extraction.", "\\newline To construct a taxonomy that fits in with a user-interested relation, we aim to preserve the same relation between all newly added parent-child topics.", "With only a few given seeds, it is impossible to train a highly accurate and complicated relation extraction model with a huge number of parameters.", "Traditional weakly supervised relation extraction methods [@bib:Snow2004LearningSP,Nakashole2012PATTYAT] find textual patterns from given instances, suffering from sparsity of relation expressions.", "Recent studies [@bib:Qu2017WeaklysupervisedRE] combine textual patterns with distributional features for mutual enhancement in a co-training framework.", "Neural-based methods like prototypical network [@bib:Gao2019HybridAP] which represents each relation as a vector have shown to be effective in few shot relation (FSL) extraction.", "Recent advances in contextualized text representation show that deep transformers (e.g., BERT [@bib:Devlin2019BERTPO] ) learn task-agnostic representations achieving strong performance on various NLP tasks.", "Researchers show that by learning from large amounts of entity pairs co-occurring in Wikipedia corpus, BERT can achieve state-of-the-art [@bib:Soares2019MatchingTB] on FSL relation extraction on benchmark datasets [@bib:Han2018FewRelAL] .", "\\newline Supervised Taxonomy Construction.", "\\newline Most supervised taxonomy construction methods focus on extracting hypernym-hyponym pairs.", "Word analogy $ (v(\\text{man})-v(\\text{king}) $ $ =v(\\text{woman})-v(\\text{queen}) $ ) is preserved in local clusters, and a piecewise linear projection from words to their hypernyms is trained in [@bib:Fu2014LearningSH] .", "For neural-based methods, order embedding [@bib:Vendrov2015OrderEmbeddingsOI,Dash2019HypernymDU] is proposed to express partial orders between words.", "Later studies show that Poincar\u00e9 space can be viewed as a continuous generalization of tree structures, so they embed large taxonomy structures extracted from WordNet [@bib:Nickel2017PoincarEF] or Wikipedia [@bib:Le2019InferringCH] .", "However, in our setting, the user-given taxonomy is of very limited size, and thus cannot be adaptive to these frameworks.", "\\newline  </section>"], ["<section> <title> 3 Problem Description </title>  In this section we describe the task of seed-guided topical taxonomy construction.", "The inputs are a collection of documents $ \\mathcal{D}=\\{d_{1},d_{2},...,d_{|\\mathcal{D}|}\\} $ and a tree-structured seed taxonomy $ T^{0} $ provided by user.", "Each node $ e $ in $ T^{0} $ is represented by a single word from the corpus, and each edge $ \\langle $ $ p_{0} $ , $ c_{0} $ $ \\rangle $ implies user-interested relation between a parent-child pair, such as \u201cis a subfield of\u201d or \u201cis a type of\u201d.", "The output is a more complete topical taxonomy $ T $ , with each node $ e $ as a conceptual topic, represented by a coherent cluster of words describing the topic.", "Figure [@ref:LABEL:fig:output] shows an example of our task.", "\\newline The meanings of the notations used in this paper are presented in Table [@ref:LABEL:tab:not] .", "\\newline  </section>"], ["<section> <title> 4 Methodology </title>  In this section, we introduce our proposed method by first giving an overview in Section [@ref:LABEL:sec:overview] and then describing the details of two modules in Sections [@ref:LABEL:sec:gen] and [@ref:LABEL:sec:exp] .", "\\newline <subsection> <title> 4.1 Method Overview </title> Figure [@ref:LABEL:fig:workflow] shows the workflow of CoRel .", "To expand the tree structure of a user-given seed taxonomy $ T^{0} $ , CoRel first leverages a relation transferring module to capture seed relations of edge $ \\langle $ $ p_{0} $ , $ c_{0} $ $ \\rangle $ .", "In step 1, it attempts to discover potential root concepts by transferring the relation upwards, such as \u201cLunch\u201d, \u201cFood\u201d and \u201cDish\u201d as more general concepts to cover the topics.", "In step 2, the relation is transferred downwards to attach new topics (internal nodes) as well as new subtopics (leaf nodes).", "Finally, a concept learning module is used to learn a discriminative embedding space to generate topical clusters for each concept node.", "Below we address the two modules in detail.", "\\newline </subsection> <subsection> <title> 4.2 Taxonomy Completion by Relation Transferring </title> The relation transferring module is used to complete the taxonomy structure by finding new topics and subtopics.", "This module first captures the relation between user given $ \\langle $ $ p $ , $ c $ $ \\rangle $ pairs by training a relation classifier on the given corpus.", "The relation classifier takes a relation statement (will be defined in section [@ref:LABEL:sec:rel] ) of a pair of terms as input, and judges whether there exists user-interested relation and which direction it is between the pair.", "After training the relation classifier, we transfer the relation upwards for root node discovery, and then transfer the relation downwards to find new topics/subtopics as the child of root/topic node.", "In both the example and evaluation we construct two layers of topics, though this module can be applied to discover more fine-grained topics by further going down.", "\\newline <subsubsection> <title> 4.2.1 Self-supervised Relation Learning </title> Previous studies show that word analogy can capture relations between words to some extent [@bib:Mikolov2013DistributedRO,Shen2018HiExpanTT] , but vector offset is only preserved in a local area in the embedding space [@bib:Fu2014LearningSH] .", "To deal with more complicated relations, our choice of the model is inspired by the effectiveness of the pre-trained deep language model, BERT [@bib:Devlin2019BERTPO] , on wide downstream applications.", "[@bib:Soares2019MatchingTB] also shows its power in few-shot relation learning by training the model in a distant supervised setting using large amounts of pairs of entities on Wikipedia corpus.", "In our setting, user gives minimal seeds which limits the potential to train such deep language model, thus we only employ the pre-trained BERT model and train a relation classifier as shown in Figure [@ref:LABEL:fig:bert] .", "\\newline Relation Statement.", "We assume that if a pair of $ \\langle $ $ p $ , $ c $ $ \\rangle $ co-occurs in a sentence in the corpus, then that sentence implies their relation.", "We refer to sentences containing $ \\langle $ $ p $ , $ c $ $ \\rangle $ as their relation statements and leverage a pre-trained deep language model to understand the relation statements.", "To learn the user-interested specific relation, we extract all the relation statements of user-given $ \\langle $ $ p_{0} $ , $ c_{0} $ $ \\rangle $ as positive training samples.", "We collect negative training sentences in two ways: (1) relation statements of sibling nodes, thus avoiding the model to only find closely related terms; and (2) random sentences from the corpus, so the model can learn from irrelevant contexts to avoid overfitting.", "\\newline Sequence Input Representation.", "Since user gives only a minimal number of seeds, which is not enough to train deep encoders, we cannot simply add explicit markers around pairs of terms to let the model pay attention to.", "Therefore, we take the original sentence and replace the two terms by \u201c[MASK]\u201d tokens with two justifications: (1) aligning with the pre-trained objective of masked language model; and (2) avoiding the classification layer to only remember relations from training pairs instead of looking into contexts.", "\\newline Classification Layer.", "We take the output of two \u201c[MASK]\u201d tokens from the last layer of the pre-trained language model, and concatenate them to be the input of the classification layer, where we use a simple linear layer before the softmax layer.", "The output label chooses the relation from $ e_{1} $ to $ e_{2} $ among three classes in the relation set $ \\mathcal{Q} $ : $ \\langle $ $ e_{1} $ $ \\rightarrow $ $ e_{2} $ $ \\rangle $ (i.e., $ e_{1} $ is a parent node of $ e_{2} $ ), $ \\langle $ $ e_{2} $ $ \\rightarrow $ $ e_{1} $ $ \\rangle $ , or non-user interested relation.", "\\newline Data Augmentation.", "To fully utilize the asymmetric property along the taxonomy edges, we augment each input training sequence by reversing the order of concatenation of $ e1 $ and $ e2 $ .", "Then the label would switch if user-interested relation exists between the pair, but will not change otherwise.", "\\newline </subsubsection> <subsubsection> <title> 4.2.2 First-layer Topic Finding by Root Node Discovery </title> After deriving a relation classifier, we can easily transfer the user-interested relation along the paths in the taxonomy.", "This is done by targeting an existing node and finding entities to be its potential parent node (transferring upwards) or child node (transferring downwards).", "To \u201cexpand\u201d more first-layer topics based on user-given ones, previous work like set expansion is good at extending a list of instances like country names or company names [@bib:Shen2017SetExpanCS,Rong2016EgoSetEW,Huang2020GuidingCS] , but is not perfect at expanding concept names.", "Another seemingly straightforward solution is to train a few-shot sibling relation classifier based on relation statements of sibling nodes.", "However, this would result in low recall of extracted new topics, since the co-occurrence of two relatively unrelated topics might be sparse in the corpus.", "\\newline To resolve the above issue, we assume that if we can discover potential root nodes, such as \u201cFood\u201d for \u201cDessert\u201d and \u201cSeafood\u201d, then the root node would have more general contexts for us to find connections with potential new topics.", "Previous studies [@bib:Meng2020DiscriminativeTM,ZhitomirskyGeffet2005TheDI] also found general concepts cover broader semantic meaning and have more varied contexts.", "\\newline Specifically, we transfer the relation upwards by using the relation classifier learned to extract a list of parent nodes for each seed topic.", "The common parent nodes for all topics are treated as root nodes $ R $ .", "\\newline Finding common root nodes.", "To find the parent or child of an existing node, we extract relation statements of a concept $ e $ and a candidate term $ w $ into the relation classifier to judge sentence-based relations.", "Corpus-based relation between $ w $ and $ e $ is then averaged over confident sentence-based results over the corpus, with the confidence threshold being $ \\delta $ .", "\\newline <equationgroup> <equation> $ \\text{Score}(w\\rightarrow e)=\\frac{\\sum_{s_{w\\rightarrow e}}% \\mathbb{1}\\left(KL\\left(\\boldsymbol{l}\\middle\\|\\boldsymbol{p}_{w}\\right)>% \\delta\\right)}{\\sum_{q\\in\\mathcal{Q}}\\sum_{s_{q}}\\mathbb{1}\\left(KL\\left(% \\boldsymbol{l}\\middle\\|\\boldsymbol{p}_{w}\\right)>\\delta\\right)} $ $ \\text{Score}(w\\rightarrow e) $ $ =\\frac{\\sum_{s_{w\\rightarrow e}}\\mathbb{1}\\left(KL\\left(% \\boldsymbol{l}\\middle\\|\\boldsymbol{p}_{w}\\right)>\\delta\\right)}{\\sum_{q\\in% \\mathcal{Q}}\\sum_{s_{q}}\\mathbb{1}\\left(KL\\left(\\boldsymbol{l}\\middle\\|% \\boldsymbol{p}_{w}\\right)>\\delta\\right)} $ </equation> </equationgroup> where $ s_{q} $ denotes relation statements in which the relation of $ q $ exists, $ \\boldsymbol{p}_{w} $ denotes the output probability from the relation classifier, and $ l $ is the uniform distribution vector among three classes of relations.", "Thus if the KL divergence between the two distributions is larger than a threshold $ \\delta $ , we treat the prediction as a confident one.", "Eq. ( [@ref:LABEL:eq:score] ) calculates the portion of term $ w $ being the parent of concept $ e $ among all the confident predictions, and we confirm $ w $ as the parent node of $ e $ if the portion is larger than a threshold.", "For each user-given first-layer topic, we can generate a list of parent nodes, and their common parent nodes are treated as root nodes $ R $ .", "\\newline Finding new first-layer topics.", "We apply the relation classifier to extract child terms for each root node $ r\\in R $ .", "This is done in a similar way as root node discovery, but we only reverse the direction of relation.", "Thus we need to replace $ (w\\rightarrow e) $ in Eq. ( [@ref:LABEL:eq:score] ) with $ (r\\rightarrow w) $ .", "New topics are selected by their average score over all root nodes.", "\\newline <equationgroup> <equation> $ \\text{Score}(R\\rightarrow w)=\\frac{\\sum_{r\\in R}\\text{Score}(r% \\rightarrow w)}{|R|} $ $ \\text{Score}(R\\rightarrow w)=\\frac{\\sum_{r\\in R}\\text{Score}(r% \\rightarrow w)}{|R|} $ </equation> </equationgroup> \\newline </subsubsection> <subsubsection> <title> 4.2.3 Candidate term extraction for subtopics </title> After generating the first-layer topics, we transfer the relation downwards to discover subtopics of each first-layer topic.", "This can be done by applying Eq. ( [@ref:LABEL:eq:score] ) again and replacing $ (w\\rightarrow e) $ with $ (e\\rightarrow w) $ .", "The candidate terms will later be clustered into subtopics.", "\\newline </subsubsection> </subsection> <subsection> <title> 4.3 Generating Topical Clusters by Concept Learning </title> Our concept learning module is used to learn a discriminative embedding space, so that each concept is surrounded by its representative terms.", "Within this embedding space, subtopic candidates are also clustered to form coherent subtopic nodes.", "This is motivated by the fact that relevant concept names can be close to each other in the embedding space, and directly using unsupervised word embedding such as Word2Vec [@bib:Mikolov2013DistributedRO] might result in relevant but not distinctive terms (e.g., \u201cfood\u2018\u2019 is relevant to both \u201cseafood\u2018\u2019 and \u201cdessert\u2018\u2019).", "Thus we use the expanded taxonomy as input to guide the word embedding learning process.", "\\newline <subsubsection> <title> 4.3.1 Concept Learning based on Taxonomy and Corpus </title> We basically design three loss functions to embed the concepts, words and documents in a joint embedding space.", "Our starting point is the assumption that similar words share similar local contexts, as is used by the Skip-Gram model [@bib:Mikolov2013DistributedRO] .", "Two sets of embedding for each word are used: center word embedding denoted as $ u_{w} $ and context word embedding as $ v_{w} $ .", "The training objective is to maximize the log probability of observing words in a fixed local context window with the size of h. \\newline <equationgroup> <equation> $  L_{l}=-\\sum_{d\\in D}\\sum_{1\\leq i\\leq|d|}\\sum_{0<|j-i|\\leq h}% \\log P(w_{j}\\mid w_{i}) $ $  L_{l} $ $ =-\\sum_{d\\in D}\\sum_{1\\leq i\\leq|d|}\\sum_{0<|j-i|\\leq h}\\log P(w_% {j}\\mid w_{i}) $ </equation> </equationgroup> where $ P(w_{j}\\mid w_{i})\\propto\\exp{\\left(u_{w_{i}}v_{w_{j}}\\right)} $ .", "\\newline Recent studies [@bib:Meng2019SphericalTE,Meng2020DiscriminativeTM] also observe the importance of modeling the documents where a word appears in, since words in similar documents share topical coherence.", "We denote document embedding as $ d $ and maximize the log probability of predicting the correct document that a word belongs to.", "\\newline <equationgroup> <equation> $  L_{d}=-\\sum_{d\\in D}\\sum_{1\\leq i\\leq|d|}\\log P(d\\mid w_{i}) $ $  L_{d} $ $ =-\\sum_{d\\in D}\\sum_{1\\leq i\\leq|d|}\\log P(d\\mid w_{i}) $ </equation> </equationgroup> where $ P(d\\mid w_{i})\\propto\\exp{\\left(u_{w_{i}}u_{d}\\right)} $ .", "\\newline Since we want to regularize the embedding space to be discriminative among the concepts in the expanded taxonomy, we wish to form topical clusters in the embedding space where each concept embedding is surrounded by its representative terms.", "We use an iterative approach to gradually grab distinctive words at each epoch.", "Specifically, we add one distinctive word to each concept cluster $ C_{e} $ at each epoch to avoid semantic drift.", "We then enforce the proximity between concept embedding and their clusters by \\newline <equationgroup> <equation> $  L_{prox}=\\sum_{e\\in\\mathcal{T}}\\sum_{w\\in\\mathcal{C}_{e}}\\log P(% e\\mid w) $ $  L_{prox} $ $ =\\sum_{e\\in\\mathcal{T}}\\sum_{w\\in\\mathcal{C}_{e}}\\log P(e\\mid w) $ </equation> </equationgroup> where $ P(e\\mid w)\\propto\\exp{\\left(u_{w_{i}}u_{e}\\right)} $ \\newline The overall training objective is a weighted sum of the above terms.", "\\newline <equationgroup> <equation> $  L=L_{l}+\\lambda_{d}L_{d}+\\lambda_{p}L_{prox} $ $  L=L_{l}+\\lambda_{d}L_{d}+\\lambda_{p}L_{prox} $ </equation> </equationgroup> \\newline </subsubsection> <subsubsection> <title> 4.3.2 Topic and Relation aware Subtopic Finding </title> To find subtopics for existing concepts in the seed taxonomy, we apply two constraints for generating potential candidates for subtopics: (1) Topical constraints: candidates should belong to the topic cluster $ C_{e} $ of that concept $ e $ ; and (2) relational constraints: candidates should bear user-interested relation with the concept.", "The two constraints can be applied by using the learned relation classifier and concept embedding.", "However, directly using the few-shot relation classifier can still include noisy and non-consistent terms, thus we carry out a co-clustering method to further filter out those noisy terms.", "\\newline An example is shown in Table [@ref:LABEL:tab:nocon] , where we use a Topic-Type table to organize the valid terms from the relation classifier.", "Valid terms are divided in columns by semantic meaning and in rows by semantic type (e.g., food , cooking style or sauces ).", "It is easily observable that the fourth subtopic of \u201cpieces, slices\u201d is an outlier sharing little type similarity with other subtopics.", "Thus we apply co-clustering method to retain those subtopics sharing similar semantic type distribution.", "\\newline Topic-Type Matrix Creation."]], "target": "We construct an indicative (0/1) Topic-Type matrix to represent the joint distribution of subtopics and types of candidates from the Topic-Type table as shown in Table , and the table is created by the following process: The topic-wise clustering is done by affinity propagation (AP) clustering in the discriminative embedding space trained by concept learning, where the concepts are separated away from each other to avoid overlapping. The type-wise clustering is conducted by AP on the average BERT embedding space: We first retrieve the contextualized embedding of each candidate mention using the last layer output of BERT, and then average over the mentions to get the embedding for each candidate."}, {"tabular": ["  Image  &  Sampling  &  UF  &  Zero-filling  &  Sparse MRI  &  DLMRI  &  PBDWS  &  PANO  &  TLMRI  &  UTMRI  &  UNITE-MRI ", " c  &  Cartesian  &  2.5x  &  24.9  &  29.9  &  36.6  &  35.8  &  34.8  &  37.2  &  37.2  &  37.4 ", " d  &  2D random  &  10x  &  23.2  &  24.9  &  41.4  &  41.1  &  42.4  &  44.3  &  44.0  &  44.6 ", " d  &  2D random  &  20x  &  21.6  &  22.9  &  34.1  &  36.7  &  37.8  &  38.8  &  38.4  &  39.4 ", " a  &  Cartesian  &  6.9x  &  27.9  &  28.6  &  30.9  &  31.1  &  31.1  &  31.4  &  31.3  &  31.5 ", " e  &  Cartesian  &  2.5x  &  28.1  &  31.7  &  37.5  &  42.5  &  40.0  &  40.7  &  40.8  &  43.4 ", " b  &  Cartesian  &  2.5x  &  27.7  &  31.6  &  39.2  &  43.3  &  41.3  &  42.6  &  42.5  &  44.3 ", " f  &  2D random  &  5x  &  26.3  &  27.4  &  30.5  &  30.4  &  30.4  &  30.6  &  30.6  &  30.7 ", " c  &  2D random  &  6x  &  13.9  &  14.5  &  15.4  &  15.2  &  33.0  &  33.2  &  32.4  &  33.6 ", " e  &  Cartesian  &  4x  &  28.5  &  30.6  &  32.4  &  34.5  &  33.7  &  33.6  &  33.5  &  34.5  "], "ref_sec": [["<section> <title> I Introduction </title>  The sparsity of signals and images in transform domains or dictionaries is a key property that has been exploited in several applications including compression [@bib:jpg2] , denoising, and in inverse problems in imaging.", "Sparsity in either a fixed or data-adaptive dictionary or transform is fundamental to the success of popular techniques such as compressed sensing that aim to reconstruct images from a few sensor measurements.", "In this work, we focus on methods for blind compressed sensing, where not only the image but also the dictionary or transform is estimated from the measurements.", "In the following, we briefly review compressed sensing and blind compressed sensing, before summarizing our contributions in this work.", "\\newline <subsection> <title> I-A Compressed Sensing </title> Compressed sensing (CS) [@bib:tao1,don,cand] (see also [@bib:feng96a,BreFen-C96c,Fen-PT97,VenBre-C98b,BreGasVen-C99,GasBre-C00a,YeBreMou-J02,Bre-C2008a] for the earliest versions of CS for Fourier-sparse signals and for Fourier imaging) is a technique that enables accurate reconstructions of images from far fewer measurements than the number of unknowns.", "To do so, it assumes that the underlying image is sufficiently sparse in some transform domain or dictionary, and that the measurement acquisition procedure is incoherent, in an appropriate sense, with the transform.", "The image reconstruction problem in CS is often formulated (using a convex relaxation of the $ \\ell_{0} $ counting \u201cnorm\u201d for sparsity) as follows [@bib:lustig] \\newline <equation> $ \\min_{x}\\>\\left\\|Ax-y\\right\\|_{2}^{2}+\\lambda\\left\\|\\Psi x\\right\\|_{1} $ </equation> Here, $ x\\in\\mathbb{C}^{p} $ is a vectorized version of the image to be reconstructed, $ \\Psi\\in\\mathbb{C}^{t\\times p} $ is a sparsifying transform for the image (often chosen as orthonormal), $ y\\in\\mathbb{C}^{m} $ denotes the imaging measurements, and $ A\\in\\mathbb{C}^{m\\times p} $ , with $ m\\ll p $ is the sensing or measurement matrix for the application.", "\\newline Compressed sensing has become an increasingly attractive tool for imaging in recent years.", "CS has been applied to several imaging modalities such as magnetic resonance imaging (MRI) [@bib:lustig,lustig2,Char,josh,Yoo,kal,Qu11] , computed tomography (CT) [@bib:chen,choi11,CT11] , and Positron emission tomography (PET) imaging [@bib:vali1,malc2] , demonstrating high quality reconstructions from few measurements.", "Such compressive measurements may help reduce the radiation dosage in CT, or reduce the scan times in MRI.", "\\newline In this work, we will develop methods that apply to compressed sensing and other general inverse problems.", "We illustrate our methods in the particular application of MRI.", "MRI is a non-invasive and non-ionizing imaging modality that offers a variety of contrast mechanisms, and enables excellent visualization of anatomical structures and physiological functions.", "However, the data in MRI, which are samples in k-space or the spatial Fourier transform of the object, are acquired sequentially in time.", "Hence, a drawback of MRI that affects both clinical throughput and image quality is that it is a relatively slow imaging technique.", "Although there have been advances in scanner hardware [@bib:pMRI-Survey] and pulse sequences, the rate at which MR data are acquired is limited by MR physics and physiological constraints on RF energy deposition.", "CS accelerates the data acquisition in MRI by collecting fewer k-space measurements than mandated by Nyquist sampling conditions.", "In particular, for MRI, the sensing matrix $ A $ in ( [@ref:LABEL:eq1] ) is $ F_{u}\\in\\mathbb{C}^{m\\times p} $ , the undersampled Fourier encoding matrix.", "\\newline </subsection> <subsection> <title> I-B Blind Compressed Sensing </title> While compressed sensing techniques typically work with fixed sparsifying transforms such as Wavelets, finite differences (total variation) [@bib:lustig,ma] , Contourlets [@bib:xia] , etc.", "to reconstruct images, there has been a growing interest in data-driven models in recent years.", "Some recent works considered learning dictionaries [@bib:Chen2010] or tight frames [@bib:wangliuj] from reference images, but in these methods, the model is kept fixed during the CS image reconstruction process, and not adapted to better sparsify and reconstruct the features/dynamics of the underlying (unknown) images.", "In this work, we instead focus on the subject of blind compressed sensing (BCS) [@bib:bresai,symul,Glei12,lingal1,wangying,josecab1,huangbays,awate,josecab2,swang1,syber,luke2,sabressiims1] .", "In BCS, the sparse model for the underlying image(s) or image patches is assumed unknown a priori.", "The goal in BCS is then to reconstruct both the image(s) as well as the dictionary or transform from only the undersampled measurements.", "Thus, the BCS problem is harder than conventional compressed sensing.", "However, BCS allows the sparse model to be better adaptive to the current (unknown) image(s).", "\\newline In an early work [@bib:fowl1] , Fowler proposed a method for recovering the principal eigenvectors of data (principal components) from random projections.", "This work shares similarities with BCS in its attempt to estimate a model for data from compressive measurements.", "However, while the prior work [@bib:fowl1] learns an under-complete principal components model, BCS can enable the learning of much richer data models by exploiting sparsity criteria.", "\\newline The sparse model in BCS can take a variety of forms.", "For example, the well-known synthesis dictionary model suggests that a real-world signal $ z\\in\\mathbb{C}^{n} $ can be approximately represented as a linear combination of a small number of (or, a sparse set of) atoms or columns from a synthesis dictionary $ D\\in\\mathbb{C}^{n\\times m} $ , i.e., $ z=D\\alpha+e $ with $ \\alpha\\in\\mathbb{C}^{m} $ sparse, or $ \\left\\|\\alpha\\right\\|_{0}\\ll n $ , and $ e $ is the approximation or modeling error in the signal domain [@bib:ambruck] .", "The alternative sparsifying transform model (which is a generalized analysis model [@bib:sabres] ) suggests that the signal $ z $ is approximately sparsifiable using a transform $ W\\in\\mathbb{C}^{m\\times n} $ , i.e., $ Wz=\\alpha+\\eta $ , where $ \\alpha\\in\\mathbb{C}^{m} $ is sparse in some sense, and $ \\eta $ is a small residual error in the {transform domain} rather than in the signal domain.", "The advantage of the transform model over the synthesis dictionary model is that sparse coding (the process of finding $ \\alpha $ for a signal $ z $ , using a given $ D $ or $ W $ ) can be performed cheaply by thresholding [@bib:sabres] , whereas it is NP-hard (Non-deterministic Polynomial-time hard) in the latter case [@bib:npb,npa] .", "In recent years, the data-driven adaptation of such sparse signal models has received increasing attention and has been shown to be advantageous in several applications [@bib:elad2,elad3,elad6,bresai,doubsp2l,sbclsTS2,saiwen] .", "\\newline In prior work on BCS [@bib:bresai] , we proposed synthesis dictionary-based blind compressed sensing for MRI.", "The overlapping patches of the underlying image were modeled as sparse in an unknown patch-based dictionary (of size much smaller than the image), and this dictionary was learnt jointly with the image from undersampled k-space measurements.", "BCS techniques can provide much better image reconstructions for MRI compared to conventional CS methods that use only a fixed sparsifying transform or dictionary [@bib:bresai,symul,lingal1,wangying,josecab2,swang1] .", "However, previous dictionary-based BCS methods, which typically solve non-convex or NP-hard problems by block coordinate descent type approaches, tend to be computationally expensive, and lack any convergence guarantees.", "\\newline </subsection> <subsection> <title> I-C Contributions </title> In this work, we focus on the efficient sparsifying transform model [@bib:sabres] , and study a particular transform-based blind compressed sensing framework that has not been explored in prior work [@bib:sabressiims1,syber] .", "The proposed framework is to simultaneously reconstruct the underlying image(s) and learn the transform model from compressive measurements.", "First, we model the patches of the underlying image(s) as approximately sparse in a {single} (square) transform domain.", "We then further extend this model to a {union of transforms model} (also known as OCTOBOS model [@bib:saiwen] ) that is better suited to capture the diversity of features in natural images.", "The transforms in our formulations are constrained to be {unitary} .", "This results in computationally cheap transform update and image update steps in the proposed block coordinate descent type BCS algorithms.", "We also work with an $ \\ell_{0} $ penalty (instead of constraint) for sparsity in our formulations, which enables a very efficient and exact sparse coding step involving thresholding in our block coordinate descent algorithms.", "The $ \\ell_{0} $ penalty also plays a key role in enabling the generalization of the proposed formulation and algorithm for single transform BCS to the union of transforms case.", "We present convergence results for our algorithms that solve the single transform or union of transforms BCS problems.", "In both cases, the algorithms are guaranteed to converge to at least the partial global and partial local minimizers of the highly non-convex BCS problems.", "Our numerical experiments show that the proposed BCS framework usually leads to better quality of image reconstructions in MRI compared to several recent image reconstruction methods.", "Importantly, the learning of a union of sparsifying transforms leads to better image reconstructions than when learning a single transform.", "The data adaptive regularizers proposed in this work can be used in general inverse problem settings, and are not restricted to compressed sensing.", "\\newline </subsection> <subsection> <title> I-D Relation to Recent Works </title> In prior work, we proposed the idea of learning square sparsifying transforms from training signals [@bib:sabres,sbclsTS2] .", "A method for learning a union of transforms model from training data has also been proposed [@bib:saiwen] .", "However, these works did not consider the problem of jointly estimating images and image models from compressive measurements (i.e., blind compressed sensing).", "The latter idea was considered in recent papers [@bib:sabressiims1,syber] , where methods for simultaneously reconstructing images and learning square sparsifying transforms for image patches were considered.", "In this work, we instead investigate a novel and efficient framework for blind compressed sensing involving the richer union of transforms model.", "We use as a building block a specific square transform-based blind compressed sensing formulation involving an $ \\ell_{0} $ sparsity penalty and unitary transform constraint that is related to formulations ((P2) and (P3)) in prior work [@bib:sabressiims1] , but was not explicitly considered therein.", "We show promise for the proposed methods for MR image reconstruction, where they achieve improved or faster reconstructions compared to our recent TLMRI method [@bib:sabressiims1] , which uses a single adaptive transform.", "\\newline The application of the methods proposed in this work for MRI was briefly considered in a very recent conference publication [@bib:saibrespsie] .", "However, unlike the conference work, here, we also provide detailed theoretical convergence results for the proposed union of transforms-based blind compressed sensing method.", "An empirical study of the convergence and (blind) learning behavior of the proposed methods is also presented here, along with expanded experimental results and comparisons.", "Importantly, the theoretical and empirical convergence results presented in this work are for union of transforms-based blind compressed sensing rather than for (the simpler) transform learning (from training signals) [@bib:saiwen,sbclsTS2] .", "The theoretical results here generalize results from our prior work [@bib:sabressiims1] to related as well as more complex scenarios.", "\\newline </subsection> <subsection> <title> I-E Organization </title> The rest of this paper is organized as follows.", "Section [@ref:LABEL:sec2] describes our transform learning-based blind compressed sensing formulations and their properties.", "Section [@ref:LABEL:sec3] derives efficient block coordinate descent algorithms for the proposed problems, and discusses the algorithms\u2019 computational costs.", "Section [@ref:LABEL:sec40] discusses the theoretical convergence properties of the proposed algorithms.", "Section [@ref:LABEL:sec4] presents experimental results demonstrating the practical convergence behavior and performance of the proposed schemes for the MRI application.", "Section [@ref:LABEL:sec5] presents our conclusions and proposals for future work.", "\\newline </subsection>  </section>"], ["<section> <title> II Blind Compressed Sensing Problem Formulations </title>  The image reconstruction Problem ( [@ref:LABEL:eq1] ) for compressed sensing is a particular instance of the following constrained regularized inverse problem, with $ \\mathcal{S}=\\mathbb{C}^{p} $ \\newline <equation> $ \\min_{x\\in\\mathcal{S}}\\>\\left\\|Ax-y\\right\\|_{2}^{2}+\\zeta(x) $ </equation>", "The regularizer $ \\zeta(x)=\\lambda\\left\\|\\Psi x\\right\\|_{1} $ encourages sparsity of the image in a fixed sparsifying transform $ \\Psi $ .", "To overcome the limitations of such a non-adaptive CS formulation, or the limitations of the recent dictionary-based BCS methods, we explore sparsifying transform-based BCS formulations in this work.", "These are discussed in the following subsections.", "\\newline <subsection> <title> II-A Unitary BCS </title> Sparsifying transform learning has been demonstrated to be effective and efficient in several applications, while also enjoying good convergence properties [@bib:sbclsTS2,saonli1,saonli2,saiwen] .", "Here, we propose to use the following transform learning regularizer [@bib:sbclsTS2] \\newline <equationgroup> <equation> $ \\zeta(x)=\\frac{1}{\\nu}\\min_{W,B}\\>\\sum_{j=1}^{N}\\begin{Bmatrix}% \\hidden@noalign\\hfil\\textstyle\\left\\|WP_{j}x-b_{j}\\right\\|_{2}^{2}+\\eta^{2}% \\left\\|b_{j}\\right\\|_{0}\\end{Bmatrix} $ $ \\zeta(x)= $ $ \\frac{1}{\\nu}\\min_{W,B}\\>\\sum_{j=1}^{N}\\begin{Bmatrix}% \\hidden@noalign\\hfil\\textstyle\\left\\|WP_{j}x-b_{j}\\right\\|_{2}^{2}+\\eta^{2}% \\left\\|b_{j}\\right\\|_{0}\\end{Bmatrix} $ </equation> <equation> $ \\;\\;\\;\\;\\;\\;\\mathrm{s.t.}\\;\\;W^{H}W=I $ $ \\;\\;\\;\\;\\;\\;\\mathrm{s.t.}\\;\\;W^{H}W=I $ </equation> </equationgroup> along with the constraint set $ \\mathcal{S}=\\left\\{x\\in\\mathbb{C}^{p}:\\left\\|x\\right\\|_{2}\\leq C\\right\\} $ within Problem ( [@ref:LABEL:reginveq1] ) to arrive at the following transform BCS formulation \\newline <equationgroup> <equation> $ (\\mathrm{P1})\\>\\>\\min_{x,W,B}\\>\\nu\\left\\|Ax-y\\right\\|_{2}^{2}+% \\sum_{j=1}^{N}\\begin{Bmatrix}\\hidden@noalign\\hfil\\textstyle\\left\\|WP_{j}x-b_% {j}\\right\\|_{2}^{2}+\\eta^{2}\\left\\|b_{j}\\right\\|_{0}\\end{Bmatrix} $ $ (\\mathrm{P1})\\>\\> $ $ \\min_{x,W,B}\\>\\nu\\left\\|Ax-y\\right\\|_{2}^{2}+\\sum_{j=1}^{N}\\begin% {Bmatrix}\\hidden@noalign\\hfil\\textstyle\\left\\|WP_{j}x-b_{j}\\right\\|_{2}^{2}+% \\eta^{2}\\left\\|b_{j}\\right\\|_{0}\\end{Bmatrix} $ </equation> <equation> $ \\;\\,\\,\\mathrm{s.t.}\\;\\;W^{H}W=I,\\;\\;\\left\\|x\\right\\|_{2}\\leq C. $ $ \\;\\,\\,\\mathrm{s.t.}\\;\\;W^{H}W=I,\\;\\;\\left\\|x\\right\\|_{2}\\leq C. $ </equation> </equationgroup> Here, $ P_{j}\\in\\mathbb{C}^{n\\times p} $ represents the operator that extracts a patch as a vector $ P_{j}x\\in\\mathbb{C}^{n} $ from the image $ x $ , and $ W\\in\\mathbb{C}^{n\\times n} $ is a square sparsifying transform for the patches of the image.", "A total of $ N $ overlapping image patches are assumed, and $ \\nu>0 $ , $ \\eta>0 $ are weights in (P1).", "The term $ \\left\\|WP_{j}x-b_{j}\\right\\|_{2}^{2} $ in the cost denotes the sparsification error or transform domain residual [@bib:sabres] for the $ j $ th image patch, with $ b_{j} $ denoting the transform {sparse code} (i.e., the sparse approximation to the transformed patch).", "The penalty $ \\left\\|b_{j}\\right\\|_{0} $ counts the number of non-zeros in $ b_{j} $ .", "We use $ B\\in\\mathbb{C}^{n\\times N} $ to denote the matrix that has the sparse codes $ b_{j} $ as its columns.", "The constraint $ W^{H}W=I $ , with $ I $ denoting the $ n\\times n $ identity matrix, restricts the set of feasible transforms to unitary matrices.", "The constraint $ \\left\\|x\\right\\|_{2}\\leq C $ with $ C>0 $ in (P1) enforces any prior knowledge on the signal energy (or, range).", "\\newline In the absence of the $ \\left\\|x\\right\\|_{2}\\leq C $ condition, the objective in (P1) is non-coercive.", "In particular, consider $ W=I $ (a unitary matrix) and $ x_{\\alpha}=x_{0}+\\alpha z $ , where $ x_{0} $ is a solution to $ y=Ax $ , $ \\alpha\\in\\mathbb{R} $ , and $ z\\in\\mathcal{N}(A) $ with $ \\mathcal{N}(A) $ denoting the null space of $ A $ .", "Then, as $ \\alpha\\to\\infty $ with $ b_{j} $ set to $ WP_{j}x_{\\alpha} $ , the objective in (P1) remains always finite (non-coercive).", "The constraint $ \\left\\|x\\right\\|_{2}\\leq C $ alleviates possible problems (e.g., unbounded iterates in algorithms) due to such a non-coercive objective.", "It can also be alternatively replaced with constraints such as box constraints depending on the application and underlying image properties.", "\\newline While a single weight $ \\eta^{2} $ is used for the sparsity penalties $ \\left\\|b_{j}\\right\\|_{0} $ $ \\forall $ $ j $ in (P1), one could also use different weights $ \\eta_{j}^{2} $ for the penalties corresponding to different patches, if such weights are known, or estimated.", "When measurements from multiple images (or frames, or slices) are available, then by considering the summation of the corresponding objective functions for each image, Problem (P1) can be easily extended to enable joint reconstruction of the images using a single adaptive (spatial) transform.", "For applications such as dynamic MRI, one can also work with adaptive spatiotemporal sparsifying transforms of 3D patches in (P1).", "\\newline We have studied some transform BCS methods in very recent works [@bib:sabressiims1,syber] .", "However, the formulation (P1) investigated here was not explored in the prior work.", "Exploiting both a unitary transform constraint (as opposed to a penalty that enables well-conditioning [@bib:sabressiims1] ) and a sparsity penalty (as opposed to a sparsity constraint [@bib:sabressiims1] ) in the transform BCS formulation leads to a very efficient block coordinate descent algorithm in this work.", "Moreover, Problem (P1) and the algorithm proposed to solve it can be readily extended to accomodate richer models as shown in the following discussions.", "\\newline </subsection> <subsection> <title> II-B Union of Transforms BCS </title> Here, we extend the single transform model in Problem (P1) to a union of transforms model (similar to [@bib:saiwen] ).", "In this model, we consider a collection (union) of square transforms $ \\{W_{k}\\}_{k=1}^{K} $ with $ W_{k}\\in\\mathbb{C}^{n\\times n}\\,\\forall\\,k $ , and each image patch is assumed to have a corresponding \u201cbest matching transform\u201d (i.e., a transform that best sparsifies the particular patch) in this collection.", "A motivation for the proposed model is that natural images or image patches need not be sufficiently sparsifiable by a single transform.", "For example, image patches from different regions of an image usually contain different types of features, or textures.", "Thus, having a union of transforms would allow groups of patches with common features (or, textures) to be better sparsified by their own specific transform.", "\\newline Such a union of square transforms can be interpreted as an overcomplete transform, also called OverComplete TransfOrm model with BlOck coSparsity constraint, or OCTOBOS.", "The equivalent overcomplete transform is obtained by stacking the square \u2018sub-transforms\u2019 as $ W=\\begin{bmatrix}W_{1}^{T}\\mid W_{2}^{T}\\mid&...&\\mid W_{K}^{T}\\end{bmatrix}^{T} $ .", "The matrix $ W\\in\\mathbb{R}^{m\\times n} $ , with $ m=Kn $ , and thus, $ m>n $ (overcomplete transform) for $ K>1 $ .", "Proposition 1 of [@bib:saiwen] proves the equivalence between the following two (sparse coding) problems, where the first one involves the union of transforms, and the second one is based directly on an overcomplete (OCTOBOS) one.", "\\newline <equationgroup> <equation> $ \\min_{1\\leq k\\leq K}\\>\\min_{\\alpha^{k}}\\>\\left\\|W_{k}z-\\alpha^{k}% \\right\\|_{2}^{2}\\;\\>\\text{s.t.}\\;\\>\\left\\|\\alpha^{k}\\right\\|_{0}\\leq s\\;% \\forall\\,k $ $ \\min_{1\\leq k\\leq K}\\>\\min_{\\alpha^{k}}\\>\\left\\|W_{k}z-\\alpha^{k}% \\right\\|_{2}^{2}\\;\\>\\text{s.t.}\\;\\>\\left\\|\\alpha^{k}\\right\\|_{0}\\leq s\\;% \\forall\\,k $ </equation> <equation> $ \\;\\;\\,\\min_{\\alpha}\\>\\left\\|Wz-\\alpha\\right\\|_{2}^{2}\\;\\;\\text{s.% t.}\\;\\>\\left\\|\\alpha\\right\\|_{0,s}\\geq 1\\; $ $ \\;\\;\\,\\min_{\\alpha}\\>\\left\\|Wz-\\alpha\\right\\|_{2}^{2}\\;\\;\\text{s.% t.}\\;\\>\\left\\|\\alpha\\right\\|_{0,s}\\geq 1\\; $ </equation> </equationgroup> Here, $ z\\in\\mathbb{C}^{n} $ is a given signal, and $ \\alpha\\in\\mathbb{C}^{m} $ in ( [@ref:LABEL:rege] ) is obtained by stacking $ K $ blocks $ \\alpha^{k}\\in\\mathbb{C}^{n} $ , $ 1\\leq k\\leq K $ .", "The operation $ \\left\\|\\alpha\\right\\|_{0,s}\\triangleq\\sum_{k=1}^{K}I(\\left\\|\\alpha^{k}\\right\\|% _{0}\\leq s) $ with $ I(\\cdot) $ denoting the indicator function, counts the number of blocks of $ \\alpha $ with at least $ n-s $ zeros (co-sparse blocks), where $ s $ is a parameter.", "Proposition 1 of [@bib:saiwen] showed that the minimum sparsification errors (objectives) in ( [@ref:LABEL:rege2] ) and ( [@ref:LABEL:rege] ) are identical and that the sparse minimizer(s) in ( [@ref:LABEL:rege2] ) (i.e., best/minimizing sparse code(s) over $ 1\\leq k\\leq K $ ) are simply the block(s) with at least $ n-s $ zeros of the minimizer(s) in ( [@ref:LABEL:rege] ).", "\\newline We have investigated the learning of a union of transforms, or OCTOBOS learning, from training data in a recent work [@bib:saiwen] .", "Here, we propose to use the following union of transforms learning regularizer \\newline <equationgroup> <equation> $ \\zeta(x)=\\frac{1}{\\nu}\\min_{\\left\\{W_{k},b_{j},C_{k}\\right\\}}\\>% \\sum_{k=1}^{K}\\sum_{j\\in C_{k}}\\begin{Bmatrix}\\hidden@noalign\\hfil\\textstyle% \\left\\|W_{k}P_{j}x-b_{j}\\right\\|_{2}^{2}+\\eta^{2}\\left\\|b_{j}\\right\\|_{0}\\end{Bmatrix} $ $ \\zeta(x)=\\frac{1}{\\nu} $ $ \\min_{\\left\\{W_{k},b_{j},C_{k}\\right\\}}\\>\\sum_{k=1}^{K}\\sum_{j\\in C% _{k}}\\begin{Bmatrix}\\hidden@noalign\\hfil\\textstyle\\left\\|W_{k}P_{j}x-b_{j}% \\right\\|_{2}^{2}+\\eta^{2}\\left\\|b_{j}\\right\\|_{0}\\end{Bmatrix} $ </equation> <equation> $ \\;\\;\\mathrm{s.t.}\\;\\;W_{k}^{H}W_{k}=I\\;\\,\\forall\\,k,\\;\\,\\left\\{C_% {k}\\right\\}\\in G $ $ \\;\\;\\mathrm{s.t.}\\;\\;W_{k}^{H}W_{k}=I\\;\\,\\forall\\,k,\\;\\,\\left\\{C_% {k}\\right\\}\\in G $ </equation> </equationgroup> along with the constraint set $ \\mathcal{S}=\\left\\{x\\in\\mathbb{C}^{p}:\\left\\|x\\right\\|_{2}\\leq C\\right\\} $ within Problem ( [@ref:LABEL:reginveq1] ) to arrive at the following union of transforms BCS formulation: \\newline <equationgroup> <equation> $ (\\mathrm{P2})\\min_{x,B,\\left\\{W_{k},C_{k}\\right\\}}\\sum_{k=1}^{K}% \\sum_{j\\in C_{k}}\\begin{Bmatrix}\\hidden@noalign\\hfil\\textstyle\\left\\|W_{k}P_% {j}x-b_{j}\\right\\|_{2}^{2}+\\eta^{2}\\left\\|b_{j}\\right\\|_{0}\\end{Bmatrix} $ $ (\\mathrm{P2}) $ $ \\min_{x,B,\\left\\{W_{k},C_{k}\\right\\}}\\sum_{k=1}^{K}\\sum_{j\\in C_{% k}}\\begin{Bmatrix}\\hidden@noalign\\hfil\\textstyle\\left\\|W_{k}P_{j}x-b_{j}% \\right\\|_{2}^{2}+\\eta^{2}\\left\\|b_{j}\\right\\|_{0}\\end{Bmatrix} $ </equation> <equation> $ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+\\nu\\left\\|Ax-y% \\right\\|_{2}^{2} $ $ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+\\nu\\left\\|Ax-y% \\right\\|_{2}^{2} $ </equation> <equation> $ \\;\\,\\;\\;\\;\\;\\;\\;\\,\\mathrm{s.t.}\\;\\;W_{k}^{H}W_{k}=I\\;\\,\\forall\\,k% ,\\;\\,\\left\\{C_{k}\\right\\}\\in G,\\;\\;\\left\\|x\\right\\|_{2}\\leq C. $ $ \\;\\,\\;\\;\\;\\;\\;\\;\\,\\mathrm{s.t.}\\;\\;W_{k}^{H}W_{k}=I\\;\\,\\forall\\,k% ,\\;\\,\\left\\{C_{k}\\right\\}\\in G,\\;\\;\\left\\|x\\right\\|_{2}\\leq C. $ </equation> </equationgroup> Here and in the remainder of this work, when certain indexed variables are enclosed within braces, it means that we are considering the set of variables over the range of the indices.", "The set $ \\left\\{C_{k}\\right\\}_{k=1}^{K} $ in (P2) indicates a clustering of the image patches $ \\left\\{P_{j}x\\right\\}_{j=1}^{N} $ into $ K $ disjoint sets.", "The cluster $ C_{k} $ contains the indices $ j $ corresponding to the patches $ P_{j}x $ in the $ k $ th cluster.", "The patches in the $ k $ th cluster are considered (best) matched to the transform $ W_{k} $ .", "The set $ G $ in (P2) is the set of all possible partitions of the set of integers $ [1:N]\\triangleq\\left\\{1,2,...,N\\right\\} $ into $ K $ disjoint subsets, i.e., \\newline <equation> $ G=\\left\\{\\left\\{C_{k}\\right\\}:\\bigcup_{k=1}^{K}C_{k}=[1:N],\\,C_{j}\\bigcap C_{k% }=\\emptyset,\\,\\forall\\,j\\neq k\\right\\} $ </equation> \\newline The term $ \\sum_{k=1}^{K}\\sum_{j\\in C_{k}}\\left\\|W_{k}P_{j}x-b_{j}\\right\\|_{2}^{2} $ in (P2) is the sparsification error of the patches of $ x $ in the (richer) union of transforms model.", "Problem (P2) is to jointly reconstruct the image $ x $ and learn the (unknown) union of transforms for the image patches, as well as cluster the patches, using only the compressive imaging measurements.", "The optimal objective function value (i.e., the minimum value) in Problem (P2) can only be lower than the corresponding optimal value in (P1).", "This is obvious because the single transform model in (P1) is a subset of the richer (or more general) union of transforms model in (P2).", "\\newline The recent PANO method [@bib:Qu2014843] for MR image reconstruction also involves a patch grouping methodology, but differs from the method proposed here in several important aspects: (i) the patch grouping criterion; (ii) the type and dimension of sparsifying transform; and (iii) the use of a reference reconstruction vs. joint clustering and reconstruction.", "In particular, in the PANO method, the patches of a reference reconstruction are grouped together according to their similarity measured in terms of the Euclidean $ \\ell_{2} $ distance.", "A penalty based on the sparsity of such groups of similar (2D) patches in a {fixed} 3D transform (Haar wavelet) domain is used as a regularizer in the CS image reconstruction problem.", "Unlike the PANO method, Problem (P2) clusters together patches that are best sparsified by a common {adaptive} transform, i.e., the clustering measure is based on the sparsification error.", "Thus the clustered patches need not be similar in Euclidean distance and the adapted clusterings in (P2) can be quite general.", "Furthermore, in (P2), because the transform is adapted to the patches in the cluster, the transform depends on the clustering, and the clustering depends on the transform.", "Another difference is that, unlike the 3D (fixed) transform in PANO, for 2D patches, the adapted transform here is a 2D transform sparsifying each patch individually.", "Finally, unlike PANO, (P2) jointly clusters patches and reconstructs $ x $ , and is not based on reference reconstructions.", "\\newline </subsection>  </section>"], ["<section> <title> III Algorithms and Properties </title>  <subsection> <title> III-A Algorithms </title> Problems (P1) and (P2) involve highly nonconvex and non-differentiable (in fact, discontinuous) objectives, as well as nonconvex constraints.", "Because of the lack of analytical solutions, iterative approaches are commonly adopted for problems of this kind.", "Here, we adopt iterative block coordinate descent algorithms for (P1) and (P2) that lead to highly efficient solutions for the corresponding subproblems.", "Another advantage of block coordinate descent is that it does not require the choice of additional parameters such as step sizes.", "We first describe our algorithm for (P2).", "The algorithm for (P1) is just a special case (with $ K=1 $ ) of the one for (P2).", "\\newline In one step of our proposed block coordinate descent algorithm for (P2) called the {sparse coding and clustering step} , we solve for $ \\left\\{C_{k}\\right\\} $ and $ B $ in (P2) with the other variables fixed.", "In another step called the {transform update step} , we solve for the transforms $ \\left\\{W_{k}\\right\\} $ in (P2), while keeping all other variables fixed.", "In the third step called the {image update step} , we update only the image $ x $ , with the other variables fixed.", "We now describe these steps in detail.", "\\newline <subsubsection> <title> III-A1 Sparse Coding and Clustering Step </title> In this step, we solve the following optimization problem: \\newline <equationgroup> <equation> $ (\\mathrm{P3})\\;\\;\\min_{\\left\\{C_{k}\\right\\},\\left\\{b_{j}\\right\\}}% \\>\\sum_{k=1}^{K}\\sum_{j\\in C_{k}}\\begin{Bmatrix}\\hidden@noalign\\hfil% \\textstyle\\left\\|W_{k}P_{j}x-b_{j}\\right\\|_{2}^{2}+\\eta^{2}\\left\\|b_{j}\\right% \\|_{0}\\end{Bmatrix} $ $ (\\mathrm{P3})\\;\\; $ $ \\min_{\\left\\{C_{k}\\right\\},\\left\\{b_{j}\\right\\}}\\>\\sum_{k=1}^{K}% \\sum_{j\\in C_{k}}\\begin{Bmatrix}\\hidden@noalign\\hfil\\textstyle\\left\\|W_{k}P_% {j}x-b_{j}\\right\\|_{2}^{2}+\\eta^{2}\\left\\|b_{j}\\right\\|_{0}\\end{Bmatrix} $ </equation> <equation> $ \\,\\,\\,\\,\\,\\,\\,\\,\\mathrm{s.t.}\\;\\>\\left\\{C_{k}\\right\\}\\in G. $ $ \\,\\,\\,\\,\\,\\,\\,\\,\\mathrm{s.t.}\\;\\>\\left\\{C_{k}\\right\\}\\in G. $ </equation> </equationgroup> By first performing the (inner) optimization with respect to the $ b_{j} $ \u2019s in (P3), it is easy to observe that Problem (P3) can be rewritten in the following equivalent form: \\newline <equationgroup> <equation> $ \\sum_{j=1}^{N}\\min_{1\\leq k\\leq K}\\begin{Bmatrix}\\hidden@noalign{% }\\hfil\\textstyle\\left\\|W_{k}P_{j}x-H_{\\eta}(W_{k}P_{j}x)\\right\\|_{2}^{2}+\\eta^% {2}\\left\\|H_{\\eta}(W_{k}P_{j}x)\\right\\|_{0}\\end{Bmatrix} $ $ \\sum_{j=1}^{N}\\min_{1\\leq k\\leq K}\\begin{Bmatrix}\\hidden@noalign{% }\\hfil\\textstyle\\left\\|W_{k}P_{j}x-H_{\\eta}(W_{k}P_{j}x)\\right\\|_{2}^{2}+\\eta^% {2}\\left\\|H_{\\eta}(W_{k}P_{j}x)\\right\\|_{0}\\end{Bmatrix} $ </equation> </equationgroup> where the minimization over $ k $ for each patch $ P_{j}x $ ( $ 1\\leq j\\leq N $ ) determines the cluster $ C_{k} $ in (P3) to which that patch belongs.", "The hard-thresholding operator $ H_{\\eta}(\\cdot) $ appears in ( [@ref:LABEL:bi1] ) because of the aforementioned (inner) optimization with respect to the $ b_{j} $ \u2019s [@bib:sbclsTS2] in (P3), and $ H_{\\eta}(\\cdot) $ is defined as follows, where $ \\alpha\\in\\mathbb{C}^{n} $ is any vector, and the subscript $ i $ indexes vector entries.", "\\newline <equation> $ \\left(H_{\\eta}(\\alpha)\\right)_{i}=\\left\\{\\begin{matrix}0&,\\;\\;\\left|\\alpha_{i}% \\right|<\\eta\\\\ \\alpha_{i}&,\\;\\;\\left|\\alpha_{i}\\right|\\geq\\eta\\end{matrix}\\right.", "$ </equation> For each patch $ P_{j}x $ , the optimal cluster index $ \\hat{k}_{j} $ in ( [@ref:LABEL:bi1] ) is then \\newline <equation> $ \\hat{k}_{j}=\\underset{k}{\\arg\\min}\\,\\left\\|W_{k}P_{j}x-H_{\\eta}(W_{k}P_{j}x)% \\right\\|_{2}^{2}+\\eta^{2}\\left\\|H_{\\eta}(W_{k}P_{j}x)\\right\\|_{0} $ </equation>", "The optimal sparse code $ \\hat{b}_{j} $ in (P3) is then $ H_{\\eta}(W_{\\hat{k}_{j}}P_{j}x) $ [@bib:sbclsTS2] .", "There is no coupling between the sparse coding/clustering problems in ( [@ref:LABEL:bi1] ) for the different image patches $ \\left\\{P_{j}x\\right\\}_{j=1}^{N} $ .", "Thus, they are clustered and sparse coded in parallel.", "\\newline The optimal cluster membership or the optimal sparse code for any particular patch $ P_{j}x $ in (P3) need not be unique.", "When there are multiple optimal cluster indices in ( [@ref:LABEL:spie1] ), we pick the lowest such index.", "The optimal sparse code for the patch $ P_{j}x $ is not unique when the condition $ \\left|\\begin{pmatrix}W_{\\hat{k}_{j}}P_{j}x\\end{pmatrix}_{i}\\right|=\\eta $ is satisfied for some $ i $ (cf.", "[@bib:sbclsTS2] for a similar scenario and an explanation).", "The definition in ( [@ref:LABEL:bcs5] ) chooses {one} of the multiple optimal solutions (corresponding to the transform $ W_{\\hat{k}_{j}} $ ) in this case.", "\\newline Note that if instead of employing a sparsity penalty (i.e., penalizing $ \\sum_{j=1}^{N}\\left\\|b_{j}\\right\\|_{0} $ ), we were to constrain the term $ \\sum_{j=1}^{N}\\left\\|b_{j}\\right\\|_{0} $ (i.e., force it to have an upper bound of $ s $ [@bib:sabressiims1] ) in (P2), then the sparse coding and clustering step of such a modified BCS problem shown below suffers from the drawback that the sparsity constraint creates inter-patch coupling, which in turn leads to exponential scaling of the computation with the number of patches.", "\\newline <equationgroup> <equation> $ \\min_{\\left\\{C_{k}\\right\\},B}\\>\\sum_{k=1}^{K}\\sum_{j\\in C_{k}}% \\left\\|W_{k}P_{j}x-b_{j}\\right\\|_{2}^{2} $ $ \\min_{\\left\\{C_{k}\\right\\},B}\\>\\sum_{k=1}^{K}\\sum_{j\\in C_{k}}% \\left\\|W_{k}P_{j}x-b_{j}\\right\\|_{2}^{2} $ </equation> <equation> $ \\,\\,\\,\\,\\,\\mathrm{s.t.}\\;\\>\\sum_{j=1}^{N}\\left\\|b_{j}\\right\\|_{0}% \\leq s,\\,\\left\\{C_{k}\\right\\}\\in G. $ $ \\,\\,\\,\\,\\,\\mathrm{s.t.}\\;\\>\\sum_{j=1}^{N}\\left\\|b_{j}\\right\\|_{0}% \\leq s,\\,\\left\\{C_{k}\\right\\}\\in G. $ </equation> </equationgroup> For a fixed clustering $ \\left\\{C_{k}\\right\\} $ , the optimal $ B $ above is readily obtained by zeroing out all but the $ s $ largest magnitude elements of the matrix $ \\begin{bmatrix}W_{k_{1}}P_{1}x\\mid W_{k_{2}}P_{2}x\\mid...\\mid W_{k_{N}}P_{N}x% \\end{bmatrix} $ , where $ k_{j} $ denotes the cluster index of patch $ P_{j}x $ .", "However, this requires examination of all the sparsified patches {jointly} .", "Now, consider the objective value attained in ( [@ref:LABEL:alterbcs3] ) for the clustering $ \\left\\{C_{k}\\right\\} $ and its corresponding optimal $ B $ , to which we refer as the sparsification error for that clustering.", "The exact solution to Problem ( [@ref:LABEL:alterbcs3] ) requires computing this sparsification error for each possible clustering, and then picking the clustering that achieves the minimum error.", "Because there are $ K^{N} $ possible clusterings, the cost of computing the solution scales exponentially with the number of patches as $ O(Nn^{2}K^{N}) $ .", "Thus, Problem ( [@ref:LABEL:alterbcs3] ) is computationally intractable.", "This is one of the reasons for pursuing formulations with sparsity penalties (rather than constraint) in this work.", "Furthermore, employing a sparsity penalty leads to a simpler sparse coding solution (with a given clustering) involving hard-thresholding, whereas using a sparsity constraint (as in ( [@ref:LABEL:alterbcs3] )) for sparse coding necessitates projections onto the $ s $ - $ \\ell_{0} $ ball [@bib:sabressiims1] using a computationally more expensive sorting procedure.", "\\newline </subsubsection> <subsubsection> <title> III-A2 Transform Update Step </title> In this step, we solve (P2) with respect to the cluster transforms $ \\left\\{W_{k}\\right\\} $ , with all other variables fixed.", "This results in the following optimization problem: \\newline <equationgroup> <equation> $ \\min_{\\left\\{W_{k}\\right\\}}\\sum_{k=1}^{K}\\sum_{j\\in C_{k}}\\begin{% Bmatrix}\\hidden@noalign\\hfil\\textstyle\\left\\|W_{k}P_{j}x-b_{j}\\right\\|_{2}^{% 2}+\\eta^{2}\\left\\|b_{j}\\right\\|_{0}\\end{Bmatrix} $ $ \\min_{\\left\\{W_{k}\\right\\}}\\sum_{k=1}^{K}\\sum_{j\\in C_{k}}\\begin{% Bmatrix}\\hidden@noalign\\hfil\\textstyle\\left\\|W_{k}P_{j}x-b_{j}\\right\\|_{2}^{% 2}+\\eta^{2}\\left\\|b_{j}\\right\\|_{0}\\end{Bmatrix} $ </equation> <equation> $ \\;\\,\\mathrm{s.t.}\\;\\;W_{k}^{H}W_{k}=I\\;\\,\\forall\\,k.", "$ $ \\;\\,\\mathrm{s.t.}\\;\\;W_{k}^{H}W_{k}=I\\;\\,\\forall\\,k.", "$ </equation> </equationgroup> The above problem is in fact separable (since the objective is in summation form) into $ K $ independent constrained optimization problems, each involving a particular square transform $ W_{k} $ .", "The $ k $ th ( $ 1\\leq k\\leq K $ ) such optimization problem is as follows: \\newline <equationgroup> <equation> $ (\\mathrm{P4})\\>\\>\\>\\min_{W_{k}}\\sum_{j\\in C_{k}}\\left\\|W_{k}P_{j}% x-b_{j}\\right\\|_{2}^{2}\\;\\;\\mathrm{s.t.}\\;\\;W_{k}^{H}W_{k}=I. $ $ (\\mathrm{P4})\\>\\>\\> $ $ \\min_{W_{k}}\\sum_{j\\in C_{k}}\\left\\|W_{k}P_{j}x-b_{j}\\right\\|_{2}% ^{2}\\;\\;\\mathrm{s.t.}\\;\\;W_{k}^{H}W_{k}=I. $ </equation> </equationgroup> Denoting by $ X_{C_{k}} $ , the matrix that has the patches $ P_{j}x $ for $ j\\in C_{k} $ , as its columns, and denoting by $ B_{C_{k}} $ , the matrix whose columns are the corresponding sparse codes, Problem (P4) can be written in compact form as \\newline <equation> $ \\min_{W_{k}}\\>\\left\\|W_{k}X_{C_{k}}-B_{C_{k}}\\right\\|_{F}^{2}\\;\\,\\,\\mathrm{s.t% .}\\;\\;W_{k}^{H}W_{k}=I. $ </equation> Now, let $ X_{C_{k}}B_{C_{k}}^{H} $ have a full singular value decomposition (SVD) of $ U\\Sigma V^{H} $ .", "Then, a global minimizer [@bib:sabres3,sbclsTS2] in ( [@ref:LABEL:bcs8] ) is $ \\hat{W}_{k}=VU^{H} $ .", "This solution is unique if and only if $ X_{C_{k}}B_{C_{k}}^{H} $ is non-singular.", "To solve Problem ( [@ref:LABEL:tuovprob1] ), Problem (P4) is solved for each $ k $ , which can be done in parallel.", "\\newline </subsubsection> <subsubsection> <title> III-A3 Image Update Step </title> In this step, we solve (P2) with respect to the unknown image $ x $ , keeping the other variables fixed.", "The corresponding optimization problem is as follows.", "\\newline <equationgroup> <equation> $ (\\mathrm{P5})\\>\\>\\>\\min_{x}\\>\\nu\\left\\|Ax-y\\right\\|_{2}^{2}+\\sum_% {k=1}^{K}\\sum_{j\\in C_{k}}\\left\\|W_{k}P_{j}x-b_{j}\\right\\|_{2}^{2} $ $ (\\mathrm{P5})\\>\\>\\> $ $ \\min_{x}\\>\\nu\\left\\|Ax-y\\right\\|_{2}^{2}+\\sum_{k=1}^{K}\\sum_{j\\in C% _{k}}\\left\\|W_{k}P_{j}x-b_{j}\\right\\|_{2}^{2} $ </equation> <equation> $ \\;\\;\\,\\mathrm{s.t.}\\;\\;\\left\\|x\\right\\|_{2}\\leq C. $ $ \\;\\;\\,\\mathrm{s.t.}\\;\\;\\left\\|x\\right\\|_{2}\\leq C. $ </equation> </equationgroup> Problem (P5) is a least squares problem with an $ \\ell_{2} $ (or, alternatively squared $ \\ell_{2} $ ) constraint [@bib:golkah1] .", "It can be solved for example using the projected gradient method, or using the Lagrange multiplier method [@bib:golkah1] .", "In the latter case, the corresponding Lagrangian formulation is simply a least squares problem.", "Therefore, the solution to (P5) satisfies the following Normal Equation \\newline <equationgroup> <equation> $ \\left(\\sum_{j=1}^{N}P_{j}^{T}P_{j}\\;+\\;\\nu\\>A^{H}A+\\hat{\\mu}I% \\right)x=\\sum_{k=1}^{K}\\sum_{j\\in C_{k}}P_{j}^{T}W_{k}^{H}b_{j}\\; $ $ \\left(\\sum_{j=1}^{N}P_{j}^{T}P_{j}\\;+\\;\\nu\\>A^{H}A+\\hat{\\mu}I% \\right)x=\\sum_{k=1}^{K}\\sum_{j\\in C_{k}}P_{j}^{T}W_{k}^{H}b_{j}\\; $ </equation> <equation> $ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;% \\;\\;\\;\\;+\\>\\nu\\>A^{H}y $ $ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;% \\;\\;\\;\\;+\\>\\nu\\>A^{H}y $ </equation> </equationgroup> where $ \\hat{\\mu}\\geq 0 $ is the optimally chosen Lagrange multiplier.", "The optimal $ \\hat{\\mu} $ is the smallest non-negative real for which the solution (i.e., the $ x $ ) in ( [@ref:LABEL:bcs10] ) satisfies the norm constraint in (P5).", "Problem (P5) can be solved by solving the Lagrangian least squares problem (or, corresponding normal equation) repeatedly (by CG) for various multiplier values (tuned in steps) until the $ \\left\\|x\\right\\|_{2}\\leq C $ condition is satisfied.", "\\newline We now discuss the solution to (P5) for the specific case of single-coil MRI.", "(In the case of multi-coil or parallel MRI, when $ A $ is for example a SENSE type sensing matrix [@bib:swang1] , the aforementioned iterative strategies can be used to solve (P5).)", "Recall that $ A=F_{u} $ for (single-coil) MRI, and we assume that the k-space measurements are obtained by subsampling on a uniform Cartesian grid.", "Assuming that periodically positioned, overlapping image patches (patch {overlap stride} [@bib:bresai] denoted by $ r $ ) are used in our formulations, and that the patches that overlap the image boundaries \u2018wrap around\u2019 on the opposite side of the image [@bib:bresai] , we have that the matrix $ \\sum_{j=1}^{N}P_{j}^{T}P_{j}=\\beta I $ , with $ \\beta=\\frac{n}{r^{2}} $ .", "Then, equation ( [@ref:LABEL:bcs10] ) simplifies for MRI as \\newline <equationgroup> <equation> $ \\left(\\beta I+\\nu\\>FF_{u}^{H}F_{u}F^{H}+\\hat{\\mu}I\\right)Fx=F\\sum% _{k=1}^{K}\\sum_{j\\in C_{k}}P_{j}^{T}W_{k}^{H}b_{j} $ $ \\left(\\beta I+\\nu\\>FF_{u}^{H}F_{u}F^{H}+\\hat{\\mu}I\\right)Fx=F\\sum% _{k=1}^{K}\\sum_{j\\in C_{k}}P_{j}^{T}W_{k}^{H}b_{j} $ </equation> <equation> $ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;% \\;\\;\\;\\;+\\nu FF_{u}^{H}y $ $ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;% \\;\\;\\;\\;+\\nu FF_{u}^{H}y $ </equation> </equationgroup> where $ F\\in\\mathbb{C}^{p\\times p} $ denotes the full Fourier encoding matrix assumed normalized ( $ F^{H}F=I $ ), and $ FF_{u}^{H}F_{u}F^{H} $ is a diagonal matrix of ones and zeros, with the ones at those entries that correspond to sampled locations in k-space.", "\\newline Denote $ S\\triangleq F\\sum_{k=1}^{K}\\sum_{j\\in C_{k}}P_{j}^{T}W_{k}^{H}b_{j} $ and $ S_{0}\\triangleq FF_{u}^{H}y $ .", "$ S_{0} $ represents the undersampled k-space measurements expanded to full (matrix) size, by inserting zeros at non-sampled locations.", "The solution to ( [@ref:LABEL:bcs10] ) for single-coil MRI, in Fourier space, is then \\newline <equation> $ Fx_{\\hat{\\mu}}\\>(k_{x},k_{y})=\\left\\{\\begin{matrix}\\frac{S(k_{x},k_{y})}{\\beta% +\\hat{\\mu}}&,\\>(k_{x},k_{y})\\notin\\Omega\\\\ \\frac{S(k_{x},k_{y})+\\nu\\,S_{0}(k_{x},k_{y})}{\\beta+\\nu+\\hat{\\mu}}&,\\>(k_{x},k% _{y})\\in\\Omega\\end{matrix}\\right.", "$ </equation> where $ (k_{x},k_{y}) $ indexes k-space locations, and $ \\Omega $ is the subset of k-space that is sampled.", "Note that the optimal Lagrange multiplier $ \\hat{\\mu} $ is the smallest non-negative real such that \\newline <equationgroup> <equation> $  f(\\hat{\\mu})\\triangleq\\left\\|x_{\\hat{\\mu}}\\right\\|_{2}^{2}=\\sum_% {(k_{x},k_{y})\\notin\\Omega}\\frac{\\left|S(k_{x},k_{y})\\right|^{2}}{\\left(\\beta+% \\hat{\\mu}\\right)^{2}} $ $  f(\\hat{\\mu})\\triangleq\\left\\|x_{\\hat{\\mu}}\\right\\|_{2}^{2} $ $ =\\sum_{(k_{x},k_{y})\\notin\\Omega}\\frac{\\left|S(k_{x},k_{y})\\right% |^{2}}{\\left(\\beta+\\hat{\\mu}\\right)^{2}} $ </equation> <equation> $ +\\sum_{(k_{x},k_{y})\\in\\Omega}\\frac{\\left|S(k_{x},k_{y})+\\nu\\,S_{% 0}(k_{x},k_{y})\\right|^{2}}{\\left(\\beta+\\nu+\\hat{\\mu}\\right)^{2}}\\leq C^{2} $ $ +\\sum_{(k_{x},k_{y})\\in\\Omega}\\frac{\\left|S(k_{x},k_{y})+\\nu\\,S_{% 0}(k_{x},k_{y})\\right|^{2}}{\\left(\\beta+\\nu+\\hat{\\mu}\\right)^{2}}\\leq C^{2} $ </equation> </equationgroup> We check if the above condition is satisfied for $ \\hat{\\mu}=0 $ first.", "If not, then we apply Newton\u2019s method to find the optimal $ \\hat{\\mu} $ in $ f(\\hat{\\mu})=C^{2} $ .", "The optimal $ \\hat{x} $ in (P5) for MRI is the 2D inverse FFT of the optimal $ Fx_{\\hat{\\mu}} $ in ( [@ref:LABEL:bcs13] ).", "\\newline The unitary property of the transforms $ W_{k} $ leads to efficient solutions in the image update step for MRI.", "In particular, if the $ W_{k} $ \u2019s were not unitary, the matrix $ \\sum_{j=1}^{N}P_{j}^{T}P_{j} $ in ( [@ref:LABEL:bcs10] ) and later equations would be replaced with $ \\sum_{k=1}^{K}\\sum_{j\\in C_{k}}P_{j}^{T}W_{k}^{H}W_{k}P_{j} $ .", "The latter matrix is neither diagonal nor readily diagonalizable.", "Hence, we cannot exploit the simple closed-form solution in ( [@ref:LABEL:bcs13] ) in this case and would have to employ slower iterative solution techniques for MRI.", "\\newline The overall algorithm corresponding to the BCS Problem (P2) is shown in Fig. [@ref:LABEL:im5pbcs] .", "The algorithm begins with an initial estimate $ x^{0},\\left\\{W_{k}^{0},C_{k}^{0}\\right\\},B^{0} $ (e.g., $ x^{0}=A^{\\dagger}y $ (assuming $ \\left\\|A^{\\dagger}y\\right\\|_{2}\\leq C $ ), a random or k-means clustering initialization $ \\left\\{C_{k}^{0}\\right\\} $ , $ W_{k}^{0}=\\mathrm{2D\\,DCT} $ $ \\forall $ $ k $ , and $ B^{0} $ set to be the minimizer of (P2) for these $ x^{0},\\left\\{W_{k}^{0},C_{k}^{0}\\right\\} $ ).", "Each outer iteration of the algorithm involves the sparse coding and clustering, transform update, and image update steps.", "(In general, one could alternate between some of these steps more frequently than between others.) Our algorithm for solving Problem (P1) is similar to that for Problem (P2), except that we work with a single cluster ( $ K=1 $ ) in the former case.", "In particular, the sparse coding and clustering step for (P2) is replaced by just a sparse coding step (in a single unitary transform) for (P1).", "\\newline </subsubsection> </subsection> <subsection> <title> III-B Computational Costs </title> Here, we briefly analyze the computational costs of our algorithms for Problems (P1) and (P2), called Algorithm A1 and A2, respectively.", "\\newline For a fixed number of clusters (constant $ K $ ), the computational cost per iteration of Algorithm A2 for (P2) for MRI scales as $ O(n^{2}N) $ .", "Thus, the cost scales quadratically with the parameter $ n $ (number of pixels in a patch) and linearly with $ N $ (number of patches).", "The cost per iteration of Algorithm A1 for (P1) scales similarly with respect to these parameters.", "These costs are dominated by the computations for matrix-matrix or matrix-vector products in our algorithms.", "In contrast, overcomplete dictionary-based BCS methods such as DLMRI [@bib:bresai] that learn a dictionary $ D\\in\\mathbb{C}^{n\\times m} $ ( $ m\\geq n $ ) from compressive measurements have a cost per outer iteration that scales as $ O(nmsN\\hat{J}) $ [@bib:bresai,sabressiims1] , where $ s $ is the synthesis sparsity level per patch, and $ \\hat{J} $ is the number of inner dictionary learning (K-SVD [@bib:elad] ) iterations in DLMRI.", "The DLMRI cost is dominated by synthesis sparse coding (an NP-hard problem).", "Assuming $ m\\propto n $ and $ s\\propto n $ , the cost per iteration of DLMRI scales as $ O(n^{3}N\\hat{J}) $ .", "Thus, the per-iteration cost of Algorithm A1 or A2 scales much better with patch size than that for prior synthesis dictionary-based BCS methods.", "This would be particularly advantageous in the context of higher-dimensional imaging applications such as 3D or 4D imaging, where the corresponding 3D or 4D patches are much bigger than the patches in 2D imaging.", "As illustrated in Section [@ref:LABEL:sec4] , the proposed algorithms tend to converge quickly in practice.", "Therefore, the per-iteration computational advantages usually translate to a net computational advantage in practice.", "\\newline Clearly the union of transforms based Algorithm A2 involves more computations/operations than the single transform based Algorithm A1.", "As the number of clusters $ K $ varies, the computational cost per iteration of Algorithm A2 for MRI scales as $ O(Kn^{2}N) $ (i.e., the cost scales linearly with the number of clusters).", "In particular, these computations (with respect to parameter $ K $ ) are dominated by the clustering step, where the product between each $ W_{k} $ ( $ 1\\leq k\\leq K $ ) and every patch needs to be computed (to determine the optimal matching transforms or clusters).", "The computations in Algorithm A2 can be reduced by performing the clustering step less often (than the sparse coding, transform update, and image update steps) in the block coordinate descent algorithm.", "\\newline </subsection>  </section>"], ["<section> <title> IV Convergence Properties </title>  Since (P1) and (P2) are highly non-convex, standard results on convegence of block coordinate descent methods [@bib:tseng6] do not apply.", "In fact, in certain scenarios, one can easily construct non-convergent iterate sequences for Algorithm A1 or A2 (cf.", "Section 4 of [@bib:sabressiims1] for examples of such scenarios for related algorithms).", "Here, we present convergence results for Algorithms A1 and A2 assuming that the various steps (such as SVD computations) are performed exactly.", "Each outer iteration of our algorithms involves a transform update step, a sparse coding and clustering step (only sparse coding in the case of (P1)), and an image update step.", "\\newline <subsection> <title> IV-A Notations </title> Problem (P1) is a constrained and non-convex minimization problem.", "By replacing each constraint with an equivalent barrier penalty (a function that takes the value $ +\\infty $ when the constraint is violated, and is zero otherwise), Problem (P1) can be written in an unconstrained form involving the following objective function: \\newline <equationgroup> <equation> $  g(W,B,x)=\\nu\\left\\|Ax-y\\right\\|_{2}^{2}+\\varphi(W)+\\chi(x) $ $  g(W,B,x) $ $ =\\nu\\left\\|Ax-y\\right\\|_{2}^{2}+\\varphi(W)+\\chi(x) $ </equation> <equation> $ \\;\\;\\;+\\sum_{j=1}^{N}\\begin{Bmatrix}\\hidden@noalign\\hfil% \\textstyle\\left\\|WP_{j}x-b_{j}\\right\\|_{2}^{2}+\\eta^{2}\\left\\|b_{j}\\right\\|_{0% }\\end{Bmatrix} $ $ \\;\\;\\;+\\sum_{j=1}^{N}\\begin{Bmatrix}\\hidden@noalign\\hfil% \\textstyle\\left\\|WP_{j}x-b_{j}\\right\\|_{2}^{2}+\\eta^{2}\\left\\|b_{j}\\right\\|_{0% }\\end{Bmatrix} $ </equation> </equationgroup> where $ \\varphi(W) $ and $ \\chi(x) $ are the barrier penalties corresponding to the unitary transform constraint and energy constraint on $ x $ , respectively.", "Problem (P2) can also be written in the following unconstrained form: \\newline <equationgroup> <equation> $  h(W,B,\\Gamma,x)=\\nu\\left\\|Ax-y\\right\\|_{2}^{2}+\\chi(x)+\\sum_{k=1% }^{K}\\varphi(W_{k}) $ $  h(W,B,\\Gamma,x) $ $ =\\nu\\left\\|Ax-y\\right\\|_{2}^{2}+\\chi(x)+\\sum_{k=1}^{K}\\varphi(W_{% k}) $ </equation> <equation> $ \\;\\;\\;+\\sum_{k=1}^{K}\\sum_{j\\in C_{k}}\\begin{Bmatrix}% \\hidden@noalign\\hfil\\textstyle\\left\\|W_{k}P_{j}x-b_{j}\\right\\|_{2}^{2}+\\eta^% {2}\\left\\|b_{j}\\right\\|_{0}\\end{Bmatrix} $ $ \\;\\;\\;+\\sum_{k=1}^{K}\\sum_{j\\in C_{k}}\\begin{Bmatrix}% \\hidden@noalign\\hfil\\textstyle\\left\\|W_{k}P_{j}x-b_{j}\\right\\|_{2}^{2}+\\eta^% {2}\\left\\|b_{j}\\right\\|_{0}\\end{Bmatrix} $ </equation> </equationgroup> where $ \\varphi(W_{k}) $ is the barrier penalty corresponding to the unitary constraint on $ W_{k} $ , $ W\\in\\mathbb{C}^{Kn\\times n} $ is obtained by stacking the $ W_{k} $ \u2019s on top of one another (or, equivalent OCTOBOS), and the row vector $ \\Gamma\\in\\mathbb{R}^{1\\times N} $ is such that its $ j $ th element $ \\Gamma_{j}\\in\\left\\{1,..,K\\right\\} $ denotes the cluster index (label) corresponding to the patch $ P_{j}x $ .", "As discussed previously, the clusters $ \\begin{Bmatrix}C_{k}\\end{Bmatrix} $ partition $ [1:N] $ .", "Here, we refer to patch cluster memberships using the row vector variable $ \\Gamma $ rather than using the $ C_{k} $ \u2019s. \\newline We denote the iterates (outputs) in each iteration $ t $ of Algorithm A1 by the set $ \\left(W^{t},B^{t},x^{t}\\right) $ .", "For Algorithm A2, the iterates are denoted by the set $ (W^{t},B^{t},\\Gamma^{t},x^{t}) $ , where $ W^{t} $ in this case denotes the matrix obtained by stacking the cluster-specific transforms $ W_{k}^{t} $ ( $ 1\\leq k\\leq K $ ), and $ \\Gamma^{t} $ is a row vector containing the patch cluster indices $ \\Gamma_{j}^{t} $ ( $ 1\\leq j\\leq N $ ) as its elements.", "\\newline </subsection> <subsection> <title> IV-B Main Results </title> For Algorithm A1 proposed for Problem (P1), the convergence results take the same form as those for similar schemes presented in a very recent work [@bib:sabressiims1] .", "The result for (P1) is summarized in the following Theorem and corollaries, where for a matrix $ H $ , $ \\left\\|H\\right\\|_{\\infty}\\triangleq\\max_{i,j}\\left|H_{ij}\\right| $ , and by \u2018globally convergent\u2019, we mean convergence from any initialization.", "\\newline <theorem> Theorem 1 For an initial $ (W^{0},B^{0},x^{0}) $ , the objective sequence $ \\left\\{g^{t}\\right\\} $ in Algorithm A1 with $ g^{t}\\triangleq g\\left(W^{t},B^{t},x^{t}\\right) $ is monotone decreasing, and converges to a finite value, say $ g^{*}=g^{*}(W^{0},B^{0},x^{0}) $ .", "Moreover, the bounded iterate sequence $ \\left\\{W^{t},B^{t},x^{t}\\right\\} $ is such that all its accumulation points are equivalent and achieve the same value $ g^{*} $ of the objective.", "The sequence $ \\left\\{a^{t}\\right\\} $ with $ a^{t}\\triangleq\\left\\|x^{t}-x^{t-1}\\right\\|_{2} $ , converges to zero.", "Every accumulation point $ (W,B,x) $ of $ \\left\\{W^{t},B^{t},x^{t}\\right\\} $ is a critical point [@bib:sabressiims1,vari1] of the objective $ g $ satisfying the following partial global optimality conditions \\newline <equationgroup> <equation> $  x\\in\\underset{\\tilde{x}}{\\arg\\min}\\;\\,g\\left(W,B,\\tilde{x}\\right) $ $  x\\in $ $ \\underset{\\tilde{x}}{\\arg\\min}\\;\\,g\\left(W,B,\\tilde{x}\\right) $ </equation> <equation> $  W\\in\\underset{\\tilde{W}}{\\arg\\min}\\;\\,g\\left(\\tilde{W},B,x\\right) $ $  W\\in $ $ \\underset{\\tilde{W}}{\\arg\\min}\\;\\,g\\left(\\tilde{W},B,x\\right) $ </equation> <equation> $  B\\in\\underset{\\tilde{B}}{\\arg\\min}\\;\\,g\\left(W,\\tilde{B},x\\right) $ $  B\\in $ $ \\underset{\\tilde{B}}{\\arg\\min}\\;\\,g\\left(W,\\tilde{B},x\\right) $ </equation> </equationgroup> Each $ (W,B,x) $ also satisfies the following partial local optimality condition that holds for all $ \\Delta x\\in\\mathbb{C}^{p} $ , and all $ \\Delta B\\in\\mathbb{C}^{n\\times N} $ satisfying $ \\left\\|\\Delta B\\right\\|_{\\infty}<\\eta/2 $ : \\newline <equation> $ g(W,B+\\Delta B,x+\\Delta x)\\geq g(W,B,x)=g^{*} $ </equation> \\newline </theorem> <theorem> Corollary 1 For each $ (W^{0},B^{0},x^{0}) $ , the iterate sequence in Algorithm A1 converges to an equivalence class of critical points that are also partial minimizers satisfying ( [@ref:LABEL:cnbcs4] ), ( [@ref:LABEL:cnbcs5] ), ( [@ref:LABEL:cnbcs6] ), and ( [@ref:LABEL:cnbcs5b] ).", "\\newline </theorem> <theorem> Corollary 2 Algorithm A1 is globally convergent to a subset of the set of critical points of the non-convex objective $ g\\left(W,B,x\\right) $ .", "The subset includes all critical points $ (W,B,x) $ , that are at least partial global minimizers of $ g(W,B,x) $ with respect to each of $ W $ , $ B $ , and $ x $ , and partial local minimizers of $ g(W,B,x) $ with respect to $ (B,x) $ .", "\\newline </theorem> Theorem [@ref:LABEL:theorem1bc] establishes that for each initial $ (W^{0},B^{0},x^{0}) $ , the iterate sequence in Algorithm A1 converges to an equivalence class of accumulation points (corresponding to the same objective value $ g^{*}=g^{*}(W^{0},B^{0},x^{0}) $ \u2013 that could vary with initialization).", "The equivalent accumulation points are all critical points (generalized stationary points [@bib:vari1] ) and at least partial minimizers of the objective $ g $ .", "\\newline In the case of the Algorithm A2 proposed for (P2), because the cluster memberships are discrete rather than continuous variables, we do not have a critical points [@bib:sabressiims1,vari1] property as for Algorithm A1.", "Instead, we establish the following convergence results for Algorithm A2.", "\\newline <theorem> Theorem 2 For an initial $ (W^{0},B^{0},\\Gamma^{0},x^{0}) $ , the objective sequence $ \\left\\{h^{t}\\right\\} $ in Algorithm A2 with $ h^{t}\\triangleq h\\left(W^{t},B^{t},\\Gamma^{t},x^{t}\\right) $ is monotone decreasing, and converges to a finite value, say $ h^{*}=h^{*}(W^{0},B^{0},\\Gamma^{0},x^{0}) $ .", "Moreover, the iterate sequence $ \\left\\{W^{t},B^{t},\\Gamma^{t},x^{t}\\right\\} $ is bounded, and all its accumulation points are equivalent and achieve the same value $ h^{*} $ of the objective.", "The sequence $ \\left\\{a^{t}\\right\\} $ with $ a^{t}\\triangleq\\left\\|x^{t}-x^{t-1}\\right\\|_{2} $ , converges to zero.", "Every accumulation point $ (W,B,\\Gamma,x) $ of $ \\left\\{W^{t},B^{t},\\Gamma^{t},x^{t}\\right\\} $ satisfies the following partial global optimality conditions \\newline <equationgroup> <equation> $  x\\in\\underset{\\tilde{x}}{\\arg\\min}\\;\\,h\\left(W,B,\\Gamma,\\tilde{x% }\\right) $ $  x\\in $ $ \\underset{\\tilde{x}}{\\arg\\min}\\;\\,h\\left(W,B,\\Gamma,\\tilde{x}\\right) $ </equation> <equation> $  W\\in\\underset{\\tilde{W}}{\\arg\\min}\\;\\,h\\left(\\tilde{W},B,\\Gamma,% x\\right) $ $  W\\in $ $ \\underset{\\tilde{W}}{\\arg\\min}\\;\\,h\\left(\\tilde{W},B,\\Gamma,x\\right) $ </equation> <equation> $ (B,\\Gamma)\\in\\underset{\\tilde{B},\\tilde{\\Gamma}}{\\arg\\min}\\;\\,h% \\left(W,\\tilde{B},\\tilde{\\Gamma},x\\right) $ $ (B,\\Gamma)\\in $ $ \\underset{\\tilde{B},\\tilde{\\Gamma}}{\\arg\\min}\\;\\,h\\left(W,\\tilde{% B},\\tilde{\\Gamma},x\\right) $ </equation> </equationgroup> Each $ (W,B,\\Gamma,x) $ also satisfies the following partial local optimality condition that holds for all $ \\Delta x\\in\\mathbb{C}^{p} $ , and all $ \\Delta B\\in\\mathbb{C}^{n\\times N} $ satisfying $ \\left\\|\\Delta B\\right\\|_{\\infty}<\\eta/2 $ : \\newline <equationgroup> <equation> $  h(W,B+\\Delta B,\\Gamma,x+\\Delta x)\\geq h(W,B,\\Gamma,x)=h^{*} $ $  h(W,B+\\Delta B,\\Gamma,x+\\Delta x)\\geq $ $  h(W,B,\\Gamma,x)=h^{*} $ </equation> </equationgroup> \\newline </theorem> Theorem [@ref:LABEL:theorem2bc] establishes that for each initial $ (W^{0},B^{0},\\Gamma^{0},x^{0}) $ , the iterate sequence in Algorithm A2 converges to an equivalence class of accumulation points.", "The equivalent accumulation points are at least partial minimizers of the objective $ h $ .", "In light of Theorem [@ref:LABEL:theorem2bc] , results similar to Corollaries [@ref:LABEL:corollary1a] and [@ref:LABEL:corollary1b] apply for Algorithm A2, as follows.", "\\newline <theorem> Corollary 3 For each $ (W^{0},B^{0},\\Gamma^{0},x^{0}) $ , the iterate sequence in Algorithm A2 converges to an equivalence class of accumulation points that are also partial minimizers satisfying ( [@ref:LABEL:cnbcs4un] ), ( [@ref:LABEL:cnbcs5un] ), ( [@ref:LABEL:cnbcs6un] ), and ( [@ref:LABEL:cnbcs5bun] ).", "\\newline </theorem> <theorem> Corollary 4 The iterate sequence in Algorithm A2 is globally convergent to the set of partial minimizers of the non-convex objective $ h\\left(W,B,\\Gamma,x\\right) $ .", "The set includes all points $ (W,B,\\Gamma,x) $ , that are at least partial global minimizers of $ h(W,B,\\Gamma,x) $ with respect to each of $ W $ , $ (B,\\Gamma) $ , $ x $ , and partial local minimizers of $ h(W,B,\\Gamma,x) $ with respect to $ (B,x) $ .", "\\newline </theorem> Notice that for both Algorithms A1 and A2, $ \\left\\|x^{t}-x^{t-1}\\right\\|_{2}\\to 0 $ .", "This is a necessary but not sufficient condition for convergence of the entire sequence $ \\left\\{x^{t}\\right\\} $ .", "In general, the set of points to which Algorithm A2 or A1 converges may be larger than the set of global minimizers in Problem (P2) or (P1).", "We leave the investigation of the conditions under which the proposed algorithms converge to the set of global minimizers of the proposed problems to future work.", "\\newline A brief proof of Theorem [@ref:LABEL:theorem2bc] is included in the supplementary material available online [@bib:suppl123] .", "The proof draws on a few results from recent works [@bib:sabressiims1,sbclsTS2] , but is for the more complex union of transforms-based blind compressed sensing scenario.", "Since Algorithm A1 for (P1) is simply a special case (with $ K=1 $ ) of Algorithm A2 for (P2), we do not provide a separate proof for Theorem [@ref:LABEL:theorem1bc] .", "\\newline </subsection>  </section>"], ["<section> <title> V NUMERICAL EXPERIMENTS </title>  <subsection> <title> V-A Framework </title> We study the convergence behavior and effectiveness of the proposed BCS methods involving (P1) and (P2) for compressed sensing MRI (CS MRI).", "The MR data used in our experiments are shown in Figure [@ref:LABEL:im1bcs] , and are labeled a-f.", "We simulate various undersampling patterns in k-space including variable density 2D random sampling [@bib:josh,bresai] , and Cartesian sampling with variable density random phase encodes (1D random).", "We then use the proposed algorithms for (P1) and (P2) to reconstruct the images from undersampled measurements.", "Our algorithm for (P1) for MRI is called Unitary Transform learning MRI (UTMRI), and our method for (P2) for MRI is referred to as UNIon of Transforms lEarning MRI (UNITE-MRI).", "\\newline We compare the reconstructions provided by our methods to those provided by the following schemes: 1) the Sparse MRI method [@bib:lustig] that utlilizes wavelets and total variation as {fixed} transforms; 2) the DLMRI method [@bib:bresai] that learns adaptive overcomplete synthesis dictionaries; 3) the PANO method [@bib:Qu2014843] that exploits the non-local similarities between image patches (similar to [@bib:dbov] ), and employs a 3D transform to sparsify groups of similar patches; and 4) the PBDWS method [@bib:Qu12] that is a recent {partially} adaptive sparsifying transform based reconstruction method that uses redundant wavelets and trained patch-based geometric directions.", "We also include in our comparisons the TLMRI method that was proposed and used in the experiments in a very recent work [@bib:sabressiims1] .", "The TLMRI method (Algorithm A1 in [@bib:sabressiims1] ) is for a variant of Problem (P1) involving a sparsity constraint (instead of penalties) and a transform regularizer $ -\\log\\left|\\det W\\right|+0.5\\left\\|W\\right\\|_{F}^{2} $ that controls the condition number of $ W $ .", "\\newline We simulated the Sparse MRI, PBDWS, PANO, DLMRI, and TLMRI methods using the software implementations available from the respective authors\u2019 websites [@bib:lus33,Quweb,PANOweb,dlmri1,tlmri1] .", "We used the built-in parameter settings in the first three implementations, which performed well in our experiments .", "Specifically, for the PBDWS method, the shift invariant discrete Wavelet transform (SIDWT) based reconstructed image is used as the {guide} (initial) image [@bib:Qu12,Quweb] .", "We employed the zero-filling reconstruction (produced within the PANO demo code [@bib:PANOweb] ) as the initial guide image for the PANO method [@bib:Qu2014843,PANOweb] .", "\\newline The DLMRI implementation [@bib:dlmri1] used image patches of size $ 6\\times 6 $ [@bib:bresai] , and learned a four fold overcomplete dictionary $ D\\in\\mathbb{R}^{36\\times 144} $ using 25 iterations of the algorithm.", "The patch stride $ r=1 $ , and $ 14400 $ (found empirically) randomly selected patches are used during the dictionary learning step (executed for 20 iterations) of the DLMRI algorithm.", "Mean-subtraction is not performed for the patches prior to the dictionary learning step of DLMRI.", "(We adopted this strategy for DLMRI as it led to better performance in our experiments.) A maximum sparsity level (of $ s=7 $ per patch) is employed together with an error threshold (for sparse coding) during the dictionary learning step.", "The $ \\ell_{2} $ error threshold per patch varies linearly from $ 0.48 $ to $ 0.04 $ over the DLMRI iterations, except in the case of Figs. [@ref:LABEL:im1bcs] (a), [@ref:LABEL:im1bcs] (c), and [@ref:LABEL:im1bcs] (f) (noisier data), where it varies from $ 0.48 $ to $ 0.15 $ over the iterations.", "These parameter settings (all other settings are as per the indications in the DLMRI-Lab toolbox [@bib:dlmri1] ) worked quite well for DLMRI.", "\\newline For UTMRI and UNITE-MRI, image patches of size $ 6\\times 6 $ were again used ( $ n=36 $ like for DLMRI), $ r=1 $ (with patch wrap around), $ \\nu=10^{6}/p $ (where $ p $ is the number of image pixels), $ C=10^{5} $ , and $ K=16 $ .", "The image, transforms, and sparse coefficients in the algorithms are initialized as indicated in Section [@ref:LABEL:sec3] .", "The clusters in UNITE-MRI were initialized appropriately.", "Both algorithms ran for 120 iterations in the experiments in Sections [@ref:LABEL:resu] and [@ref:LABEL:resu3] .", "The parameter $ \\eta $ in our methods is set to $ 0.007 $ , except in the case of Figs. [@ref:LABEL:im1bcs] (a), [@ref:LABEL:im1bcs] (c), and [@ref:LABEL:im1bcs] (f) (noisier data), where it is set to 0.05, and in the experiment in Section [@ref:LABEL:conver] (where our algorithms\u2019 convergence behavior is illustrated through an example), where it is set to 0.07.", "We use even larger values of $ \\eta $ during the initial several iterations of our algorithms in Sections [@ref:LABEL:resu] and [@ref:LABEL:resu3] , leading to faster convergence and aliasing removal.", "\\newline Finally, for the recent TLMRI algorithm [@bib:tlmri1] , we employed similar parameter settings and initializations as for UTMRI, but initialized the sparse coefficients as indicated in Section 5.1 of our prior work [@bib:sabressiims1] .", "Additionally, the parameters $ \\hat{M}=1 $ and $ \\lambda_{0}=0.2 $ for TLMRI, and the sparsity parameter $ s=0.28\\times nN $ except in the case of Figs. [@ref:LABEL:im1bcs] (a), (c), and (f), where $ s=0.1\\times nN $ .", "Even lower sparsity levels $ s $ are used during the initial several iterations of TLMRI in Sections [@ref:LABEL:resu] and [@ref:LABEL:resu3] .", "\\newline All simulations used Matlab.", "The computing platform used for the experiments was an Intel Core i5 CPU at 2.5 GHz and 4 GB memory, employing a 64-bit Windows 7 operating system.", "\\newline Similar to prior work [@bib:bresai] , we employ the peak-signal-to-noise ratio (PSNR), and high frequency error norm (HFEN) metrics to measure the quality of MR image reconstructions.", "The PSNR (expressed in decibels (dB)) is computed as the ratio of the peak intensity value of a reference image to the root mean square reconstruction error (computed between image magnitudes) relative to the reference.", "The HFEN metric quantifies the quality of reconstruction of edges or finer features.", "A rotationally symmetric Laplacian of Gaussian (LoG) filter is used, whose kernel is of size $ 15\\times 15 $ pixels, and with a standard deviation of 1.5 pixels [@bib:bresai] .", "HFEN is computed as the $ \\ell_{2} $ norm of the difference between the LoG filtered reconstructed and reference magnitude images.", "\\newline </subsection> <subsection> <title> V-B Convergence Behavior </title> In this experiment, we consider the complex-valued reference image in Fig. [@ref:LABEL:im1bcs] (c), and perform 2.5 fold undersampling of the k-space of the reference.", "The variable density sampling mask is shown in Fig. [@ref:LABEL:imcvbcs] (a).", "We study the behavior of the UTMRI and UNITE-MRI algorithms when used to reconstruct the image from the undersampled k-space measurements.", "UNITE-MRI is employed with $ 3 $ clusters for the image patches.", "The objective function (Fig. [@ref:LABEL:imcvbcs] (e)) converged monotonically and quickly over the iterations for both UTMRI and UNITE-MRI.", "In particular, the objective for UNITE-MRI converged to a much lower value than for UTMRI.", "This is because UNITE-MRI learned a richer model and achieved a lower value than UTMRI for both the sparsification error and sparsity penalty terms in its cost (i.e., in (P2)).", "The sparsity fractions (i.e., the fraction of non-zeros in the sparse code matrix $ B $ ) achieved by the UTMRI and UNITE-MRI algorithms over their iterations are shown in Fig. [@ref:LABEL:imcvbcs] (f).", "UNITE-MRI has clearly achieved lower (i.e., better) sparsities for image patches.", "The changes between successive iterates $ \\left\\|x^{t}-x^{t-1}\\right\\|_{2} $ (Fig. [@ref:LABEL:imcvbcs] (g)) decrease to small values for both UTMRI and UNITE-MRI.", "Such behavior was established for these algorithms by Theorems [@ref:LABEL:theorem1bc] and [@ref:LABEL:theorem2bc] , and is indicative (a necessary but not suffficient condition) of convergence of the entire sequence $ \\left\\{x^{t}\\right\\} $ .", "\\newline The initial zero-filling reconstruction (Fig. [@ref:LABEL:imcvbcs] (b)) has large aliasing artifacts along the phase encoding (vertical) direction, as expected for the undersampled measurements scenario.", "The initial PSNR is only $ 24.9 $ dB. In contrast, the UNITE-MRI reconstruction (Fig. [@ref:LABEL:imcvbcs] (c)) is much improved and has a PSNR of $ 37.3 $ dB. Both the PSNR and HFEN metrics (Fig. [@ref:LABEL:imcvbcs] (d)) improve significantly and converge quickly for UNITE-MRI.", "UTMRI exhibited similar behavior.", "However, the UTMRI reconstruction has a lower PSNR of $ 37.1 $ dB. \\newline Why does UNITE-MRI provide an improvement over UTMRI in reconstructing the rather simple (mostly smooth) image in this experiment?", "To answer this question, we study the clustering results produced by the union-of-transforms based UNITE-MRI.", "Since we work with overlapping image patches, each pixel in the image belongs to several different overlapping patches.", "We cluster an image pixel into a particular class $ C_{k} $ if the majority of the patches to which it belongs are clustered into that class by the UNITE-MRI algorithm.", "Figs. [@ref:LABEL:imcvbcs2] (b)-(d) show image pixels from the reconstructed image that are clustered into each of the 3 classes by UNITE-MRI.", "The pixels from each class (shown with the reconstructed intensities) are overlaid on a black background in these images.", "The results show that UNITE-MRI groups regions that share common orientations of edges.", "(Edges exist at a variety of orientations for the phantom image.) For example, the second cluster (Fig. [@ref:LABEL:imcvbcs2] (c)) captures near horizontal and vertical edges .", "The learnt transform for this cluster is also shown.", "This is a complex-valued transform.", "The real (Fig. [@ref:LABEL:imcvbcs2] (e)) and imaginary (Fig. [@ref:LABEL:imcvbcs2] (f)) parts of the transform display frequency like structures, and in particular contain horizontal and vertical features that were learnt to sparsify the corresponding edges better.", "\\newline In this example, the UNITE-MRI algorithm is able to group patches together according to the directionality of their edges, and it learns transforms in each cluster that are better suited to sparsify specific types of edges.", "Since UTMRI learns only a square transform, the learned transform is unable to sparsify the diverse features (edges) of the phantom image as well as the more adaptive and overcomplete UNITE-MRI transform.", "The reconstruction error maps shown later in Fig. [@ref:LABEL:im4bcsbb] show UNITE-MRI recovering the image edges better than UTMRI.", "\\newline </subsection> <subsection> <title> V-C Results and Comparisons </title> We now consider the images a-f in Fig. [@ref:LABEL:im1bcs] and simulate the performance of the proposed UTMRI and UNITE-MRI algorithms at various undersampling factors, and with Cartesian sampling or 2D random sampling of k-space.", "Table [@ref:LABEL:tab2bcs] lists the reconstruction PSNRs corresponding to the zero-filling, Sparse MRI, DLMRI, PBDWS, PANO, TLMRI, UTMRI, and UNITE-MRI reconstructions for various cases.", "\\newline The transform-based blind compressed sensing algorithms typically provide the best reconstruction PSNRs in Table [@ref:LABEL:tab2bcs] (analogous results were observed to usually hold with respect to the HFEN metric not shown in the table).", "Specifically, the UNITE-MRI method provides an improvement of 3.2 dB in reconstruction PSNR on average in Table [@ref:LABEL:tab2bcs] over the recent partially adaptive PBDWS method, and an average improvement of 1.7 dB over the recent non-local patch similarity-based PANO method.", "It also provides significant improvements in reconstruction quality over the non-adaptive Sparse MRI method, and an average improvement of 4.6 dB over the synthesis dictionary-based DLMRI method."]], "target": "(Unlike the proposed transform-based schemes, the overcomplete dictionary-based DLMRI algorithm lacks convergence guarantees, and the NP-hard synthesis sparse coding in DLMRI lacks closed-form solutions.) The single transform-based TLMRI or UTMRI methods perform better than prior methods in most cases in Table . TLMRI provides slightly better (about 0.2 dB better) PSNRs than UTMRI on the average. Importantly, the union of transforms based UNITE-MRI provides 1 dB better reconstruction PSNR on the average compared to the single transform based UTMRI. This indicates that the union of transforms (or OCTOBOS ) model is a better match for the characteristics of the MR images than a single transform model for all image patches."}, {"tabular": ["  Problem  &  $ n $  &  $ \\ell $  &  oASIS  &  Random  &  Leverage scores  &  $ K $ -means  &  Farahat ", " Two Moons  &  2,000  &  450  &  $ 1.00e{-6} $ (1.20)  &  $ 2.14e{-3} $ (0.01)  &  $ 9.46e{-4} $ (3.96)  &  $ 1.05e{-3} $ (0.38)  &  $ 8.31e{-7} $ (19.7) ", "  &    &    &  $ 1.10e{-6} $ (1.16)  &  $ 1.22e{-2} $ (0.01)  &  $ 7.45e{-3} $ (4.00)  &  $ 5.49e{-3} $ (1.21)  &  $ 1.11e{-6} $ (19.6) ", " Abalone  &  4,177  &  450  &  $ 1.23e{-6} $ (2.60)  &  $ 2.65e{-3} $ (0.01)  &  $ 5.23e{-4} $ (35.8)  &  $ 1.73e{-3} $ (0.84)  &  $ 2.85e{-7} $ (64.8) ", "  &    &    &  $ 1.62e{-6} $ (2.51)  &  $ 3.76e{-1} $ (0.01)  &  $ 1.47e{-1} $ (35.9)  &  $ 3.24e{-1} $ (8.26)  &  $ 5.61e{-7} $ (64.7) ", " BORG  &  7,680  &  450  &  $ 5.30e{-2} $ (4.71)  &  $ 3.90e{-1} $ (0.01)  &  $ 4.31e{-1} $ (252)  &  $ 8.89e{-2} $ (2.53)  &  $ 2.75e{-2} $ (176) ", "  &    &    &  $ 6.29e{-2} $ (4.73)  &  $ 3.90e{-1} $ (0.01)  &  $ 4.23e{-1} $ (244)  &  $ 7.70e{-2} $ (48.3)  &  $ 2.78e{-2} $ (174)  "], "ref_sec": [["<section> <title> I Introduction </title>  <subsection> <title> I-A Kernel Matrix Approximation </title> Many machine learning and data analysis frameworks for classification, clustering, and dimensionality reduction require the formation of kernel matrices that contain the pairwise \u201csimilarities\u201d or distances between signals in a collection of data.", "For instance, kernel methods for classification [@bib:Williams01usingthe] , nonlinear dimensionality reduction [@bib:Coifman20065,tenenbaum_global_2000] , and spectral clustering [@bib:Shi:2000:NCI:351581.351611] all require computing and storing an $ n\\times n $ kernel matrix, where $ n $ is the number of examples (points) in the dataset.", "\\newline As the size $ n $ of the dataset grows, the computation and storage of kernel matrices becomes increasingly difficult.", "For instance, explicitly storing a kernel matrix with dimension $ n=10^{5} $ using IEEE standard binary64 requires $ 80 $ gigabytes of memory [@bib:4610935] .", "To extend kernel-based methods to extremely large $ n $ , a host of methods have focused on sampling a small subset of columns from the kernel matrix and then computing a low-rank approximation of the matrix using some flavor of the Nystr\u00f6m method [@bib:journals/jmlr/DrineasM05] .", "\\newline An accurate low-rank approximation determines and keeps only the most important dimensions in the column space of the matrix.", "In doing so, it captures the majority of the information in a matrix with a smaller ambient dimensional space.", "In the kernel matrix setting, the size of the dataset is larger than its dimensionality.", "This results in a kernel matrix with low-dimensional structure lying in a large ambient space.", "A low-rank approximation, then, can capture all of the information in the kernel matrix without requiring $ n^{2} $ entries.", "\\newline Nystr\u00f6m methods are one example of a general approach to computing low-rank matrix approximation from a subset of rows and/or columns of the matrix [@bib:citeulike:12704915] .", "Choosing a relevant subset is broadly referred to as column subset selection (CSS).", "CSS methods have been applied successfully in applications ranging from image segmentation [@bib:Fowlkes:2004:SGU:960255.960312] to genomic analysis [@bib:pmid17151345] and matrix factorization [@bib:MackeyTJ11] .", "\\newline The success of CSS-based approaches for matrix approximation depends strongly on the columns chosen to approximate the range space of the matrix.", "Intuitively, uniform random sampling of the columns will provide an accurate approximation when the columns of the kernel matrix are independently and identically distributed.", "However, when the underlying data are non-uniformly distributed or even clustered, uniform sampling requires extra column draws to ensure an accurate approximation.", "In these settings, it has been shown in both theory [@bib:deshpande2006matrix] and practice [@bib:journals/jmlr/FarahatGK11] that adaptive sampling methods provide accurate approximations of low-rank kernel matrices with far fewer samples than uniform random sampling.", "In this way, we say that adaptive methods are more efficient than uniform random sampling.", "\\newline Current adaptive sampling methods take advantage of the structure of the kernel matrix.", "Random adaptive sampling methods use the entries of the kernel matrix to compute a weighted probability distribution over the column indices.", "The distribution improves the chances of sampling relevant columns.", "Deterministic adaptive sampling methods use the already-sampled columns to compute a residual over the kernel matrix, from which a new column index is selected.", "\\newline The downside of current adaptive methods is their computational burden.", "Adaptive methods do not scale well to large problem sizes for two reasons.", "First, existing adaptive methods inspect the entire kernel matrix to determine which columns to select.", "For extremely large datasets, both forming and storing an explicit representation of the kernel matrix is intractable.", "Second, existing adaptive methods require dense $ n\\times n $ matrix computations, even for sparse matrices that are otherwise easy to store because they have relatively few non-zeros elements.", "For these reasons, current adaptive methods cannot be applied to extremely large collections of data [@bib:JMLR:v14:talwalkar13a] .", "\\newline </subsection> <subsection> <title> I-B Contributions </title> For adaptive sampling methods, it is not generally possible to determine the best columns to select from a kernel matrix without explicitly forming all of the candidate columns.", "However, as the kernel matrix is symmetric, a small sample of columns provides partial information about the remaining un-sampled columns.", "Based upon this observation, we introduce a principled adaptive sampling scheme called Accelerated Sequential Incoherence Selection (oASIS) that predicts the most informative columns to sample from a kernel matrix without forming the entire matrix.", "oASIS has several advantages over existing adaptive sampling schemes.", "\\newline <list> \\ oASIS does not require a fully precomputed kernel matrix.", "It can operate solely on the data, using the kernel function.", "This is because oASIS selects the column to be included in the approximation before explicitly computing it.", "For this reason, only the submatrix of sampled columns must be computed/stored.", "\\newline \\ \\ oASIS\u2019s total runtime scales linearly with the matrix dimension $ n, $ making it practical for large datasets.", "For this reason, oASIS is orders of magnitude faster than other adaptive methods that have $ \\mathcal{O}(n^{2}) $ or higher runtime.", "\\newline \\ \\ oASIS can exactly recover the rank $ r $ kernel matrix in $ r $ steps.", "\\newline \\ \\ oASIS preserves zero entries in sampled columns of sparse kernel matrices, enabling greater efficiency in these cases.", "This is in contrast to conventional greedy methods that require dense $ n\\times n $ matrix computations that \u201cfill in\u201d the zero entries in a matrix [@bib:journals/jmlr/FarahatGK11] .", "\\newline \\ </list> oASIS provides a tractable solution for approximating extremely large kernel matrices where other adaptive methods simply cannot be applied [@bib:SmoSch00,journals/jmlr/FarahatGK11,conf/icml/GittensM13] .", "In a range of numerical experiments below, we demonstrate that oASIS provides accuracy comparable to the best existing adaptive methods [@bib:SmoSch00,journals/jmlr/FarahatGK11,conf/icml/GittensM13,Zhang:2008:INL:1390156.1390311] with dramatically reduced complexity and memory requirements.", "\\newline While oASIS is useful for kernel matrices, its usefulness becomes more pronounced when the dataset is so large that it can no longer be held entirely in memory.", "This is because we can parallelize oASIS by splitting up the dataset and the working matrices among various processors.", "We introduce an algorithm called oASIS-P that efficiently distributes the data and the submatrices used in approximation, as well as the computation and selection of a new column to add to the approximation.", "oASIS-P is highly scalable as it incurs minimum communication overhead in between the parallel computing nodes.", "We implemented oASIS-P using a standard message passing interface (MPI) [@bib:gabriel04:open_mpi] .", "With oASIS-P, we can perform the Nystr\u00f6m approximation in a data size regime where even the simplest algorithms become difficult to run.", "\\newline In addition, we study oASIS from a theoretical perspective and propose conditions under which oASIS will exactly recover a rank- $ r $ kernel matrix in $ r $ steps.", "Other greedy methods do not have this guarantee.", "oASIS can perform this recovery because it chooses linearly independent columns at each step, which enables efficient sampling.", "Random selection methods do not necessarily choose independent columns, and can choose redundant columns, resulting in inefficient sampling.", "\\newline This paper is organized as follows.", "In Section [@ref:LABEL:sec:bkgnd] , we introduce the Nystr\u00f6m method, survey existing sampling methods, and describe important applications of kernel matrices in classification, clustering, and dimensionality reduction.", "In Section [@ref:LABEL:sec:oASIS] , we describe the motivation behind our initial column sampling method, called Sequential Incoherence Selection or SIS.", "We then describe the accelerated version of SIS, or oASIS.", "We then describe a parallel version of oASIS, which we call oASIS-P. In Section [@ref:LABEL:sec:theory] , we provide theory determining the conditions under which oASIS will exactly recover the kernel matrix. And in Section [@ref:LABEL:sec:Experiments] , we use multiple synthetic and real datasets to demonstrate the efficacy of oASIS for approximating kernel matrices and diffusion distances for nonlinear dimensionality reduction [@bib:Coifman20065] .", "\\newline </subsection>  </section>"], ["<section> <title> II Background </title>  To set the stage, we will quickly describe a few common kernel and distance matrices used in machine learning.", "Following this, we introduce the Nystr\u00f6m method and describe its variants and applications.", "\\newline <subsection> <title> II-A Notation </title> We write matrices $ G $ and vectors $ x $ in upper and lowercase script, respectively.", "We use $ A^{\\dagger} $ to denote the Moore-Penrose pseudo-inverse of $ A $ .", "We represent the element-wise product of matrices $ A $ and $ B $ as $ A\\circ B. $ $ \\operatorname*{colsum}(A) $ denotes a row vector, where the $ i^{th} $ entry contains the sum of the $ i^{th} $ column of $ A. $ When describing algorithms, we use \u201cMatlab\u201d style indexing in which $ G(i,j) $ denotes the $ (i,j) $ entry of the matrix $ G $ and $ G(:,j) $ denotes its $ j^{th} $ column.", "We use $ \\Lambda $ to denote a collection of chosen indices of the columns of a matrix $ A $ ; $ {\\Lambda^{c}} $ is the set of indices not chosen.", "For example, $ A_{\\Lambda} $ are all of the columns of $ A $ indexed by the set $ \\Lambda $ .", "\\newline </subsection> <subsection> <title> II-B Kernel Matrices and their Applications </title> Kernel methods are widely used in classification and clustering to \u201clift\u201d datasets into a high-dimensional space where the classes of data are linearly separable.", "This is done with the help of a kernel function $ k(\\cdot,\\cdot) $ which measures pairwise similarities between points in the lifted space.", "An $ n\\times n $ kernel matrix is then formed from $ n $ data points $ \\{z_{i}\\}_{i=1}^{n} $ with $ G(i,j)=k(z_{i},z_{j}), $ where high magnitude entries of $ G $ correspond to pairs of similar data points.", "The singular vectors of $ G $ are then computed and used to map the data back into a low-dimensional space where the data is still linearly separable.", "The kernel trick is widely used in classification and clustering [@bib:Williams01usingthe,Fowlkes:2004:SGU:960255.960312,Shi:2000:NCI:351581.351611,hastie_09_elements-of.statistical-learning,Simard:1992:EPR:645753.668226,Filippone:2008:SKS:1284917.1285173,KreBel:1999:PCS:299094.299108,Hastie:1998:CPC:302528.302744] \\newline Manifold learning methods, including diffusion maps [@bib:Coifman20065] and Laplacian eigenmaps [@bib:LEM_NC_03] , map high-dimensional data that lie on nonlinear but low-dimensional manifolds onto linear low-dimensional spaces.", "These methods use a kernel matrix that encodes the geodesic distance between pairs of points \u2014 the shortest path between two points along the surface of the underlying manifold.", "High-dimensional data are mapped into a low-dimensional space using the left singular vectors of $ G $ , and thus a singular value decomposition (SVD) of $ G $ is required.", "For a review of dimensionality reduction using geodesic and diffusion distance kernel matrices, see [@bib:DBLP:journals/spm/TalmonCGC13,JMLR:v14:talwalkar13a] .", "\\newline </subsection> <subsection> <title> II-C The Nystr\u00f6m Method </title> Williams and Seeger [@bib:Williams01usingthe] first presented the Nystr\u00f6m method to improve the speed of kernel-based methods for classification.", "The method approximates a low-rank symmetric positive semidefinite (PSD) matrix using a subset of its columns.", "\\newline Consider an $ n\\times n $ PSD matrix $ G $ of rank $ r. $ For all PSD matrices $ G $ , there exists a matrix $ X\\in\\mathbb{R}^{r\\times n} $ such that $ G=X^{T}X $ .", "Suppose we choose a set $ \\Lambda $ of $ k\\leq r $ indices and then sample those $ \\Lambda $ columns from $ G $ as $ C_{k} $ , $ C_{k}\\in\\mathbb{R}^{n\\times k} $ .", "We collect the $ k $ indices into a set $ \\Lambda $ .", "The sampling forms a partition of $ X=\\begin{bmatrix}X_{\\Lambda}&X_{\\Lambda^{c}}\\end{bmatrix} $ .", "We can then express $ G $ as \\newline <equation> $ G=\\begin{bmatrix}X_{\\Lambda}^{T}\\\\ X_{\\Lambda^{c}}^{T}\\end{bmatrix}\\begin{bmatrix}X_{\\Lambda}&X_{\\Lambda^{c}}\\end% {bmatrix}=\\begin{bmatrix}W_{k}&X_{\\Lambda}^{T}X_{\\Lambda^{c}}\\\\ X_{\\Lambda^{c}}^{T}X_{\\Lambda}&X_{\\Lambda^{c}}^{T}X_{\\Lambda^{c}}\\end{bmatrix}, $ </equation> where $ C_{k}=\\begin{bmatrix}W_{k}&X_{\\Lambda^{c}}^{T}X_{\\Lambda}\\end{bmatrix}^{T} $ consists of the $ n\\times k $ sampled columns of $ G $ , and $ W_{k}=X_{\\Lambda}^{T}X_{\\Lambda} $ is the $ k\\times k $ symmetric matrix containing the row entries of the sampled columns at the indices of the sampled columns.", "Note that without loss of generality we can permute the rows and columns of $ G $ so that the columns in $ C_{k} $ are the first $ k $ columns of $ G $ .", "The Nystr\u00f6m approximation of $ G $ is defined as \\newline <equation> $ G\\approx\\widetilde{G}_{k}=C_{k}W^{\\dagger}_{k}C_{k}^{T}. $ </equation> Note that neither $ X $ nor any partition of $ X $ is found explicitly, but that the $ \\widetilde{G}_{k} $ is found through the set of sampled columns $ C_{k} $ and the respective rows $ W_{k} $ .", "\\newline An approximate SVD of $ G $ can be obtained from the SVD of $ W_{k}, $ which is written as $ W_{k}=U_{W}\\Sigma_{W}U_{W}^{T}. $ The singular values $ {\\widetilde{\\Sigma}} $ of the approximation $ \\widetilde{G}_{k}=\\widetilde{U}\\widetilde{\\Sigma}\\widetilde{U}^{T} $ are given by $ (n/k)\\Sigma_{W} $ [@bib:Kumar:2012:SMN:2188385.2343678] , and the singular vectors are given by \\newline <equation> $ \\widetilde{U}=\\sqrt{\\frac{k}{n}}C_{k}U_{W}\\Sigma_{W}^{-1}. $ </equation> Since $ W_{k} $ is $ k\\times k, $ this computation is much faster than computing the full $ n\\times n $ SVD of $ G $ .", "The complexity of the SVD step reduces from $ \\mathcal{O}(n^{3}) $ to $ \\mathcal{O}(k^{3}) $ with $ k\\leq r\\ll n $ .", "\\newline Note that the Nystr\u00f6m method enables the singular vectors of $ G, $ and thus a low dimensional embedding of the data, to be computed from only a subset of its columns.", "When $ n $ is large, it is desirable to form only a subset of the columns of $ G $ rather than calculate and store all $ n(n-1)/2 $ pairwise kernel distances.", "\\newline </subsection> <subsection> <title> II-D Column Sampling Methods </title> We now describe the four main categories of column selection methods.", "We compare oASIS with the methods listed below, as together they cover all of the types of sampling used currently in Nystr\u00f6m approximation.", "\\newline <subsubsection> <title> II-D1 Uniform Random Sampling </title> Early work on the Nystr\u00f6m method focused on random column sampling methods [@bib:Williams01usingthe] .", "Theoretical bounds on the accuracy of a rank- $ k $ approximation to $ G $ after sampling a sufficient number of columns have been delveloped for various norms [@bib:conf/icml/GittensM13] .", "\\newline Uniform random sampling is an appealing method as it is computationally fast.", "However, the accuracy of a matrix approximation depends directly on the specific columns sampled.", "This method does not take advantage of the structure inherent in the kernel matrix, leading to redundant sampling and larger approximation error.", "Improvements on this sampling method can be made by weighting the probability distribution used for the column draw, to increase the chance of selecting relevant columns.", "\\newline </subsubsection> <subsubsection> <title> II-D2 Non-deterministic Adaptive Sampling </title> Leverage scores are a recent method for computing the distribution over the column draw [@bib:conf/icml/GittensM13] .", "Given the rank- $ k $ SVD of $ G_{k}=U_{k}\\Sigma_{k}U_{k}^{T} $ , the scores are computed as $ s_{j}=\\|U_{k}(j,:)\\|^{2} $ , and each column is selected with probability proportional to its score.", "This method provides accurate approximations by sampling more relevant columns.", "However, Leverage scores require the low-rank approximate SVD of $ G $ to be precomputed at expensive $ \\mathcal{O}(n^{3}) $ cost.", "There are fast approximations available for finding the first few singular vectors and values of $ G $ [@bib:DBLP:journals/jmlr/DrineasMMW12] .", "Regardless, $ G $ must be completely formed and stored before it is approximated.", "\\newline </subsubsection> <subsubsection> <title> II-D3 Deterministic Adaptive Sampling </title> Early deterministic adaptive methods [@bib:SmoSch00] use an exhaustive search to find columns that minimize the Frobenius norm error $ \\|G-\\widetilde{G}_{k}\\|_{F} $ .", "While accurate, this method also requires a precomputed $ G $ , and has combinatorial complexity.", "A more efficient adaptive scheme by Farahat [@bib:journals/jmlr/FarahatGK11] builds a Nystr\u00f6m approximation by selecting columns sequentially using a matrix of \u201cresiduals.", "\u201d At each stage of the method, the column with the largest residual is selected, and the residual matrix is updated to reflect its contribution.", "While accurate, the method also requires a precomputed $ G $ , and the cost of updating the residual matrix is $ \\mathcal{O}(n^{2}) $ per iteration.", "\\newline The residual criterion is related to the adaptive probability distribution calculated by Deshpande [@bib:deshpande2006matrix] .", "After a sufficient number of columns are chosen, an orthogonalization step obtains a rank- $ k $ approximation of $ \\widetilde{G}_{k} $ .", "\\newline </subsubsection> <subsubsection> <title> II-D4 K -means Nystr\u00f6m </title> Instead of approximating $ G $ with direct column sampling, an approximation can be made from representative data points found with a $ K $ -means algorithm.", "A dataset consisting of clouds of points clustering around $ K $ centroids can be described by finding the locations of the centroids.", "Each datapoint is then remapped into the eigenspace of the centroids.", "This method was first described by Zhang [@bib:Zhang:2008:INL:1390156.1390311] .", "Since the computed centroids do not exist in the dataset, the method does not directly sample columns, but remaps them onto a rank- $ K $ space.", "Once the solution to the $ K $ -means is found, the remapping is $ \\mathcal{O}(\\ell n) $ .", "While finding an exact solution to $ K $ -means is NP-hard, generally $ K $ -means will converge in $ \\mathcal{O}(n^{2}) $ time.", "The resulting $ \\widetilde{G} $ can not be formed from the columns of $ G $ , and so has no space saving representation.", "\\newline In a survey of methods by Kumar [@bib:Kumar:2012:SMN:2188385.2343678] , $ K $ -means was found to be the state-of-the-art approximation method compared to previous sampling methods such as Incomplete Cholesky Decomposition [@bib:Fine01efficientsvm] , Sparse Matrix Greedy Approximation [@bib:SmoSch00] , and Kumar\u2019s Adaptive Partial method derived from Deshpande\u2019s Adaptive Sampling method [@bib:deshpande2006matrix] .", "For this reason, in lieu of comparisons with many different adaptive sampling techniques we can compare our results directly with $ K $ -means.", "For our experiments, we used the same code as provided in [@bib:Zhang:2008:INL:1390156.1390311] , with parameters used in both [@bib:Zhang:2008:INL:1390156.1390311] and [@bib:Kumar:2012:SMN:2188385.2343678] .", "\\newline </subsubsection> </subsection> <subsection> <title> II-E Finding Low-Dimensional Structure </title> In addition to using CSS for low-rank kernel approximation, column selection approaches have also been used to find important data points and in turn, reveal low-dimensional structure in data [@bib:Mahoney20012009,journals/siamsc/ChengGMR05] .", "Recently, it was shown in [@bib:Dyer2015SEED] that oASIS can be used to select representative examples from large datasets in order to enable clustering and dimensionality reduction.", "This method, called Sparse Self-Expressive Decomposition (SEED), consists of two main steps.", "First, oASIS is used to select data points for a dictionary.", "Second, all of the data is then represented by a sparse combination of the points in the dictionary using Orthogonal Matching Pursuit [@bib:davisOMP,rubinstein2008efficient] .", "The sparsity patterns found in the representations can be used for for clustering, denoising, or classification.", "SEED\u2019s ability to properly describe data hinges on the selection of data points used for the dictionary.", "oASIS is able to efficiently sample good points to use for this task, compared to other adaptive sampling methods.", "A full treatment of SEED is can be found in [@bib:Dyer2015SEED] .", "\\newline </subsection>  </section>"], ["<section> <title> III Accelerated Sequential Incoherence Selection (oASIS) </title>  In this section, we introduce oASIS, a new adaptive sampling method for column subset selection.", "We also introduce a parallel version called oASIS-P, and we analyze the complexity of both.", "\\newline <subsection> <title> III-A Sequential Incoherence Selection (SIS) </title> We now address the question of how to build a Nystr\u00f6m approximation by sequentially choosing columns from $ G. $ Suppose we have already selected $ k $ columns from $ G $ and computed a Nystr\u00f6m approximation $ \\widetilde{G}_{k}. $ Our goal is to select a new column that improves the approximation.", "If a candidate column lies in the span of the columns that we have already sampled, then adding this column has no effect on $ \\|G-\\widetilde{G}_{k}\\| $ .", "Ideally, we would like to quantify how much each candidate column will change the existing approximation and select the column that will produce the most significant impact.", "Since an ideal column does not lie in the span of the columns that have been selected, we say that this column should be incoherent with those already selected.", "\\newline We can develop a criteria for finding this new, incoherent column of $ G $ as follows.", "Consider a PSD matrix $ G $ .", "Recall that any such $ G $ can be written as $ X^{T}X $ , where $ X $ contains $ n $ points in $ r $ dimensions.", "Given an index set $ \\Lambda $ of $ k $ columns we can form a partition $ X=\\begin{bmatrix}X_{\\Lambda}&X_{\\Lambda^{c}}\\end{bmatrix} $ , and can collect the $ k $ selected columns from $ G $ into a matrix $ {C_{k}=G_{\\Lambda}=\\begin{bmatrix}W_{k}&X_{\\Lambda^{c}}^{T}X_{\\Lambda}\\end{% bmatrix}^{T}} $ .", "To improve the approximation $ \\widetilde{G}_{k} $ , we select the best new column from $ G $ , append it to $ C_{k} $ , and compute a new $ \\widetilde{G}_{k+1} $ .", "The best new column index $ i\\in{\\Lambda^{c}} $ in $ G $ directly corresponds to the index of the column $ x_{i} $ that lies farthest from the span of $ X_{\\Lambda} $ .", "This column $ x_{i} $ satisfies \\newline <equation> $ \\operatorname*{arg\\,max}_{i\\in{\\Lambda^{c}}}{\\|(I-P_{\\Lambda})x_{i}\\|_{2}^{2}}, $ </equation> where $ I $ is the identity matrix and $ P_{\\Lambda}=X_{\\Lambda}X_{\\Lambda}^{\\dagger} $ is an orthogonal projection onto the span of the $ k $ columns in $ X $ that have already been selected.", "Provided that the columns in $ X_{\\Lambda} $ are linearly independent, we can expand ( [@ref:LABEL:bestinspan2] ) as \\newline <equation> $ \\operatorname*{arg\\,max}_{i\\in{\\Lambda^{c}}}{x_{i}^{T}x_{i}-x_{i}^{T}X_{% \\Lambda}(X_{\\Lambda}^{T}X_{\\Lambda})^{-1}X_{\\Lambda}^{T}x_{i}}. $ </equation> \\newline Even though $ X $ is not known explicitly, ( [@ref:", "LABEL:bestinspan3] ) can be evaluated based upon knowledge of $ C_{k} $ and $ \\operatorname*{diag}(G) $ .", "The first term of the expression in ( [@ref:LABEL:bestinspan3] ) is the diagonal entry $ i $ of $ G $ , which we denote as $ d_{i} $ .", "The second term can be written as $ b_{i}^{T}W_{k}^{^{-1}}b_{i} $ , where $ b_{i}^{T}=x_{i}^{T}X_{\\Lambda} $ is one of the $ n-k $ rows of $ C_{k} $ indexed by $ {\\Lambda^{c}} $ , and $ W_{k} $ is comprised of the $ k $ rows of $ C_{k} $ indexed by $ \\Lambda $ .", "When $ X_{\\Lambda} $ contains linearly dependent columns, we replace $ W_{k}^{-1} $ with $ W_{k}^{\\dagger} $ .", "Therefore, we can iteratively select columns to sample for the approximation without precomputing the entire kernel matrix $ G $ , as shown in Figure [@ref:LABEL:fig:factorization] .", "This sets oASIS apart from all other adaptive methods, as discussed in Sections [@ref:LABEL:sss:ndas] and [@ref:LABEL:sss:dkm] .", "\\newline With the evaluation of our criteria now possible, we develop the following sampling method for sequential incoherent selection (SIS).", "We assume that the process has been seeded with a small set $ \\Lambda $ of $ k_{0} $ column indices chosen at random.", "Columns are then selected to be included in the approximation as follows: \\newline <list> \\ Let $ k=|\\Lambda| $ .", "Collect the columns of $ G $ indexed by $ \\Lambda $ as $ C_{k} $ .", "Form $ W_{k}^{-1} $ from the rows of $ C_{k} $ indexed by $ \\Lambda $ .", "\\newline \\ \\ Let $ b_{i}^{T} $ denote row $ i $ of $ C_{k} $ , and let $ d_{i} $ denote element $ i $ of $ \\operatorname*{diag}(G) $ .", "For each unselected column $ i\\in{\\Lambda^{c}} $ , calculate \\newline <equation> $ \\Delta_{i}=d_{i}-b_{i}^{T}W_{k}^{-1}b_{i}. $ </equation> \\newline \\ \\ Select the column that maximizes $ |\\Delta_{i}| $ and set $ {\\Lambda\\leftarrow\\Lambda\\cup\\{i\\}} $ .", "\\newline \\ \\ If the selected value of $ |\\Delta_{i}| $ is smaller than a user set threshold, then terminate.", "Otherwise, return to Step 1.", "\\newline \\ </list> \\newline </subsection> <subsection> <title> III-B oASIS </title> A naive implementation of SIS in Section [@ref:LABEL:section:ma] is inefficient, because each step requires a matrix inversion to form $ W_{k}^{-1} $ in addition to calculating the errors $ \\Delta_{i}. $ Fortunately, both of these calculations can be performed efficiently by updating the results from the previous step using block matrix inversion formulas.", "We dub this new method oASIS.", "\\newline We first consider the calculation of $ W_{k+1}^{-1} $ after a new column is added to the approximation made from $ k $ columns.", "We assume throughout the rest of this section that $ W_{k+1} $ is invertible and thus $ W_{k+1}^{\\dagger}=W_{k+1}^{-1}. $ We show that our column selection rule guarantees the invertibility of $ W_{k} $ in Section [@ref:LABEL:sec:guarantees] .", "Let $ b $ denote the first $ k $ entries of the new column, $ d $ denote the relevant element of $ \\operatorname*{diag}(G) $ , and $ \\Delta_{k+1}=d-b^{T}W_{k}^{-1}b $ .", "Using a block inversion formula, we obtain \\newline <equationgroup> <equation> $  W_{k+1}^{-1}=\\begin{bmatrix}W_{k}&b\\\\ b^{T}&d\\end{bmatrix}^{-1}=\\begin{bmatrix}W^{-1}_{k}+sqq^{T}&-sq\\\\ -sq^{T}&s\\end{bmatrix}, $ $  W_{k+1}^{-1}=\\begin{bmatrix}W_{k}&b\\\\ b^{T}&d\\end{bmatrix}^{-1}= $ $ \\begin{bmatrix}W^{-1}_{k}+sqq^{T}&-sq\\\\ -sq^{T}&s\\end{bmatrix}, $ </equation> </equationgroup> where $ s=(d-b^{T}W^{-1}_{k}b)^{-1}=\\Delta_{k+1}^{-1} $ is the (scalar valued) Schur complement and $ q=W^{-1}_{k}b $ is a column vector.", "This update formula enables $ W_{k+1}^{-1} $ to be formed by updating $ W_{k}^{-1} $ and only requires inexpensive vector-vector multiplication.", "Note that $ W_{k+1} $ is invertible as long as $ \\Delta_{k+1} $ is non-zero, which is guaranteed since the algorithm terminates if $ \\Delta_{k+1}=0 $ , in which case our approximation is exact.", "\\newline Now consider the calculation of $ \\Delta_{i}=d_{i}-b_{i}^{T}W_{k}^{\\dagger}b_{i} $ for all candidate columns $ i. $ Note that $ C_{k}^{T}=[b_{1},b_{2},\\cdots,b_{n}].", "$ We can evaluate all $ b_{i}^{T}W_{k}^{\\dagger}b_{i} $ simultaneously by computing the entry-wise product of $ C_{k} $ with the matrix $ R_{k}:=W^{-1}_{k}C_{k}^{T} $ and then summing the resulting columns.", "If we have already formed $ C_{k} $ and $ R_{k} $ , then the matrix $ R_{k+1}=W^{-1}_{k+1}C_{k+1}^{T} $ needed on the next iteration is obtained by applying ( [@ref:LABEL:update1] ) to $ C_{k+1}^{T} $ to obtain \\newline <equationgroup> <equation> $  R_{k+1}=W^{-1}_{k+1}C^{T}_{k+1}=W^{-1}_{k+1}\\begin{bmatrix}C^{T}% _{k}\\\\ c_{k+1}^{T}\\end{bmatrix} $ $  R_{k+1} $ $ =W^{-1}_{k+1}C^{T}_{k+1}=W^{-1}_{k+1}\\begin{bmatrix}C^{T}_{k}\\\\ c_{k+1}^{T}\\end{bmatrix} $ </equation> <equation> $ =\\begin{bmatrix}R_{k}+sq(q^{T}C^{T}_{k}-c^{T}_{k+1})\\\\ s(-q^{T}C^{T}_{k}+c^{T}_{k+1})\\end{bmatrix}. $ $ =\\begin{bmatrix}R_{k}+sq(q^{T}C^{T}_{k}-c^{T}_{k+1})\\\\ s(-q^{T}C^{T}_{k}+c^{T}_{k+1})\\end{bmatrix}. $ </equation> </equationgroup> \\newline Equation ( [@ref:LABEL:update2] ) forms $ R_{k+1} $ by updating the matrix $ R_{k} $ from the previous iteration.", "The update requires only matrix-vector and vector-vector products.", "The application of this fast update rule to the method described in Section [@ref:LABEL:section:ma] yields oASIS, detailed in Figure [@ref:LABEL:alg:oasis] .", "\\newline oASIS can be initialized with a small random subset of $ k_{0} $ starting columns from $ G. $ Next, the starting matrices $ C_{k}, $ $ W^{-1}_{k} $ and $ R_{k}=W^{-1}_{k}C^{T}_{k} $ are formed.", "On each iteration of the algorithm, the vector of Schur complements $ \\Delta $ is formed by computing \\newline <equation> $ \\Delta=d-\\operatorname*{colsum}(C_{k}\\circ R_{k}).", "$ </equation> Next, the largest entry in $ \\Delta $ is found, and its index is used to select the next column from $ G. $ The update formulas ( [@ref:LABEL:update1] ) and ( [@ref:LABEL:update2] ) are then used to form the matrices $ W^{-1}_{k+1} $ and $ R_{k+1} $ required for the next iteration.", "\\newline </subsection> <subsection> <title> III-C Parallel oASIS </title> For the case of kernel matrices $ G $ generated from a dataset $ \\{z_{i}\\}_{i=1}^{n} $ , oASIS does not need to explicitly store $ G $ .", "Therefore, oASIS saves time, as computing the full $ G $ is expensive.", "oASIS also saves space, as the full $ G $ increases quadratically with $ n $ .", "However, the dataset may be itself very difficult to store due to size.", "In addition, oASIS requires space to build $ C $ , $ W^{-1} $ , and $ R $ .", "In total, oASIS requires $ \\mathcal{O}(mn+\\ell^{2}+2\\ell n) $ of memory.", "In cases where dataset is too large to fit in memory, the matrix operations for oASIS can be distributed among $ p $ separate processor nodes.", "We begin by arranging the dataset columnwise into a matrix $ Z $ .", "Each node stores a submatrix $ Z_{(i)} $ consisting of $ n/p $ columns of $ Z $ , a copy of $ W^{-1} $ , and the column entries of $ C_{k} $ and $ R_{k} $ corresponding to the results of the kernel function over the entries in $ Z_{(i)} $ with the entries in $ Z_{\\Lambda} $ .", "When a new column index $ i $ is selected, the node storing column vector $ z_{i} $ is found and the column is broadcast to all of the nodes.", "Each node can then calculate the appropriate new entries as needed, as shown in Fig. [@ref:LABEL:fig:oASISPdiagram] .", "For each new column, the size of the communicated vector is the dimensionality of the data point, which is much smaller than the kernel matrix.", "Low communication overhead is an essential property of oASIS-P since, in distributed settings, the cost of internode communication can be larger than intranode computation.", "The memory requirements for over each node becomes $ \\mathcal{O}(mn/p+\\ell^{2}+2\\ell n/p+\\ell m) $ , which makes performing oASIS over datasets with millions of points tractable.", "\\newline We call this method Parallel oASIS, or oASIS-P, and it is detailed in Figure [@ref:LABEL:alg:oasispar] .", "The implementation makes use of the standard MPI commands $ Broadcast(data) $ (to send data from one node to every node) and $ Gather(variable) $ (to concatenate variables in each node into a single variable on one central node).", "\\newline </subsection>  </section>"], ["<section> <title> IV Properties and Applications of oASIS </title>  <subsection> <title> IV-A Theoretical Guarantees of oASIS </title> For general PSD matrices $ G $ of rank $ r $ , we can guarantee that oASIS will finish in $ r $ steps.", "We develop the theory needed to prove this guarantee in Sections [@ref:LABEL:sec:isp] and [@ref:LABEL:sec:emr] .", "When $ G $ is a Gram matrix, formed as $ G(i,j)={z_{i}}^{T}z_{j} $ , we can use the sample index set $ \\Lambda $ found with oASIS to make additional guarantees on approximating the dataset itself.", "We mention the guarantees briefly in Section [@ref:LABEL:sss:oasisgram] , and they are described fully in [@bib:Dyer2015SEED] .", "\\newline In Section [@ref:LABEL:sec:isp] , we show that oASIS will select linearly independent columns of $ G $ at each step.", "This becomes very useful in practice, as $ \\widetilde{G} $ is computed from the $ W^{\\dagger} $ , where $ W=X_{\\Lambda}^{T}X_{\\Lambda} $ .", "If the selected columns of $ G $ are not independent, then $ W $ is a singular matrix.", "By selecting linearly independent columns of $ G $ , oASIS can guarantee that $ W^{\\dagger}=W^{-1} $ , enabling time and space saving calculation of this element when computing $ \\widetilde{G} $ .", "We discuss this further in Section [@ref:LABEL:sss:othertheory] .", "\\newline <subsubsection> <title> IV-A1 Independent Selection Property of oASIS </title> Given a PSD matrix $ G=X^{T}X $ , $ {\\rm rank}(G)={\\rm rank}(X)=r $ .", "In Lemma [@ref:LABEL:thm:indep] below, we provide a sufficient condition that describes when oASIS will return a set of $ r $ linearly independent columns.", "This is a similar condition as that provided in [@bib:Dyer2015SEED] , although we provide an alternate proof.", "\\newline <theorem> Lemma 1 .", "At each step of Alg. [@ref:LABEL:alg:oasis] , the $ i^{th} $ column of the matrix $ G $ is linearly independent from the previously selected columns provided that $ \\Delta(i)>0 $ .", "\\newline </theorem> <proof> Proof: We prove this by construction of $ X_{\\Lambda} $ .", "Consider adding a new column $ x_{i} $ to $ X_{\\Lambda} $ with nonzero $ \\Delta(i)={\\|(I-P_{\\Lambda})x_{i}\\|_{2}^{2}} $ and $ i\\in{\\Lambda^{c}} $ .", "Then $ x_{i} $ is linearly independent of each column in $ X_{\\Lambda} $ , and so $ G_{k+1}=X^{T}x_{i} $ is linearly independent from any other $ G_{j}=X^{T}x_{j} $ .", "Therefore as long as $ \\Delta(i)>0 $ at each step, the column selected will be linearly independent from the previous columns selected.", "\u220e \\newline </proof> Remark.", "This result guarantees that oASIS will return a set of $ r $ linearly independent columns in $ r $ steps as long as the selection criterion $ \\Delta(i)\\neq 0 $ holds before exact reconstruction occurs.", "While the algorithm may terminate early if $ \\Delta(i)=0 $ before $ r $ columns have been selected, we have not observed this early termination in practice.", "\\newline </subsubsection> <subsubsection> <title> IV-A2 Exact Matrix Recovery </title> We now prove that when oASIS selects $ r $ columns from $ G $ , then $ \\widetilde{G}=G $ .", "\\newline <theorem> Theorem 1 .", "If oASIS chooses $ r $ columns from a PSD matrix $ G $ with $ {\\rm rank}(G)=r $ , the Nystr\u00f6m $ \\widetilde{G}=G $ .", "\\newline </theorem> <proof> Proof: As $ X $ is rank $ r $ , and oASIS has chosen $ r $ linearly independent columns, then at the next step all $ \\Delta(i)=0 $ as $ {\\|(I-P_{\\Lambda})x_{i}\\|_{2}^{2}}=0\\forall{i} $ .", "Therefore $ {\\|(I-X_{\\Lambda}X_{\\Lambda}{^{\\dagger}})x_{i}\\|_{2}^{2}}=0 $ , or $ {\\|X-X_{\\Lambda}X_{\\Lambda}{^{\\dagger}}X\\|_{F}}=0.", "$ $ X=\\begin{bmatrix}X_{\\Lambda}&X_{\\Lambda^{c}}\\end{bmatrix} $ , and therefore $ {\\|X_{\\Lambda^{c}}-X_{\\Lambda}X_{\\Lambda}{^{\\dagger}}X_{\\Lambda^{c}}\\|_{F}}=0 $ , or $ X_{\\Lambda^{c}}=X_{\\Lambda}X_{\\Lambda}{^{\\dagger}}X_{\\Lambda^{c}}. $ Expanding $ \\widetilde{G} $ in terms of $ X_{\\Lambda} $ and $ X_{\\Lambda^{c}} $ , \\newline <equationgroup> <equation> $ \\widetilde{G}=CW^{\\dagger}C^{T}=\\begin{bmatrix}X_{\\Lambda}^{T}X_{% \\Lambda}\\\\ X_{\\Lambda^{c}}^{T}X_{\\Lambda}\\end{bmatrix}\\begin{bmatrix}X_{\\Lambda}^{T}X_{% \\Lambda}\\end{bmatrix}^{\\dagger}\\begin{bmatrix}X_{\\Lambda}^{T}X_{\\Lambda}&X_{% \\Lambda}^{T}X_{\\Lambda^{c}}\\end{bmatrix} $ $ \\widetilde{G}=CW^{\\dagger}C^{T} $ $ =\\begin{bmatrix}X_{\\Lambda}^{T}X_{\\Lambda}\\\\ X_{\\Lambda^{c}}^{T}X_{\\Lambda}\\end{bmatrix}\\begin{bmatrix}X_{\\Lambda}^{T}X_{% \\Lambda}\\end{bmatrix}^{\\dagger}\\begin{bmatrix}X_{\\Lambda}^{T}X_{\\Lambda}&X_{% \\Lambda}^{T}X_{\\Lambda^{c}}\\end{bmatrix} $ </equation> <equation> $ =\\begin{bmatrix}X_{\\Lambda}^{T}X_{\\Lambda}&X_{\\Lambda}^{T}X_{% \\Lambda^{c}}\\\\ X_{\\Lambda^{c}}^{T}X_{\\Lambda}&X_{\\Lambda^{c}}^{T}X_{\\Lambda}(X_{\\Lambda}^{T}X% _{\\Lambda})^{\\dagger}X_{\\Lambda}^{T}X_{\\Lambda^{c}}\\end{bmatrix}. $ $ =\\begin{bmatrix}X_{\\Lambda}^{T}X_{\\Lambda}&X_{\\Lambda}^{T}X_{% \\Lambda^{c}}\\\\ X_{\\Lambda^{c}}^{T}X_{\\Lambda}&X_{\\Lambda^{c}}^{T}X_{\\Lambda}(X_{\\Lambda}^{T}X% _{\\Lambda})^{\\dagger}X_{\\Lambda}^{T}X_{\\Lambda^{c}}\\end{bmatrix}. $ </equation> </equationgroup> We examine the lower right block of this expansion as the others exactly match that of $ G $ in ( [@ref:LABEL:eq:original] ).", "\\newline By Lemma [@ref:LABEL:thm:indep] $ X_{\\Lambda} $ is full rank, and so \\newline <equationgroup> <equation> $  X_{\\Lambda^{c}}^{T}X_{\\Lambda}(X_{\\Lambda}^{T}X_{\\Lambda})^{% \\dagger}X_{\\Lambda}^{T}X_{\\Lambda^{c}}=X_{\\Lambda^{c}}^{T}X_{\\Lambda}(X_{% \\Lambda}^{T}X_{\\Lambda})^{-1}X_{\\Lambda}^{T}X_{\\Lambda^{c}} $ $  X_{\\Lambda^{c}}^{T}X_{\\Lambda}(X_{\\Lambda}^{T}X_{\\Lambda})^{% \\dagger}X_{\\Lambda}^{T}X_{\\Lambda^{c}} $ $ =X_{\\Lambda^{c}}^{T}X_{\\Lambda}(X_{\\Lambda}^{T}X_{\\Lambda})^{-1}X% _{\\Lambda}^{T}X_{\\Lambda^{c}} $ </equation> <equation> $ =X_{\\Lambda^{c}}^{T}(X_{\\Lambda}X_{\\Lambda}^{\\dagger})X_{\\Lambda^% {c}} $ $ =X_{\\Lambda^{c}}^{T}(X_{\\Lambda}X_{\\Lambda}^{\\dagger})X_{\\Lambda^% {c}} $ </equation> <equation> $ =X_{\\Lambda^{c}}^{T}X_{\\Lambda^{c}}. $ $ =X_{\\Lambda^{c}}^{T}X_{\\Lambda^{c}}. $ </equation> </equationgroup> Thus the expansion of $ \\widetilde{G} $ is equal to the expansion of $ G $ in ( [@ref:LABEL:eq:original] ).", "\u220e \\newline </proof> </subsubsection> <subsubsection> <title> IV-A3 Guarantees for oASIS when G is a Gram Matrix </title> When $ G $ is a Gram matrix, we can arrange the points in the dataset $ \\{z_{i}\\}_{i=1}^{n},z_{i}\\in\\mathbb{R}^{m} $ columnwise into a matrix $ Z $ .", "Then we can write $ G=Z^{T}Z $ , with $ Z $ of rank $ m $ .", "oASIS selects a set $ |\\Lambda|=m $ such that $ Z=P_{\\Lambda}(Z) $ exactly.", "This property is useful in solving a more general CSS problem than Nystr\u00f6m, precisely formulated as \\newline <equation> $ \\min_{|\\Lambda|=L}\\|Z-P_{\\Lambda}{Z}\\|_{F}, $ </equation> where $ Z $ is an $ m\\times n $ matrix.", "This problem has combinatorial complexity, and many of the selection schemes for Nystr\u00f6m arise from attempting to solve this more general problem.", "Indeed, the adaptive selection methods in [@bib:journals/jmlr/DrineasM05,deshpande2006matrix] , and others, can also apply to this problem.", "We have developed guarantees on oASIS\u2019s ability to exactly recover $ Z $ so that we can use the columns in $ Z_{\\Lambda} $ in developing a self-expressive decomposition of $ Z $ .", "Although a full treatment of SEED is described in [@bib:Dyer2015SEED] , we briefly describe this extension in Section [@ref:LABEL:ss:otherapps] .", "\\newline </subsubsection> <subsubsection> <title> IV-A4 Comparison with Other Theory </title> oASIS can guarantee exact matrix recovery in an information theoretically efficient number of steps.", "We show a synthetic example in Figure [@ref:LABEL:fig:exactrecovery] .", "Using a dataset consisting of points drawn from a $ 2D $ Gaussian distribution centered on $ (0,0) $ and points drawn from a $ 3D $ Gaussian distribution centered on $ (0,0,1) $ , we compute a PSD Gram matrix $ G $ with a resulting rank $ (G)=3 $ .", "oASIS selects columns linearly independent from previously selected columns at each step, increasing the rank of the approximation each time.", "This enables oASIS to use an iterative update of $ W^{-1} $ instead of computing $ W^{\\dagger} $ after all columns have been selected.", "At 3 steps, oASIS terminates, with $ \\widetilde{G}=G $ within machine tolerance.", "\\newline Random or adaptive random sampling techniques have theoretical guarantees that $ \\widetilde{G} $ will be close to a rank- $ k $ approximation of $ G $ after a certain number of iterations [@bib:conf/icml/GittensM13,journals/jmlr/DrineasM05] .", "However, the lack of guarantees on column selection make for redundant sampling.", "As an illustration, we include separate trials of uniform random sampling in Figure [@ref:LABEL:fig:exactrecovery] .", "Uniform random sampling frequently selects columns within the span of previously selected columns at each step, and as a result the approximation error is generally higher than oASIS.", "In cases of very large data, this becomes a practical concern in computing both $ C $ and $ W^{\\dagger} $ .", "\\newline </subsubsection> </subsection> <subsection> <title> IV-B Complexity of oASIS </title> The rate-limiting step of oASIS in Fig. [@ref:LABEL:alg:oasis] is the computation of $ R_{k+1} $ by updating $ R_{k}. $ Equation ( [@ref:LABEL:update2] ) enables this to be performed by sweeping over the entries of $ R_{k}, $ which has dimension $ k\\times n. $ The complexity of a single iteration is thus $ \\mathcal{O}(kn).", "$ If $ \\ell $ columns are sampled in total, then $ \\sum_{k=1}^{\\ell}kn=\\frac{1}{2}\\ell(\\ell+1)n $ entries must be updated.", "The resulting complexity of the entire oASIS algorithm is thus $ \\mathcal{O}(\\ell^{2}n).", "$ In practice, the number of sampled columns $ \\ell $ is much less than $ n. $ This makes oASIS considerably more efficient than adaptive methods such as Farahat\u2019s [@bib:journals/jmlr/FarahatGK11] , which requires the computation of $ n\\times n $ residual matrices at each stage resulting in $ \\mathcal{O}(\\ell n^{2}) $ complexity.", "oASIS is also more efficient than Leverage scores [@bib:conf/icml/GittensM13] , since the scores use an approximate SVD of $ G $ that requires $ \\mathcal{O}(n^{2}) $ computations over dense matrices.", "oASIS is about as efficient as $ K $ -means Nystr\u00f6m, with complexity $ \\mathcal{O}(\\ell n) $ .", "However, $ K $ -means does not select columns, and instead forms the full $ \\widetilde{G} $ from the low-dimensional remapping.", "As a result, while $ K $ -means is useful in Nystr\u00f6m approximation, it may not be as useful for more general CSS methods.", "oASIS, in contrast, can be used in more general CSS problems via the Gram matrix.", "\\newline If we only compare the speed in finding $ \\Lambda $ , oASIS is much slower than uniform random sampling, with its $ \\mathcal{O}(1) $ sampling speed. But oASIS also computes $ C $ and $ W^{-1} $ along the way, while these still need to be computed after selecting the columns to be used under uniform random sampling.", "In large data regimes, these become practical considerations that make implementation of uniform random sampling less efficient, as we discuss in Section [@ref:LABEL:ss:cmplxoasisp] .", "\\newline </subsection> <subsection> <title> IV-C Complexity of oASIS-P </title> The low complexity of oASIS makes it practical for extremely large matrices where other adaptive sampling schemes are intractable.", "For oASIS-P, the computational complexity of oASIS is divided by the $ p $ nodes, such that each node has $ \\mathcal{O}(\\ell^{2}n/p) $ complexity.", "At first blush, oASIS-P is still slower than uniform random sampling and its $ \\mathcal{O}(1) $ sampling speed.", "However, in regimes where the dataset cannot be loaded entirely in memory, three practical considerations make uniform random sampling less competitive.", "First, forming $ \\ell $ columns from a dataset $ \\{z_{i}\\}_{i=1}^{n} $ with $ z_{i}\\in\\mathbb{R}^{m} $ takes at least $ \\mathcal{O}(\\ell n) $ time.", "For many applications, forming the columns as they are sampled is substantially more expensive than the process of adaptively selecting columns.", "Second, communication of data vectors among nodes becomes the bottleneck in the parallel implementation, and oASIS-P and random sampling appear competitive in terms of column selection/generation time, as shown in Table", "[@ref:LABEL:tab:ptable] .", "Third, random sampling may require substantially more columns than oASIS to achieve the same accuracy, in which case adaptive sampling is highly advantageous.", "\\newline </subsection>  </section>"], ["<section> <title> V Numerical Experiments </title>  <subsection> <title> V-A General Setup </title> To evaluate the performance of oASIS, we measure the accuracy of Nystr\u00f6m approximations for three size classes of kernel matrices.", "We first consider matrices where we can directly measure the approximation error of the Nystr\u00f6m method.", "Second, we consider larger problems for which forming the entire kernel matrix is impractical.", "Third, we consider problems so large that the dataset will not fit in memory.", "For each dataset $ \\{z_{i}\\}_{i=1}^{n} $ in all classes, we consider Gaussian kernel matrices where $ {G(i,j)=\\exp(\\|z_{i}-z_{j}\\|_{2}^{2}/\\sigma^{2})} $ .", "For datasets in the first class we also consider diffusion distance matrices $ M=D^{-1/2}ND^{-1/2} $ where $ D $ is a diagonal matrix containing the row sums of $ M $ , and $ N $ is a Gaussian kernel matrix [@bib:Coifman20065] .", "For each dataset, we tune $ \\sigma $ to provide good matrix approximation for any sampling method.", "\\newline We compare oASIS to the following state-of-the-art Nystr\u00f6m approximation methods: (i) uniform random sampling, (ii) Leverage scores [@bib:conf/icml/GittensM13] (Section [@ref:LABEL:sss:ndas] ), (iii) $ K $ -means Nystr\u00f6m approximation [@bib:Zhang:2008:INL:1390156.1390311] (Section [@ref:LABEL:sss:dkm] ). and (iv) Farahat\u2019s greedy update method [@bib:journals/jmlr/FarahatGK11] (Section [@ref:LABEL:sss:dgm] ).", "For methods (i), (ii), and (iii), we repeat experiments 10 times and average the results.", "For the second class of matrices we consider oASIS, uniform random sampling, and $ K $ -means since the other methods become intractable when the matrix becomes too large to explicitly store.", "For the largest class of matrices we only consider oASIS and uniform random sampling.", "Specific datasets and experiments are described below.", "\\newline </subsection> <subsection> <title> V-B Full Kernel Matrices </title> Here, we consider datasets for which the kernel matrices can entirely fit in memory, making all the sampling methods tractable.", "Convergence curves are generated by forming $ \\widetilde{G}_{k} $ for increasing $ k $ and then calculating the approximation error defined by $ \\|\\widetilde{G}_{k}-G\\|_{F}/\\|G\\|_{F}. $ We consider the following datasets, run using MATLAB on an iMac with a 2.7 GHz processor and 16GB of memory."]], "target": "Results and column selection runtimes at the largest sample sizes are shown for full matrices in Table . oASIS is competitive with the most accurate adaptive schemes, at a fraction of the runtime."}, {"tabular": ["  Method  &  Accuracy  &  Precision  &  Recall ", " Without Gradient  &  49.2%  &  46.7%  &  85.9% ", " Without t-SNE  &  86.5%  &  83.1 %  &  87.5% ", " With t-SNE  &  87.3 %  &  81.5%  &  93.0 %  "], "ref_sec": [["<section> <title> I Introduction </title>  Timely detection of traffic anomaly is one of the prerequisites of an Intelligent Transportation Systems (ITS).", "If not done timely, anomalies may create cascading effects leading to chaos in traffic.", "Typical examples of traffic anomalies are, lane driving violation, over-speeding, collision, red-light violation, etc.", "Anomaly detection using video object trajectories with deep learning has not yet been explored much.", "In this paper, we propose a color gradient approach for representing vehicular trajectories extracted from videos.", "These trajectories are then used for classification and anomaly detection at traffic junctions using a hybrid CNN-VAE architecture.", "\\newline Most commonly used features for video guided scene understanding are trajectories.", "A trajectory is a time series data with object locations indexed in temporal order.", "Classifying trajectories using neural networks is not trivial due to variation in the data length.", "Key to the success of a time series signal classification lies in finding an effective representation of the data.", "Neural networks-based classifiers need fixed size inputs.", "CNN, Long Short Term Memory (LSTM) and Recurrent Neural Network (RNN) have been used for time series classification [@bib:yang2015deep,AKhosroshahi,hammerla2016deep] .", "However, time series data can be of varying length. .", "Therefore, classification of varying length data can be applied after preprocessing, e.g. converting them into fixed length data either by padding or subsampling.", "If the trajectory length variance is large, preprocessing in mandatory.", "\\newline Video anomaly detection at traffic junctions is highly challenging due to its contextual nature.", "For example, when a signal turns green at a traffic junction, only a few of the paths or directions are allowed for vehicle movement.", "Any motion that violates direction, is assumed to be anomaly though such motions can be normal in a different context.", "\\newline <subsection> <title> I-A Related Work </title> Traditional features such as basis transform coding using wavelet and Fourier coefficients [@bib:bulling2014tutorial] , time series mean and covariance [@bib:bulling2014tutorial] , and symbolic representation [@bib:lin2003symbolic] have been used for classification of time-series data using neural networks.", "Also, other models such as Deep Belief Networks (DBN) [@bib:tieleman2008training] have been used for human activity detection [@bib:plotz2011feature] .", "On the other hand, CNNs are primarily used in image classification [@bib:krizhevsky2012imagenet,zeiler2014visualizing] , activity recognition in videos [@bib:ji20133d] , speech recognition [@bib:deng2013recent] , etc.", "\\newline Long Short Term Memory networks (LSTMs) [@bib:hochreiter1997long] are a special kind of Recurrent Neural Network (RNN) that can be used for handling sequential/time series data.", "Authors of [@bib:ng2015beyond,donahue2015long] have proposed a recurrent network connecting LSTMs to CNNs to perform action recognition and video classification, respectively.", "Donahue et al. [@bib:donahue2015long] have tested the learned models for activity recognition, image description and video description.", "The work proposed in [@bib:wu2015modeling] has achieved the state-of-the-art performance in video classification by connecting CNNs and LSTMs under a hybrid deep learning framework.", "Sequential Deep Trajectory Descriptor (DTD) has been used for action recognition [@bib:shi2017sequential] from the video sequences.", "Deep Neural Network (DNN)-based trajectory classification has been applied on Global Positioning System (GPS) trajectories [@bib:Endo2016] .", "Dense feature trajectories used have been utilized for action recognition in videos [@bib:HWang] .", "The LSTM-based work proposed in [@bib:AKhosroshahi] uses fixed size features to classify trajectories of surrounding vehicles at four way intersections based on LIDAR (LIght Detection And Ranging), GPS, and inertial measurement unit (IMU) measurements.", "\\newline Dense trajectories extracted using neural networks have also been used for action recognition in videos including classifying a person when walking, running, jumping [@bib:HWang,2001_AF_Bobick] , etc.", "These methods cannot handle multiple actions present in a scene.", "However, in real life scenario, multiple objects can interact resulting more than one action within the scene.", "Training neural networks for action recognition can be challenging in presence of multiple activities.", "However, object trajectories extracted using traditional methods [@bib:benfold2011stable,AMilan1,SHBae] can be used for learning the motion patterns using DNNs as they can automatically extract features from trajectories.", "The trained/learned model can then be used in classification and action recognition applications.", "\\newline In this work, we encode video trajectories using a high-level representation, named color gradient, that embeds spatio-temporal information of the objects-in-motion.", "The high-level representation is then used for trajectory classification and anomaly detection using a hybrid CNN-VAE architecture.", "\\newline </subsection> <subsection> <title> I-B Motivation and Contributions </title> Since accurate classification is the key to detect anomalies, a classifier that can handle time series data with length variations, has been preferred.", "Typical neural networks-based methods need fixed input size.", "Therefore, varying length trajectories cannot directly be used in such classifiers.", "Conventional methods such as the one proposed in [@bib:yang2015deep] convert the varying length time series data into fixed size by sampling.", "This is similar to quantization, which leads to information loss.", "The question is: Why can\u2019t a trajectory represented using an image be given as an input to a classifier?", "However, trajectories representing movement of more than one object in between two locations may look visually similar when projected in 2D space.", "Such representations fail to preserve temporal relations between successive points of a trajectory.", "Encoding of time information in the form of color gradient (red $ \\to $ violet) reveals, similar patterns produce similar color gradient as depicted in Fig. [@ref:LABEL:fig_MOTIVATION] (a).", "Similarly, the trajectories with possible anomalies exhibit different spatio-temporal characteristics as depicted in Fig. [@ref:LABEL:fig_MOTIVATION] (b).", "This has motivated us to propose the following: \\newline <list> \\ A high-level representation of object trajectories using color gradient that encodes spatio-temporal information of trajectories of varying length.", "\\newline \\ \\ A semi-supervised labeling technique based on modified Dirichlet Process Mixture Model (mDPMM) [@bib:TUIC_ITS_2018] clustering to identify the trajectory classes.", "\\newline \\ \\ A method using t-Distributed Stochastic Neighbor Embedding (t-SNE) [@bib:maaten2008visualizing] to eliminate anomalous trajectories in the training data.", "\\newline \\ \\ Detection of traffic anomalies using a hybrid CNN-VAE architecture.", "\\newline \\ </list> Rest of the paper is organized as follows.", "In Section [@ref:LABEL:sec:Methodology] , we present the proposed methodology.", "Section [@ref:LABEL:sec:Experimental_Results] presents experimental results and Section [@ref:LABEL:sec:Conclusions] presents conclusion.", "\\newline </subsection>  </section>"], ["<section> <title> II Methodology </title>  First we discuss the background of the terms and concepts used in the work.", "A scene represents the view captured using static camera.", "We use observation or data to represent a trajectory.", "A cluster is a collection of trajectories of similar characteristics.", "A class is a set of trajectories having some selected common characteristics.", "Here, a class typically represents a unique path in a scene.", "A model is a representation of a real-world phenomenon.", "Here, model represents the weight parameters of the trained neural networks.", "We assume a model can represent a scene.", "Reconstruction loss (of CNN-VAE architecture) represents a measure of deviation from the input.", "A typical anomaly represents deviation from the normal path.", "Some anomalies are known a-priori.", "For example, when a signal turns green at a traffic junction, only a few of the paths are allowed for vehicle motion.", "Any motion that conflicts/intersects the allowed path, is considered as known anomaly.", "However, some anomalies may not be present in the training data.", "We refer them to as unknown anomalies.", "\\newline Object trajectories are obtained using [@bib:SHBae,TUIC_ITS_2018] .", "A trajectory ( $ \\tau_{i} $ ) can be represented using ( [@ref:LABEL:equation:TRAJ] ), where $ (x_{l},y_{l}) $ represents the position of moving object at time $ t_{l} $ and $ L_{i} $ be its length.", "A cluster is a collection of trajectories of similar characteristics.", "A class is a set of trajectories having some selected common characteristics.", "It can be trajectories in the same lanes, trajectories following same route, etc.", "\\newline <equation> $ \\tau_{i}=<(x_{0},y_{0},t_{0}),(x_{1},y_{1},t_{1}),\\cdots,(x_{L_{i}},y_{L_{i}},% t_{L_{i}})> $ </equation> \\newline Traffic anomalies can be classified into two types; known and unknown .", "Known anomalies correspond to trajectories that may be allowed in different contexts.", "On the contrary, unknown anomalies correspond to trajectories that are not present in the training data.", "In order to detect both types of anomalies, it is important to learn the normal trajectory patterns or classes.", "The overall anomaly detection framework is presented in Fig. [@ref:LABEL:fig_anomaly_framework] .", "\\newline <subsection> <title> II-A Background </title> <subsubsection> <title> II-A1 Modified DPMM Guided Clustering </title> When raw trajectories are obtained from some tracking algorithms, they need to be clustered to identify different patterns.", "In [@bib:TUIC_ITS_2018] , we have proposed a modified DPMM (mDPMM) to group pixels having similar characteristics.", "Here, we use mDPMM to group trajectories to learn the motion patterns.", "The model is expressed using ( [@ref:LABEL:equation:DPM1] - [@ref:LABEL:equation:DPM4] ).", "\\newline <equation> $ z_{i}|\\pi\\sim\\mbox{Discrete}(\\pi) $ </equation> <equation> $ \\tau_{i}|z_{i},\\theta_{k}\\sim F(\\theta_{z_{i}}) $ </equation> <equation> $ \\pi|e^{-\\beta}\\sim\\mbox{Dirichlet}(e^{-\\beta}/K,\\cdots,e^{-\\beta}/K) $ </equation> <equation> $ \\theta_{k}|H\\sim H $ </equation> Here, $ \\tau_{i} $ is a random variable representing the trajectory and $ z_{i} $ corresponds to the latent variable representing cluster labels.", "$ z_{i} $ takes one of the values from $ k=1\\cdots K $ , where $ K $ is the number of clusters.", "$ \\pi=(\\pi_{1},\\cdots,\\pi_{K}) $ , referred to as mixing proportion, is a vector of length $ K $ representing the probabilities of $ z_{i} $ to be $ k $ .", "$ \\theta_{k} $ is the parameter of cluster $ k $ and $ F(\\theta_{z_{i}}) $ denotes the distribution defined by $ \\theta_{z_{i}} $ .", "$ e^{-\\beta} $ is the concentration parameter of Dirichlet distribution and its value decides the number of clusters formed.", "$ \\beta $ is referred to as concentration radius.", "Trajectory clustering is to be done by taking $ \\tau_{i} $ as $ < $ $ x_{s},y_{s},x_{e},y_{e},t_{d} $ $ > $ , where $ (x_{s} $ , $ y_{s}) $ represents the start position, $ (x_{e},y_{e}) $ the end position and $ t_{d} $ is the duration/length of the trajectory.", "\\newline Using the inference method given in [@bib:TUIC_ITS_2018] , clustering of clustering of trajectories can be done.", "These clusters can be typically grouped into two types.", "First type contains large number of trajectories and they represent prominent patterns in the scene.", "The second type of clusters contain less number of trajectories.", "They can either correspond to less frequently occurring patterns or anomalies.", "\\newline </subsubsection> <subsubsection> <title> II-A2 Gradient Conversion of the Trajectories </title> A trajectory in time series is mapped into a color gradient form by varying hue using $ hue(x_{l},y_{l})=(t_{l}-t_{0})/L_{i}*180 $ , $ 0\\leq l\\leq L_{i} $ within an image frame.", "These gradient frames become inputs to the CNN and VAE.", "\\newline </subsubsection> <subsubsection> <title> II-A3 Anomaly Elimination in Training Data using t-SNE </title> t-SNE [@bib:maaten2008visualizing] is a machine learning algorithm for visualizing high-dimensional data in a low-dimensional space.", "We use this for visualizing latent features of a trained VAE in two dimensions.", "Trajectories belonging to same class typically lie in close proximity in the visualization plane.", "However, trajectories that are far away from a class are inspected again for manual anomaly checking.", "\\newline </subsubsection> </subsection> <subsection> <title> II-B Trajectory Annotation </title> Suppose a set of trajectories captured from a traffic junction or road are given.", "These trajectories must belong to any one of the defined set of paths (classes).", "Applying mDPMM helps to identify prominent patterns from these trajectories.", "Like any unsupervised method, clustering algorithm can only identify different possible patterns from the trajectory data.", "Though prominent patterns can correspond to normal trajectories, clusters with less number of trajectories can represent a rare pattern or an anomaly.", "This necessitates to have an additional annotation process to identify allowed classes.", "Clustering reduces the load of the manual labeling process as an initial grouping is done through mDPMM.", "The annotator can identify these rare patterns through visual observation of the scene and separate the anomalous trajectories to finalize the allowed classes.", "This process is called class annotation.", "\\newline More refinements are possible within a class.", "It is possible that two trajectories with similar endpoints and duration may follow different paths, out of which one may be normal.", "This may not always be detected through visual observation.", "Therefore, t-SNE has been used to visualize the distribution of trajectories within the classes.", "This helps to remove noises (anomalies) from the training set being prepared for VAE.", "\\newline </subsection> <subsection> <title> II-C Training CNN and VAE Framework </title> A CNN classifier typically consists of repeated occurrences of cascaded convolution, activation, and pooling layers followed by fully connected layers.", "The architecture used in this work is depicted in Fig. [@ref:LABEL:fig_CNN_AUTO] (a).", "During the training stage, a cost/loss function representing the cross-entropy between the expected and predicted class is minimized using Adam optimizer [@bib:AdamOptimizer] with a learning rate of $ \\lambda $ .", "\\newline We use a variational autoencoder (VAE) similar to [@bib:kingma2013auto] to detect unknown anomalies.", "It typically consists of encoding and decoding stages.", "Input to the encoder $ q\u200b_{\\theta}\u200b\u200b(z|\\tau) $ is $ \\tau $ .", "Output is a hidden/latent feature $ z $ , where $ \\theta $ represents weights and biases of encoder network.", "Decoder $ p\u200b_{\\phi}\u200b\u200b(\\tau|z) $ takes latent feature $ z $ and regenerates $ \\tau $ , where $ \\phi $ represents weights and biases of decoder.", "Loss function ( $ l_{i} $ ) for a trajectory $ \\tau_{i} $ is given in ( [@ref:LABEL:equation:vae_loss_function] ) in terms of log likelihood ( $ ll $ ) as given in as given ( [@ref:LABEL:equation:vae_likelihood] ) and Kullback-Leibler Divergence (KLD) as given in as given ( [@ref:LABEL:equation:KLD] ).", "Adam optimizer minimizes the average loss function during training.", "Once trained, VAE can detect anomalies using the average reconstruction loss on the trained VAE.", "\\newline <equation> $ ll=\\mathbb{E}_{z\\sim q_{\\theta}(z|\\tau_{i})}[logp_{\\phi}(\\tau_{i}|z)] $ </equation> <equation> $ KLD=q_{\\theta}(z|\\tau_{i})||p(z) $ </equation> <equation> $ l_{i}(\\theta,\\phi)=-ll+KLD $ </equation> \\newline </subsection> <subsection> <title> II-D Anomaly Detection </title> Classification is performed on the trained CNN using test trajectories represented in gradient form to obtain class $ c $ . Let $ \\delta $ be the threshold of reconstruction loss value for normal classes on the trained VAE.", "$ \\delta $ is derived using the variance of loss values on the training trajectories.", "A trajectory can be considered anomalous when $ c\\notin A_{s} $ or $ l_{i}(\\theta,\\phi)>\\delta $ , such that $ A_{s} $ is a set of allowed trajectory classes of a particular signal $ s $ .", "\\newline However, a classifier is needed for anomaly detection to handle conflicting trajectories.", "In a typical traffic junction, a set of flows may be allowed at a given time.", "For example, the QMUL dataset (Fig. [@ref:LABEL:fig_QMUL_CLUSTERS] ) suggests, any two flows, e.g, south-to-north on left side and north-to-south on right side, are allowed at a given time.", "Any other movements can be termed anomalous though individually such movements may be allowed at a different time.", "VAE cannot detect such known anomalies.", "Therefore, CNN helps to detect such conflicting anomalies.", "It also helps to identify the anomalous path.", "\\newline </subsection>  </section>"], ["<section> <title> III Experimental Results </title>  We have used tensorflow and openCV for developing the classification and anomaly detection framework.", "We have used three datasets, namely T15 [@bib:xu2015unsupervised_t15] , QMUL [@bib:QMUL_DATASET] and a junction video dataset (referred to as 4WAY).", "Context tracker [@bib:ContextTracker] has been used for creating trajectories from QMUL dataset, and Temporal Unknown Incremental Clustering (TUIC) [@bib:TUIC_ITS_2018] has been used for obtaining 4WAY trajectories.", "Inputs to CNN-VAE are resized to 120x120x3.", "CNN training has been completed with 50 epochs with a learning rate of $ \\lambda=1e^{-3} $ on T15 and 4WAY dataset videos.", "A batch size of 20 has been used for the QMUL dataset.", "VAE for T15 has been trained with $ \\lambda=5e^{-4} $ in 500 epochs using a batch size of 20.", "VAE for QMUL dataset has been trained with $ \\lambda=1e^{-4} $ and batch size = 10 in 500 epochs.", "\\newline <subsection> <title> III-A Experiments on Trajectory Clustering and Annotation </title> The annotation aspects of unlabeled trajectories using mDPMM are shown in Fig. [@ref:LABEL:fig_QMUL_CLUSTERS] .", "Trajectory details are presented in Table [@ref:LABEL:Tab:Dataset] .", "Since T15 dataset readily comes with associated class annotation, unsupervised clustering has not been not applied on this dataset.", "Fig. [@ref:LABEL:fig_T15_tSNE] presents the t-SNE guided refinement.", "\\newline </subsection> <subsection> <title> III-B Experiments on Classification and Comparisons </title> Trajectories of T15, QMUL and 4WAY datasets have been used for classification.", "Classification results are shown in Fig. [@ref:LABEL:fig_Classification] and summarized in Table [@ref:LABEL:Tab:Accuracy] .", "It can be observed that the proposed method performs accurate classification across all datasets.", "We have randomly selected $ 75 $ % of the trajectories for training and the rest for testing.", "Our proposed classification method has been compared with other state-of-the-art classification methods such as HAR-CNN [@bib:yang2015deep] , LSTM [@bib:AKhosroshahi] , LSTM+CNN [@bib:wu2015modeling] typically used for time series data classification.", "We have converted the input trajectories to $ 128 $ samples by downsampling or upsampling depending on their size.", "The comparative results are shown in Table [@ref:LABEL:Tab:Accuracy] .", "The results reveal, our proposed method performs better than the existing approaches across all datasets.", "However, classification without color gradient degrades slightly, even though it performs better than most of the existing work.", "\\newline </subsection> <subsection> <title> III-C Experiments on Anomaly Detection </title> T15 dataset has been used to evaluate the anomaly detection framework.", "Reconstructions using VAE are depicted in Fig. [@ref:LABEL:fig_T15] .", "Four kinds of anomalous trajectories are used in our experiments: (i) Trajectories terminating abruptly.", "(ii) Speed variation as compared to normal trajectories of the same class.", "(iii) Trajectories of objects traveling in opposite direction of the normal traffic.", "(iv) Trajectories corresponding to vehicles violating lane driving.", "Since T15 dataset does not contain type three anomalous trajectories, we have created a few such trajectories by gradient conversion in reverse order.", "We have used two times the converged loss value as a threshold for detecting anomaly based on the empirical study on anomalous and normal trajectories as shown in Fig [@ref:LABEL:fig_LOSS_CURVE] (a).", "Anomaly detection results are shown in Fig. [@ref:LABEL:fig_LOSS_CURVE] (b).", "We have used 69 randomly selected normal trajectories that are not used in the training and 31 identified anomalous trajectories along with synthetically created ones.", "We have created $ 11 $ synthetic trajectories for lane change and $ 15 $ corresponding to each class for opposite direction driving anomalies."]], "target": "The comparisons of trajectory projection on image plane using VAE under different conditions are presented in Table . We are able to detect anomalies with an accuracy of 87.3% when t-SNE is used. This reveals, without gradient representation, anomaly detection accuracy drops significantly (49.2%)."}, {"tabular": ["  Key  &  Definition ", " {model}  &  The details of the network model ", " {shape}  &  The shape of input sample ", " {bounds}  &  The bounds of input sample ", " {layers}  &  The details of model layers ", " {type}  &  The type of a layer ", " {weights}  &  The weights matrix of a layer ", " {bias}  &  The bias vector of a layer ", " {func}  &  The activation function of a layer ", " {filters}  &  The filters matrix of a conv. layer ", " {padding}  &  The padding value of a conv. layer ", " {stride}  &  The stride value of a conv. layer ", " {h0}  &  The $ h0 $ vector of a recurrent layer ", " {c0}  &  The $ c0 $ vector of a recurrent layer ", " {path}  &  The path to the pre-trained model  "], "ref_sec": [["<section> <title> I Introduction </title>  Neural network models are getting ever more popular due to their exceptional performance in solving many real-world problems, such as self-driving cars [@bib:driving2016cars] , face recognition [@bib:yin2017multi] , malware detection [@bib:malware2014dtc] , sentiment analysis [@bib:tang2015document] and machine translation [@bib:machine2014translation] .", "At the same time, neural networks are shown to be vulnerable to a variety of issues.", "For instance, it is shown that adversarial perturbation can be applied to generate samples which trigger wrong model prediction [@bib:szegedy2013intriguing,goodfellow2014explaining,cw2017Robustness] ; and it is shown that neural network models may discriminate certain groups or individuals [@bib:zhang2020white] .", "Given that neural networks are increasingly applied in applications which are safety-critical (e.g., self-driving cars) or have significant societal impact (e.g., personal credit rating systems or face recognition), it is desirable that such neural network models are systematically verified against a variety of desirable properties.", "For instance, an image recognition neural network model used in a self-driving car should be verified to be robust (i.e., the classification result remains the same in the presence of perturbation) and a neural network for predicting personal credit rating should be verified to be fair.", "\\newline Recently, there has been an increasing number of efforts on formally verifying neural network models.", "In [@bib:katz2017reluplex] , Katz {et al.} proposed a constraint solving technique targeting feedforward neural networks with ReLU activation functions.", "In [@bib:wang2018formal,DBLP:conf/nips/WangPWYJ18] , Wang {et al.} improved the constraint solving techniques for verifying the same class of neural networks with symbolic intervals.", "In [@bib:gehr2018ai2,singh2018fast,singh2019abstract] , the authors applied the classic abstract interpretation techniques to verify neural networks, with customized abstraction domains and functions supporting feedforward neural networks with activation functions such as ReLU, Sigmoid and Tanh.", "\\newline The status quo is however less than satisfactory, i.e., existing approaches are limited in multiple ways, which makes applying, comparing, reusing and extending existing verification efforts difficult.", "First, existing approaches support only restricted classes of neural networks or properties.", "For instance, some existing work [@bib:katz2017reluplex,DBLP:conf/nips/WangPWYJ18] only support verification of feedforward neural networks using ReLU activation functions.", "Only very recently, researchers have started exploring the verification of feedforward neural networks with different activation functions [@bib:singh2018fast,singh2019abstract] and some subclasses of recurrent neural networks [@bib:DBLP:journals/corr/abs-2004-02462,DBLP:journals/corr/abs-2005-13300] .", "Furthermore, existing approaches all focus on reachability properties or local robustness, and ignores the verification of other important properties such as fairness and beyond.", "Secondly, existing verification toolkits require input models in specific format and different tools often require different format.", "For instance, Reluplex [@bib:katz2017reluplex] requires a text file contains the weights and bias of multilayer perceptron layers, whereas DeepPoly [@bib:singh2019abstract] needs a more complex input which specifies the types of layers before providing their parameters\u2019 values.", "This will likely get worse as there are an increasing list of popular frameworks for training neural network models, such as TensorFlow, Cafe, MXNet, PyTorch, Theano and Keras, all of which encode neural network models in their own ways.", "As a result, a verification tool developed for one framework may not be applicable to models trained using another.", "This not only limits the applicability of the existing verification toolkits but also makes comparing them infeasible.", "We remark that two recent efforts on solving this problem are ONNX [@bib:onnx] and NNEF [@bib:nnef] , which aims to provide a cross-platform format for neural networks.", "It is however designed for a different purpose and lacks important features which are required for neural network verification.", "Thirdly, each existing approach typically focuses on one property, whereas in fact the (sometimes rather sophisticated) verification algorithm could be easily extended to solve the verification problem of another property.", "For instance, algorithms for verifying local robustness can easily be extended to verify fairness defined in terms of individual discrimination.", "With different verification algorithms and optimization techniques implemented in different repositories, reusing these efforts is often highly nontrivial.", "\\newline In this project, we aim to build a unified framework for developing verification techniques for neural networks.", "The goal is to have a platform which allows us to apply, compare, reuse and develop verification techniques for a variety of neural network models against a variety of properties.", "Towards this goal, we design and implement an open source platform called Socrates , which embodies multiple technical contributions.", "First, Socrates provides a standardized format for a variety of neural network models based on JSON.", "By compiling models trained using different frameworks to this common format and building verification algorithms around it, the same verification algorithm can be applied to models trained using different frameworks.", "Secondly, Socrates supports an assertion language which is designed to specify a range of properties of neural network models, including robustness, fairness and more.", "Thirdly, Socrates provides two new algorithms, i.e., optimization-based falsification and statistical model checking, which can be applied to verify or falsify a variety of neural network models.", "More importantly, Socrates is designed to be modular and extensive, i.e., it is straightforward to support new models, properties or verification algorithms; or integrate existing verification engines.", "\\newline Furthermore, we provide a comprehensive set of 12347 verification tasks (i.e., neural network models and respective assertions) as a part of the Socrates repository so that researchers can easily evaluate and compare the effectiveness and efficiency of different verification algorithms using a comprehensive set of benchmarks.", "Using the benchmarks, we conduct multiple experiments to evaluate the effectiveness of the two verification algorithms developed in Socrates .", "The experiment results show that the two new algorithms solve more verification tasks than existing approaches and offer complimentary verification results.", "We remark that Socrates is open source at [@bib:srcurl] and we are making all the effort required to make it a platform for synergistic research on verification of neural networks.", "\\newline The rest of the paper is organized as follows.", "In Section [@ref:LABEL:sec:overall] , we discuss the overall design of Socrates .", "In Section [@ref:LABEL:sec:json] , we present details on the model format in JSON supported in Socrates .", "In Section [@ref:LABEL:sec:algos] , we present the two new algorithms supported in Socrates and evaluate their effectiveness against state-of-the-art approaches.", "In Section [@ref:LABEL:sec:related] , we review related work and we conclude in Section [@ref:LABEL:sec:conclude] .", "\\newline  </section>"], ["<section> <title> II System Overview </title>  Socrates is designed for both ordinary users who require a tool for verifying a particular neural network model as well as researchers who are working on developing neural network verification techniques.", "In the following, we first illustrate how Socrates works from an ordinary user point of view and then introduce its design from a verification researcher point of view.", "Lastly, we provide an overview of functionalities provided by Socrates and those by existing verification toolkits for neural networks.", "\\newline <subsection> <title> II-A For Ordinary Users </title> To use Socrates to verify a well-trained neural network against a desirable property, a user must provide a JSON file which encodes the verification task in the required format.", "A verification task is composed of three main parts, i.e., a model, a property, and a verification engine selected for solving the verification task.", "The JSON format is designed to support a variety of neural network models.", "The model part of a JSON file can be generated automatically from models trained using existing frameworks such as Tensorflow and PyTorch.", "The property part of the JSON file is specified in an assertion language designed for neural network verification, with a formal syntax as well as supporting easy-to-use templates for commonly verified properties.", "Together with the model and the property are JSON keys for specifying the verification engine.", "Note that some verification engines have configurable parameters, which are specified as part of the JSON file as well.", "The readers are referred to Section [@ref:LABEL:model] and [@ref:LABEL:assertion] for details on the format.", "Once the JSON file is loaded, the user simply waits for the verification result.", "\\newline In the following, we use an example to illustrate the process.", "Assume that the user has trained a network for classifying images with 1 channel and a dimension of $ 28\\times 28 $ (i.e., 784 pixels in total) based on the MNIST dataset.", "The design of the neural network is shown in Figure [@ref:LABEL:enet] .", "It is a multilayer perceptron with 4 layers.", "Beside the input layer, each of the two hidden layers has 50 neurons, and the output layer has 10 neurons.", "The activation function used in two hidden layers is the ReLU function, and the output layer uses the softmax function to return the probability of each class according to the input sample.", "The property to be verified is local robustness, i.e., given a particular input image, with a limit on the value of each pixel to be perturbed, all perturbed images have the same label as the original one.", "\\newline The JSON file is shown in Figure [@ref:LABEL:jsoninput] .", "At line 2, a model is defined with the key {model} .", "The value of {model} is a JSON object.", "At line 3, the value of the key {shape} is specified as an integer tuple which represents the shape of the input sample.", "For this example, the value is $ (1,784) $ where $ 1 $ is the length of the sample and $ 784 $ is the size of each element in the sample.", "At line 4, the key {bounds} specifies the lower bound and the upper bound respectively for features in valid input samples.", "In this example, the bound $ [(0,1)] $ means each of the features in a valid input (i.e., a feature vector) is a value $ v $ which satisfies $ 0\\leq v\\leq 1 $ .", "Lines 5 to 24 then specify the value of the key {layers} , i.e., an array in which each element specifies the details of one layer.", "In this example, the array contains information of the two hidden layers and the output layer.", "Note that the details of the input layer are not necessary (since they have been specified using other keys).", "Each array element specifies the type of the layer, the value of the weights matrix, the values of the bias and the activation function.", "These information are defined using the keys {type} , {weights} , {bias} and {func} respectively.", "We remark that the values of {weights} and {bias} are omitted as they are rather complicated, e.g., the value of {weights} for the first hidden layer is a matrix of dimension $ 784\\times 50 $ written as a string with a syntax similar to the right-hand side of Python multidimensional array initialization.", "Instead of providing these values directly, the user can provide addresses to the files (either local or online) containing their values.", "Note that the key values might be correlated and thus must be checked for well-formness, i.e., the first dimension of the weight matrix must be equal to the number of neurons in the previous layer; the second dimension of the weight matrix and the size of the bias vector must be equal to the number of neurons in the current layer.", "\\newline Lines 26 to 31 then define the property to be verified.", "In this example, the property is local robustness which is specified with multiple keys.", "The key {x0} is an input image, i.e., a vector of size 784, or an address to an image.", "In this example, assume that the input image is the one shown on the left of Figure [@ref:LABEL:mov] , i.e., an image from the MNIST dataset with label 7.", "The key {distance} specifies the searching space using one of the predefined functions in the framework.", "In this example, the distance function is the infinity norm distance, which intuitively means the maximum element-wise absolute difference between two samples.", "Finally, the key {eps} specifies the maximum value of the distance.", "We remark that in this example, a predefined template for local robustness is used.", "Socrates supports a general assertion language, which we present in Section [@ref:LABEL:assertion] .", "\\newline Lines 32 to 34 then specify the verification engine that is applied to solving the verification problem.", "In this example, the user selects an optimization-based falsifier.", "The falsifier automatically transforms the verification problem into an optimization problem, which is then solved using an optimization algorithm (see details in Section [@ref:LABEL:solver] ).", "An image which violates the specified property is identified in about 1 second, which is shown on the right of Figure [@ref:LABEL:mov] .", "That is, this image has a distance from the original image not greater than the specified bound (i.e., $ 0.1 $ in this example) and has a label which is not 7. Note that the JSON file also contains keys (at lines 35-37) which are for presenting the verification result, e.g., by setting the {display} function and providing a {resolution} .", "\\newline </subsection> <subsection> <title> II-B For Researchers on Neural Network Verification </title> More relevantly, Socrates is designed to enable synergistic effort on developing state-of-the-art verification techniques for neural networks.", "It has a publisher-subscriber architecture which facilitates developing verification techniques for different neural network models and properties independently.", "It has three main modules, i.e., the {Parser} and {Display} on the front-end and {Verifiers} on the back-end.", "In the following, we briefly discuss the main functionality of each component.", "The technical details are discussed in the subsequent sections.", "\\newline The {Parser} module is built upon the JSON format (as exemplified in Figure [@ref:LABEL:jsoninput] ).", "The parser receives a JSON file, checks its well-formness, decodes it and publishes it internally as a verification task.", "Note that each verification task is associated with a number of parameters (such as the network model type, size and the assertion type), which are used to determine whether a verification engine is applicable or not.", "The models which are currently supported in Socrates include multilayer perceptron (MLP), convolutional networks (CNN), residual networks (ResNet), and recurrent networks (RNN).", "To support new models, the developers are required to extend the JSON format (by introducing new values for certain existing keys or introducing new keys) and extend the parser accordingly to generate the verification task, which is relatively easy.", "\\newline The {Verifiers} module consists of a set of verification engines which could be developed independently from each other.", "Each verification engine could be either general or specific (i.e., dedicated to certain models or certain properties, such as many existing verification engines [@bib:singh2018fast,singh2019abstract] ).", "For instance, Socrates supports two general verification engines which applies to all neural network models which are currently supported in Socrates .", "The first one is an optimization-based falsification engine, which transforms the verification task into the problem of finding a counterexample through optimization.", "The second one is a statistical model checking [@bib:DBLP:conf/atva/ClarkeZ11] engine which can be used to verify that the assertion holds with certain level of statistical confidence.", "As the verification engines are independent, extending Socrates with a new verification algorithm is straightforward.", "\\newline The {Display} module is used to present the verification results in a user-friendly way to the user.", "A verification engine typically generates three kinds of results, i.e., the property is verified, no counterexample is identified (e.g., which timeout occurs) or a counterexample is identified.", "Depending on the application domain and the property, the counterexample could be an image, a text, a feature vector or a set of them (for instance, if the property to be verified is individual fairness, two contrasting feature vectors form a counterexample).", "The display module receives the result from the verification engines and displays them accordingly. Note that some additional keys are defined in the JSON format so that the user can specify the display options.", "\\newline </subsection> <subsection> <title> II-C Functionalities </title> Socrates is designed to be a unified platform supporting a variety of neural network models, properties and verification algorithms.", "In the following, we compare Socrates with existing state-of-the-art approaches in terms of functionalities.", "There are recently a booming number verification engines for neural networks and thus it is hard to keep up with all of them.", "Our search of state-of-the-art tools are based on research papers recently published at top-tier conferences and it is possible that we might miss some of them.", "Furthermore, not all tools reported in the publications are available for evaluation (or reliable enough to be evaluated independently).", "The following are the tools that we gather and compare: Reluplex [@bib:katz2017reluplex] , Neurify [@bib:DBLP:conf/nips/WangPWYJ18] , DeepZ [@bib:singh2018fast] , DeepPoly [@bib:singh2019abstract] , RefineZono [@bib:singh2018boosting] , RefinePoly [@bib:singh2019beyond] , ADF [@bib:zhang2020white] , and C&W [@bib:cw2017Robustness] .", "Note that the last two are technically not verification engines but rather testing engines.", "They are included as representatives of their kind to provide additional benchmark on the state-of-the-art for falsification.", "Their results however should be taken with a grain of salt as they are designed for completely different purpose.", "To find out the functionalities of each tool, we check the papers which reported the tool and experiment the tool to find out whether new capabilities have been introduced recently.", "For each tool, we identify the kind of neural network models and the kind of properties that are supported.", "\\newline The comparison is summarized in Table [@ref:LABEL:nets] , where $ \\blacktriangle $ means partial support (i.e., only works with small networks and may not be scallable to bigger ones).", "In terms of models supported by the tools, it can be observed that Socrates is the only tool which supports all types of neural networks.", "For Reluplex, experiments on verifying small multilayer perceptron networks have been reported.", "For Neurify, besides multilayer perceptron, it also supports convolutional networks.", "The next four tools, i.e., DeepZ, DeepPoly, RefineZono and RefinePoly, have the same capability, i.e., they support multilayer perceptron, convolutional, and residual networks.", "For ADF, the reported experiments only deal with small multilayer perceptron networks.", "All of the adversarial sample generation tools that C&W represents focus on the image recognition problem, and thus do not support recurrent networks.", "\\newline The properties that each tool can handle are shown in the last column in Table [@ref:LABEL:nets] .", "We again observe that only Socrates supports all types of properties.", "Most of the other tools support the local robustness property.", "Reluplex reportedly supports verification of the global robustness property for small networks.", "Other tools except ADF do not support global robustness.", "Most of the tools can support reachability properties expressed using linear (in)equalities, execpt ADF and C&W. Besides ADF which supports falsification of fairness properties (through a combination of clustering and searching), fairness properties are only supported by Socrates .", "\\newline </subsection> <subsection> <title> II-D Implementation </title> Socrates is open source at [@bib:srcurl] , including all the source code as well as a set of 12347 verification tasks.", "Socrates is implemented using Python 3 with a total of 2400 lines of code.", "Multiple public Python libraries are used in the implementation, including {json} and {ast} for parsing the JSON input file, {numpy} and {autograd.numpy} for mathematical computation, {matplotlib} for displaying imagery results, and {sicpy} for solving the optimization problem.", "By default, the local optimization function (instead of the global one) in {scipy} is applied, although this can be easily configured.", "\\newline Socrates is designed with the extensiblity in mind.", "The types of network models supported by Socrates can be easily extended by introducing new types of layers and activation functions.", "Currently, each type of layer is implemented as an independent class.", "In each class, the most important function is $ apply $ , which compute the output vector from the input vector.", "To extend the capability of Socrates with new type of layer, a new class can simply added into the library.", "Similarly, all the supported activation functions are kept inside an utility class.", "The new functions can be easily added at any time.", "The new types of layers and activation functions may need new parameters, which should not be the problem because users can always define the new keys for the JSON input file and update the JSON parser to represent the necessary parameters.", "\\newline In Socrates , the property can be a first-order logic formula composed from a set of predefined functions or a map contains syntactic sugar definition (see Section [@ref:LABEL:assertion] for more details).", "Socrates has a parser (independent from the above JSON parser) implemented with ANTLR to parse general first-order logic formula in form of string, then returns an AST to represent the formula.", "The expressiveness of the formula can be extended by adding new predefined functions and update the parser.", "Otherwise, users can define new syntactic sugar keys to model new properties.", "\\newline Finally, similar to the layers, each verification engine in Socrates is an independent class.", "So the new engines can be easily added as the new classes in Socrates .", "The most important function in these classes is $ solve $ , which receives a model and a property, then applies a specific algorithm of the engine.", "Each engine can be designed to solve general problem with property in form of first-order logic formula or just its own specific problem defined with its own set of syntactic sugar keys.", "Moreover, each engine may have its own meta parameters which use to configure its algorithm.", "As explained previously, these parameters are easily defined using new keys and then can be provided in JSON input file.", "\\newline </subsection>  </section>"], ["<section> <title> III The JSON Inputs </title>  Existing efforts on neural network verification techniques have results in multiple impressive tools, such as DeepPoly [@bib:singh2019abstract] and Reluplex [@bib:katz2017reluplex] .", "These tools, however, have their own input format.", "For instance, Reluplex only supports multilayer perceptron networks and requires a text file containing the number of layers, the number of neurons in each layer, the normalization information, as well as weights and bias values of each layer in the network.", "DeepPoly, on the other hand, supports different types of networks and thus it requires the type of each layer before the values of the layer\u2019s parameters (e.g., weights and bias).", "Moreover, because DeepPoly focuses on local robustness, it allows users to define the distance value between samples explicitly, whereas Reluplex does not have this feature.", "As a result, it is hard to compare the performance of different tools or to combine techniques developed by different research groups.", "Furthermore, existing toolkits are often developed for specific properties.", "For instance, DeepPoly is designed for verifying local robustness; Reluplex focuses on reachability properties; and ADF focuses on falsifying a particular notion of fairness only.", "A close investigation however shows that an algorithm developed in one tool (e.g., the one developed in ADF) could be potentially extended to verify other properties (e.g., local or global robustness).", "Thus, we develop a JSON format which supports a variety of neural network models and an assertion language which allows user to specify a range of properties.", "\\newline <subsection> <title> III-A Specifying Models </title> The JSON file is composed a sequence of keys which specifies the details of the network model and the property."]], "target": "The keys used to define the model are shown in Table . At the top-level, a model is specified using the key {model} . The value of {model} is then defined as a JSON object using a triple consisting of keys {shape} , {bounds} , and {layers} . The key {shape} is used to define the shape of the input sample, which is a tuple containing multiple integer values. The first value represents the length of the sample. Note that the first value is always $ 1 $ for non-recurrent neuron networks and is $ n $ with $ n\\geq 1 $ for recurrent neural networks. The remaining numbers represent the shape for each element in the sample. For instance, the tuple $ (5,80) $ means that the input sample is a sequence with length $ 5 $ and each element in the sequence is a vector with size $ 80 $ ."}, {"tabular": ["    &  SAT-Single  &  SAT-Multi ", " #TOS  &  PAR-10  &  PAR-1  &  #TOS  &  PAR-10  &  PAR-1 ", " PCIT  &  181  &  119  &  21  &  35  &  1164  &  219 ", " Priss6  &  225  &  146  &  25  &  -  &  -  &  - ", " PfolioUZK  &  -  &  -  &  -  &  36  &  1185  &  213 ", " Plinegling-bbc  &  452  &  276  &  32  &  33  &  1090  &  199  "], "ref_sec": [["<section> <title> 1 Introduction </title>  It has been widely observed in many problem domains [@bib:xu2010hydra,tang2014population] that there is no universal optimal solver dominating all other solvers on all problem instances.", "Instead, different solvers perform well on different problem instances.", "Thus a natural idea is to combine those complementary solvers together to achieve a better overall performance.", "Typical examples include algorithm selection methods [@bib:rice1976algorithm,xu2008satzilla,kotthoff2016algorithm] which try to select the best solver for every single problem instance before solving it, and adaptive solvers such as adaptive parameter control [@bib:karafotias2015parameter] , reactive search [@bib:battiti2008reactive] and hyper-heuristics [@bib:burke2013hyper] which seek to dynamically determine the best solver setting while solving a problem instance.", "In principle, all these methods need to involve some mechanisms (e.g., selection or scheduling) to appropriately allocate computational resource to different solvers.", "\\newline Recently parallel portfolios [@bib:gomes2001algorithm,tang2014population,lindauer2017automatic] as another paradigm of simultaneously utilizing several sequential solvers, have attracted more and more research interest.", "While solving a problem instance, parallel portfolios run all the component solvers in parallel until the first of them solves it; thus the performance of a parallel portfolio is always the best performance achieved by its component solvers.", "Different from algorithm selection and adaptive solvers, parallel portfolios do not necessarily require any extra resource allocation since each involved component solver is simply assigned with the same amount of resource.", "Moreover, the rapid growth of parallelism in computational power [@bib:gepner2006multi] makes such parallel solving strategy more and more critical for solving computationally hard problems.", "However, the manual construction of parallel portfolios is non-trivial.", "Specifically, identifying (or designing) a set of relatively uncorrelated sequential solvers which are complementary to each other still requires relatively significant domain knowledge [@bib:xu2010hydra] .", "\\newline Recently [@bib:lindauer2017automatic] proposed using automatic construction of parallel portfolios (ACPP) as a first step towards tackling parallel portfolio construction.", "The goal of ACPP is to automatically construct a parallel portfolio based on the rich design space induced by a highly parametrized sequential solver or a set of them.", "More formally, let $ C $ and $ I $ denote the configuration space of the parameterized solvers and the given set of problem instances, respectively.", "The parallel portfolio with $ k $ component solvers could be denoted as a $ k $ -tuple, i.e., $ P=(c_{1},...,c_{k}) $ , in which $ c_{i}\\in C $ is an individual configuration and represents the $ i $ -th component solver of $ P $ .", "The goal is to find $ c_{1},...,c_{k} $ from $ C $ , such that the performance of $ P $ on $ I $ according to a given metric $ m $ is optimized.", "\\newline There are three key ACPP methods, namely GLOBAL, $ \\mathrm{PARHYDRA} $ and CLUSTERING, in which GLOBAL and $ \\mathrm{PARHYDRA} $ are both proposed by [@bib:lindauer2017automatic] while CLUSTERING is adapted by [@bib:lindauer2017automatic] from $ \\mathrm{ISAC} $ [@bib:kadioglu2010isac] for comparison .", "Generally, these methods can be divided into two categories.", "GLOBAL belongs to the first category, which considers ACPP an algorithm configuration problem by directly treating $ P $ as a parameterized solver.", "By this means powerful automatic algorithm configurators such as ParamILS [@bib:hutter2009paramils] , GGA [@bib:ansotegui2009gender] , irace [@bib:ansotegui2009gender] and SMAC [@bib:hutter2011sequential] could be directly applied to configure $ P $ (GLOBAL uses SMAC in [@bib:lindauer2017automatic] ).", "The key issue of GLOBAL is that its scalability is limited since the size of the configuration space of $ P $ , i.e., $ |C|^{k} $ , increases exponentially with the number of the component solvers, i.e., $ k $ .", "The other two methods, $ \\mathrm{PARHYDRA} $ and CLUSTERING, solve the ACPP problem from the perspective of instance grouping.", "That is, they explicitly or implicitly promote different component solvers of $ P $ to handle different subsets of problem instances, with the goal that the resulting component solvers would be complementary to each other.", "More specifically, starting from an empty portfolio, $ \\mathrm{PARHYDRA} $ proceeds iteratively and in the $ i $ -th iteration it uses an algorithm configurator (also SMAC) to configure $ c_{i} $ to add to the current portfolio, i.e., $ (c_{1},...,c_{i-1}) $ , such that the performance of the resulting portfolio, i.e., $ (c_{1},...,c_{i-1},c_{i}) $ , is optimized.", "In other words, in each iteration $ \\mathrm{PARHYDRA} $ intrinsically aims to find a solver that can improve the current portfolio to the best extent.", "Since the greatest chance of the current portfolio getting improved is on those problem instances which cannot be solved satisfactorily, thus while $ \\mathrm{PARHYDRA} $ configuring the $ i $ -th component solver $ c_{i} $ , the configurator would actually promote $ c_{i} $ to handle those intractable instances to the current portfolio $ (c_{1},...,c_{i-1}) $ .", "Compared to $ \\mathrm{PARHYDRA} $ , CLUSTERING adopts a more explicit way to group instances.", "It clusters the problem instances in a given (normalized) instance feature space and then independently configures (using SMAC) a component solver on each instance cluster.", "The advantage of PARHDYRA and CLUSTERING is that they keep the size of the configuration space involved in each algorithm configuration task as $ |C| $ .", "\\newline The main issue of $ \\mathrm{PARHYDRA} $ is that its intrinsic greedy mechanism may cause stagnation in local optima.", "To alleviate this problem, [@bib:lindauer2017automatic] makes a modification to $ \\mathrm{PARHYDRA} $ by allowing simultaneously configuring several component solvers in each iteration.", "The resulting method is named $ \\mathrm{PARHYDRA_{b}} $ , where $ b\\ (b\\geq 1) $ is the number of the component solvers configured in each iteration.", "$ \\mathrm{PARHYDRA} $ and GLOBAL could be both seen as special cases of $ \\mathrm{PARHYDRA_{b}} $ with $ b=1 $ and $ b=k $ respectively.", "It is conceivable that the choice of $ b $ is very important for $ \\mathrm{PARHYDRA_{b}} $ since the tendency to stagnate in local optima would increase as $ b $ gets smaller, while the size of the configuration space involved in each configuration task in $ \\mathrm{PARHYDRA_{b}} $ , i.e., $ |C|^{b} $ , would grow exponentially as $ b $ gets larger.", "However, in general the best value of $ b $ may vary across different scenarios, and for a specific scenario it is very hard to determine a good choice of $ b $ in advance.", "\\newline For methods based on explicit instance grouping such as CLUSTERING, obviously the quality of the instance grouping is crucial.", "A good instance grouping should meet at least one requirement: The instances that are grouped together should be similar in the sense that in the configuration space $ C $ there exist same good configurations for them.", "CLUSTERING uses the distances in the normalized feature space to characterize such similarity.", "Although the problem features have been proved very useful for modeling the relationship between problem instances and solvers (e.g., algorithm selection), some practical issues still exist while applying CLUSTERING to ACPP.", "Specifically, the used instance features as well as the normalization of the features would greatly influence the final clustering results.", "However, determining appropriate choices of them is very hard since accurate assessment of the cluster quality relies on completely constructed portfolios.", "\\newline In this paper, we investigate further solving the ACPP problem based on explicit instance grouping.", "Specifically, we propose a new ACPP method named parallel configuration with instance transfer (PCIT) , which explicitly divides the instances into different subsets and configures a component solver on each subset.", "The most novel feature of PCIT is its dynamic instance transfer mechanism.", "Unlike CLUSTERING which determines the instance grouping in advance and then keeps it fixed through the whole process, during portfolio construction PCIT would dynamically adjust the instance grouping by transferring instances between different subsets.", "The instance transfer is conducted with the goal that the instances which share the same high-quality configurations (in the configuration space $ C $ ) would be grouped together, such that the complementarity between the component solvers configured on different subsets would be favourably enhanced.", "The experimental results showed that the parallel portfolios constructed by PCIT could achieve consistently superior performances to the ones output by the existing ACPP methods, and could even rival the state-of-the-art hand-designed parallel solvers.", "\\newline  </section>"], ["<section> <title> 2 Proposed Method </title>  The basic idea of PCIT is simple.", "Although it is hard to obtain an appropriate instance grouping at one stroke, it is possible to gradually improve an instance grouping.", "PCIT adopts a random splitting strategy to obtain an initial grouping; that is, the instances are evenly and randomly divided into $ k $ subsets.", "It is conceivable that the quality of random instance grouping is not guaranteed at all since there is no guidance involved in the grouping procedure.", "Consider a simple example where instance set $ I=\\{ins_{1},ins_{2},ins_{3},ins_{4}\\} $ , configuration space $ C=\\{\\theta_{1},\\theta_{2}\\} $ , $ ins_{1},ins_{2} $ shares the high-quality configuration $ \\theta_{1} $ and $ ins_{3},ins_{4} $ shares the high-quality configuration $ \\theta_{2} $ .", "Obviously the appropriate grouping for this example is $ \\{ins_{1},ins_{2}\\}\\{ins_{3},ins_{4}\\} $ , which would lead algorithm configurator to output $ \\theta_{1} $ and $ \\theta_{2} $ on the first and the second subset respectively, thus producing the optimal portfolio $ P=\\{\\theta_{1},\\theta_{2}\\} $ .", "Random splitting strategy may fail on this example if it happens to split $ I $ as $ \\{ins_{1},ins_{3}\\}\\{ins_{2},ins_{4}\\} $ or $ \\{ins_{1},ins_{4}\\}\\{ins_{2},ins_{3}\\} $ , which could cause algorithm configurator to output the same component solver i.e., $ (\\theta_{1},\\theta_{1}) $ or $ (\\theta_{2},\\theta_{2}) $ , on both subsets.", "\\newline The key point here is that if the problem instances grouped together do not share the same high-quality configurations, then the cooperation between the component solvers configured on these subsets would be much affected, thus limiting the quality of the final output parallel portfolio.", "To handle this issue, PCIT employs an instance transfer mechanism to improve the instance grouping during the construction process by transferring instances between different subsets.", "More specifically, as the configuration process of a component solver on a subset proceeds, if the algorithm configurator cannot manage to find a common high-performance configuration for every instance in the subset but only some of them, then it can be inferred that these intractable instances may correspond to different high-quality configurations (in the configuration space $ C $ ) from others.", "It is therefore better to transfer these instances to other subsets that are more suitable to them.", "\\newline PCIT conducts the instance transfer with the help of incumbent configurations (i.e., the best configurations found by the algorithm configurator).", "In each subset, the instances which cannot be solved satisfactorily by the corresponding incumbent are identified as the ones that need to be transferred, and the target subset of each transferred instance is determined according to how well the incumbent on the candidate subset could perform on the instance.", "In essence, the incumbent on a subset can be seen as a common special characteristic of those \u201csimilar\u201d instances (in the sense they share the same high-quality configurations) within the subset, and PCIT uses it to identify those \u201cdissimilar\u201d instances and find better subsets for them.", "In each subset, the performance of the incumbent on each instance could be obtained from the rundata collected from the configuration process.", "However, while determining the target subsets for the transferred instances, how well the incumbents on the candidate subsets would perform on the transferred instances are unknown.", "One way to obtain these performances is to actually test these incumbents on the transferred instances, which however would introduce considerable additional computational costs.", "To avoid this, PCIT builds empirical performance models (EPM) [@bib:hutter2014algorithm] based on the collected rundata to predict these performances.", "\\newline <subsection> <title> 2.1 Algorithm Framework </title> The pseudo-code of PCIT is given in Algorithm [@ref:LABEL:PCIT] .", "The main difference between PCIT and the existing methods (e.g., GLOBAL and CLUSTERING) is that in PCIT the portfolio construction process is divided into $ n $ (we always set $ n=4 $ in this paper) sequential phases (Lines 3-13 in Algorithm [@ref:LABEL:PCIT] ).", "The first $ (n-1) $ phases serve as adjustment phases, in each of which the instance grouping is adjusted (Line 12) once the configuration procedures for all component solvers (Lines 9-11) finish.", "The last phase is the construction phase in which the component solvers of the final portfolio are configured on the obtained subsets with a large amount of time.", "In fact, the time consumed for the configuration processes in the last phase amounts to the sum of the time consumed for the configuration processes in the first $ (n-1) $ phases (Lines 4-8).", "One thing which is not detailed in Algorithm [@ref:LABEL:PCIT] for brevity is that, on each subset, to keep the continuity of the configuration processes across successive phases, the incumbent configuration obtained in the previous phase is always used to initialize the configuration procedure in the next phase.", "\\newline <float> PCIT Input: parameterized solvers with configuration space $ C $ ; number of component solvers $ k $ ; instance set $ I $ ; performance metric $ m $ ; configurator $ AC $ ; number of independent runs of portfolio construction $ r_{pc} $ ; time budget for configuration process $ t_{c} $ ; time budget for validation process $ t_{v} $ ; number of stages $ n $ ; features $ F $ for all instances in $ I $ \\newline Output: parallel portfolio $ (c_{1},..,c_{k}) $ \\newline \\ for $ i:=1...r_{pc} $ do \\ \\ Randomly and evenly split $ I $ into $ I_{1},...,I_{k} $ \\ \\ for $ phase:=1...n $ do \\ \\ if $ phase $ = $ n $ then \\ \\ $ t\\leftarrow\\frac{t_{c}}{2} $ \\ \\ else \\ \\ $ t\\leftarrow\\frac{t_{c}}{2(n-1)} $ \\ \\ end if \\ \\ for $ j:=1...k $ do \\ \\ Obtain component solver $ c_{j} $ by running $ AC $ on configuration space $ C $ on $ I_{j} $ using $ m $ for time $ t $ \\ \\ end for \\ \\ $ I_{1},...I_{k}\\leftarrow\\textrm{InsTransfer}(I_{1},...I_{k},c_{1},...c_{k},F) $ \\ \\ end for \\ \\ $ P_{i}\\leftarrow(c_{1},...,c_{k}) $ \\ \\ end for \\ \\ Validate each of $ P_{1},...,P_{r_{pc}} $ on $ I $ using $ m $ for time $ t_{v} $ \\ \\ Let $ P $ be the portfolio which achieved the best validation performance \\ \\ return $ P $ \\ </float> \\newline Another important difference between PCIT and the existing methods lies in the way of obtaining reliable outputs.", "For existing methods, the uncertainty of the portfolio construction results mainly comes from the randomness of the output of the algorithm configurator (especially when the given parametrized solvers are not deterministic).", "Thus for each specific algorithm configuration task, typically they conduct multiple independent runs of the algorithm configurator (with different random seeds), and then validate the configurations produced by these runs to determine the output one.", "For PCIT, in addition to the randomness mentioned above, a greater source of uncertainty is the randomness of the initial instance grouping results.", "One way to handle both of them is to perform multiple runs of portfolio construction (with different initial instance groupings), and in each construction process the algorithm configurator is also run for multiple times for each configuration task.", "In this paper, to keep the design simple, we only allow repeated runs of portfolio construction and rely on the validation to ensure the reliability of the final output (Lines 16-18 in Algorithm [@ref:LABEL:PCIT] ).", "\\newline PCIT can be easily performed in parallel.", "First, different portfolio construction runs (Lines 1-15 in Algorithm [@ref:LABEL:PCIT] ) can be executed in parallel, and second, during each construction run the configuration processes for different component solvers (Lines 9-11 in Algorithm [@ref:LABEL:PCIT] ) can also be executed in parallel.", "\\newline </subsection> <subsection> <title> 2.2 Instance Transfer </title> As shown in Algorithm [@ref:LABEL:IT] , the instance transfer procedure first builds an empirical performance model (EPM) based on the rundata collected from all the previous algorithm configuration processes (Line 1).", "More specifically, the rundata is actually records of runs of different solver configurations on different instances, and each run can be represented by a 3-tuple, i.e., $ (config,ins,result) $ .", "The exact implementation of EPM here is the same as the one in SMAC [@bib:hutter2011sequential] , which is a random forest that takes as input a solver configuration $ config $ and a problem instance $ ins $ (represented by a feature vector), and predicts performance of $ config $ on $ ins $ .", "The performances of the incumbent configuration on instances in each subset are obtained by querying the corresponding runs in rundata (Line 2).", "After collecting all of them, the median value is used to identify the instances which will be transferred (without loss of generality, we assume a smaller value is better for $ m $ ) (Line 3).", "Then these instances are examined one by one in a random order (Lines 7-22), for each examined instance the target subset is determined according to three rules (Line 13): 1) Both the source subset and the target subset will not violate the constraints on the subset size after the instance is transferred; 2) The predicted performance on the instance is not worse on the target subset; 3) The target subset is the one with the best predicted performance among the ones satisfying 1) and 2).", "The subset size constraints, i.e., the lower bound $ L $ and the upper bound $ U $ in Algorithm [@ref:LABEL:IT] , are set to prevent the occurrence of too large or too small subsets.", "In this paper $ L $ and $ U $ are set as $ \\lceil(1\\pm 0.2)\\frac{|I|}{k}\\rceil $ , respectively.", "Since the sizes of the subsets keep changing during the instance transfer process, there is a possibility that an instance, which was examined earlier and at that time no target subset satisfying the above conditions was found, has a satisfactory target subset later.", "To handle this situation, instances which are not successfully transferred will be examined again in the next round (Line 26), and the whole procedure will be terminated (Lines 23-25) if there is no instance which needs to be transferred, or there is no successful transfer in a round (Lines 7-22).", "\\newline <float> InsTransfer $ R $ is the run data collected from all the previous algorithm configuration processes.", "$ L $ and $ U $ are the lower bound and the upper bound of the size of a subset, respectively.", "\\newline Input: instance subsets $ I_{1},...,I_{k} $ , incumbent configurations $ c_{1},...,c_{k} $ , instance features $ F $ \\newline Output: instance subsets $ I_{1},...,I_{k} $ \\newline \\ Build an $ EPM $ based on $ R $ and $ F $ \\ \\ For each instance $ ins $ in each subset, obtain the performance of the corresponding incumbent configuration on it from $ R $ , denoted as $ P(ins) $ \\ \\ Let $ v $ be the median value of all $ P(ins) $ across all subsets, and the instances with bigger values than $ v $ are identified as the ones which need to be transferred, denoted as $ T $ \\ \\ while $ true $ do \\ \\ $ T_{success}\\leftarrow\\varnothing $ \\ \\ $ T_{remaining}\\leftarrow\\varnothing $ \\ \\ while $ T\\neq\\varnothing $ do \\ \\ Randomly select an instance $ ins $ from $ T $ and let $ I_{s} $ and $ c_{s} $ be the subset containing $ ins $ and the corresponding incumbent configuration, respectively \\ \\ $ T\\leftarrow T-\\{ins\\} $ \\ \\ For each incumbent configuration $ c $ of $ c_{1},...c_{k} $ , use $ EPM $ to obtain the predicted performance of $ c $ on $ ins $ , denoted as $ E(c) $ .", "\\ \\ Sort $ c_{1},...c_{k} $ according to the goodness of $ E(c_{1}),...,E(c_{k}) $ , denoted as $ c_{\\pi(1)},...,c_{\\pi(k)} $ \\ \\ for $ j:=1...k $ do \\ \\ if $ E(c_{\\pi(j)})\\leq E(c_{s})\\ \\&\\&\\ |I_{\\pi(j)}|<U\\ \\&\\&\\ |I_{s}|>L $ then \\ \\ $ I_{s}\\leftarrow I_{s}-\\{ins\\},I_{\\pi(j)}\\leftarrow I_{\\pi(j)}\\cup\\{ins\\} $ \\ \\ $ T_{success}\\leftarrow T_{success}\\cup\\{ins\\} $ \\ \\ break \\ \\ end if \\ \\ end for \\ \\ if $ ins\\notin T_{success} $ then \\ \\ $ T_{remaining}\\leftarrow T_{remaining}\\cup\\{ins\\} $ \\ \\ end if \\ \\ end while \\ \\ if $ T_{success}=\\varnothing\\ ||\\ T_{remaining}=\\varnothing $ then \\ \\ break \\ \\ end if \\ \\ $ T\\leftarrow T_{remaining} $ \\ \\ end while \\ \\ return $ I_{1},...I_{k} $ \\ </float> \\newline </subsection> <subsection> <title> 2.3 Computational Costs </title> The computational costs of ACPP methods are mainly composed of two parts: the costs of configuration processes and the costs of validation.", "For PCIT, the total CPU time consumed is $ r_{pc}\\cdot k\\cdot(t_{c}+t_{v}) $ (the small overhead introduced by instance transfer in PCIT is ignored here).", "Similarly, for GLOBAL and CLUSTERING, it is $ r_{ac}\\cdot k\\cdot(t_{c}+t_{v}) $ , where $ r_{ac} $ is the number of independent runs of algorithm configurator (for each configuration task).", "For $ \\mathrm{PARHYDRA_{b}} $ , the consumed CPU time is $ r_{ac}\\cdot\\sum_{i=1}^{\\frac{k}{b}}[i\\cdot b\\cdot(t_{c}^{b}+t_{v}^{b})] $ , where $ t_{c}^{b} $ and $ t_{v}^{b} $ refer in particular to the configuration time budget and the validation time budget used in $ \\mathrm{PARHYDRA_{b}} $ (See [@bib:lindauer2017automatic] for more details).", "\\newline </subsection>  </section>"], ["<section> <title> 3 Empirical Study </title>  We conducted experiments on two widely studied domains, SAT and TSP.", "Specifically, we used our method to build parallel portfolios based on a training set, and then compared them with the ones constructed by the existing methods, on an unseen test set.", "\\newline <subsection> <title> 3.1 Experimental Setup </title> <subsubsection> <title> 3.1.1 Portfolio Size and Performance Metric </title> We set the number of component solvers to 8 (same as [@bib:lindauer2017automatic] ), since 8-core (and 8-thread) machines are widely available now.", "The optimization goal considered here is to minimize the time required by a solver to solve the problem (for SAT) or to find the optimum of the problem (for TSP).", "In particular, we set the performance metric to Penalized Average Runtime\u201310 (PAR-10) [@bib:hutter2009paramils] , which counts each timeout as 10 times the given cutoff time.", "The optimal solutions for TSP instances were obtained using Concorde [@bib:applegate2006concorde] , an exact TSP solver.", "\\newline </subsubsection> <subsubsection> <title> 3.1.2 Scenarios </title> For each problem domain we considered constructing portfolios based on a single parameterized solver and based on multiple parameterized solvers, resulting in four different scenarios.", "For brevity, we use SAT/TSP-Single/Multi to denote these scenarios.", "Table [@ref:LABEL:tab:scenario] summarizes the used instance sets, cutoff time, and base parameterized solvers in each scenario.", "Except in SAT-Multi we reused the settings from [@bib:lindauer2017automatic] , in the other three scenarios we all used new settings which had never been considered before in the literature of ACPP.", "We especially note that this was the first time the ACPP methods were applied to TSP.", "Settings in SAT-Multi are the same as the ones in [@bib:lindauer2017automatic] : 1) Instance set obtained from the application track of the SAT\u201912 Challenge were randomly and evenly split into a training set and a test set, and to ensure the computational costs for portfolio construction would not be prohibitively large, the cutoff time used in training (180s) was smaller than the one used in testing (900s, same as the SAT\u201912 challenge); 2) The parameterized solvers in SAT-Multi (the configuration space $ C $ contains 150 parameters in total, including a top-level parameter used to select a base solver) were the 8 sequential solvers considered by [@bib:wotzlaw2012pfoliouzk] when designing pfolioUZK, the gold medal winning solver in the parallel track of the SAT\u201912 Challenge.", "In SAT-Single, we chose instances from the benchmark used in the agile track of the SAT\u201916 Competition for its moderate cutoff time (60s).", "Specifically, we randomly selected 2000 instances from the original benchmark (containing 5000 instances) and divided them evenly for training and testing.", "We chose Riss6 [@bib:manthey2016riss] , the gold medal winning solver of this track, as the base solver.", "Since Riss6 exposes a large number of parameters, we selected 135 parameters from them to be tunable while leaving others as default.", "For TSP-Single and TSP-Multi we used a same instance set.", "Specifically, we used the $ portgen $ and the $ portcgen $ generators from the 8th DIMACS Implementation Challenge to generate 1000 \u201cuniform\u201d instances (in which the cities are randomly distributed) and 1000 \u201cclustering\u201d instances (in which the cities are distributed around different central points).", "The problem sizes of all these generated instances are within $ [1500,2500] $ .", "Once again, we divided them evenly for training and testing.", "The base solver used in TSP-Single was LKH version 2.0.7 [@bib:helsgaun2000effective] (with 35 parameters), one of the state-of-the-art inexact solver for TSP.", "In TSP-Multi, in addition to LKH, we included another two powerful TSP solvers, GA-EAX version 1.0 [@bib:nagata2013powerful] (with 2 parameters) and CLK [@bib:applegate2003chained] (with 4 parameters), as the base solvers, resulting in a configuration space containing 43 parameters (including a top-level parameter used to select a base solver).", "\\newline </subsubsection> <subsubsection> <title> 3.1.3 Competitors and Time Budgets </title> Besides PCIT, we implemented GLOBAL, $ \\mathrm{PARHYDRA_{b}} $ (with b=1,2,4), and CLUSTERING (with normalization options including linear normalization, standard normalization and no normalization), as described in [@bib:lindauer2017automatic] for comparison.", "For all considered ACPP methods here, SMAC version 2.10.03 [@bib:hutter2011sequential] was used as the algorithm configurator.", "Since the performance of SMAC could be often improved when used with the instance features, we gave SMAC access to the 126 SAT features used in [@bib:hutter2011sequential] , and the 114 TSP features used in [@bib:kotthoff2015improving] .", "The same features were also used by PCIT (for transferring instances) and CLUSTERING (for clustering instances).", "To make the comparisons fair, the total CPU time consumed by each method was kept almost the same.", "The detailed setting of time budget for each method is given in Table [@ref:LABEL:tab:cputime] .", "To validate whether the instance transfer in PCIT is useful, we included another method, named PCRS (parallel configuration with random splitting), in the comparison.", "PCRS differs from PCIT in that it directly configures the final portfolios on the initial random instance grouping and involves no instance transfer.", "The time budgets for PCRS were the same as PCIT.", "\\newline </subsubsection> <subsubsection> <title> 3.1.4 Baselines </title> For each scenario, we identified a sequential solver as the baseline by using SMAC to configure on the training set and the configuration space of the scenario.", "\\newline </subsubsection> <subsubsection> <title> 3.1.5 Experimental Environment </title> All the experiments were conducted on a cluster of 5 Intel Xeon machines with 60 GB RAM and 6 cores each (2.20 GHz, 15 MB Cache), running Centos 7.5.", "\\newline </subsubsection> </subsection> <subsection> <title> 3.2 Results </title> We tested each solver (including the ACPP portfolios and the baseline) by running it on each test instance for 3 times, and reported the median performance.", "The obtained number of timeouts (#TOS), PAR-10 and PAR-1 are presented in Table [@ref:LABEL:tab:results_1] .", "For CLUSTERING and $ \\mathrm{PARHYDRA_{b}} $ , we always reported the best performance achieved by their different implementations.", "To determine whether the performance differences between these solvers were significant, we performed a permutation test (with 100000 permutations and significance level $ p=0.05 $ ) to the (0/1) timeout scores, the PAR-10 scores and the PAR-1 scores.", "Overall the portfolios constructed by PCIT achieved the best performances in Table [@ref:LABEL:tab:results_1] .", "In SAT-Single, SAT-Multi and TSP-Single, it achieved significantly and substantially better performances than all the other solvers.", "Although in TSP-Multi, the portfolio constructed by $ \\mathrm{PARHYDRA_{b}} $ obtained slightly better results than the one constructed by PCIT (however the performance difference is insignificant), as aforementioned, the appropriate value of $ b $ varied across different scenarios (as shown in Table [@ref:LABEL:tab:results_1] ) and for a specific scenario it was actually unknown in advance (in TSP-Multi it was 2).", "Similarly, as shown in Table [@ref:LABEL:tab:results_1] , the best normalization strategy for CLUSTERING also varied across different scenarios.", "Compared to the portfolios constructed by PCRS, the ones constructed by PCIT consistently obtain much better results, which verified the effectiveness of the instance transfer mechanism of PCIT.", "Finally, all the ACPP methods here could build portfolios that obtained much better results than the baselines, indicating the great benefit by combining complementary configurations obtained from a rich design space.", "\\newline To further evaluate the portfolios constructed by PCIT, we compared them with the state-of-the-art manually designed parallel solvers.", "Specifically, we considered the ones constructed for SAT.", "We chose Priss6 [@bib:manthey2016riss] to compare with the one constructed in SAT-Single, since Priss6 is the official parallel version of Riss6 (the base solver in SAT-Single).", "For the same reason, we chose PfolioUZK [@bib:wotzlaw2012pfoliouzk] (the gold medal winning solver of the parallel track of the SAT\u201912 Challenge) to compare with the one constructed in SAT-Multi.", "Finally, we chose Plingeling (version bbc) [@bib:biere2016splatz] , the gold medal winning solver of the parallel track of the SAT\u201916 Competition, to compare with both.", "Note that all the manually designed solvers considered here have implemented far more advanced solving strategies (e.g., clause sharing) than only independently running component solvers in parallel.", "In the experiments the default settings of these solvers were used and the same statistical tests as before were conducted."]], "target": "As shown in Table , on SAT-Single test set, the portfolio constructed by PCIT achieved much better results than others. This may be because the parallel solvers considered here are not designed for the type of these instances (obtained from the SAT\u201916 Competition Agile track, which is for simple fast SAT solvers with low overhead), which on the other hand demonstrates the wide applicability of ACPP methods. It is impressive that, on SAT-Multi test set, the portfolio constructed by PCIT (regardless of its simple solving strategy) obtained slightly better results than pfolioUZK, and could reach the performance level of the more state-of-the-art Plingeling. Such results imply that the portfolios constructed by PCIT may be a good staring point for designing more powerful parallel solvers."}, {"tabular": ["  Dataset  &  Type  &  Th.  &  source  &  target  &  both ", " DailyDialog  &  id  &  1  &  5.64%  &  6.98%  &  12.2% ", " ae  &  3.5  &  5.39%  &  7.06%  &  12.0% ", " sc  &  3.5  &  6.53%  &  8.45%  &  14.3% ", " Cornell  &  id  &  4  &  -  &  7.39%  &  14.1% ", " Twitter  &  id  &  0.5  &  -  &  1.82%  &  9.96% ", "  &    &    &    &    &    "], "ref_sec": [["<section> <title> 1 Introduction </title>  Current open-domain neural conversational models (NCM) are trained on pairs of source and target utterances in an effort to maximize the likelihood of each target given the source [@bib:Vinyals:2015d] .", "However, real-world conversations are much more complex, and a plethora of suitable targets (responses) can be adequate for a given input.", "We propose a data filtering approach where the \u2018\u2018most open-ended\u2019\u2019 inputs - determined by calculating the entropy of the distribution over target utterances - are excluded from the training set.", "We show that dialog models can be improved using this simple unsupervised method which can be applied to any conversational dataset.", "We conduct several experiments to uncover how some of the current open-domain dialog evaluation methods behave with respect to overfitting and random data.", "Our software for filtering dialog data and automatic evaluation using 17 metrics is released on GitHub under an MIT license .", "This paper exists in poster and blog post form as well.", "\\newline  </section>"], ["<section> <title> 2 Background </title>  Most open-domain NCMs are based on neural network architectures developed for machine translation (MT, [@bib:Sutskever:2014,Cho:2014,Vaswani:2017] ).", "Conversational data differs from MT data in that targets to the same source may vary not only grammatically but also semantically [@bib:Wei:2017,Tandon:2017] : consider plausible replies to the question What did you do today? .", "Dialog datasets also contain generic responses, e.g. yes , no and i don\u2019t know , that appear in a large and diverse set of contexts [@bib:Mou:2016,Wu:2018] .", "Following the approach of modeling conversation as a sequence to sequence ( seq2seq , [@bib:Sutskever:2014] ) transduction of single dialog turns, these issues can be referred to as the one-to-many , and many-to-one problem.", "seq2seq architectures are not suited to deal with the ambiguous nature of dialogs since they are inherently deterministic, meaning that once trained they cannot output different sequences to the same input.", "Consequently they tend to produce boring and generic responses [@bib:Li:2016d,Wei:2017,Shao:2017b,Zhang:2018a,Wu:2018] .", "\\newline Previous approaches to the one-to-many , many-to-one problem can be grouped into three categories.", "One approach involves feeding extra information to the dialog model such as dialog history [@bib:Serban:2015,Xing:2018] , categorical information like persona [@bib:Li:2016a,Joshi:2017,Zhang:2018] , mood/emotion [@bib:Zhou:2018,Li:2017b] , and topic [@bib:Xing:2017,Liu:2017,Baheti:2018] , or through knowledge-bases [@bib:Dinan:2018,Ghazvininejad:2018,Zhu:2017,Moghe:2018] .", "A downside to these approaches is that they require annotated datasets which are not always available, or might be smaller in size.", "Augmenting the model itself, with e.g. latent variable sampling [@bib:Serban:2017b,Zhao:2017,Zhao:2018a,Gu:2019,Park:2018,Shen:2018,Gao:2019] , or improving the decoding process [@bib:Shao:2017b,Kulikov:2018,Mo:2017,Wang:2018a] is also a popular approach.", "Sampling provides a way to generate more diverse responses, however such models are more likely to output ungrammatical or irrelevant responses.", "Finally, directly modifying the loss function [@bib:Li:2016d] , or training by reinforcement [@bib:Li:2016b,Serban:2017a,Li:2016c,Lipton:2017,Lewis:2017] or adversarial learning [@bib:Li:2017a,Ludwig:2017,Olabiyi:2018,Zhang:2018b] has also been proposed, but this is still an open research problem, as it is far from trivial to construct objective functions that capture conversational goals better than cross-entropy loss.", "\\newline Improving dataset quality through filtering is frequently used in the machine learning literature [@bib:Sedoc:2018,Ghazvininejad:2018,Wojciechowski:2002] and data distillation methods in general are used both in machine translation and dialog systems [@bib:Axelrod:2011,Li:2017c] .", "[@bib:Xu:2018] introduced coherence for measuring the similarity between contexts and responses, and then filtered out pairs with low coherence.", "This improves datasets from a different aspect and could be combined with our present approach.", "However, natural conversations allow many adequate responses that are not similar to the context, thus it is not intuitively clear why filtering these should improve dialog models.", "Our experiments also further support that cross-entropy is not an adequate loss function (shown qualitatively by [@bib:Csaky:2017] and [@bib:Tandon:2017] ), by showing that many automatic metrics continue to improve after the validation loss reaches its minimum and starts increasing.", "However, we found that the metrics steadily improve even after we can be certain that the model overfitted (not just according to the loss function).", "Further research is required, to determine whether this indicates that overfitted model responses are truly better or if it\u2019s a shortcoming of the metrics that they prefer such models.", "\\newline Currently, there is no well-defined automatic evaluation method [@bib:Liu:2016] , and while some metrics that correlate more with human judgment have been proposed recently [@bib:Li:2017a,Lowe:2017,Tao:2018] , they are harder to measure than simpler automatic metrics like perplexity or BLEU [@bib:Papineni:2002] .", "Furthermore, even human evaluation has its downsides, like high variance, high cost, and difficulty of replicating experimental setups [@bib:Zhang:2018,Tao:2018] .", "Some works resort to human evaluations [@bib:Krause:2017a,Fang:2018] , others use automatic metrics only [@bib:Olabiyi:2018,Xing:2018a,Kandasamy:2017,Shalyminov:2018,Xu:2018] , and some use both [@bib:Shen:2018a,Xu:2018a,Baheti:2018,Ram:2018] .", "While extensive human evaluation of the methods presented here is left for future work, we do conduct an especially thorough automatic evaluation both at the validation loss minimum and of overfitted models.", "We believe our experiments also shed light on the limitations of frequently used automatic metrics.", "\\newline  </section>"], ["<section> <title> 3 Methods </title>  <subsection> <title> 3.1 Intuition </title> We approach the one-to-many , many-to-one problem from a relatively new perspective: instead of adding more complexity to NCMs, we reduce the complexity of the dataset by filtering out a fraction of utterance pairs that we assume are primarily responsible for generic/uninteresting responses.", "Of the 72 000 unique source utterances in the DailyDialog dataset (see Section [@ref:LABEL:ssec:dataset] for details), 60 000 occur with a single target only.", "For these it seems straightforward to maximize the conditional probability $ P(T|S) $ , $ S $ and $ T $ denoting a specific source and target utterance.", "However, in the case of sources that appear with multiple targets ( one-to-many ), models are forced to learn some \u201caverage\u201d of observed responses [@bib:Wu:2018] .", "\\newline The entropy of response distribution of an utterance $ s $ is a natural measure of the amount of \u201cconfusion\u201d introduced by $ s $ .", "For example, the context What did you do today? has high entropy, since it is paired with many different responses in the data, but What color is the sky?", "has low entropy since it\u2019s observed with few responses.", "The many-to-one scenario can be similarly formulated, where a diverse set of source utterances are observed with the same target (e.g. I don\u2019t know has high entropy).", "While this may be a less prominent issue in training NCMs, we shall still experiment with excluding such generic targets, as dialog models tend to generate them frequently (see Section [@ref:LABEL:sec:background] ).", "\\newline </subsection> <subsection> <title> 3.2 Clustering Methods and Filtering </title> We refer with identity to the following entropy computation method.", "For each source utterance $ s $ in the dataset we calculate the entropy of the conditional distribution $ T|S=s $ , i.e. given a dataset $ D $ of source-target pairs, we define the target entropy of $ s $ as \\newline <equation> $ H_{\\text{tgt}}(s,D)=-\\sum_{(s,t_{i})\\in D}p(t_{i}|s)\\log_{2}p(t_{i}|s) $ </equation> Similarly, source entropy of a target utterance is \\newline <equation> $ H_{\\text{src}}(t,D)=-\\sum_{(s_{i},t)\\in D}p(s_{i}|t)\\log_{2}p(s_{i}|t) $ </equation> The probabilities are based on the observed relative frequency of utterance pairs in the data.", "\\newline For the purposes of this entropy-based filtering, we considered the possibility of also including some form of similarity measure between utterances that would allow us to detect whether a set of responses is truly diverse, as in the case of a question like What did you do today? , or diverse only on the surface, such as in the case of a question like How old are you? (since answers to the latter are semantically close).", "Measuring the entropy of semantic clusters as opposed to individual utterances may improve our method by reducing data sparsity.", "For example How are you? can appear in many forms, like How are you <name>? (see Section [@ref:", "LABEL:ssec:sent2vec_results] ).", "While the individual forms have low entropy (because they have low frequency), we may decide to filter them all if together they form a high-entropy cluster.", "\\newline To this end we performed the filtering based not only on the set of all utterances, as in the case of identity , but also on clusters of utterances established by clustering their vector representations using the Mean Shift algorithm [@bib:Fukunaga:1975] .", "Source and target utterances are clustered separately.", "In the avg-embedding setup the representation $ R(U) $ of utterance $ U $ is computed by taking the average word embedding weighted by the smooth inverse frequency $ R(U)=\\frac{1}{|U|}\\sum_{w\\in U}\\frac{E(w)\\cdot 0.001}{0.001+p(w)} $ of words [@bib:Arora:2016a] , where $ E(w) $ and $ p(w) $ are the embedding and the probability of word $ w $ respectively.", "We also experiment with sent2vec , a more sophisticated sentence embedding approach, which can be thought of as an extension of word2vec to sentences [@bib:Pagliardini:2018] .", "\\newline The target entropy of a source cluster $ c_{s} $ is \\newline <equation> $ H_{\\text{tgt}}(c_{s},C)=-\\sum_{c_{i}\\in C}p(c_{i}|c_{s})\\log_{2}p(c_{i}|c_{s}) $ </equation> where $ C $ is the set of all clusters and $ p(c_{i}|c_{s}) $ is the conditional probability of observing an utterance from cluster $ i $ after an utterance from cluster $ s $ .", "In the context of these methods, the entropy of an utterance will mean the entropy of its cluster.", "Note that identity is a special case of this cluster-based entropy computation method, since in identity a \u201ccluster\u201d is comprised of multiple examples of one unique utterance.", "Thus a target cluster\u2019s entropy is computed similarly to Equation [@ref:LABEL:eq:source_entropy] , but using clusters as in Equation [@ref:", "LABEL:eq:target_cluster_entropy] .", "\\newline Entropy values obtained with each of these methods were used to filter dialog data in three ways.", "The source approach filters utterance pairs in which the source utterance has high entropy, target filters those with a high entropy target, and finally the both strategy filters all utterance pairs that are filtered by either source or target .", "Some additional techniques did not yield meaningful improvement and were excluded from further evaluation.", "Clustering based on the Jaccard similarity of the bag of words of utterances only added noise to identity and resulted in much worse clusters than sent2vec .", "Clustering single occurrences of each unique utterance (as opposed to datasets with multiplicity) lead to less useful clusters than when clustering the whole dataset, probably because it resulted in less weight being given to the frequent utterances that we want to filter out.", "K-means proved inferior to the Mean Shift algorithm, which is a density-based clustering algorithm and seems to work better for clustering vectors of sentences.", "Filtering stop words before clustering did not improve the quality of clusters, probably because many utterances that we want to filter out contain a large number of stop words.", "\\newline </subsection>  </section>"], ["<section> <title> 4 Data Analysis </title>  <subsection> <title> 4.1 Dataset </title> With 90 000 utterances in 13 000 dialogs, DailyDialog [@bib:Li:2017b] , our primary dataset, is comparable in size with the Cornell Movie-Dialogs Corpus [@bib:Danescu:2011] , but contains real-world conversations.", "Using the identity approach, about 87% of utterances have 0 entropy (i.e. they do not appear with more than one target), 5% have an entropy of 1 (e.g. they appear twice, with different targets), remaining values rise sharply to 7.", "This distribution is similar for source and target utterances.", "\\newline Entropy is clearly proportional to utterance frequency (Figure [@ref:LABEL:fig:frequencies] ), but has a wide range of values among utterances of equal frequency.", "For example, utterances with a frequency of 3 can have entropies ranging from 0 to $ \\log_{2}3\\approx 1.58 $ , the latter of which would be over our filtering threshold of 1 (see Section [@ref:LABEL:ssec:parameters] for details on selecting thresholds).", "Since high-entropy utterances are relatively short, we also examined the relationship between entropy and utterance length (Figure [@ref:LABEL:fig:length] ).", "Given the relationship between frequency and entropy, it comes as no surprise that longer utterances have lower entropy.", "\\newline </subsection> <subsection> <title> 4.2 Clustering Results </title> Compared to identity , both sent2vec and avg-embedding produce a much lower number of clusters with 0 entropy, but also a huge cluster with more than 5000 elements (the size of the second largest cluster is below 500), which we didn\u2019t filter since it clearly doesn\u2019t group utterances with similar meaning.", "Generally, clusters were formed of similar utterances with the occasional exception of longer outlier utterances clustered together (instead of creating a separate cluster for each outlier), which can be attributed to the nature of the clustering algorithm.", "Overall, sent2vec appeared to produce better clusters than avg-embedding , as reflected in the evaluation in Section [@ref:LABEL:sec:filt_experiments] .", "\\newline We experimented with different bandwidth values for the Mean Shift algorithm to produce clusters with as many elements as possible while also keeping the elements semantically similar.", "In an example cluster (Figure [@ref:LABEL:fig:cluster_examples] ) we can see that the clustering was able to group together several variants of How are you? , in particular, those with different names.", "In general, we noticed that both in the case of identity and the clustering methods, utterances labeled with the highest entropy are indeed those generic sources and replies which we hoped to eliminate.", "See Appendix [@ref:LABEL:ssec:high_entropy] for a selection of high entropy utterances and clusters.", "\\newline </subsection>  </section>"], ["<section> <title> 5 Experiments </title>  In this section the model and parameter setups are presented along with 17 evaluation metrics.", "Limitations of these metrics are discussed and a comparison between our filtering methods is presented on DailyDialog (Section [@ref:LABEL:ssec:results] ), and other datasets (Section [@ref:LABEL:ssec:other_datasets] ).", "\\newline <subsection> <title> 5.1 Model and Parameters </title> We use transformer [@bib:Vaswani:2017] as our dialog model, an encoder-decoder architecture relying solely on attention mechanisms [@bib:Bahdanau:2015] .", "transformer has already been applied to a plethora of natural language processing tasks, including dialog modeling [@bib:Dinan:2018,Mazare:2018,Devlin:2018] .", "We used the official implementation (see Appendix [@ref:LABEL:ssec:parameters_appendix] for a report of hyperparameters).", "The vocabulary for DailyDialog was limited to the most frequent 16 384 words, and train / validation / test splits contained 71 517 / 9 027 / 9 318 examples, respectively.", "\\newline <paragraph> <title> Clustering and Filtering.", "</title> For avg-embedding fastText embeddings were used.", "The bandwidth of Mean Shift was set to 0.7 and 3.5 for avg-embedding and sent2vec , which produced 40 135 and 23 616 clusters, respectively."]], "target": "Entropy thresholds and amount of data filtered can be found in Table . Generally we set the threshold so that filtered data amount is similar to the DailyDialog identity scenario."}]