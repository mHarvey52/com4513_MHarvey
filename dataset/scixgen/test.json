[{"tabular": ["    &  Azimuth of the captured objects ", "  &  \u200b10-61  &  \u200b78-129  &  \u200b146-197  &  \u200b214-265  &  \u200b282-333 ", " Source  &  $ M $  &  $ M/r $  &  $ M/r $  &  $ M/r^{2} $  &  $ M/r $ ", " Target  &  $ M/r^{2} $  &  $ M/r $  &  $ M/r $  &  $ M $  &  $ M/r $  "], "ref_sec": [["<section> <title> 1 Introduction </title>  In many algorithms for supervised learning, it is assumed that training data are obtained from the same distribution as that of test data [@bib:Hastie2009] .", "Unfortunately, this assumption is often violated in practical applications.", "For example, Fig. [@ref:LABEL:fig:exm_video] shows images of two different surveillance videos that are obtained from Video Surveillance Online Repository [@bib:Vezzani2010] .", "Suppose we want to recognize vehicles from these videos.", "Since the position and pose of the camera are different, the appearance of the vehicle is somewhat different between two videos.", "Due to this difference, even if we train a highly accurate classifier on video A, it may work poorly on video B. Such discrepancy has recently become a major problem in pattern recognition, because it is often difficult to obtain training data that are sufficiently similar to the test data.", "To deal with this problem, domain adaptation techniques have been proposed.", "\\newline Given two datasets, called source and target data, domain adaptation aims to adapt source domain data to the target domain data so that distributions of both datasets are matched [@bib:Csurka2017] .", "By applying domain adaptation, classifiers trained on the adapted source data can achieve high accuracy on the target data.", "Since the discrepancy between two distributions is measured based on observed data, we need a sufficient number of data in each dataset to estimate the distributional discrepancy accurately.", "However, due to the motivation of the domain adaptation, obtaining a large number of target data is often hard, which limits the application of domain adaptation methods to practical cases.", "\\newline In this work, we consider the most extreme case in which we cannot obtain any target data, called zero-shot domain adaptation.", "A few recent studies [@bib:Yang2015,Peng2018] have tackled this challenging problem, but they require additional data such as multiple source datasets [@bib:Yang2015] or target data of another task [@bib:Peng2018] that are not easy to obtain in practice.", "In this paper, we propose a novel method of zero-shot domain adaptation that would be more suitable for practical cases.", "We assume that we have prior knowledge about what factor causes the difference in distributions between source and target data.", "For example, in Fig. [@ref:LABEL:fig:exm_video] , the shooting angle for vehicles can be considered as a major factor that causes the appearance change between videos.", "Other examples include gender information in an age estimation task from facial images and the azimuth of captured objects in an object recognition task, both of which are examined in our experiments.", "\\newline We call such a factor an attribute, and assume that we can only obtain attribute priors at the target domain instead of the target data.", "We then reformulate the domain adaptation problem so that we can conduct adaptation based only on attribute priors.", "In addition, we clarify requirements for the attribute to be useful in domain adaptation, and reveal that our method provides more precise estimation of sample-wise transferability than the straightforward attribute-based reweighting approach.", "Experimental results with both toy datasets and benchmark datasets validate the advantage of our method, even though it does not use any target data.", "\\newline We explain our setting by using vehicle recognition from surveillance videos as an example.", "In this task, input data and labels are cropped video frames and vehicle types, respectively.", "Suppose that we have already constructed training datasets from existing surveillance cameras and want to transfer those datasets to a classifier for a new surveillance camera.", "If the new camera is not installed yet, we cannot obtain any target videos, therefore, we cannot apply a standard domain adaptation method nor evaluate how much data can be transfered via domain adaptation. But, if where and how the new camera will be installed have been already determined, we can estimate the shooting angle for the target vehicle.", "Since the shooting angle is a major factor that causes the appearance change of vehicles, we can consider the shooting angle as an attribute.", "In this case, we calculate it for each sample at the source domain and also estimate how often the vehicle will be captured with a certain shooting angle at the target domain by using the information about the pose and position of a camera.", "As shown in the above example, the assumption about attribute information in our method is sufficiently practical, and we believe that our method can be applied in many practical applications, especially for computer vision tasks.", "\\newline  </section>"], ["<section> <title> 2 Problem formulation and related works </title>  Recent domain adaptation methods [@bib:Ganin2016,Tzeng2017,Peng2018] often adopt deep neural networks (DNNs) to embed both-domain data into a common feature space in which the distributions of both data are matched. But, due to the \u201cdata-hungry\u201d property of DNN, this approach requires a relatively large number of data.", "Since we tackle the \u201czero-shot\u201d scenario in which we cannot obtain any target data, we utilize a different approach in this work, that is the instance-weight based approach [@bib:Huang2007,Sugiyama2008,Kanamori2009] .", "In this approach, domain adaptation is achieved by assigning an instance weight for each sample in the source data.", "\\newline We briefly show the problem setting of the domain adaptation and how to solve it by the instance-weight based approach.", "Let us consider a supervised classification task, and let $ x\\in\\mathbb{R}^{m},y\\in C $ and $ d\\in\\{{\\rm S},{\\rm T}\\} $ denote input data, labels, and domains, respectively.", "Here, $ m $ is the dimensionality of the input data, $ C $ is the set of the class candidates, and $ \\{{\\rm S},{\\rm T}\\} $ represent the source and target domains, respectively.", "Note that we treat $ d $ as a random variable.", "We assume that the joint distributions of $ (x,y) $ are different between domains, which means $ p(x,y|d={\\rm S})\\neq p(x,y|d={\\rm T}) $ .", "Given labeled source data $ \\mathcal{D}_{S}=\\{(x^{{\\rm S}}_{i},y^{{\\rm S}}_{i})\\}\\sim p(x,y|d={\\rm S}) $ and unlabeled target data $ \\mathcal{D}_{T}=\\{x^{{\\rm T}}_{i}\\}\\sim p(x|d={\\rm T}) $ , our goal is to train a model $ f:\\mathbb{R}^{m}\\rightarrow C $ that can accurately predict labels for input data at the target domain.", "More specifically, supposing $ f $ is parameterized by $ \\theta $ , we want to obtain the optimal $ \\theta $ that minimizes the target risk defined as \\newline <equationgroup> <equation> $  R_{\\mathrm{T}}(\\theta)\\!\\!\\!=\\!\\!\\!\\sum_{y\\in C}\\int l(x,y,% \\theta)p(x,y|d=\\mathrm{T}){\\rm d}x, $ $  R_{\\mathrm{T}}(\\theta)\\!\\!\\!", "$ $ = $ $ \\!\\!\\!\\sum_{y\\in C}\\int l(x,y,\\theta)p(x,y|d=\\mathrm{T}){\\rm d}x, $ </equation> </equationgroup> where $ l(x,y,\\theta) $ is a loss when $ y $ is predicted by $ f $ with $ \\theta $ at $ x $ .", "\\newline Since the target data are not labeled, we cannot directly estimate the risk in Eq. ( [@ref:LABEL:eq:risk_T] ) by empirical approximation.", "Instead, we try to use the source data to estimate it.", "The target risk can be related to the source risk with instance weights as: \\newline <equationgroup> <equation> $  R_{\\mathrm{T}}(\\theta)\\!\\!\\!=\\!\\!\\!\\sum_{y\\in C}\\int w(x,y)l(x,y% ,\\theta)p(x,y|d=\\mathrm{S}){\\rm d}x, $ $  R_{\\mathrm{T}}(\\theta)\\!\\!\\!", "$ $ = $ $ \\!\\!\\!\\sum_{y\\in C}\\int w(x,y)l(x,y,\\theta)p(x,y|d=\\mathrm{S}){% \\rm d}x, $ </equation> </equationgroup> where $ w(x,y)=\\frac{p(x,y|d=\\mathrm{T})}{p(x,y|d=\\mathrm{S})} $ is an instance weight for the corresponding data $ (x,y) $ .", "By assuming covariate shift [@bib:Shimodaira2000] , that means $ p(y|x) $ is common in the source and target domains, we can simplify the weight as follows \\newline <equationgroup> <equation> $ \\frac{p(x,y|d=\\mathrm{T})}{p(x,y|d=\\mathrm{S})}=\\frac{p(y|x,d=% \\mathrm{T})}{p(y|x,d=\\mathrm{S})}\\frac{p(x|d=\\mathrm{T})}{p(x|d=\\mathrm{S})}=% \\frac{p(x|d=\\mathrm{T})}{p(x|d=\\mathrm{S})}=w(x).", "$ $ \\frac{p(x,y|d=\\mathrm{T})}{p(x,y|d=\\mathrm{S})} $ $ = $ $ \\frac{p(y|x,d=\\mathrm{T})}{p(y|x,d=\\mathrm{S})}\\frac{p(x|d=% \\mathrm{T})}{p(x|d=\\mathrm{S})} $ $ = $ $ \\frac{p(x|d=\\mathrm{T})}{p(x|d=\\mathrm{S})}=w(x).", "$ </equation> </equationgroup> \\newline Equation ( [@ref:LABEL:eq:weight_risk] ) indicates that we can obtain the optimal $ \\theta $ by minimizing the weighted source risk.", "Therefore, many existing instance-weight based methods [@bib:Huang2007,Sugiyama2008,Kanamori2009] basically try to accurately estimate the weight defined in Eq. (", "[@ref:LABEL:eq:ratio] ).", "When we estimate the weight, we assume that the weight is always finite.", "Once we obtain the weight for each sample in the source data, we can calculate the empirically approximated risk $ \\hat{R_{{\\rm T}}}(\\theta) $ as: \\newline <equationgroup> <equation> $ \\hat{R_{{\\rm T}}}(\\theta)=\\frac{1}{|\\mathcal{D}_{S}|}\\sum_{(x_{i}% ,y_{i})\\in\\mathcal{D}_{S}}\\hat{w}(x_{i})l(x_{i},y_{i},\\theta), $ $ \\hat{R_{{\\rm T}}}(\\theta)=\\frac{1}{|\\mathcal{D}_{S}|}\\sum_{(x_{i}% ,y_{i})\\in\\mathcal{D}_{S}}\\hat{w}(x_{i})l(x_{i},y_{i},\\theta), $ </equation> </equationgroup> where $ \\hat{w}(x_{i}) $ is the estimated weight for $ (x_{i},y_{i}) $ .", "By minimizing this empirical risk, we can estimate the optimal $ \\theta $ .", "\\newline In our zero-shot scenario, the standard instance-weight based approach cannot be adopted, because they require target data as well as source data to estimate the weight.", "Therefore, the main problem in our scenario is how to estimate the weight without target data.", "We will show that it can be solved by utilizing the attribute information instead of the unavailable target data.", "\\newline  </section>"], ["<section> <title> 3 Zero-shot domain adaptation based on attribute information </title>  We assume that we can obtain attribute information at both the source and target domains that is a major factor for the discrepancy between the data distributions.", "More specifically, at the source domain, attribute $ z $ for each sample is also given in addition to $ (x,y) $ , and at the target domain, we cannot obtain any data or attributes as well, but only the probability distribution of attributes $ p(z|d=\\mathrm{T}) $ is given.", "To make our formulation simple, we assume a single categorical attribute, but our method can be extended to multivariate or continuous attributes in a straightforward way.", "\\newline <subsection> <title> 3.1 How to calculate instance weights </title> First, we transform the probability density ratio in Eq. ( [@ref:LABEL:eq:ratio] ).", "Since we do not have any information about the domain prior $ p(d) $ especially for the target domain, we assumed a uniform distribution ( $ p(d=\\mathrm{S})=p(d=\\mathrm{T}) $ ) that is often used as a non-informative prior.", "By using this assumption and Bayes\u2019 theorem, we obtain the following equation: \\newline <equationgroup> <equation> $  w(x)\\!=\\!\\frac{p(x|d\\!=\\!\\mathrm{T})}{p(x|d\\!=\\!\\mathrm{S})}\\!=% \\!\\frac{p(d\\!=\\!\\mathrm{T}|x)}{p(d\\!=\\!\\mathrm{S}|x)}\\frac{p(d\\!=\\!\\mathrm{S})% }{p(d\\!=\\!\\mathrm{T})}\\!=\\!\\frac{p(d\\!=\\!\\mathrm{T}|x)}{p(d\\!=\\!\\mathrm{S}|x)}% .\\!\\!\\!", "$ $  w(x)\\!=\\!\\frac{p(x|d\\!=\\!\\mathrm{T})}{p(x|d\\!=\\!\\mathrm{S})}\\!=% \\!\\frac{p(d\\!=\\!\\mathrm{T}|x)}{p(d\\!=\\!\\mathrm{S}|x)}\\frac{p(d\\!=\\!\\mathrm{S})% }{p(d\\!=\\!\\mathrm{T})}\\!=\\!\\frac{p(d\\!=\\!\\mathrm{T}|x)}{p(d\\!=\\!\\mathrm{S}|x)}% .\\!\\!\\!", "$ </equation> </equationgroup> Then, based on the attribute information, we approximate $ p(d|x) $ as follows: \\newline <equationgroup> <equation> $  p(d|x)\\approx\\sum_{z}p(d|z)p(z|x).", "$ $  p(d|x)\\approx\\sum_{z}p(d|z)p(z|x).", "$ </equation> </equationgroup> We will discuss what condition is required for the approximation in Eq. ( [@ref:LABEL:eq:approx] ) in the next subsection.", "Substituting Eq. ( [@ref:LABEL:eq:approx] ) into Eq. ( [@ref:LABEL:eq:w_mid] ), we obtain \\newline <equationgroup> <equation> $  w(x)=\\frac{\\sum_{z}p(d=\\mathrm{T}|z)p(z|x)}{\\sum_{z}p(d=\\mathrm{% S}|z)p(z|x)}. $ $  w(x)=\\frac{\\sum_{z}p(d=\\mathrm{T}|z)p(z|x)}{\\sum_{z}p(d=\\mathrm{% S}|z)p(z|x)}. $ </equation> </equationgroup> By adopting the approximation in Eq. ( [@ref:LABEL:eq:approx] ), we can calculate $ w(x) $ by estimating $ p(d|z) $ and $ p(z|x) $ .", "It means that we do not need the target data, because $ p(d|z) $ can be estimated from the given information about the attributes, and $ p(z|x) $ that does not depend on domains can be estimated from the source data.", "This is the key trick of our method.", "\\newline Since we assume that $ p(z|d) $ is given and $ p(d={\\rm S})=p(d={\\rm T}) $ , $ p(d|z) $ can be calculated by using Bayes\u2019 theorem as follows: \\newline <equationgroup> <equation> $  p(d=\\mathrm{T}|z)=\\frac{p(z|d=\\mathrm{T})}{p(z|d=\\mathrm{S})+p(z% |d=\\mathrm{T})}, $ $  p(d=\\mathrm{T}|z) $ $ = $ $ \\frac{p(z|d=\\mathrm{T})}{p(z|d=\\mathrm{S})+p(z|d=\\mathrm{T})}, $ </equation> <equation> $  p(d=\\mathrm{S}|z)=1-p(d=\\mathrm{T}|z) $ $  p(d=\\mathrm{S}|z) $ $ = $ $  1-p(d=\\mathrm{T}|z) $ </equation> </equationgroup> For the estimation of $ p(z|x) $ , we adopt the $ k $ -nearest neighbor method which is the simplest method for the posterior estimation: given $ x $ , we search $ k $ nearest samples from the source data and extract the corresponding attributes.", "Since we assumed that the attributes are categorical, we calculate the proportion of each attribute class within the extracted attributes.", "If the attribute is continuous, we may use kernel density estimation.", "\\newline <float> Zero-shot domain adaptation \\ Source data $ (x,y,z)\\sim p(x,y,z|d=S) $ is given \\ \\ Target attribute information $ p(z|d=T) $ is given \\ \\ Equation ( [@ref:LABEL:eq:approx] ) and $ p(d=S)=p(d=T) $ hold \\ \\ Calculate $ p(d|z) $ by Eq. ( [@ref:LABEL:eq:pdzT] ) and ( [@ref:LABEL:eq:pdzS] ) \\ \\ Estimate $ p(z|x) $ with the source data ( $ k $ -NN method is used in this paper) \\ \\ Calculate $ w(x) $ by Eq. ( [@ref:LABEL:eq:weight] ) using $ p(d|z) $ and $ p(z|x) $ \\ \\ return $ w(x) $ \\ </float> \\newline </subsection> <subsection> <title> 3.2 Requirements for the attribute information </title> The most important assumption in our method is Eq. ( [@ref:LABEL:eq:approx] ).", "In this subsection, we clarify requirements for this approximation.", "Since $ p(d|x) $ equals $ \\sum_{z}p(d|x,z)p(z|x) $ , we need the following approximation to have Eq. ( [@ref:LABEL:eq:approx] ): \\newline <equationgroup> <equation> $  p(d|x,z)\\approx p(d|z).", "$ $  p(d|x,z)\\approx p(d|z).", "$ </equation> </equationgroup> By multiplying $ p(x|z) $ to both sides of Eq. ( [@ref:LABEL:eq:pdxz] ), we can obtain $ p(d,x|z)\\approx p(d|z)p(x|d) $ .", "Therefore, this approximation assumes that $ x $ and $ d $ are conditionally independent given $ z $ .", "\\newline We show another aspect of this approximation.", "By using Bayes\u2019 theorem, the left-hand side of Eq. ( [@ref:LABEL:eq:pdxz] ) can be transformed as follows: \\newline <equationgroup> <equation> $  p(d|x,z)=\\frac{p(x,z|d)p(d)}{p(x,z)}\\!\\!\\!\\!=\\!\\!\\!\\!\\frac{p(x|z% ,d)p(z|d)p(d)}{p(x|z)p(z)}=\\!\\!\\!\\!\\frac{p(x|z,d)}{p(x|z)}p(d|z).", "$ $  p(d|x,z)=\\frac{p(x,z|d)p(d)}{p(x,z)}\\!\\!\\!\\! $ $ = $ $ \\!\\!\\!\\!\\frac{p(x|z,d)p(z|d)p(d)}{p(x|z)p(z)} $ $ = $ $ \\!\\!\\!\\!\\frac{p(x|z,d)}{p(x|z)}p(d|z).", "$ </equation> </equationgroup> By substituting Eq. ( [@ref:LABEL:eq:mid] ) into Eq. ( [@ref:LABEL:eq:pdxz] ), we obtain \\newline <equationgroup> <equation> $  p(x|z,d)\\approx p(x|z).", "$ $  p(x|z,d)\\approx p(x|z).", "$ </equation> </equationgroup> This equation indicates that, given a certain $ z $ , the probability distribution of $ x $ is common between domains.", "Since marginal probability density $ p(x|d)=\\sum_{z}p(x|z,d)p(z|d) $ is different between the source and target domains while $ p(x|z) $ is common, only the attribute prior given a domain $ p(z|d) $ is different between domains.", "Therefore, the approximation in Eq. ( [@ref:LABEL:eq:approx] ) corresponds to the latent prior change assumption that is adopted in some existing works [@bib:Storkey2007,Hu2018] .", "\\newline </subsection> <subsection> <title> 3.3 Characteristics of the proposed method </title> We clarify some characteristics of our method.", "First, we take two special cases to explain how our method works, and after that we show how our method is different from the straightforward attribute-based instance weighting.", "\\newline If the attribute prior is identical between the source and target domains, that means $ p(z|d\\!=\\!\\mathrm{S})\\!=\\!p(z|d\\!=\\!\\mathrm{T}) $ , $ p(d|z) $ in Eqs. ( [@ref:LABEL:eq:pdzT] ) and ( [@ref:LABEL:eq:pdzS] ) are always $ 0.5 $ regardless of the value of $ z $ .", "This results in $ w(x)\\!=\\!1 $ , which indicates that the source data have already been adapted to the target data and we do not need to conduct domain adaptation.", "This is natural behavior, because we assumed that only the attribute prior changes between domains as noted in the previous subsection.", "\\newline If $ p(z|x) $ is the delta function $ \\delta(z=z^{*}) $ where $ z^{*} $ is the attribute value that corresponds to given sample $ x $ , $ w(x) $ in Eq. ( [@ref:LABEL:eq:weight] ) can be simplified as follows: \\newline <equationgroup> <equation> $  w(x)=\\frac{p(d=\\mathrm{T}|z=z^{*})}{p(d=\\mathrm{S}|z=z^{*})}=% \\frac{p(z=z^{*}|d=\\mathrm{T})}{p(z=z^{*}|d=\\mathrm{S})}. $ $  w(x)=\\frac{p(d=\\mathrm{T}|z=z^{*})}{p(d=\\mathrm{S}|z=z^{*})}=% \\frac{p(z=z^{*}|d=\\mathrm{T})}{p(z=z^{*}|d=\\mathrm{S})}. $ </equation> </equationgroup> This means that the weight is determined based on only attribute information and not on data.", "It corresponds to the straightforward approach for attribute-based instance weighting.", "If we define the weight as $ w(x,y,z)=\\frac{p(x,y,z|d=\\mathrm{T})}{p(x,y,z|d=\\mathrm{S})} $ and assume $ p(x,y|z,d=\\mathrm{S})=p(x,y|z,d=\\mathrm{T}) $ that is somewhat a stronger assumption in Eq. ( [@ref:LABEL:eq:assumption] ), we can derive the above instance weight as follows: \\newline <equationgroup> <equation> $  w(x,y,z)\\!=\\!\\frac{p(x,y,z|d=\\mathrm{T})}{p(x,y,z|d=\\mathrm{S})}% \\!\\!\\!\\!\\!=\\!\\!\\!\\!\\!\\frac{p(x,y|z,d=\\mathrm{T})p(z|d=\\mathrm{T})}{p(x,y|z,d=% \\mathrm{S})p(z|d=\\mathrm{S})}=\\!\\!\\!\\!\\!\\frac{p(z|d=\\mathrm{T})}{p(z|d=\\mathrm% {S})}. $ $  w(x,y,z)\\!=\\!\\frac{p(x,y,z|d=\\mathrm{T})}{p(x,y,z|d=\\mathrm{S})}% \\!\\!\\!\\!\\!", "$ $ = $ $ \\!\\!\\!\\!\\!\\frac{p(x,y|z,d=\\mathrm{T})p(z|d=\\mathrm{T})}{p(x,y|z,d% =\\mathrm{S})p(z|d=\\mathrm{S})} $ $ = $ $ \\!\\!\\!\\!\\!\\frac{p(z|d=\\mathrm{T})}{p(z|d=\\mathrm{S})}. $ </equation> </equationgroup> As shown above, our method includes the straightforward attribute-based method as a special case.", "In other cases, that mean $ p(z|x) $ is not a delta function, our method behaves differently compared with the straightforward method.", "\\newline Let us illustrate the behavior of our method using a simple example.", "Suppose there are only two attribute classes $ z\\in\\{0,1\\} $ that have one-dimensional Gaussian distributions with different means as shown in Fig. [@ref:LABEL:fig:exmA_w] .", "At the source domain, $ [p(z\\!=\\!0|d\\!=\\!\\mathrm{S}),p(z\\!=\\!1|d\\!=\\!\\mathrm{S})] $ is set to $ [0.5,0.5] $ , while it is set to $ [1.0,0.0] $ at the target domain.", "In this case, the weight estimated in the straightforward method (Eq. ( [@ref:LABEL:eq:straight] )) leads to a simple delta function, that is $ w(x,y,z)\\!=\\!2\\cdot\\delta(z\\!=\\!0) $ .", "In contrast, the weight in our method (Eq. ( [@ref:LABEL:eq:weight] ))", "behaves differently according to the amount of overlap between $ p(x|z\\!=\\!0) $ and $ p(x|z\\!=\\!1) $ .", "Figure [@ref:LABEL:fig:exmA] shows the case in which the overlap is quite small.", "The weight function $ w(x) $ becomes almost the same as a step function over $ x $ as shown in Fig. [@ref:LABEL:fig:exmA_w] .", "As a result, the weight over $ z $ becomes the delta function that is the same as that in the straightforward method as shown in Fig. [@ref:LABEL:fig:exmA_wh] .", "In contrast, when the overlap is large, our method shows somewhat different behavior as presented in Fig. [@ref:LABEL:fig:exmB] .", "In this case, $ w(x) $ becomes a smoother function compared with the previous case as shown in Fig. [@ref:LABEL:fig:exmB_w] .", "It leads to non-zero weights for the samples with $ z\\!=\\!1 $ as shown in Fig. [@ref:LABEL:fig:exmB_wh] , which means that we can transfer these samples even though the samples with $ z\\!=\\!1 $ do not appear at the target domain.", "This characteristic is not available in the straightforward method, because it focuses only on the attribute to estimate the weight.", "On the other hand, our method utilizes the information of $ p(z|x) $ , which results in smoother weights that can transfer the source data more efficiently.", "\\newline </subsection>  </section>"], ["<section> <title> 4 Experiments </title>  In this section, we show the experimental results with both toy datasets and benchmark datasets.", "\\newline <subsection> <title> 4.1 Experiments with toy dataset </title> We conducted experiments with a 2-dimensional toy dataset for binary classification, In this dataset, the first feature $ x_{0} $ stemmed from a Gaussian mixture model (GMM) that has five centroids ( $ -0.75\\pi,\\ -0.5\\pi,\\ 0.0,\\ 0.5\\pi,\\ 0.75\\pi $ ) with common standard deviation $ \\sigma=0.2\\pi $ , and the second feature $ x_{1} $ stemmed from the uniform distribution from $ -2.0 $ to $ 2.0 $ .", "For each sample, the index of the corresponding centroid was treated as attribute $ z\\in\\{0,1,2,3,4\\} $ .", "The mixing ratio of GMM was set differently for the source and target domains as shown in Table [@ref:LABEL:tab:GMM] .", "To change the difficulty of domain adaptation, we constructed three datasets (Datasets A\u2013C) by changing the discrepancy of the ratios between the domains.", "The posterior $ p(y|x) $ is determined by $ p(y|x)=\\frac{1}{1+{\\rm exp}\\left(-5.0(x_{1}-\\sin x_{0})\\right)} $ .", "\\newline To make the dataset, first, we generated the sample $ (x,z) $ according to the data distribution that is previously described, then, we determined its label by randomly sampling according to the above posterior.", "Figure [@ref:LABEL:fig:toydata] shows a brief flow of how to generate the toy datasets.", "We generated 600 samples as source and target data, respectively.", "Note that we can obtain ground-truth $ w(x) $ by calculating Eq. ( [@ref:LABEL:eq:ratio] ) with true probability density functions $ p(x|d) $ .", "\\newline First, we evaluated the accuracy of the weights estimated by our method by comparing them with the ground-truth weights.", "To quantitatively evaluate the accuracy, we compared our method with unconstrained Least-Squares Importance Fitting (uLSIF) [@bib:Kanamori2009] that is one of the representative methods to estimate a probability density ratio.", "Using the target data, we estimated the weight by uLSIF, and compared its estimation error with that of our method.", "We measured the error by the root mean squared error.", "The results are shown in Table [@ref:LABEL:tab:err] .", "Although our method does not use any target data, it shows better performance than uLSIF.", "This indicates that attribute information can be more useful to estimate the probability density ratio.", "\\newline We also evaluate the performance of our method as domain adaptation.", "We trained a classifier with weighted source data and tested it with the target data.", "To train a classifier, we used $ C $ -support vector machine ( $ C $ -SVM) with the Gaussian kernel and tuned its hyper-parameters that are regularization coefficient $ C $ and kernel width $ \\sigma $ by five-fold cross validation.", "We compared three methods: training without weights, training with estimated weights, and training with the ground-truth weights.", "Table [@ref:LABEL:tab:err_SVM] shows the accuracy of the SVM trained by each method.", "Our method achieved higher accuracy than that without importance weights and almost reached the same performance as that with ground-truth weights, though our method does not utilize ground-truth weights or any target data.", "Figure [@ref:LABEL:fig:vis] visualizes the instance weights and the trained classifier.", "The size of circles corresponds to the value of the instance weight, and contour lines represent the output of the decision function of SVM.", "Note that the true decision boundary is a sinusoidal curve as shown in Fig. [@ref:LABEL:fig:toydata] .", "Since only few source data are distributed at the left-hand side while many target data are at that side, large weights are assigned to those source data in our method, which results in a more accurate classifier especially at the left-hand side.", "\\newline </subsection> <subsection> <title> 4.2 Experiments with benchmark dataset </title> To evaluate our method in a more practical scenario, we conducted experiments with popular benchmark datasets on computer vision tasks.", "\\newline <subsubsection> <title> 4.2.1 MNIST dataset </title> For the first experiment, we used the MNIST dataset [@bib:LeCun1998] that contains handwritten digit images.", "The task is to classify these images into ten classes that correspond to digit numbers.", "We randomly chose 10,000 samples from the training data, and used them as source data, while the test data that includes 10,000 samples were used as target data.", "To make the source and target data have different data distributions, we clockwisely rotated each image with a randomly determined angle, where we set different probability distributions of the rotation angle for source and target data as shown in Table [@ref:LABEL:tab:ang] .", "We measured the performance of our method by the accuracy of the classifier trained with weighted source data similarly to the previous experiments.", "Instead of SVM, we used a deep neural network in this experiment.", "Table [@ref:LABEL:tab:net_MNIST] shows its network architecture that is loosely based on LeNet [@bib:LeCun1998] but is modified by adding batch normalization layers.", "We trained the network by stochastic gradient descent with momentum, and the number of total update iterations was 10,000.", "To calculate the weight in our method, we estimated $ p(z|x) $ by the $ k $ -nearest neighbor method with the features at the last hidden layer of the network.", "Since the calculation cost of the weight estimation is not small compared with that of the training network, we calculated the weights after each 100 iterations, and fixed them for the next 100 iterations.", "We used the weights to calculate the sampling probability of each sample when making a mini-batch.", "\\newline Table [@ref:LABEL:tab:result_MNIST] shows the accuracy of the trained classifier on the MNIST dataset.", "Without instance weights, the accuracy decreased from $ 97.1\\% $ to $ 93.8\\% $ when shifting from the source to target domains.", "On the other hand, our method suppressed this degradation of the classification performance, and achieved $ 94.9\\% $ at the target domain.", "Interestingly, the accuracy at the source domain remains almost unchanged while adopting the instance weights.", "\\newline </subsubsection> <subsubsection> <title> 4.2.2 Adience dataset </title> For the second experiment, we used the Adience dataset [@bib:Eidinger2014] that contains facial images with age and gender annotations.", "In this experiment, we conducted age estimation while considering gender as an attribute.", "Since eight age groups are defined in this dataset, age estimation can be formulated as an eight-class classification problem.", "There are five sub-datasets in this dataset, and we used the fifth sub-dataset as target data and the other sub-datasets as source data.", "While gender in this dataset is almost balanced, we artificially made it imbalanced in the target data to change the data distribution.", "We varied this imbalance, and evaluated our method for each setting.", "The network architecture for this experiment is shown in Table [@ref:LABEL:tab:net_face] .", "The number of total update iterations was 5,000.", "The other setting is the same as that in the previous experiment.", "\\newline Table [@ref:LABEL:tab:result_face] shows the accuracy of the trained classifier on the Adience dataset.", "When the ratio between male and female samples in the target data is set to $ [0.5,0.5] $ , the accuracy of our method is almost the same as that of the other methods.", "This is because the ratio in the source data is also balanced and the data distribution is almost the same between the source and target data.", "In contrast, when the ratio became imbalanced, our method achieved better performance.", "It indicates that the effectiveness of our method gets more significant as the discrepancy between the source and target data distributions becomes larger.", "The straightforward attribute-based weight did not lead to better performance, because it could not effectively utilize female samples in heavily imbalanced case.", "For example, when the ratio was set to $ [0.9,0.1] $ , the average weight of female examples was 9 times smaller than that of male examples in the straightforward method, while, in the proposed method, it became 2.2 times smaller, which is substantially more smooth weight than the straightforward method.", "\\newline </subsubsection> <subsubsection> <title> 4.2.3 VisDA2017 dataset </title> For more large-scale experiment, we used the VisDA2017 classification dataset [@bib:VisDA2017] .", "This dataset contains object images with twelve categories, and the task is to discriminate the object category from the given image.", "Since the azimuth of the captured object is also provided in this dataset, we discretized the azimuth into five classes and used it as an attribute."]], "target": "We constructed the source and target data as shown in Table . Intuitively, the source domain is biased to \u201cfront-view\u201d images, while the target domain is biased to \u201crear-view\u201d images."}, {"tabular": ["  Office (10)  &  Plants (10)  &  Insects (8)  &  Animals (44) ", " backpack  &  palm tree  &  butterfly  &  bat  &  hummingbird  &  horse  &  horseshoe-crab ", " touring-bike  &  bonsai  &  centipede  &  bear  &  owl  &  iguana  &  crab ", " calculator  &  cactus  &  cockroach  &  camel  &  hawksbill  &  kangaroo  &  conch ", " headphones  &  fern  &  grasshopper  &  chimp  &  ibis  &  llama  &  dolphin ", " computer keyboard  &  hibiscus  &  house fly  &  dog  &  cormorant  &  leopards  &  goldfish ", " laptop  &  sun flower  &  praying-mantis  &  elephant  &  duck  &  porcupine  &  killer-whale ", " computer monitor  &  grapes  &  scorpion  &  elk  &  goose  &  raccoon  &  mussels ", " computer mouse  &  mushroom  &  spider  &  frog  &  iris  &  skunk  &  octopus ", " coffee mug  &  tomato  &    &  giraffe  &  ostrich  &  snail  &  starfish ", " video projector  &  water melon  &    &  gorilla  &  penguin  &  toad  &  snake ", "  &    &    &  greyhound  &  swan  &  zebra  &  goat  "], "ref_sec": [["<section> <title> 1 Introduction </title>  A basic assumption in classical learning and estimation is the availability of a random sample from the target distribution.", "However, in many cases, obtaining such a sample is difficult or impossible.", "In domain adaptation (e.g, [@bib:kifer2004detecting,ben2010theory,blitzer2008learning,cortes2014domain] ), this sample is replaced with samples from a source distribution, and fewer or unlabeled samples from the target distribution.", "In this work, we consider an extreme case, in which no random samples from the target distribution are available.", "The only access to the target distribution is via {weight queries} , which retrieve the weight of a given subset of the domain according to the target distribution at a cost.", "This is relevant to many types of data sources.", "For instance, if the data is accessed via a search engine, the number of matches of a specific search criterion can be obtained, but there is no interface for randomly sampling a data element.", "As a different example, consider the distribution of users currently using a set of websites.", "The number of users currently in a website or a domain of websites can be measured, but there is no mechanism for drawing a random user.", "Lastly, consider a learning task in which the target distribution is accessed via a user\u2019s subjective or apriori knowledge of the importance of each example.", "For instance, learning a classifier of images based on a given data set, to be used in a new environment (e.g., a data set of diverse outdoor images, which will be used for navigation in an uncharted tropical island).", "The relative importance of parts of the domain can be crucial for directing the learning effort, for instance in active learning [@bib:MccallumNi98] .", "Thus, our goal is to use weight queries to approximate the target distribution.", "\\newline We assume access to a large data set of domain examples.", "If the data set is sufficiently comprehensive, then reweighting it according to the target distribution is a useful proxy for a sample of the target, for learning or estimation tasks.", "In a basic weight query, an example from the data set is presented to an oracle, which returns the weight of the example by the target distribution.", "While our terminology refers to examples from the domain and their weights, the elements in the data set may also represent non-overlapping subsets of the domain, with the oracle returning the weight of the subset.", "For instance, a data set element could be a search query which represents all the examples that match it, or it could be an example representing a neighborhood of similar examples.", "In addition to basic weight queries, some higher-order queries are allowed.", "These obtain the total target weight of a set of elements.", "The possible higher-order queries are represented via a hierarchical binary tree structure, whose leaves are the data set examples.", "Each internal node (up to a certain depth) can be queried for the total weight of its descendant leaves.", "Such nodes can represent, e.g., broader search engine queries.", "We assume that such queries are expensive, and so limit their use to a minimal number.", "\\newline The data set and the hierarchical tree define a set of reweighting functions, based on {prunings} of the tree.", "A pruning is a set of internal nodes such that each leaf (example) is a descendant of exactly one node.", "Equivalently, it is a set of non-overlapping sub-trees that cover the data set.", "Each pruning defines a weighting, by distributing the total weight of each subtree equally between its leaves.", "The goal is to find a pruning of a limited size, whose induced weighting is close to the true weighting defined by the target distribution, as measured by the $ \\ell_{1} $ distance (equivalently, the total variation distance).", "Thus, if a weighting has a small distance from the true weighting, any bounded statistical property has a similar value on both weightings.", "For instance, if the data set and the target distribution have the same labeling function, as in the covariate shift setting (e.g., [@bib:bickel2009discriminative] ) then the accuracy of a classifier calculated on a good reweighting will be similar to its accuracy based on the true weights.", "\\newline Our contributions.", "We propose a novel algorithm for finding a weighting induced by a limited-size pruning of the given tree structure.", "We prove that with a high probability, the $ \\ell_{1} $ distance between the output weighting and the true weighting approximates the distance of the best weighing induced by a pruning of the same size.", "The algorithm adaptively selects examples for weight queries, while iteratively constructing the pruning.", "The number of higher-order queries used by the algorithm is limited to the size of the pruning.", "We further upper-bound the number of basic weight queries that the algorithm requests.", "Lastly, we compare the algorithm to several natural baselines in experiments, showing its advantage in obtaining a low distance from the true weighting.", "Some of our analysis and experiment results are deferred to the appendices.", "\\newline <subsection> <title> Related work </title> In recent years, many interactive learning settings in which the feedback is not an i.i.d. sample have been studied.", "Perhaps the most established is active learning [@bib:CohnAtLa94,MccallumNi98] .", "Others include learning with side information [@bib:VisotskyAtCh19] comparison queries [@bib:kane2017active] and feature feedback [@bib:DasguptaDeRoSa18] .", "The current work adds to this line of research, by expanding the machine learning toolbox to new forms of interaction.", "\\newline In the domain adaptation framework (e.g., [@bib:kifer2004detecting,ben2007analysis,blitzer2008learning,mansour2009domain,ben2010theory] ), random labeled examples from the target distribution are assumed scarce, and a sample from a source distribution is used as a proxy.", "In particular, these works use the total variation distance between the source and the target to bound the excess target error when learning from the source.", "In the covariate shift setting, the target and the source distributions have the same labeling function, with a different marginal distribution on unlabeled examples.", "In [@bib:bickel2007discriminative,sugiyama2008direct,bickel2009discriminative] , reweighing the labeled source sample based on unlabeled target examples is studied.", "[@bib:kpotufe18a] studies trade-offs between source and target labels.", "In [@bib:berlind2015active] , interactive domain adaptation is studied, in which a labeled source sample guides label requests from the target.", "In this work, we assume that the input data set is organized in a hierarchical tree, which represents relevant structures in the data set.", "This type of input is common to many works in which structure is required.", "For instance, in [@bib:dasgupta2008hierarchical] an active learning algorithm uses such an input tree.", "In [@bib:slivkins2011multi,bubeck2011x] , a hierarchical tree is used to organize different arms in a multi-armed-bandits problem, and in [@bib:munos2011optimistic] such a structure is used when adaptively estimating the maximum of an unknown function.", "\\newline </subsection>  </section>"], ["<section> <title> 2 Setting and Notations </title>  Denote by $ \\mathbf{1} $ the all-1 vector; its size will always be clear from context.", "For an integer $ n $ , let $ [n]:=\\{1,\\ldots,n\\} $ .", "For a vector or a sequence $ \\mathbf{x}=(x(1),\\ldots,x(n)) $ , let $ \\|\\mathbf{x}\\|_{1}:=\\sum_{i\\in[n]}|x(i)| $ be the $ \\ell_{1} $ norm of $ \\mathbf{x} $ .", "For a function $ f:\\mathcal{X}\\rightarrow\\mathbb{R} $ on a discrete domain $ \\mathcal{X} $ , denote $ \\|f\\|_{1}:=\\sum_{x\\in\\mathcal{X}}|f(x)| $ .", "\\newline The input data set $ S $ is provided with a binary hierarchical tree $ T $ whose leaves are the elements in $ S $ .", "The target weighting of $ S $ is $ w^{*}:S\\rightarrow[0,1] $ , where $ \\|w^{*}\\|_{1}=1 $ .", "$ w^{*}(x) $ is the probability mass of the example $ x $ (or the subset of the domain that it represents) according to the unknown target distribution.", "For a set $ V\\subseteq S $ , denote $ w^{*}(V):=\\sum_{x\\in V}w^{*}(x) $ .", "The goal of the algorithm is to approximate the target weighting $ w^{*} $ using weight queries.", "The tree $ T $ indicates which higher-order weight queries are allowed: Each internal node (up to some depth) can be queried for the total weight of its descendant leaves.", "In addition, weights of leaves (examples) can be queried.", "Formally, for an internal node $ v $ , let $ \\mathcal{L}_{v}\\subseteq S $ be the set of leaves in the subtree rooted in $ v $ .", "A higher-order query for $ v $ returns the response $ w^{*}_{v}:=w^{*}(\\mathcal{L}_{v}) $ .", "A basic query for a leaf $ x\\in S $ returns $ w^{*}(x) $ .", "\\newline The algorithm attempts to approximate the target weighting by finding a small {pruning} of the tree which induces a weighting on $ S $ that is as similar as possible to $ w^{*} $ .", "Formally, for a tree with a root node $ r $ , a pruning of the tree is a set of tree nodes which are descendants of $ r $ , such that the subtrees rooted in these nodes are disjoint, and each of the leaves that are descendants of $ r $ is included in exactly one of these subtrees.", "Thus, a pruning of the input tree $ T $ induces a partition on $ S $ .", "The weighting induced by the pruning is defined by assigning each subset $ \\mathcal{L}_{v}\\subseteq S $ in the partition its true weight $ w^{*}_{v} $ , and evenly distributing it among the examples in $ \\mathcal{L}_{v} $ .", "Formally, let $ N_{v}:=|\\mathcal{L}_{v}| $ .", "For a pruning $ P $ and an example $ x\\in S $ , let $ \\textsf{A}(P,x) $ be the node in $ P $ which is the ancestor of $ x $ .", "The weighting $ w_{P}:S\\rightarrow\\mathbb{R}^{+} $ induced by the pruning $ P $ is defined as $ w_{P}(x):=w^{*}_{\\textsf{A}(P,x)}/N_{\\textsf{A}(P,x)} $ .", "\\newline The quality of the weighting $ w_{P} $ provided by the algorithm is measured by the total variation distance between the distribution induced by $ w_{P} $ and the one induced by $ w^{*} $ , which is equivalent to the $ \\ell_{1} $ norm between the two weight functions (see, e.g., [@bib:wilmer2009markov] ).", "Formally, the total variation distance between two weight functions $ w_{1},w_{2}:S\\rightarrow\\mathbb{R}^{+} $ is \\newline <equation> $ \\mathrm{dist}(w_{1},w_{2}):=\\max_{S^{\\prime}\\subseteq S}|w_{1}(S^{\\prime})-w_{% 2}(S^{\\prime})|\\equiv{\\frac{1}{2}}\\sum_{x\\in S}|w_{1}(x)-w_{2}(x)|\\equiv{\\frac% {1}{2}}\\|w_{1}-w_{2}\\|_{1}. $ </equation> For a node $ v $ , define $ \\mathbb{D}_{v}:=\\sum_{x\\in\\mathcal{L}_{v}}|w^{*}_{v}/N_{v}-w^{*}(x)|.", "$ The {discrepancy} of $ w_{P} $ (with respect to $ w^{*} $ ) is $ \\mathbb{D}_{P}:=2\\mathrm{dist}(w_{P},w^{*})=\\|w_{P}-w^{*}\\|_{1}=\\sum_{v\\in P}% \\mathbb{D}_{v}. $ More generally, for any subset $ G $ of a pruning, define $ \\mathbb{D}_{G}:=\\sum_{v\\in G}\\mathbb{D}_{v} $ .", "We also call $ \\mathbb{D}_{G},\\mathbb{D}_{v} $ the discrepancy of $ G $ , $ v $ , respectively.", "The goal is to find a pruning with a low discrepancy, using few weight queries.", "As we later observe, a larger pruning size necessitates more higher-order queries.", "Thus, the pruning size will be restricted to control this number.", "In addition, we wish to use a small number of weight queries of individual examples.", "\\newline  </section>"], ["<section> <title> 3 Main result: the AWP algorithm </title>  We propose the AWP (Approximating Weights via Pruning) algorithm, listed in Alg.", "[@ref:LABEL:alg:alg] .", "AWP uses weight queries to find a pruning $ P $ , which induces a weight function $ w_{P} $ as defined in Section [@ref:LABEL:sec:settings] .", "AWP gets the following inputs: a binary tree $ T $ whose leaves are the data set elements, the requested pruning size $ K\\geq 2 $ , a confidence parameter $ \\delta\\in(0,1) $ , and a constant $ \\beta>1 $ , which controls the trade-off between the number of weight queries requested by AWP and the approximation factor that it obtains.", "Finding a pruning with a small discrepancy while limiting the number of weight queries involves several challenges, since the discrepancy of any given pruning is unknown in advance, and the number of possibilities is exponential in $ K $ .", "AWP starts with the trivial pruning, which includes only the root node.", "It iteratively samples weight queries of leaves to estimate the discrepancy of nodes in the current pruning.", "AWP decides in a greedy manner which node in the current pruning to {split} , that is, to replace in the pruning with its two child nodes.", "\\newline We first provide the notation used in Alg.", "[@ref:LABEL:alg:alg] .", "For a node $ v $ in $ T $ , $ M_{v} $ is the number of weight queries of examples in $ \\mathcal{L}_{v} $ requested so far by the algorithm for estimating $ \\mathbb{D}_{v} $ .", "The sequence of $ M_{v} $ weights returned by the oracle for these queries is denoted $ \\mathbf{z}_{v} $ .", "We note that although an example in $ \\mathcal{L}_{v} $ is also in $ \\mathcal{L}_{u} $ for any descendant $ u $ of $ v $ , weight queries used for estimating $ \\mathbb{D}_{v} $ are not reused for estimating $ \\mathbb{D}_{u} $ , since this would bias the estimate.", "AWP uses the following estimator for $ \\mathbb{D}_{v} $ : \\newline <equation> $ \\hat{\\mathbb{D}}_{v}:=w^{*}_{v}+\\frac{N_{v}}{M_{v}}(\\|\\mathbf{z}_{v}-\\frac{w^{% *}_{v}}{N_{v}}\\cdot\\mathbf{1}\\|_{1}-\\|\\mathbf{z}_{v}\\|_{1}).", "$ </equation> Note that this estimator requires knowing $ w^{*}_{v} $ , the total weight of node $ v $ .", "In Section [@ref:LABEL:sec:analysis] , the necessity of this information for estimating $ \\mathbb{D}_{v} $ , as well as the failure of naive estimators, are discussed, and a concentration bound for $ \\hat{\\mathbb{D}}_{v} $ is provided.", "AWP iteratively samples weight queries of examples for nodes in the current pruning, until it can identify a node which has a relatively large discrepancy.", "The iterative sampling procedure takes inspiration from the upper-confidence-bound (UCB) approach, common in best-arm-identification problems [@bib:audibert2010best] ; In our case, the goal is to find the best node up to a multiplicative factor.", "In each iteration, the node with the maximal known upper bound on its discrepancy is selected, and the weight of a random example from its leaves is queried.", "To calculate the upper bound, we define $ \\Delta_{v}:=w^{*}_{v}\\cdot\\sqrt{2\\ln(2K\\pi^{2}M_{v}^{2}/(3\\delta))/M_{v}} $ .", "We show in Section [@ref:LABEL:sec:analysis] that $ |\\mathbb{D}_{v}-\\hat{\\mathbb{D}}_{v}|\\leq\\Delta_{v} $ with a high probability.", "Hence, the upper bound for $ \\mathbb{D}_{v} $ is set to $ \\hat{\\mathbb{D}}_{v}+\\Delta_{v} $ .", "Whenever a node from the pruning is identified as having a large discrepancy in comparison with the other nodes, it is replaced by its child nodes, thus increasing the pruning size by one.", "Formally, AWP splits a node if with a high probability, $ \\forall v^{\\prime}\\in P\\setminus\\{v\\},\\mathbb{D}_{v}\\geq\\mathbb{D}_{v^{\\prime}% }/\\beta $ .", "The factor of $ \\beta $ allows splitting even if all nodes have a similar discrepancy.", "This is formalized by the following Boolean splitting criterion: \\newline <equation> $ \\mathrm{SC}(v,P)=\\left\\{\\beta(\\hat{\\mathbb{D}}_{v}-\\Delta_{v})\\geq\\max_{v^{% \\prime}\\in P\\setminus\\{v\\}}\\hat{\\mathbb{D}}_{v^{\\prime}}+\\Delta_{v^{\\prime}}% \\right\\}. $ </equation> To summarize, AWP selects a node by the UCB criterion, and queries the weight of a random leaf of that node.", "If the splitting criterion holds, a node satisfying it is split.", "This is repeated until achieving the pruning size.", "Also, when a node is added to the pruning, its weight is queried for use in Eq. ( [@ref:LABEL:eq:hatdev] ).", "\\newline We now provide our guarantees for AWP .", "The properties of the tree $ T $ affect the quality of the output weighting.", "First, the pruning found by AWP cannot be better than the best pruning of size $ K $ in $ T $ .", "Thus, we guarantee an approximation factor relative to that pruning.", "In addition, we require the tree to be sufficiently nice, in that a child node should have a somewhat lower discrepancy than its parent.", "Formally, we define the notion of {split quality} .", "\\newline <float> AWP : Approximating a target weighting by finding a low-discrepancy pruning \\ A binary tree $ T $ with examples as leaves; Maximum pruning size $ K\\geq 2 $ ; $ \\delta\\in(0,1) $ ; $ \\beta>1 $ .", "\\ \\ $ P_{o} $ : A pruning of $ T $ with a small discrepancy $ \\mathbb{D}_{P_{o}} $ \\ \\ Initializations: $ P\\leftarrow\\{\\text{The root node of }T\\} $ ; For all nodes $ v $ in $ T $ : $ \\mathbf{z}_{v}\\leftarrow,M_{v}\\leftarrow 0 $ .", "\\ \\ while $ |P|<K $ do \\ \\ Set $ {v_{s}}\\leftarrow\\operatorname*{argmax}_{v\\in P}(\\hat{\\mathbb{D}}_{v}+\\Delta_{% v}) $ .", "$ \\vartriangleright $ {Select a node to sample from} \\ \\ Draw an example $ x $ uniformly at random from $ \\mathcal{L}_{{v_{s}}} $ , and query its true weight, $ w^{*}(x) $ .", "\\ \\ $ M_{v_{s}}\\leftarrow M_{v_{s}}+1 $ , $ \\mathbf{z}_{v_{s}}\\leftarrow\\mathbf{z}_{v_{s}}\\circ w^{*}(x) $ .", "\\ \\ $ \\vartriangleright $ {Decide whether to split a node in the pruning:} \\ \\ while $ \\exists v\\in P\\text{s.t. }\\mathrm{SC}(v,P) $ holds (see Eq. ( [@ref:LABEL:eq:split] )) do \\ \\ Let $ v $ such that $ \\mathrm{SC}(v,P) $ holds, with children $ v_{R} $ and $ v_{L} $ , and set $ P\\leftarrow P\\setminus\\{v\\}\\cup\\{v_{R},v_{L}\\} $ .", "\\ \\ Query $ w^{*}_{v_{R}} $ ; set $ w^{*}_{v_{L}}\\leftarrow w^{*}_{v}-w^{*}_{v_{R}} $ .", "\\ \\ return $ P_{o}:=P $ .", "\\ </float> \\newline <theorem> Definition 3.1 (Split quality) .", "Let $ T $ be a hierarchical tree for $ S $ , and $ q\\in(0,1) $ .", "$ T $ has a {split quality} $ q $ , if for any two nodes $ v,u $ in $ T $ such that $ u $ is a child of $ v $ , we have $ \\mathbb{D}_{u}\\leq q\\mathbb{D}_{v} $ .", "\\newline </theorem> This definition is similar in nature to other tree quality notions, such as the taxonomy quality of [@bib:slivkins2011multi] , though the latter restricts weights and not the discrepancy.", "We note that Def. [@ref:LABEL:def:split] could be relaxed, for instance by allowing different values of $ q $ in different tree levels.", "Nonetheless, we prove in Appendix [@ref:LABEL:app:split] that greedily splitting the node with the largest discrepancy cannot achieve a reasonable approximation factor without some restriction on the input tree, and that this also holds for other types of greedy algorithms.", "It is an open problem whether this limitation applies to all greedy algorithms.", "Note also that even in trees with a split quality less than $ 1 $ , splitting a node might increase the total discrepancy; see Section [@ref:LABEL:sec:analysis] for further discussion.", "Our main result is the following theorem.", "\\newline <theorem> Theorem 3.2 .", "Suppose that AWP gets the inputs $ T $ , $ K\\geq 2 $ , $ \\delta\\in(0,1) $ , $ \\beta>1 $ and let $ P_{o} $ be its output.", "Let $ Q $ be a pruning of $ T $ of size $ K $ with a minimal $ \\mathbb{D}_{Q} $ .", "With a probability at least $ 1-\\delta $ , we have: \\newline <list> \\ If $ T $ has split quality $ q $ for some $ q<1 $ , then $ \\mathbb{D}_{P_{o}}\\leq 2\\beta(\\frac{\\log(K)}{\\log(1/q)}+1)\\mathbb{D}_{Q} $ ; \\newline \\ \\ AWP requests $ K-1 $ weight queries of internal nodes; \\newline \\ \\ AWP requests $ \\tilde{O}((1+\\frac{1}{\\beta-1})^{2}K^{3}\\ln(1/\\delta)/\\mathbb{D}_{P_{o}}^{2}) $ weight queries of examples.", "\\newline \\ </list> \\newline </theorem> Thus, an approximation factor with respect to the best achievable discrepancy is obtained, while keeping the number of higher-order weight queries minimal and bounding the number of weight queries of examples requested by the algorithm.", "The theorem is proved in the next section.", "\\newline  </section>"], ["<section> <title> 4 Analysis </title>  First, we discuss the estimator $ \\hat{\\mathbb{D}}_{v} $ .", "Observe that the discrepancy cannot be reliably estimated from weight queries of examples alone.", "For instance, suppose that a single example in $ \\mathcal{L}_{v} $ is heavy and the others are equally light.", "Then, if a random sample of example weights does not include the heavy example, it is impossible to distinguish between a zero discrepancy and a large constant discrepancy without additional information (see Appendix", "[@ref:LABEL:app:estimator] for a detailed example).", "To overcome this, AWP obtains $ w_{v}^{*} $ , using a higher-order weight query.", "However, even then, a standard empirical estimator obtained by aggregating $ |w^{*}_{v}/N_{v}-w^{*}(x)| $ over sampled examples can have a large estimation error (see example in Appendix [@ref:LABEL:app:estimator] ).", "We thus propose the estimator $ \\hat{\\mathbb{D}}_{v} $ , given in Eq. ( [@ref:LABEL:eq:hatdev] ).", "The lemma below gives a concentration bound for this estimator.", "\\newline <theorem> Lemma 4.1 . Let $ \\mathbf{x}=(x_{1},\\ldots,x_{n}) $ be a sequence of non-negative real values with a known $ \\|\\mathbf{x}\\|_{1} $ , and let $ U $ be a uniform distribution over the indices in $ [n] $ . Let $ W:=\\|\\mathbf{x}\\|/n $ , and $ \\mathbb{D}(\\mathbf{x}):=\\|\\mathbf{x}-W\\cdot\\mathbf{1}\\|_{1} $ .", "Suppose that $ m $ i.i.d.", "samples $ I_{1},\\ldots,I_{m} $ are drawn from $ U $ .", "Denote $ Z_{i}:=x_{I_{i}} $ for $ i\\in[n] $ , and $ \\mathbf{Z}:=(Z_{1},\\ldots,Z_{m}) $ .", "Define the following estimator for $ \\mathbb{D}(\\mathbf{x}) $ : \\newline <equation> $ \\hat{\\mathbb{D}}(\\mathbf{x}):=\\|\\mathbf{x}\\|_{1}+\\frac{n}{m}(\\|\\mathbf{Z}-W% \\cdot\\mathbf{1}\\|_{1}-\\|\\mathbf{Z}\\|_{1}).", "$ </equation> Then, with a probability at least $ 1-\\delta $ , $ |\\mathbb{D}(\\mathbf{x})-\\hat{\\mathbb{D}}(\\mathbf{x})|\\leq\\|\\mathbf{x}\\|_{1}% \\sqrt{2\\ln(2/\\delta)/m}. $ \\newline </theorem> <proof> Proof. Let $ Z_{i}^{\\prime}=|Z_{i}-W|-Z_{i} $ .", "If $ Z_{i}\\geq W $ , we have $ Z_{i}^{\\prime}=W $ .", "Otherwise, we have $ Z_{i}^{\\prime}=W-2Z_{i}\\geq-W $ .", "Hence, $ \\mathbb{P}[Z_{i}^{\\prime}\\in[-W,W]]=1 $ .", "Thus, by Hoeffding\u2019s inequality, with a probability at least $ 1-\\delta $ , we have $ |\\mathbb{E}[Z^{\\prime}_{1}]-\\frac{1}{m}\\sum_{i\\in[m]}Z^{\\prime}_{i}|\\leq W% \\cdot\\sqrt{2\\ln(2/\\delta)/m}. $ Now, \\newline <equation> $ \\mathbb{E}[Z^{\\prime}_{1}]=\\frac{1}{n}(\\|\\mathbf{x}-W\\cdot\\mathbf{1}\\|_{1}-\\|% \\mathbf{x}\\|_{1})=\\frac{1}{n}(\\mathbb{D}(\\mathbf{x})-\\|\\mathbf{x}\\|_{1}).", "$ </equation> In addition, $ \\frac{1}{m}\\sum_{i\\in[m]}Z^{\\prime}_{i}=\\frac{1}{m}(\\|\\mathbf{Z}-W\\cdot\\mathbf% {1}\\|_{1}-\\|\\mathbf{Z}\\|_{1})=\\frac{1}{n}(\\hat{\\mathbb{D}}(\\mathbf{x})-\\|% \\mathbf{x}\\|_{1}) $ .", "Therefore, with a probability at least $ 1-\\delta $ , \\newline <equation> $ \\big{|}\\mathbb{D}(\\mathbf{x})-\\|\\mathbf{x}\\|_{1}-(\\hat{\\mathbb{D}}(\\mathbf{x})% -\\|\\mathbf{x}\\|_{1})\\big{|}\\leq nW\\sqrt{2\\ln(2/\\delta)/m}=\\|\\mathbf{x}\\|_{1}% \\sqrt{2\\ln(2/\\delta)/m}, $ </equation> as claimed.", "\u220e \\newline </proof> The estimator $ \\hat{\\mathbb{D}}_{v} $ defined in Eq. ( [@ref:LABEL:eq:hatdev] ) is equal to $ \\hat{\\mathbb{D}}(\\mathbf{x}) $ in Lemma [@ref:LABEL:lem:bounds] , where $ \\mathbf{x} $ is the sequence of weights of $ x\\in\\mathcal{L}_{v} $ .", "In the next lemma, we apply Lemma [@ref:LABEL:lem:bounds] to all the estimates used in AWP , and prove the correctness of the definition of $ \\Delta_{v} $ given in Section [@ref:LABEL:sec:main] .", "\\newline <theorem> Lemma 4.2 .", "Fix inputs $ T,K,\\delta,\\beta $ to AWP .", "Recall that $ P $ is the pruning updated by AWP during its run.", "The following event holds with a probability at least $ 1-\\delta $ on the randomness of AWP : \\newline <equation> $ E_{0}:=\\{\\text{At all times during the run of {AWP}, $\\forall v\\in P,|\\mathbb{% D}_{v}-\\hat{\\mathbb{D}}_{v}|\\leq\\Delta_{v}$}\\}. $ </equation> \\newline </theorem> <proof> Proof.", "Fix a node $ v $ in $ T $ , and consider the value of $ \\hat{\\mathbb{D}}_{v} $ after drawing $ M_{v} $ random samples from $ \\mathcal{L}_{v} $ .", "To apply Lemma [@ref:LABEL:lem:bounds] , set $ \\mathbf{x} $ to be the sequence of weights of the examples in $ \\mathcal{L}_{v} $ .", "Then $ \\mathbb{D}_{v}=\\mathbb{D}(\\mathbf{x}) $ and $ \\hat{\\mathbb{D}}(\\mathbf{x})=\\hat{\\mathbb{D}}_{v} $ .", "For an integer $ M $ , let $ \\delta(M):=\\frac{3\\delta}{K\\pi^{2}M^{2}} $ .", "By Lemma [@ref:LABEL:lem:bounds] , with a probability at least $ 1-\\delta(M_{v}) $ , $ |\\mathbb{D}_{v}-\\hat{\\mathbb{D}}_{v}|\\leq w_{v}^{*}\\sqrt{2\\ln(2/\\delta(M_{v}))% /M_{v}}\\equiv\\Delta_{v} $ .", "We have $ \\sum_{n=1}^{\\infty}\\delta(n)=\\frac{3\\delta}{K\\pi^{2}}\\sum_{n=1}^{\\infty}\\frac{% 1}{n^{2}}=\\delta/(2K) $ .", "Thus, for any fixed node $ v $ , with a probability at least $ 1-\\delta/(2K) $ , after any number of samples $ M_{v} $ , $ |\\mathbb{D}_{v}-\\hat{\\mathbb{D}}_{v}|\\leq\\Delta_{v} $ .", "Denote this event $ D_{v} $ .", "Now, the pruning $ P $ starts as a singleton containing the root node.", "Subsequently, in each update of $ P $ , one node is removed and its two children are added.", "Thus, in total $ 2K-1 $ nodes are ever added to $ P $ (including the root node).", "Let $ v_{i} $ be the $ i $ \u2019th node added to $ P $ , and let $ V=\\{v_{1},\\ldots,v_{2K-1}\\} $ .", "We have, \\newline <equation> $ \\mathbb{P}[E_{0}]\\geq\\mathbb{P}[\\forall v\\in V,D_{v}]=1-\\mathbb{P}[\\exists v% \\in V,\\neg D_{v}].", "$ </equation> Now, letting $ \\mathcal{N} $ be the nodes in $ T $ , \\newline <equation> $ \\mathbb{P}[\\exists v\\in V,\\neg D_{v}]\\leq\\sum_{i=1}^{2K-1}\\sum_{v\\in\\mathcal{N% }}\\mathbb{P}[v_{i}=v]\\mathbb{P}[\\neg D_{v}\\mid v_{i}=v].", "$ </equation> Now, $ \\mathbb{P}[\\neg D_{v}\\mid v_{i}=v]=\\mathbb{P}[\\neg D_{v}] $ , since the estimate $ \\hat{\\mathbb{D}}_{v} $ uses samples that are drawn after setting $ v_{i}=v $ .", "Therefore, $ \\mathbb{P}[\\neg D_{v}\\mid v_{i}=v]\\leq\\delta/(2K) $ .", "Since $ \\sum_{v\\in\\mathcal{N}}\\mathbb{P}[v_{i}=v]=1 $ , it follows that $ \\mathbb{P}[\\exists v\\in V,\\neg D_{v}]\\leq\\delta $ .", "Therefore, We have $ \\mathbb{P}[E_{0}]\\geq 1-\\delta $ , as claimed.", "\u220e \\newline </proof> Some splits may increase the total discrepancy of the pruning, even in trees with a split quality smaller than $ 1 $ .", "The next auxiliary lemma upper bounds this increase, and shows that this bound is tight.", "\\newline <theorem> Lemma 4.3 . Let $ r $ be the root of a hierarchical tree and let $ P $ be a pruning of this tree.", "Then $ \\mathbb{D}_{P}\\leq 2\\mathbb{D}_{r} $ .", "Moreover, for any $ \\epsilon>0 $ , there exists a tree with a split quality $ q<1 $ and a pruning $ P $ of size $ 2 $ such that $ \\mathbb{D}_{P}\\geq(2-\\epsilon)\\mathbb{D}_{r} $ .", "\\newline </theorem> <proof> Proof.", "To prove the first part, denote the nodes in $ P $ by $ v_{1},\\ldots,v_{n} $ and let $ v_{0}:=r $ be the root node.", "For $ i\\in\\{0,\\ldots,n\\} $ , let $ \\mathbf{w}_{i} $ be a sequence of length $ N_{v_{i}} $ of the weights $ w^{*}(x) $ of all the leaves $ x\\in\\mathcal{L}_{v_{i}} $ . Let $ \\bar{w}^{*}_{i}:=\\frac{w^{*}_{v_{i}}}{N_{v_{i}}} $ .", "Then \\newline <equationgroup> <equation> $ \\mathbb{D}_{v_{i}}=\\|\\mathbf{w}_{i}-\\bar{w}^{*}_{i}\\cdot\\mathbf{1% }\\|_{1}=\\|\\mathbf{w}_{i}-\\bar{w}^{*}_{0}\\cdot\\mathbf{1}+\\bar{w}^{*}_{0}\\cdot% \\mathbf{1}-\\bar{w}^{*}_{i}\\cdot\\mathbf{1}\\|_{1} $ $ \\mathbb{D}_{v_{i}} $ $ =\\|\\mathbf{w}_{i}-\\bar{w}^{*}_{i}\\cdot\\mathbf{1}\\|_{1}=\\|\\mathbf{% w}_{i}-\\bar{w}^{*}_{0}\\cdot\\mathbf{1}+\\bar{w}^{*}_{0}\\cdot\\mathbf{1}-\\bar{w}^{% *}_{i}\\cdot\\mathbf{1}\\|_{1} $ </equation> <equation> $ \\leq\\|\\mathbf{w}_{i}-\\bar{w}^{*}_{0}\\cdot\\mathbf{1}\\|_{1}+\\|\\bar{% w}^{*}_{0}\\cdot\\mathbf{1}-\\bar{w}^{*}_{i}\\cdot\\mathbf{1}\\|_{1}=\\|\\mathbf{w}_{i% }-\\bar{w}^{*}_{0}\\cdot\\mathbf{1}\\|_{1}+N_{v_{i}}|\\bar{w}^{*}_{i}-\\bar{w}^{*}_{% 0}|.", "$ $ \\leq\\|\\mathbf{w}_{i}-\\bar{w}^{*}_{0}\\cdot\\mathbf{1}\\|_{1}+\\|\\bar{% w}^{*}_{0}\\cdot\\mathbf{1}-\\bar{w}^{*}_{i}\\cdot\\mathbf{1}\\|_{1}=\\|\\mathbf{w}_{i% }-\\bar{w}^{*}_{0}\\cdot\\mathbf{1}\\|_{1}+N_{v_{i}}|\\bar{w}^{*}_{i}-\\bar{w}^{*}_{% 0}|.", "$ </equation> </equationgroup> Now, observe that \\newline <equation> $ N_{v_{i}}|\\bar{w}_{i}^{*}-\\bar{w}^{*}_{0}|=|w_{i}^{*}-N_{v_{i}}\\bar{w}^{*}_{0}% |=|\\sum_{x\\in\\mathcal{L}_{v_{i}}}(w^{*}(x)-\\bar{w}^{*}_{0})|\\leq\\sum_{x\\in% \\mathcal{L}_{v_{i}}}|w^{*}(x)-\\bar{w}^{*}_{0}|=\\|\\mathbf{w}_{i}-\\mathbf{1}% \\cdot\\bar{w}^{*}_{0}\\|_{1}. $ </equation> Therefore, $ \\mathbb{D}_{v_{i}}\\leq 2\\|\\mathbf{w}_{i}-\\mathbf{1}\\cdot\\bar{w}^{*}_{0}\\|_{1} $ .", "Summing over all the nodes, and noting that $ \\mathbf{w}_{0}=\\mathbf{w}_{1}\\circ\\ldots\\circ\\mathbf{w}_{n} $ , we get: \\newline <equation> $ \\sum_{i\\in[n]}\\mathbb{D}_{v_{i}}\\leq\\sum_{i\\in[n]}2\\|\\mathbf{w}_{i}-\\bar{w}^{*% }_{0}\\cdot\\mathbf{1}\\|_{1}=2\\|\\mathbf{w}_{0}-\\bar{w}^{*}_{0}\\cdot\\mathbf{1}\\|_% {1}=2\\mathbb{D}_{v_{0}}, $ </equation> which proves the first part of the lemma.", "For the second part of the lemma, let $ n $ be an integer sufficiently large such that $ \\frac{2}{1+2/n}\\geq 2-\\epsilon $ .", "We consider a tree (see illustration in Figure [@ref:LABEL:fig:splitproof] ) with $ n+2 $ leaves.", "Denote the leaves by $ x_{1},\\ldots,x_{n+2} $ .", "Denote $ w:=1/(n+2) $ , and define $ w^{*}(x_{1})=0 $ , $ w^{*}(x_{2})=2w $ , and $ w^{*}(x_{i})=w $ for $ i\\geq 2 $ .", "Denote by $ v_{0} $ the root node of the tree, and let its two child nodes be $ v_{1} $ and $ v_{2} $ .", "The tree is organized so that $ x_{1} $ and $ n/2 $ of the examples with weight $ w $ are descendants of $ v_{1} $ , and the other examples are descendants of $ v_{2} $ .", "$ v_{1} $ has two child nodes, one is the leaf $ x_{1} $ and the other is some binary tree whose leaves are all the other $ n/2 $ examples.", "Similarly, $ v_{2} $ has a child node which is the leaf $ x_{2} $ , and the other examples are organized in some binary tree rooted at the other child node.", "It is easy to see that $ \\mathbb{D}_{v_{0}}=2w $ .", "To calculate $ \\mathbb{D}_{v_{1}} $ , note that the average weight of node $ v_{1} $ is $ \\frac{nw/2}{n/2+1}=nw^{2} $ .", "Thus, \\newline <equation> $ \\mathbb{D}_{v_{1}}\\equiv\\sum_{x\\in\\mathcal{L}_{v_{1}}}|nw^{2}-w^{*}(x)|=\\frac{% n}{2}(w-nw^{2})+nw^{2}=\\frac{nw}{2}(1-\\frac{n}{n+2})+nw^{2}=2nw^{2}. $ </equation> A similar calculation shows that $ \\mathbb{D}_{v_{2}}=2nw^{2} $ .", "Define the pruning $ P=\\{v_{1},v_{2}\\} $ of the tree rooted at $ v_{0} $ .", "Then \\newline <equation> $ \\mathbb{D}_{P}=4nw^{2}=2nw\\cdot\\mathbb{D}_{v_{0}}=\\frac{2}{1+2/n}\\mathbb{D}_{v% _{0}}\\geq(2-\\epsilon)\\mathbb{D}_{v_{0}}, $ </equation> as required.", "To show that this tree has a split quality of less than $ 1 $ , note that $ \\mathbb{D}_{v_{1}}=\\mathbb{D}_{v_{2}}=\\frac{1}{1+2/n}\\mathbb{D}_{v_{0}} $ , and that the discrepancy of each of the child nodes of $ v_{1} $ and $ v_{2} $ is zero, since all their leaves have the same weight.", "Therefore, this tree has a split quality $ \\frac{1}{1+2/n}<1 $ .", "\u220e \\newline </proof> We now prove the two main parts of Theorem [@ref:LABEL:thm:main] , starting with the approximation factor of AWP .", "\\newline <theorem> Lemma 4.4 .", "Fix inputs $ T,K,\\delta,\\beta $ to AWP , and suppose that $ T $ has a split quality $ q\\in(0,1) $ .", "Let $ P_{o} $ be the output of AWP .", "Let $ E_{0} $ be the event defined in Eq. ( [@ref:", "LABEL:eq:e0] ).", "In any run of AWP in which $ E_{0} $ holds, for any pruning $ Q $ of $ T $ such that $ |Q|=K $ , we have $ \\mathbb{D}_{P_{o}}\\leq 2\\beta(\\frac{\\log(K)}{\\log(1/q)}+1)\\mathbb{D}_{Q} $ .", "\\newline </theorem> <proof> Proof.", "Let $ Q $ be some pruning such that $ |Q|=K $ .", "Partition $ P_{o} $ into $ R,P_{a} $ and $ P_{d} $ , where $ R:=P_{o}\\cap Q $ , $ P_{a}\\subseteq P_{o} $ is the set of strict ancestors of nodes in $ Q $ , and $ P_{d}\\subseteq P_{o} $ is the set of strict descendants of nodes in $ Q $ . Let $ Q_{a}\\subseteq Q $ be the ancestors of the nodes in $ P_{d} $ and let $ Q_{d}\\subseteq Q $ be the descendants of the nodes in $ P_{a} $ , so that $ R,Q_{d} $ and $ Q_{a} $ form a partition of $ Q $ .", "First, we show that if any of the sets $ P_{a},P_{d},Q_{a},Q_{d} $ is empty then all of them are empty.", "By definition, $ P_{a}=\\emptyset\\Leftrightarrow Q_{d}=\\emptyset $ and $ P_{d}=\\emptyset\\Leftrightarrow Q_{a}=\\emptyset $ .", "Now, suppose that $ P_{a}=Q_{d}=\\emptyset $ .", "Since $ |R|+|P_{d}|+|P_{a}|=|P_{o}|=|Q|=|R|+|Q_{d}|+|Q_{a}| $ , we deduce that $ |P_{d}|=|Q_{a}| $ . But for each node in $ Q_{a} $ , there are at least two descendants in $ P_{d} $ , thus $ |P_{d}|\\geq 2|Q_{a}| $ .", "Combined with the equality, it follows that $ P_{d}=Q_{a}=\\emptyset $ .", "The other direction is proved in an analogous way.", "Lastly, if $ P_{a}=P_{d}=Q_{a}=Q_{d}=\\emptyset $ then $ P_{o}=Q $ , thus in this case $ \\mathbb{D}_{P}=\\mathbb{D}_{Q} $ .", "We therefore assume below that these sets are non-empty.", "We bound the discrepancies of $ P_{d} $ and of $ P_{a} $ separately.", "For each node $ u\\in Q_{a} $ , denote by $ P(u) $ the descendants of $ u $ in $ P_{d} $ .", "These form a pruning of the subtree rooted at $ u $ .", "In addition, the sets $ \\{P(u)\\}_{u\\in Q_{a}} $ form a partition of $ P_{d} $ .", "Thus, by the definition of discrepancy and Lemma [@ref:LABEL:lem:sons] , \\newline <equation> $ \\mathbb{D}_{P_{d}}=\\sum_{u\\in Q_{a}}\\mathbb{D}_{P(u)}\\leq\\sum_{u\\in Q_{a}}2% \\mathbb{D}_{u}=2\\mathbb{D}_{Q_{a}}. $ </equation> Let $ r $ be a node with the smallest discrepancy out of the nodes that were split by AWP during the entire run. Let $ P $ be the pruning when AWP decided to split node $ r $ .", "By the definition of the splitting criterion $ \\mathrm{SC} $ (Eq. ( [@ref:LABEL:eq:split] )), for all $ v\\in P\\setminus\\{r\\} $ , we had then $ \\beta(\\hat{\\mathbb{D}}_{r}-\\Delta_{r})\\geq\\hat{\\mathbb{D}}_{v}+\\Delta_{v} $ .", "Since $ E_{0} $ holds, we have $ \\mathbb{D}_{r}\\geq\\hat{\\mathbb{D}}_{r}-\\Delta_{r} $ and $ \\hat{\\mathbb{D}}_{v}+\\Delta_{v}\\geq\\mathbb{D}_{v} $ .", "Therefore, $ \\forall v\\in P\\setminus\\{r\\},\\beta\\mathbb{D}_{r}\\geq\\mathbb{D}_{v} $ .", "Now, any node $ v^{\\prime}\\in P_{o}\\setminus P $ is a descendant of some node $ v\\in P $ .", "Since $ T $ has split quality $ q $ for $ q<1 $ , we have $ \\mathbb{D}_{v^{\\prime}}\\leq\\mathbb{D}_{v} $ .", "Therefore, for all $ v^{\\prime}\\in P_{o} $ , $ \\mathbb{D}_{v^{\\prime}}\\leq\\beta\\mathbb{D}_{r} $ .", "In particular, $ \\mathbb{D}_{P_{a}}\\equiv\\sum_{v\\in P_{a}}\\mathbb{D}_{v}\\leq\\beta|P_{a}|\\mathbb% {D}_{r} $ .", "Now, since all the nodes in $ Q_{a} $ were split by AWP , we have $ \\mathbb{D}_{r}\\leq\\min_{v\\in Q_{a}}\\mathbb{D}_{v} $ .", "Thus, if $ \\mathbb{D}_{Q_{a}}=0 $ then $ \\mathbb{D}_{r}=0 $ .", "For $ \\mathbb{D}_{Q_{a}}>0 $ , define $ \\theta:=|P_{a}|\\cdot\\mathbb{D}_{r}/\\mathbb{D}_{Q_{a}} $ .", "It follows that $ \\mathbb{D}_{P_{a}}\\leq\\beta\\theta\\mathbb{D}_{Q_{a}} $ .", "By defining $ \\theta:=0 $ if $ \\mathbb{D}_{Q_{a}}=0 $ , this upper bound holds for all values of $ \\mathbb{D}_{Q_{a}} $ .", "Combining this with Eq. ( [@ref:LABEL:eq:pd] ), we get \\newline <equation> $ \\mathbb{D}_{P_{o}}=\\mathbb{D}_{R}+\\mathbb{D}_{P_{d}}+\\mathbb{D}_{P_{a}}\\leq% \\mathbb{D}_{R}+2\\mathbb{D}_{Q_{a}}+\\beta\\theta\\mathbb{D}_{Q_{a}}\\leq\\max(2,% \\beta\\theta)\\mathbb{D}_{Q}. $ </equation> Thus, to bound the approximation factor, it suffices to bound $ \\theta $ . Let $ P_{d}^{\\prime} $ be the set of nodes both of whose child nodes are in $ P_{d} $ .", "Denote $ n:=|P_{d}^{\\prime}| $ .", "In addition, each node in $ P_{d}^{\\prime} $ has an ancestor in $ Q_{a} $ , and no ancestor in $ P_{d}^{\\prime} $ .", "Therefore, $ P_{d}^{\\prime} $ can be partitioned to subsets according to their ancestor in $ Q_{a} $ , and each such subset is a part of some pruning of that ancestor.", "Thus, by Lemma [@ref:LABEL:lem:sons] , $ \\mathbb{D}_{P_{d}^{\\prime}}\\leq 2\\mathbb{D}_{Q_{a}} $ .", "Hence, for some node $ v\\in P^{\\prime}_{d} $ , $ \\mathbb{D}_{v}\\leq 2\\mathbb{D}_{Q_{a}}/n $ .", "It follows from the definition of $ r $ that $ \\mathbb{D}_{r}\\leq 2\\mathbb{D}_{Q_{a}}/n $ .", "Hence, $ \\theta\\leq 2|P_{a}|/n $ .", "Define $ \\alpha:=\\frac{\\log(1/q)}{\\log(|P_{a}|)+\\log(1/q)}\\leq 1 $ .", "If $ n\\geq\\alpha|P_{a}| $ , we have $ \\theta\\leq 2/\\alpha $ .", "We now consider the case $ n<\\alpha|P_{a}| $ , by deriving an additional upper bound on $ \\mathbb{D}_{r} $ .", "\\newline For a node $ v $ with an ancestor in $ Q_{a} $ , let $ l_{v} $ be the path length from this ancestor to $ v $ , and define $ L:=\\sum_{v\\in P^{\\prime}_{d}}l_{v} $ .", "We now prove that $ L\\geq|P_{a}|-n $ .", "Fix some $ u\\in Q_{a} $ , and let $ P_{u}(t) $ be the set of nodes in the pruning $ P $ in iteration $ t $ which have $ u $ as an ancestor. Let $ P^{\\prime}_{u}(t) $ be the set of nodes both of whose child nodes are in $ P_{u}(t) $ , and denote $ L_{u}(t):=\\sum_{v\\in P^{\\prime}_{u}(t)}l_{v} $ .", "We prove that for all iterations $ t $ , $ L_{u}(t)\\geq|P_{u}(t)|-2 $ .", "First, immediately after $ u $ is split, we have $ P^{\\prime}_{u}(t)=\\{u\\} $ , $ |P_{u}(t)|=2 $ , $ L_{u}(t)=0 $ .", "Hence, $ L_{u}(t)\\geq|P_{u}(t)|-2 $ .", "Next, let $ t $ such that $ P_{u}(t) $ grows by 1, that is some node $ u_{t} $ in $ P_{u}(t) $ is split.", "If $ u_{t} $ is the child of a node $ v_{t}\\in P^{\\prime}_{u}(t) $ , then $ P^{\\prime}_{u}(t+1)=P^{\\prime}_{u}(t)\\setminus\\{v_{t}\\}\\cup\\{u_{t}\\} $ .", "In this case, $ L_{u}(t+1)=L_{u}(t)+1 $ , since $ l_{u_{t}}=l_{v_{t}}+1 $ .", "Otherwise, $ u_{t} $ is not a child of a node in $ P^{\\prime}_{u}(t) $ , so $ P^{\\prime}_{u}(t+1)=P^{\\prime}_{u}(t)\\cup\\{u_{t}\\} $ , and so $ L_{u}(t+1)=L_{u}(t)+l_{u_{t}}\\geq L_{u}(t)+1 $ .", "Thus, $ L_{u}(t) $ grows by at least $ 1 $ when the size of $ P_{u}(t) $ grows by $ 1 $ .", "It follows that in all iterations, $ L_{u}(t)\\geq|P_{u}(t)|-2 $ .", "Summing over $ u\\in Q_{a} $ and considering the final pruning, we get $ L\\geq|P_{d}|-2|Q_{a}| $ .", "Now, since $ |P|=|Q| $ , we have $ |P_{d}|-|Q_{a}|=|Q_{d}|-|P_{a}| $ .", "From the definition of $ Q_{d} $ , $ |Q_{d}|\\geq 2|P_{a}| $ .", "Therefore, $ |P_{d}|-|Q_{a}|\\geq|P_{a}| $ .", "It follows that $ L\\geq|P_{a}|-|Q_{a}| $ .", "Lastly, every node $ u\\in Q_{a} $ was split by AWP , and has at least one descendant in $ P_{d}^{\\prime} $ .", "Therefore, $ |Q_{a}|\\leq|P^{\\prime}_{d}|\\equiv n $ .", "Hence, $ L\\geq|P_{a}|-n $ .", "\\newline It follows that for some node $ v\\in P_{d}^{\\prime} $ , $ l_{v}\\geq(|P_{a}|-n)/n=\\frac{|P_{a}|}{n}-1>0 $ , where the last inequality follows since $ n<\\alpha|P_{a}|<|P_{a}| $ .", "Letting $ u\\in Q_{a} $ be the ancestor of $ v $ in $ Q_{a} $ , we have by the split quality $ q $ of $ T $ that $ \\mathbb{D}_{v}\\leq\\mathbb{D}_{u}\\cdot q^{\\frac{|P_{a}|}{n}-1} $ .", "Since $ u\\in Q_{a} $ , we have $ \\mathbb{D}_{u}\\leq\\mathbb{D}_{Q_{a}} $ .", "In addition, $ \\mathbb{D}_{r}\\leq\\mathbb{D}_{v} $ by the definition of $ r $ .", "Therefore, $ \\mathbb{D}_{r}\\leq\\mathbb{D}_{Q_{a}}\\cdot q^{\\frac{|P_{a}|}{n}-1} $ .", "Since $ n<|P_{a}|\\alpha $ and $ q<1 $ , from the definition of $ \\alpha $ we have $ |P_{a}|q^{\\frac{|P_{a}|}{n}-1}\\leq 1<2/\\alpha $ .", "Therefore, in this case as well, $ \\theta\\leq 2/\\alpha $ .", "It follows that in all cases, $ \\theta\\leq 2/\\alpha\\leq 2(\\frac{\\log(|P_{a}|)}{\\log(1/q)}+1)\\leq 2(\\frac{\\log(% K)}{\\log(1/q)}+1) $ .", "Substituting this upper bound in Eq. ( [@ref:LABEL:eq:all] ), we get the statement of the lemma.", "\u220e \\newline </proof> Next, we prove an upper bound on the number of weight queries requested by AWP .", "\\newline <theorem> Lemma 4.5 . Let $ \\beta>1 $ .", "Consider a run of AWP in which $ E_{0} $ holds, and fix some iteration in this run.", "Let $ P $ be the current pruning, and for a node $ v $ in $ T $ , denote $ \\alpha_{v}:=\\frac{\\beta}{\\beta-1}\\cdot\\frac{w_{v}^{*}}{\\max_{u\\in P}\\mathbb{D}% _{u}} $ .", "Then in this iteration, the node $ {v_{s}} $ selected by AWP satisfies $ M_{v_{s}}<22\\alpha^{2}_{v_{s}}(\\ln(\\alpha^{4}_{v_{s}}K/\\delta)+10) $ .", "\\newline </theorem> <proof> Proof.", "Recall that the next weight query to be sampled by AWP is set to $ {v_{s}}\\in\\operatorname*{argmax}_{v\\in P}(\\hat{\\mathbb{D}}_{v}+\\Delta_{v}) $ .", "First, if some nodes $ v\\in P $ have $ M_{v}=0 $ , they will have $ \\Delta_{v}=\\infty $ , thus one of them will be set as $ {v_{s}} $ , in which case the bound on $ M_{v_{s}} $ trivially holds.", "Hence, we assume below that for all $ v\\in P $ , $ M_{v}\\geq 1 $ .", "Denote $ \\mathbb{D}_{\\mathrm{max}}:=\\max_{v\\in P}\\mathbb{D}_{v} $ . Let $ u\\in\\operatorname*{argmax}_{v\\in P}\\hat{\\mathbb{D}}_{v} $ be a node with a maximal estimated discrepancy.", "Since $ E_{0} $ holds, for all $ v\\in P $ we have $ \\hat{\\mathbb{D}}_{v}+\\Delta_{v}\\geq\\mathbb{D}_{v} $ .", "Thus, by definition of $ {v_{s}} $ , $ \\hat{\\mathbb{D}}_{{v_{s}}}+\\Delta_{{v_{s}}}\\geq\\mathbb{D}_{\\mathrm{max}} $ which implies $ \\hat{\\mathbb{D}}_{u}\\geq\\hat{\\mathbb{D}}_{{v_{s}}}\\geq\\mathbb{D}_{\\mathrm{max}% }-\\Delta_{{v_{s}}} $ .", "Therefore, \\newline <equationgroup> <equation> $ \\beta(\\hat{\\mathbb{D}}_{u}-\\Delta_{u})=\\hat{\\mathbb{D}}_{u}+(% \\beta-1)\\hat{\\mathbb{D}}_{u}-\\beta\\Delta_{u}\\geq\\hat{\\mathbb{D}}_{u}+(\\beta-1)% (\\mathbb{D}_{\\mathrm{max}}-\\Delta_{{v_{s}}})-\\beta\\Delta_{u}. $ $ \\beta(\\hat{\\mathbb{D}}_{u}-\\Delta_{u}) $ $ =\\hat{\\mathbb{D}}_{u}+(\\beta-1)\\hat{\\mathbb{D}}_{u}-\\beta\\Delta_{% u}\\geq\\hat{\\mathbb{D}}_{u}+(\\beta-1)(\\mathbb{D}_{\\mathrm{max}}-\\Delta_{{v_{s}}% })-\\beta\\Delta_{u}. $ </equation> </equationgroup> Denote $ \\theta:=(\\beta-1)\\mathbb{D}_{\\mathrm{max}}/(2\\beta) $ , and assume for contradiction that $ \\Delta_{{v_{s}}}\\leq\\theta $ .", "By the definitions of $ u $ and $ {v_{s}} $ , we have $ \\Delta_{u}\\leq\\Delta_{{v_{s}}}\\leq\\theta $ .", "Thus, from the inequality above and the definitions of $ \\theta,u,{v_{s}} $ , \\newline <equation> $ \\beta(\\hat{\\mathbb{D}}_{u}-\\Delta_{u})\\geq\\hat{\\mathbb{D}}_{u}+(\\beta-1)(% \\mathbb{D}_{\\mathrm{max}}-\\theta)-\\beta\\theta=\\hat{\\mathbb{D}}_{u}+\\theta\\geq% \\hat{\\mathbb{D}}_{{v_{s}}}+\\Delta_{{v_{s}}}\\geq\\max_{z\\in P\\setminus\\{u\\}}(% \\hat{\\mathbb{D}}_{z}+\\Delta_{z}), $ </equation> Implying that $ \\mathrm{SC}(u,P) $ holds. But this means that the previous iteration should have split this node in the pruning, a contradiction.", "Therefore, $ \\Delta_{{v_{s}}}>\\theta $ .", "Since $ \\Delta_{v_{s}}\\equiv w^{*}_{v_{s}}\\sqrt{2\\ln(2K\\pi^{2}M_{v_{s}}^{2}/(3\\delta))% /M_{v_{s}}} $ , it follows that $ M_{v_{s}}<\\frac{2{w_{v_{s}}^{*}}^{2}}{\\theta^{2}}\\cdot\\ln(2K\\pi^{2}M_{v_{s}}^{% 2}/(3\\delta)) $ .", "Denoting $ \\phi=\\frac{{4w_{v_{s}}^{*}}^{2}}{\\theta^{2}} $ and $ \\mu=\\sqrt{2K\\pi^{2}/(3\\delta)} $ , this is equivalent to $ M_{v_{s}}<\\phi\\ln(\\mu M_{v_{s}}) $ .", "By Lemma [@ref:LABEL:lem:mathineq] in Appendix [@ref:LABEL:app:mathineq] , this implies $ M_{v_{s}}<e\\phi\\ln(e\\mu\\phi) $ .", "Noting that $ \\phi=16\\alpha_{v}^{2} $ and bounding constants, the bound in the lemma is obtained.", "\u220e \\newline </proof> Lastly, we combine the lemmas above and prove the main theorem.", "\\newline <proof> Proof of Theorem Consider a run in which $ E_{0} $ holds.", "By Lemma [@ref:LABEL:lem:prob] , this occurs with a probability at least $ 1-\\delta $ .", "If $ T $ has a split quality $ q $ , the approximation factor follows directly from Lemma [@ref:LABEL:lem:devbound] .", "Next, note that AWP makes a higher-order query of a node only if it is the right child of a node that was split in line [@ref:LABEL:line:split] of Alg.", "[@ref:LABEL:alg:alg] .", "Thus, the number of weight queries of internal nodes is $ K-1 $ .", "We now use Lemma [@ref:LABEL:lem:queries] to bound the total number of weight queries of examples under $ E_{0} $ .", "First, we lower bound $ \\max_{v\\in P}\\mathbb{D}_{v} $ for any pruning $ P $ during the run of AWP .", "Let $ u\\in\\operatorname*{argmax}_{v\\in P_{o}}\\mathbb{D}_{v} $ .", "By the definition of $ u $ , we have $ \\mathbb{D}_{u}\\geq\\mathbb{D}_{P_{o}}/K $ .", "Now, at any iteration during the run of AWP , some ancestor $ v $ of $ u $ is in $ P $ .", "By Lemma [@ref:LABEL:lem:sons] , we have $ \\mathbb{D}_{v}\\geq\\mathbb{D}_{u}/2 $ .", "Therefore, $ \\max_{v\\in P}\\mathbb{D}_{v}\\geq\\mathbb{D}_{P_{o}}/(2K) $ .", "Thus, by Lemma [@ref:LABEL:lem:queries] , at any iteration of AWP , $ {v_{s}} $ is set to some node in $ P $ that satisfies $ M_{v_{s}}<22\\alpha^{2}_{v_{s}}(\\ln(\\alpha^{4}_{v_{s}}K/\\delta)+10) $ , where $ \\alpha_{v_{s}}=\\frac{\\beta}{\\beta-1}\\cdot\\frac{2Kw_{v}^{*}}{\\mathbb{D}_{P_{o}}} $ .", "Hence, the number of samples taken for node $ v $ by AWP is at most $ T_{v}:=22\\alpha^{2}_{v_{s}}(\\ln(\\alpha^{4}_{v_{s}}K/\\delta)+10)+1 $ , and so the the total number of example weight queries taken by AWP is at most $ \\sum_{v\\in V}T_{v} $ , where $ V $ is the set of nodes that participate in $ P $ at any time during the run.", "To bound this sum, note that for any pruning $ P $ during the run of AWP , we have $ \\sum_{v\\in P}w_{v}^{*}=1 $ .", "Hence, $ \\sum_{v\\in P}{w_{v}^{*}}^{2}\\leq 1 $ .", "Since there are $ K $ different prunings during the run, we have $ \\sum_{v\\in V}{w_{v}^{*}}^{2}\\leq K $ .", "Substituting $ \\alpha_{v} $ by its definition and rearranging, we get that the total number of example weight queries by AWP is $ \\tilde{O}((1+\\frac{1}{\\beta-1})^{2}K^{3}\\ln(1/\\delta)/\\mathbb{D}_{P_{o}}^{2}) $ .", "\u220e \\newline </proof>  </section>"], ["<section> <title> 5 Experiments </title>  We report experiments comparing AWP to natural baselines.", "A python implementation of AWP and all experiments can be found at https://github.com/Nadav-Barak/AWP .", "The implementation of AWP includes two practical improvements: First, we use an empirical Bernstein concentration bound [@bib:MaurerPo09] to reduce the size of $ \\Delta_{v} $ when possible; This is consistent with the analysis.", "See Appendix [@ref:LABEL:app:bernstein] for details.", "Second, for all algorithms, we take account of the known weight values of single examples in the output weighting, as follows.", "For $ v\\in P_{o} $ , let $ S_{v} $ be the examples in $ \\mathcal{L}_{v} $ whose weight was queried.", "Given the output pruning $ P $ , we define the weighting $ w_{P}^{\\prime} $ .", "For $ x\\in S_{v} $ , $ w_{P}^{\\prime}(x):=w^{*}(x) $ ; for $ x\\in\\mathcal{L}_{v}\\setminus S_{v} $ , we set $ w^{\\prime}_{P}(x):=(w^{*}_{v}-\\sum_{x\\in S_{v}}w^{*}(x))/(N_{v}-|S_{v}|) $ .", "In all the plots we report the normalized output distance $ \\mathrm{dist}(w^{\\prime}_{P},w^{*})=\\|w^{\\prime}_{P}-w^{*}\\|_{1}/2\\in[0,1] $ , equal to half the discrepancy of $ w_{P}^{\\prime} $ .", "\\newline To fairly compare AWP to baselines, they were all allowed the same number of higher-order weight queries and example weight queries as requested by AWP for the same inputs.", "The baselines are non-adaptive, thus the example weight queries were drawn uniformly at random from the data set at the start of their run.", "We tested the following baselines: (1) WEIGHT : Iteratively split the node with the largest weight.", "Example weight queries are used only for the final calculation of $ w^{\\prime}_{P} $ .", "The rationale is to get a finer resolution of the pruning in more important parts of the data set.", "However, this can lead to wasting resources on low-discrepancy parts of the tree and an unbounded approximation factor.", "(2) UNIFORM : Iteratively split the node $ v $ with the largest $ \\hat{\\mathbb{D}}_{v} $ , the same estimator used by AWP , but without adaptive queries.", "(3) EMPIRICAL : The same as UNIFORM , except that instead of $ \\hat{\\mathbb{D}}_{v} $ , it uses the naive empirical estimator, $ \\frac{n}{|S_{v}|}\\sum_{x\\in S_{v}}|w^{*}_{v}(x)/N_{v}-w^{*}(x)| $ ; See discussion of this estimator in Section [@ref:LABEL:sec:analysis] .", "\\newline Figure [@ref:LABEL:fig:exps] provides representative results of experiments.", "The full descriptions and results of the experiments are given below.", "In all experiments, AWP performs better than the other algorithms.", "In addition, UNIFORM and EMPIRICAL behave similarly in most experiments, with UNIFORM sometimes being slightly better.", "This shows that our new estimator is empirically adequate, on top of its crucial advantage in getting a small $ \\Delta_{v} $ .", "\\newline We ran several types of experiments, all with inputs $ \\delta=0.05 $ and $ \\beta=4 $ .", "For each experiment, we report the average normalized output distance over $ 10 $ runs, as a function of the pruning size.", "Error bars (shaded regions) show the maximal and minimal normalized distances obtained in these runs.", "The hierarchical tree $ T $ was generated from the input data set using Ward\u2019s method [@bib:mullner2011modern] , implemented by the scipy python package.", "First, we tested a scenario where the target weighting $ w^{*} $ of examples in the data set is controlled by simple example properties.", "$ w^{*} $ was defined to be sufficiently different from uniform, to allow non-trivial prunings.", "The data sets were (1) MNIST [@bib:MNIST] : 60,000 (training) images of hand-written digits, classified into 10 classes (digits), and (2) Caltech256 [@bib:griffin2007caltech] , with 29,780 images of various objects, classified into 256 classes.", "For each data set, $ w^{*} $ was generated by dividing the data into $ 10 $ ordered bins, and allocating the weight so that an example in each bin is $ N $ times heavier than an example in the next bin.", "This was tested for $ N=2,4 $ , and for two ways of dividing into bins: (1) By brightness: The bins represented the brightness of the example, as measured by average pixel value.", "The results for this experiment can be seen in Figure [@ref:LABEL:fig:bright] for $ N=2 $ (left) and for $ N=4 $ (right).", "(2) By class: $ 3 $ random bin orders were tested.", "For the MNIST data set each bin includes the examples of one class, the results are displayed in Figure [@ref:LABEL:fig:mnistrand] .", "For the Caltech256 dataset 10 bins were generated by randomly partitioning the $ 256 $ classes into 10 bins with (almost) the same number of classes in each.", "The results of this experiment are displayed in Figure [@ref:LABEL:fig:caltechrand] .", "The allocation of classes to bins and their ordering, for both data sets, are provided as part of the code implantation.", "It can be seen that AWP obtains an improvement over the baselines in the MNIST experiments, while the Caltech256 experiment obtains about the same results for all algorithms, with a slight advantage for AWP .", "\\newline Next, we experimented with standard domain-adaptation data sets (see, e.g., [@bib:gong2012geodesic,hoffman2012discovering,ding2015deep] ).", "The input data set was Caltech256.", "The target weight $ w^{*} $ of each image was set to the fraction of images from the target data set which have this image as their nearest neighbor.", "The tested target data sets were: (1) The Office dataset [@bib:saenko2010adapting] , out of which the 10 classes that also exist in Caltech256 (1410 images) were used as the target data (2) The Bing dataset [@bib:BergamoTorresani10,Bing] , which includes $ 300 $ images in each Caltech256 class.", "The results for those experiments are displayed in Figure [@ref:LABEL:fig:nn] .", "In addition, for the Bing dataset, we also ran three experiments where images from a single super-class from the taxonomy in [@bib:griffin2007caltech] were used as the target data set.", "The super-classes that were tested were \u201cplants\u201d \u201cinsects\u201d and \u201canimals\u201d, results are displayed in Figure [@ref:LABEL:fig:BingSupercat] ."]], "target": "The classes in each such super-class, as well as those in the Office data set, are given in Table . In all of the experiments, AWP performs significantly better than the baselines."}, {"tabular": ["    &  Layer Type  &  Maps  &  Map Size  &  Neurons  &  Kernel Size  &  Weights ", " Large  &  Input  &  -  &  29x29  &  841  &  -  &  - ", " Convolutional  &  20  &  26x26  &  13520  &  4x4  &  340 ", " Max-pooling  &  20  &  26x26  &  13520  &  1x1  &  - ", " Convolutional  &  60  &  22x22  &  29040  &  5x5  &  30060 ", " Max-pooling  &  60  &  11x11  &  7260  &  2x2  &  - ", " Convolutional  &  100  &  6x6  &  3600  &  6x6  &  216100 ", " Max-pooling  &  100  &  2x2  &  900  &  3x3  &  - ", " Fully connected  &  -  &  150  &  150  &  -  &  135150 ", " Output  &  -  &  10  &  10  &  -  &  1510 ", " Medium  &  Input  &  -  &  29x29  &  841  &  -  &  - ", " Convolutional  &  20  &  26x26  &  13520  &  4x4  &  340 ", " Max-pooling  &  20  &  13x13  &  3380  &  2x2  &  - ", " Convolutional  &  40  &  9x9  &  3240  &  5x5  &  20040 ", " Max-pooling  &  40  &  3x3  &  360  &  3x3  &  - ", " Fully connected  &  -  &  150  &  150  &  -  &  54150 ", " Output  &  -  &  10  &  10  &  -  &  1510 ", " Small  &  Input  &  -  &  29x29  &  841  &  -  &  - ", " Convolutional  &  5  &  26x26  &  3380  &  4x4  &  85 ", " Max-pooling  &  5  &  13x13  &  845  &  2x2  &  - ", " Convolutional  &  10  &  9x9  &  810  &  5x5  &  1260 ", " Max-pooling  &  10  &  3x3  &  90  &  3x3  &  - ", " Fully connected  &  -  &  50  &  50  &  -  &  4550 ", " Output  &  -  &  10  &  10  &  -  &  510  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Traditionally engineers developed applications by specifying computer instructions that determined the application behavior.", "Nowadays engineers focus on developing and implementing sophisticated deep learning models that can learn to solve complex problems.", "Moreover, deep learning algorithms [@bib:lecun2015nature] can learn from their own experience rather than that of the engineer.", "\\newline Many private and public organizations are collecting huge amounts of data that may contain useful information from which valuable knowledge may be derived.", "With the pervasiveness of the Internet of Things the amount of available data is getting much larger [@bib:Hsu2014] .", "Deep learning is a useful tool for analyzing and learning from massive amounts of data (also known as Big Data) that may be unlabeled and unstructured [@bib:strawn2016,sharma2014,najafabadi2015] .", "Deep learning algorithms can be found in many modern applications [@bib:siri,taigman2014deepface,hadsell2009learning,wu2014deep,szegedy2015going,fox2014,jiang2016,zhang2012] , such as, voice recognition, face recognition, autonomous cars, classification of liver diseases and breast cancer, computer vision, or social media.", "\\newline A Convolutional Neural Network (CNN) is a variant of a Deep Neural Network (DNN) [@bib:110_deeplearning_lenet] .", "Inspired by the visual cortex of animals, CNNs are applied to state-of-the-art applications, including computer vision and speech recognition [@bib:deng2014deep] .", "However, supervised training of CNNs is computationally demanding and time consuming, and in many cases, several weeks are required to complete a training session.", "Often applications are tested with different parameters, and each test requires a full session of training.", "\\newline Multi-core processors [@bib:Williams:2009] and in particular many-core [@bib:benkner11] processing architectures, such as the NVIDIA Graphical Processing Unit (GPU) [@bib:nvidia_gpu] or the Intel Xeon Phi [@bib:chrysos2012intel] co-processor, provide processing capabilities that may be used to significantly speed-up the training of CNNs.", "While existing research [@bib:cirecsan2011high,vrtanoski2012pattern,szegedy2015going,yadan2013multi,sainath2015deep] has addressed extensively the training of CNNs using GPUs, so far not much attention is given to the Intel Xeon Phi co-processor.", "Beside the performance capabilities, the Xeon Phi deserves our attention because of programmability [@bib:pllana09] and portability [@bib:KesslerDTNRDBTP12] .", "\\newline In this paper, we present our parallelization scheme for training convolutional neural networks, named Controlled Hogwild with Arbitrary Order of Synchronization (CHAOS).", "CHAOS is tailored for the Intel Xeon Phi co-processor and exploits both the thread- and SIMD-level parallelism.", "The thread-level parallelism is used to distribute the work across the available threads, whereas SIMD parallelism is used to compute the partial derivatives and weight gradients in convolutional layer.", "Empirical evaluation of CHAOS is performed on an Intel Xeon Phi 7120 co-processor.", "For experimentation, we use various number of threads, different CNNs architectures, and the MNIST dataset of handwritten digits [@bib:lecun2010mnist] .", "Experimental evaluation results show that using the total number of available threads on the Intel Xeon Phi we can achieve speedups of up to $ 103\\times $ compared to the execution on one thread of the Xeon Phi, $ 14\\times $ compared to the sequential execution on Intel Xeon E5, and $ 58\\times $ compared to the sequential execution on Intel Core i5.", "The error rates of the parallel execution are comparable to the sequential one.", "Furthermore, we use performance prediction to study the performance behavior of our parallel solution for training CNNs for numbers of cores that go beyond the generation of the Intel Xeon Phi that was used in this paper.", "The main contributions of this paper include: \\newline <list> \\ design and implementation of CHAOS parallelization scheme for training CNNs on the Intel Xeon Phi, \\newline \\ \\ performance modeling of our parallel solution for training CNNs on the Intel Xeon Phi, \\newline \\ \\ measurement-based empirical evaluation of CHAOS parallelization scheme, \\newline \\ \\ model-based performance evaluation for future architectures of the Intel Xeon Phi.", "\\newline \\ </list> \\newline The rest of the paper is organized as follows.", "We discuss the related work in Section [@ref:LABEL:sec:related-work] .", "Section [@ref:LABEL:sec:background] provides background information on CNNs and the Intel Xeon Phi many-core architecture.", "Section [@ref:LABEL:sec:chaos] discusses the design and implementation aspects of our parallelization scheme.", "The experimental evaluation of our approach is presented in Section [@ref:LABEL:sec:evaluation] .", "We summarize the paper in Section [@ref:LABEL:sec:conclusion] .", "\\newline  </section>"], ["<section> <title> 2 Related Work </title>  In comparison to related work that target GPUs, the work related to machine learning for Intel Xeon Phi is sparse.", "In this section, we describe machine learning approaches that target the Intel Xeon Phi co-processor, and thereafter we discuss CNN solutions for GPUs and contrast them to our CHAOS implementation.", "\\newline <subsection> <title> 2.1 Machine Learning targeting Intel Xeon Phi </title> In this section, we discuss existing work for Support Vector Machines (SVMs), Restricted Boltzmann Machines (RBMs), sparse auto encoders and the Brain-State-in-a-Box (BSB) model.", "\\newline You et al. [@bib:you2014mic] present a library for parallel Support Vector Machines, MIC-SVM, which facilitates the use of SVMs on many- and multi-core architectures including Intel Xeon Phi.", "Experiments performed on several known datasets showed up to 84x speed up on the Intel Xeon Phi compared to the sequential execution of LIBSVM [@bib:chang2011libsvm] .", "In comparison to their work, we target deep learning.", "\\newline Jin et al. [@bib:JinWGYH14] perform the training of sparse auto encoders and restricted Boltzmann machines on the Intel Xeon Phi 5110p.", "The authors reported a speed up factor of $ 7-10\\times $ times compared to the Xeon E5620 CPU and more than $ 300\\times $ times compared to the un-optimized version executed on one thread on the co-processor.", "Their work targets unsupervised deep learning of restricted Boltzmann machines and sparse auto encoders, whereas we target supervised deep learning of CNNs.", "\\newline The performance gain on Intel Xeon Phi 7110p for a model called Brain-State-in-a-Box (BSB) used for text recognition is studied by Ahmed et al. in [@bib:ahmed2014accelerating] .", "The authors report about two-fold speedup for the co-processor compared to a CPU with 16 cores when parallelizing the algorithm.", "While both approaches target Intel Xeon Phi, our work addresses training of CNNs on the MNIST dataset.", "\\newline </subsection> <subsection> <title> 2.2 Related Work Targeting CNNs </title> In this section, we will discuss CNNs solutions for GPUs in the context of computer vision (image classification).", "Work related to MNIST [@bib:lecun2010mnist] dataset is of most interest, also NORB [@bib:lecun2004learning] and CIFAR 10 [@bib:krizhevsky2009learning] is considered.", "Additionally, work done in speech recognition and document processing is briefly addressed.", "We conclude this section by contrasting the presented related work with our CHAOS parallelization scheme.", "\\newline Work presented by Cire\u015fan et al. [@bib:cirecsan2011high] target a CNN implementation raising the bars for the CIFAR10 (19.51% error rate), NORB (2.53% error rate) and MNIST (0.35% error rate) datasets.", "The training was performed on GPUs (Nvidia GTX 480 and GTX 580) where the authors managed to decrease the training time severely - up to $ 60\\times $ compared to sequential execution on a CPU - and decrease the error rates to an, at the time, state-of-the-art accuracy level.", "\\newline Later, Cire\u015fan et al. [@bib:cirecsan2012multi] presented their multi-column deep neural network for classification of traffic sings.", "The results show that the model performed almost human-like (humans'error rate about 0.20%) on the MNIST dataset, achieving a best error rate of 0.23%.", "The authors trained the network on a GPU.", "Vrtanoski et al. [@bib:vrtanoski2012pattern] use OpenCL for parallelization of the back-propagation algorithm for pattern recognition.", "They showed a significant cost reduction, a maximum speedup of $ 25.8\\times $ was achieved on an ATI 5870 GPU compared to a Xeon W3530 CPU when training the model on the MNIST dataset.", "The ImageNet challenge aims to evaluate algorithms for large-scale object detection and image classification based on the ImageNet dataset.", "Krizhevsky et al. [@bib:krizhevsky2012imagenet] joined the challenge and reduced the error rate of the test set to 15.3% from the second best 26.2% using a CNN with 5 convolutional layers.", "For the experiments, two GPUs (Nvidia GTX 580) were used only communicating in certain layers.", "The training lasted for 5 to 6 days.", "In a later challenge, ILSVRC 2014, a team from Google entered the competition with GoogleNet, a 22-layer deep CNN and won the classification challenge with a 6.67% error rate.", "The training was carried out on CPUs.", "The authors state that the network could be trained on GPUs within a week, illuminating the limited amount of memory to be one of the major concerns [@bib:szegedy2015going] .", "Yadan et al. [@bib:yadan2013multi] used multiple GPUs to train CNNs on the ImageNet dataset using both data- and model-parallelism, i.e. either the input space is divided into mini-batches where each GPU train its own batch (data parallelism) or the GPUs train one sample together (model parallelism).", "There is no direct comparison with the training time on CPU, however, using 4 GPUs (Nvidia Titan) and model- and data-parallelism, the network was trained for 4.8 days.", "Song et al. [@bib:song2014deep] constructed a CNN to recognize face expressions and developed a smart-phone app in which the user can capture a picture and send it to a server hosting the network.", "The network, predicts a face expression and sends the result back to the user.", "With the help of GPUs (Nvidia Titan), the network was trained in a couple of hours on the ImageNet dataset.", "Scherer et al. [@bib:scherer2010accelerating] accelerated the large-scale neural networks with parallel GPUs.", "Experiments with the NORB dataset on an Nvidia GTX 285 GPU showed a maximal speedup of $ 115\\times $ compared to a CPU implementation (Core i7 940).", "After training the network for 360 epochs, an error rate of 8.6% was achieved.", "Cire\u015fan et al. [@bib:cirecsan2011committee] combined multiple CNNs to classify German traffic signs and achieved a 99.15% recognition rate (0.85 % error rate).", "The training was performed using an Intel Core i7 and 4 GPUs (2 x GTX 480 and 2 x GTX 580).", "More recently Abadi et al. [@bib:tensorflow2015whitepaper] presented TensorFlow, a system for expressing and executing machine learning algorithms including training deep neural network models.", "Researchers have also found CNNs successful for speech tasks.", "Large vocabulary continuous speech recognition deals with translation of continuous speech for languages with large vocabularies.", "Sainath et al. [@bib:sainath2015deep] investigated the advantages of CNNs performing speech recognition tasks and compared the results with previous DNN approaches.", "Results indicated on a 12-14% relative improvement of word error rates compared to a DNN trained on GPUs.", "Chellapilla et al. [@bib:chellapilla2006high] investigated GPUs (Nvidia Geforce 7800 Ultra) for document processing on the MNIST dataset and achieved a $ 4.11\\times $ speed up compared to the sequential execution a Intel Pentium 4 CPU running at 2.5 GHz clock frequency.", "\\newline In contrast to CHAOS, these studies target training of CNNs using GPUs, whereas our approach addresses training of CNNs on the MNIST dataset using the Intel Xeon Phi co-processor.", "While there are several review papers (such as, [@bib:bahrampour2015comparative,shi2016benchmarking,tabik2017snapshot] ) and on-line articles (such as, [@bib:murphy2016review] ) that compare existing frameworks for parallelization of training CNN architectures, we focus on detailed analysis of our proposed parallelization approach using measurement techniques and performance modeling.", "We compare the performance improvement achieved with CHAOS parallelization scheme to the sequential version executed on Intel Xeon Phi, Intel Xeon E5 and Intel Core i5 processor.", "\\newline </subsection>  </section>"], ["<section> <title> 3 Background </title>  In this section, we first provide some background information related to the neural networks focusing on convolutional neural networks, and thereafter we provide some information about the architecture of the Intel Xeon Phi.", "\\newline <subsection> <title> 3.1 Neural Networks </title> A Convolutional Neural Network is a variant of a Deep Neural Network, which introduces two additional layer types: {convolutional layers} and {pooling layers} .", "The mammal visual processing system is hierarchical (deep) in nature.", "Higher level features are abstractions of lower level ones.", "E.g. to understand speech, waveforms are translated through several layers until reaching a linguistic level.", "A similar analogy can be drawn for images, where edges and corners are lower level abstractions translated into more spatial patterns on higher levels.", "Moreover, it is also known that the animal cortex consists of both simple and complex cells firing on certain visual inputs in their receptive fields.", "Simple cells detect edge-like patterns whereas complex cells are locally invariant, spanning larger receptive fields.", "These are the very fundamental properties of the animal brain inspiring DNNs and CNNs.", "\\newline In this section, we first describe the DNNs and the Forward- and Back-propagation, thereafter we introduce the CNNs.", "\\newline <subsubsection> <title> 3.1.1 Deep Neural Networks </title> The architecture of a DNN consists of multiple layers of neurons.", "Neurons are connected to each other through edges (weights).", "The network can simply be thought of as a weighted graph; a directed acyclic graph represents a feed-forward network.", "The depth and breadth of the network differs as may the layer types.", "Regardless of the depth, a network has at least one input and one output layer.", "A neuron has a set of incoming weights, which have corresponding outgoing edges attached to neurons in the previous layer.", "Also, a bias term is used at each layer as an intercept term.", "The goal of the learning process is to adjust the network weights and find a global minimum by reducing the overall error, i.e. the deviation between the predicted and the desired outcome of all the samples.", "The resulting weight parameters can thereafter be used to make predictions of unseen inputs [@bib:ng2011ufldl] .", "\\newline </subsubsection> <subsubsection> <title> 3.1.2 Forward Propagation </title> DNNs can make predictions by forward propagating an input through the network.", "Forward propagation proceeds by performing calculations at each layer until reaching the output layer, which contains a vector representing the prediction.", "For example, in image classification problems, the output layer contains the prediction score that indicates the likelihood that an image belongs to a category [@bib:agibansky,ng2011ufldl] .", "\\newline The forward propagation starts from a given input layer, then at each layer the activation for a neuron is activated using the equation $ y^{l}_{i}=\\sigma(x^{l}_{i})+I^{l}_{i} $ where $ y^{l}_{i} $ is the output value of neuron $ i $ at layer $ l $ , $ x^{l}_{i} $ is the input value of the same neuron, and $ \\sigma $ (sigmoid) is the activation function.", "$ I^{l}_{i} $ is used for the input layer when there is no previous layer.", "The goal of the activation function is to return a normalized value ( sigmoid return [0,1] and tanh is used in cases where the desired return values are [-1,1]).", "The input $ x^{l}_{i} $ can be calculated as $ x^{l}_{i}=\\sum_{j}(w^{l}_{ji}y^{l-1}_{j}) $ where $ w^{l}_{ji} $ denotes the weight between neuron $ i $ in the current layer $ l $ , and $ j $ in the previous layer, and $ y^{l-1}_{j} $ the output of the $ j $ th neuron at the previous layer.", "This process is repeated until reaching the output layer.", "At the output layer, it is common to apply a soft max function, or similar, to squash the output vector and hence derive the prediction.", "\\newline </subsubsection> <subsubsection> <title> 3.1.3 Back-Propagation </title> Back-propagation is the process of propagating errors, i.e. the loss calculated as the deviation between the predicted and the desired output, backward in the network, by adjusting the weights at each layer.", "The error and partial derivatives $ \\delta^{l}_{i} $ are calculated at the output layer based on the predicted values from forward propagation and the labeled value (the correct value).", "At each layer, the relative error of each neuron is calculated and the weight parameters are updated based on how much the neuron participated in the faulty prediction.", "The equation: $ \\dfrac{\\delta E}{\\delta y^{l}_{i}}=\\sum{w^{l}_{ij}\\dfrac{\\delta E}{\\delta x^{l% +1}_{j}}} $ denotes that the partial derivative of neuron $ i $ at the current layer $ l $ is the sum of the derivatives of connected neurons at the next layer multiplied with the weights, assuming $ w^{l} $ denotes the weights between the maps.", "Additionally, a decay is commonly used to control the impact of the updates, which is omitted in the above calculations.", "More concretely, the algorithm can be thought of as updating the layer's weights based on \u201dhow much it was responsible for the errors in the output\u201d [@bib:agibansky,ng2011ufldl] .", "\\newline </subsubsection> <subsubsection> <title> 3.1.4 Convolutional Neural Networks </title> A Convolutional Neural Network is a multi-layer model constructed to learn various levels of representations where higher level representations are described based on the lower level ones [@bib:schmidhuber2015deep] .", "It is a variant of deep neural network that introduces two new layer types: {convolutional} and {pooling} layers.", "\\newline The convolutional layer consists of several feature maps where neurons in each map connect to a grid of neurons in maps in the previous layer through overlapping kernels.", "The kernels are tiled to cover the whole input space.", "The approach is inspired by the receptive fields of the mammal visual cortex.", "All neurons of a map extract the same features from a map in the previous layer as they share the same set of weights.", "\\newline Pooling layers intervene convolutional layers and have shown to lead to faster convergence.", "Each neuron in a pooling layer outputs the (maximum/average) value of a partition of neurons in the previous layer, and hence only activates if the underlying grid contains the sought feature.", "Besides from lowering the computational load, it also enables position invariance and down samples the input by a factor relative to the kernel size [@bib:lecun1998gradient] .", "\\newline Figure [@ref:LABEL:fig:LeNet] shows LeNet-5 that is an example of a Convolutional Neural Network.", "Each layer of convolution and pooling (that is a specific method of sub-sampling used in LeNet) comprise several feature maps.", "Neurons in the feature map cover different sub-fields of the neurons from the previous layer.", "All neurons in a map share the same weight parameters, therefore they extract the same features from different parts of the input from the previous layers.", "\\newline CNNs are commonly constructed similarly to the LeNet-5, beginning with an input layer, followed by several convolutional/pooling combinations, ending with a fully connected layer and an output layer [@bib:lecun1998gradient] .", "Recent networks are much deeper and/or wider, for instance, the GoogleNet [@bib:szegedy2015going] consists of 22 layers.", "\\newline Various implementations target the Convolutional Neural Networks, such as: {EbLearn} at New York University and {Caffe} at Berkeley.", "As a basis for our work we selected a project developed by Cire\u015fan [@bib:dciresan] .", "This implementation targets the MNIST dataset of handwritten digits, and has the possibility to dynamically configure the definition of layers, the activation function and the connection types using a configuration file.", "\\newline </subsubsection> </subsection> <subsection> <title> 3.2 Parallel Systems accelerated with Intel\u00aeXeon Phi\u2122 </title> Figure [@ref:LABEL:fig:emil-platform] depicts an overview of the Intel Xeon Phi (codenamed Knights Corner) architecture.", "It is a many-core shared-memory co-processor, which runs a lightweight Linux operating system that offers the possibility to communicate with it over {ssh} .", "The Xeon Phi offers two programming models: \\newline <list> \\ {offload} - parts of the applications running on the host are offloaded to the co-processor \\newline \\ \\ {native} - the code is compiled specifically for running natively on the co-processor.", "The code and all the required libraries should be transferred on the device.", "In this paper, we focus on the native mode.", "\\newline \\ </list> \\newline The Intel Xeon Phi (type 7120P used in this paper) comprises 61 x86 cores, each core runs at 1.2 GHz base frequency, and up to 1.3GHz on max turbo frequency [@bib:chrysos2012intel] .", "Each core can switch between four hardware threads in a round-robin manner, which amounts to a total of 244 threads per co-processor.", "Theoretically, the co-processor can deliver up to one teraFLOP/s of double precision performance, or two teraFLOP/s of single precision performance.", "Each core has its own L1 (32KB) and L2 (512KB) cache.", "The L2 cache is kept fully coherent by a global distributed tag-directory (TD).", "The cores are connected through a bidirectional ring bus interconnect, which forms a unified shared L2 cache of 30.5MB.", "In addition to the cores, there are 16 memory channels that in theory offer a maximum memory bandwidth of 352GB/s.", "The GDDR memory controllers provide direct interface to the GDDR5 memory, and the PCIe Client Logic provides direct interface to the PCIe bus.", "\\newline Efficient usage of the available vector processing units of the Intel Xeon Phi is essential to fully utilize the performance of the co-processor [@bib:TianSPGKMCP13] .", "Through the 512-bit wide SIMD registers it can perform 16 (16 wide $ \\times $ 32 bit) single-precision or 8 (8 wide $ \\times $ 64 bit) double-precision operations per cycle.", "\\newline The performance capabilities of the Intel Xeon Phi are discussed and investigated empirically by different researches within several domain applications [@bib:dokulil13,lu2013optimizing,DNAxphi,teodoro2013comparative,leung2013investigating,CPE4037] .", "\\newline </subsection>  </section>"], ["<section> <title> 4 Our Parallelization Scheme for Training Convolutional Neural Networks on Intel Xeon Phi </title>  The parallelism can be either divided data-wise, i.e. threads process several inputs concurrently, or model-wise, i.e. several threads share the computational burden of one input.", "Whether one approach can be advantageous over the other mainly depends on the synchronization overhead of the weight vectors and how well it scales with the number of processing units.", "\\newline In this section, we first discuss the design aspects of our parallelization scheme for training convolutional neural networks.", "Thereafter, we discuss the implementation aspects that allow full utilization of the Intel Xeon Phi co-processor.", "\\newline <subsection> <title> 4.1 Design Aspects </title> On-line stochastic gradient descent has the advantage of instant updates of weights for each sample.", "However, the sequential nature of the algorithm yields impediments as the number of multi- and many-core platforms are emerging.", "We consider different existing parallelization strategies for stochastic gradient descent: \\newline Strategy A: Hybrid - uses both data- and model parallelism, such that data parallelism is applied in convolutional layers, and the model parallelism is applied in fully connected layers [@bib:krizhevsky2014one] .", "\\newline Strategy B: Averaged Stochastic Gradient - divides the input into batches and feeds each batch to a node.", "This strategy proceeds as follows: (1) Initialize the weights of the learner by randomization; (2) Split the training data into {n} equal chunks and send them to the learners; (3) each learner process the data and calculates the weight gradients for its batch; (4) send the calculated gradients back to the master; (5) the master computes and updates the new weights; and (6) the master sends the new weights to the nodes and a new iteration begins [@bib:de2012parallelization] .", "The convergence speed is slightly worse than for the sequential approach, however the training time is heavily reduced.", "\\newline Strategy C: Delayed Stochastic Gradient - suggests updating the weight parameters in a round-robin fashion by the workers.", "One solution is splitting the samples by the number of threads, and let each thread work on its own distinct chunk of samples, only sharing a common weight vector.", "Threads are only allowed to update the weight vector in a round-robin fashion, and hence each update will be delayed [@bib:ZinkevichSL09] .", "\\newline Strategy D: HogWild! - is a stochastic gradient descent without locks.", "The approach is applicable for sparse optimization problems (threads/core updates do not conflict much) [@bib:recht2011hogwild] .", "\\newline In this paper, we introduce C ontrolled H ogwild with A rbitrary O rder of S ynchronization (CHAOS), a parallelization scheme that can exploit both thread- and SIMD-level parallelism available on Intel Xeon Phi.", "CHAOS is a data-parallel controlled version of HogWild! with delayed updates, which combines parts of strategies A-D. The key aspects of CHAOS are: \\newline <list> \\ {Thread parallelism} - The overview of our parallelization scheme is depicted in Figure [@ref:LABEL:fig:chaos-scheme] .", "Initially for as many threads as there are available network instances are created, which share weight parameters, whereas to support concurrent processing of images some variables are private to each thread.", "After the initialization of CNNs and images is done, the process of training starts.", "The major steps of an epoch include: {Training} , {Validation} and {Testing} .", "The first step, {Training} , proceeds with each worker picking an image, forward propagates it through the network, calculates the error, and back-propagates the partial derivatives, adjusting the weight parameters.", "Since each worker picks a new image from the set, other workers do not have to wait for significantly slow workers.", "After Training, each worker participates in {Validation} and {Testing} evaluating the prediction accuracy of the network by predicting images in the validation and test set accordingly.", "Adoption of data parallelism was inspired by Krizhevsky [@bib:krizhevsky2014one] , promoting data parallelism for convolutional layers as they are computationally intensive.", "\\newline \\ \\ {Controlled HogWild} - during the back-propagation the shared weights are updated after each layer's computations (a technique inspired by [@bib:ZinkevichSL09] ), whereas the local weight parameters are updated instantly (a technique inspired by [@bib:recht2011hogwild] ), which means that the gradients are calculated locally first then shared with other workers.", "However, the update to the global gradients can be performed at any time, which means that there is no need to wait for other workers to finish their updates.", "This technique, which we refer to as non-instant updates of weight parameters without significant delay, allows us to avoid unnecessary cache line invalidation and memory writes.", "\\newline \\ \\ {Arbitrary Order of Synchronization} - There is no need for explicit synchronization, because all workers share weight parameter.", "However, an implicit synchronization is performed in an arbitrary order because writes are controlled by a first-come-first schedule and reads are performed on demand.", "\\newline \\ </list> \\newline The main goal of CHAOS is to minimize the time spent in the convolutional layers, which can be done through data parallelism, adapting the knowledge presented in strategy A. In strategy B, the synchronization is performed because of averaging worker's gradient calculations.", "Since work is distributed, computations are performed on stale parameters.", "The strategy can be applied in distributed and non-distributed settings.", "The division of work over several distributed workers was adapted in CHAOS.", "In strategy C, the updates are postponed using a round-robin-fashion where each thread gets to update when it is its turn.", "The difference compared to strategy B is that instances train on the same set of weights and no averaging is performed.", "The advantage is that all instances train on the same weights.", "The disadvantage of this approach is the delayed updates of the weight parameters as they are performed on stale data.", "Training on shared weights and delaying the updates are adopted in CHAOS.", "Strategy D presents a lock-free approach of updating the weight parameters, updates are performed instantly without any locks.", "Our updates are not instant, however, after computing the gradients there is nothing prohibiting a worker contributing to the shared weights, the notion of instant inspired CHAOS.", "\\newline </subsection> <subsection> <title> 4.2 Implementation Aspects </title> The main goal is to utilize the many cores of the Intel Xeon Phi co-processor efficiently to lower the training time (execution time) of the selected CNN algorithm, at the same time maintaining low deviation in error rates, especially on the test set.", "Moreover, the quality of the implementation is verified using errors and error rates on the validation and test set.", "\\newline In the sequential version, only minor modifications of the original version were performed.", "Mainly, we added a {Reporter} class to serialize execution results.", "The instrumentation should not add any time penalties in practice.", "However, if these penalties occur in the sequential version they are likely to imply corresponding penalties in the parallel version, therefore it should not impact the results.", "\\newline The main goal of the parallel version is to lower the execution time of the sequential implementation and to scale well with the number of processing units on the co-processor.", "To facilitate this, it is essential to fully consider the characteristics of the underlying hardware.", "From results derived in the sequential execution we found the hotspots of the application to be predominantly the convolutional layers.", "The time spent in both forward- and back-propagation is about 94% of the total time of all layers (up to 99% for the larger network), which is depicted in the Table [@ref:LABEL:tab:tab_par_fp_conv] .", "\\newline In our proposed strategy, a set of $ N $ network instances are created and assigned to $ T $ threads.", "We assume $ T==N $ , i.e. one thread per network instance.", "$ T $ threads are spawned, each responsible for its own instance.", "\\newline The overview of the algorithm is shown in Fig. [@ref:LABEL:fig:chaos-scheme] .", "In Fig. [@ref:LABEL:fig:train_test_back] the training, testing and back-propagation phase are shown in details.", "Training (see Fig. [@ref:LABEL:fig:cnn-training] ) picks an image, forward propagates it, determines the loss and back-propagates the partial derivatives (deltas) in the network - this process is done simultaneously by all workers, each worker processing one image.", "Each worker participating in testing (see Fig. [@ref:LABEL:fig:cnn-testing] ), picks an image, forward propagates it and then collects errors and error rates.", "The results are cumulated for all threads.", "Perhaps the most interesting part is the back-propagation (see Fig. [@ref:LABEL:fig:cnn-backpropagation] ).", "The shared weights are used when propagating the deltas, however, before updating the weight gradients, the pointers are set to the local weights.", "Thereafter the algorithm proceeds by updating the local weights first.", "When a worker has contributions to the global weights it can update in a controlled manner, avoiding data races.", "Updates immediately affect other workers in their training process.", "Hence the update is delayed slightly, to decrease the invalidation of cache lines, yet almost instant and workers do not have to wait for a longer period before contributing with their knowledge.", "\\newline To see why delays are important, consider the following scenario: If training several network instances concurrently, they share the same weight vectors, other variables are thread private.", "The major consideration lies in the weight updates.", "Let $ W^{j}_{l} $ be the $ j $ -th weight on the $ l $ -th layer.", "In accordance with the current implementation, a weight is updated several times since neurons in a map (on the same layer) share the same weights, and the kernel is shifted over the neurons.", "Further assume that several threads work on the same weight $ W^{j}_{l} $ at some point in time.", "Even if other threads only read the weights, their local data, as saved in the Level 2 cache, will be invalidated and a re-fetch is required to assert their integrity.", "This happens because cache lines are shared between cores.", "The approach of slightly delaying the updates and forcing one thread to update in atomicity leads to fewer invalidations.", "Still a major disadvantages is that the shared weights does not infer any data locality (data cannot retain completely in Level 2 cache for a longer period).", "\\newline <float> An extract from the vectorization report for the partial derivative updates in the convolutional layer.", "\\ remark #15475: --- begin vector loop cost summary --- \\ \\ remark #15476: scalar loop cost : 30 \\ \\ remark #15477: vector loop cost : 7.500 \\ \\ remark #15478: estimated potential speedup : 3.980 \\ \\ remark #15479: lightweight vector operations : 6 \\ \\ remark #15480: medium - overhead vector operations : 1 \\ \\ remark #15481: heavy - overhead vector operations : 1 \\ \\ remark #15488: --- end vector loop cost summary --- \\ </float> \\newline To further decrease the time spent in convolutional layers, loops were vectorized to facilitate the vector processing unit of the co-processor.", "Data was allocated using $ \\_mm\\_malloc $ with $ 64 $ byte alignment increasing the accuracy of memory requests.", "The vectorization was achieved by adding $ \\#pragmaompsimd $ instructions and explicitly informing the compiler of the memory alignment using $ \\_\\_assume\\_aligned $ .", "Some unnecessary overhead is added through the lack of data alignment of the deltas and weights.", "The computations of partial derivatives and weight gradients in the convolutional layers are performed in a SIMD way, which allows efficient utiliziation of the 512 bit wide vector processing units of the Intel Xeon Phi.", "An extract from the vectorization report (see Listing [@ref:LABEL:listing:vectorization] ), for the updates of partial derivatives in the convolutional layer shows an estimated potential speed up of $ 3.98\\times $ compared to the scalar loop.", "\\newline Further algorithmic optimizations were performed.", "For example: (1) The images are loaded into a pre-allocated memory instead of allocating new memory when requesting an image; (2) Hardware pre-fetching was applied to mitigate the shortcomings of the in-order-execution scheme.", "Pre-fetching loads data to L2 cache to make it available for future computations; (3) Letting workers pick images instead of assigning images to workers, allow for a smaller overhead at the end of a work-sharing construct; (4) The number of locks are minimized as far as possible; (5) We made most of the variables thread private to achieve data locality.", "\\newline The training phase was distributed through thread parallelism, dividing the input space over available workers.", "CHAOS uses the vector processing units to improve performance and tries to retain local variables in local cache as far as possible.", "The delayed updates decrease the invalidation of cache lines.", "Since weight parameters are shared among threads, there is a possibility that data can be fetched from another core's cache instead of main memory, reducing the wait times.", "Also, the memory was aligned to 64 bytes and unnecessary system calls were removed from the parallel work.", "\\newline </subsection>  </section>"], ["<section> <title> 5 Evaluation </title>  In this section, we first describe the experimentation environment used for evaluation of our CHAOS parallelization scheme.", "Thereafter, we describe the development of a performance model for CHAOS.", "Finally we discuss the obtained results with respect to scalability, speedup, and prediction accuracy.", "\\newline <subsection> <title> 5.1 Experimental Setup </title> In this study, OpenMP was selected to facilitate the utilization of thread- and SIMD-parallelism available in the Intel Xeon Phi co-processor.", "C++ programming language is used for algorithm implementation.", "The Intel Compiler 15.0.0 was used for native compilation of the application for the co-processor, whereas the $ O3 $ level was used for optimization.", "\\newline {System Configuration} - To evaluate our approach we use an Intel Xeon Phi accelerator that comprises 61 cores that run at 1.2 GHz.", "For evaluation 1, 15, 30, 60, 120, 180, 240, and 244 threads of the co-processor were used.", "Each thread was responsible for one network instance.", "For comparison, we use two general purpose CPUs, including the Intel Xeon E5-s695v2 that runs at 2.4 GHz clock frequency, and the Intel Core i5 661 that runs at 3.33GHz clock frequency.", "\\newline {Data Set} - To evaluate our approach, the MNIST [@bib:lecun2010mnist] dataset of handwritten digits is used.", "In total the MNIST dataset comprises 70000 images, 60000 of which are used for training/validation and the rest for testing.", "\\newline {CNN Architectures} - Three different CNN architectures were used for evaluation, {small, medium} and {large} .", "The small and medium architecture were trained for 70 epochs, and the large one for 15 epochs, using a starting decay (eta) of 0.001 and factor of 0.9.", "The small and medium network consist of seven layers in total (one input layer, two convolutional layers, two max-poling layers, one fully connected layer and the output layer).", "The difference between these two networks is in the number of feature maps per layer and the number of neurons per map.", "For example, the first convolutional layer of the small network has five feature maps and 3380 neurons, whereas the first convolutional layer of the medium network has 20 feature maps and 13520 neurons.", "The large network differs from the small and the medium network in the number of layers as well.", "In total, there are nine layers, one input layer, three convolutional layers, three max-pooling layers, one fully connected layer and the output layer."]], "target": "Detailed information (including the number and the size of feature maps, neurons, the size of the kernels and the weights) about the considered architectures is listed in Table ."}, {"tabular": ["  \\backslashbox StageTS/s  &  0.33  &  1  &  2  &  3  &  4 ", " Raw  &  0.69  &  0.74  &  0.75  &  0.75  &  0.75 ", " Refined  &  0.71  &  0.74  &  0.76  &  0.76  &  0.76  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Human navigates the world through five senses, including taste, touch, smell, hearing, and sight.", "We sometimes rely on one sense while sometimes on multiple senses.", "For computer systems, the optical sensor is perhaps the most essential sensor which captures information like human eyes.", "Cameras are widely used for public safety and services in hospitals, shopping malls, streets, etc.", "On the other hand, booming use of other sensors is seen in many IoT applications due to the advances in wireless communications and MEMS.", "In this work, we like to raise one fundamental question: how can we improve the perceptivity of computer systems by integrating multiple sensors?", "More specifically, we are interested in fusing video and inertial sensor data to achieve person identification (PID), as is shown in Fig. [@ref:LABEL:fig:scene:labeled] .", "\\newline Efficient PID is the first step toward surveillance, home security, person tracking, no checkout supermarkets, and human-robot conversation.", "Traditional PID technologies are usually based on capturing biological features like face, voice, tooth, fingerprint, DNA, and iris [@bib:FaceRecognition,tooth,iris] .", "However, these techniques require intimate information of users, cumbersome registration, training process, and user cooperation.", "Also, relying on optical sensors implies high environmental dependency (such as lighting, obstacle, resolution, view angle, etc.), thus not suitable for public sites.", "A scene captured in a construction site is shown in Fig. [@ref:LABEL:fig:scene:ZhongDing01] , where workers must wear helmets and masks to protect themselves from falling objects and toxic gases.", "A top view of a courtyard is shown in Fig. [@ref:LABEL:fig:scene:labeled] .", "Clearly, recognizing biological features is difficult in such scenarios.", "Some other recognition approaches are based on wireless signals, but require active participation by users [@bib:WirelessRecognition01,WirelessRecognition02] .", "The ID-Match method proposed in [@bib:IDMatchRFID] integrates computer vision via depth camera and UHF RFID.", "It is capable of recognizing individuals walking in groups while wearing RFID tags, thus enabling human-robot interaction.", "However, this method is handicapped by short range, and all the users need to carry extra RFID tags.", "\\newline In this work, we propose a practical, effective and convenient PID system by combining computer vision and inertial sensor data.", "Because almost everyone carries a smartphone and almost every smartphone has inertial sensors inside.", "The main workflow of our PID system is shown in Fig. [@ref:LABEL:fig:IdentificationFlow] .", "From video data, a set $ O=\\{o_{1},o_{2},...\\} $ of human objects and their comparable features are retrieved.", "Similarly, from inertial sensors, a set $ S=\\{s_{1},s_{2},...\\} $ of inertial data and their comparable features are retrieved.", "Then, the similarity score of each $ o_{i} $ and each $ s_{j} $ is calculated.", "By analyzing all the similarity scores, the pairing between $ O $ and $ S $ is derived, which leads to PID result.", "Inertial sensors are widely used to derive carrier\u2019s motions, paths, and physical activities.", "They are standard modules for current smartphones.", "On the other hand, we can get motions, traces, and physical activities of people from videos.", "When persons do different types of activities, it is easy to pair an object with a sensor. But when people do the same activity at the same time, it is difficult to identify persons.", "So this work only discusses the situation that all the people under camera are walking.", "\\newline The contributions of this work are as follows.", "First, we develop a practical, low-cost, and robust PID system.", "Second, our solution integrates two types of popular sensors.", "Third, in this work, our matching method focuses on WPID to show the robust of our PID system that combines video and inertial sensor data together.", "\\newline The rest of this paper is structured as follows.", "Section [@ref:LABEL:sec:method] introduces our PID system and WPID method.", "Performance evaluation results are presented in Section [@ref:LABEL:sec:simu] .", "Conclusions are drawn in Section [@ref:LABEL:sec:conclu] .", "\\newline  </section>"], ["<section> <title> 2 PROPOSED WALKING PERSON IDENTIFICATION </title>  We consider an environment in Fig. [@ref:LABEL:fig:IdentificationFlow] with a video camera and multiple users.", "The data collected from both camera and smartphones is sent to a server for PID purpose.", "Our PID system has four software modules as shown in Fig. [@ref:LABEL:fig:SystemArchitecture4] .", "The video feature extraction module retrieves human objects and walking traces from a sequence of video frames.", "The acceleration (Acc) feature extraction module retrieves walking information from acceleration data.", "The similarity scoring module compares the walking features from both data sources and assigns them similarity scores.", "The object-ID pairing module couples human objects with smartphones based on the similarity scores.", "\\newline <subsection> <title> 2.1 Video Feature Extraction Module </title> The human object retrieval sub-module processes each frame to extract the objects that are recognized as human.", "It is directly realized by YOLO [@bib:YOLO,YOLO9000,ObjectDetection] .", "For each frame, YOLO outputs a set $ O $ of human objects represented by bounding boxes, and each bounding box is a rectangle inside where YOLO recognizes a human object.", "The $ i $ th bounding box of $ O $ is denoted by $ o_{i} $ and its center, width, and height are denoted by $ o_{i}.c $ , $ o_{i}.w $ , and $ o_{i}.h $ , respectively.", "Examples are shown in Fig. [@ref:LABEL:fig:boxforwalking] .", "\\newline The trace-finding sub-module is to connect the human objects of adjacent video frames and form continuous traces, where a trace is a sequence of human objects that are regarded as the same person.", "Efficient object tracking algorithms are available in [@bib:Bewley2016_sort,7045866,6909555,Yang,7410891] , but we design a lightweight tracing method based on movement limitation.", "Generally, human\u2019s running speed is less than $ 15 $ km/h.", "Assuming a frame rate of $ 30 $ frames per second (fps), in most cases, a person cannot move over $ 0.1 $ of his height between two frames.", "Based on this assumption, each trace has a search range to find its human object in the next frame.", "The results are some traces connecting human objects in continuous frames.", "\\newline After trace-finding, the step feature extraction sub-module retrieves walking-related features from each trace.", "Fig. [@ref:LABEL:fig:boxforwalking] shows two sequences of frames of two human objects.", "Suppose our camera has a downward viewing angle.", "Person 1 walks along a vertical line.", "When he steps forward, his bounding box becomes taller.", "When he closes feet, his bounding box becomes shorter.", "Person 2 walks along a horizontal line.", "When he steps forward, his bounding box becomes wider.", "When he closes feet, his bounding box narrows down.", "As a result, the changes of $ o_{i}.h/o_{i}.w $ over time are regarded as step patterns.", "We use $ t_{i} $ to denote the ratio-feature of $ i $ th trace.", "Fig. [@ref:LABEL:fig:steppatternextraction] shows the ratio-features extracted from two persons, who make $ 6 $ and $ 5 $ strides in $ 100 $ frames, respectively.", "We also mark the ground truth of strides in the graph.", "As can be seen, the ratio-feature can well present human step patterns.", "\\newline </subsection> <subsection> <title> 2.2 Acc Feature Extraction Module </title> In this work, each user carries a smartphone which has installed our application (app), and they can put them in pockets or just hand them.", "Our software only collects acceleration from the inertial sensor.", "Since activity recognition from inertial sensor data has been intensively studied, we simply adopt existing solutions [@bib:Senorinmobilephone,sensorbetter] .", "The sensor data $ \\hat{a_{i}} $ from the $ i $ th device is a sequence of acceleration magnitudes after removing direction.", "Since most energy captured by accelerometer associated with human movements is below 15 Hz [@bib:mathie2003monitoring] , we remove the high-frequency components from $ \\hat{a_{i}} $ .", "$ \\hat{a_{i}} $ is low-pass filtered by a $ 10 $ th order Butterworth filter with a 15 Hz cut-off frequency [@bib:SensorForStep] .", "Further, since our frame rate is 30 fps, the simple frequency of $ \\hat{a_{i}} $ is decreased to 30 per second.", "After these steps, we get $ a_{i} $ as step feature.", "\\newline </subsection> <subsection> <title> 2.3 Similarity Scoring Module </title> After retrieving step features from video data and sensor data, we want to answer the following question: How similar is ratio-feature sequence $ t_{i} $ to Acc sequence $ a_{j} $ ?", "The similarity between $ t_{i} $ and $ a_{j} $ is denoted by $ Sim $ .", "In this work, we try to match the extremum positions of two sequences by ignoring their exact values.", "First, we conduct an extremum detection to find local maximum/minimum points with a window of length $ d $ .", "For example, when we set $ d=10 $ , we traverse all the points and their most adjacent $ 10 $ points.", "If the value of a point is bigger/smaller than all the other $ 10 $ most adjacent points, this point is recorded as a maximum/minimum point.", "In our experiments, we set $ d=10 $ .", "A maximum point is marked as $ 1 $ , a minimum point is marked as $ -1 $ , and the rest are marked as $ 0 $ .", "This process transforms $ t_{i} $ and $ a_{j} $ into ternary sequences: $ \\widetilde{t_{i}} $ and $ \\widetilde{a_{j}} $ .", "The similarity score between $ \\widetilde{t_{i}} $ and $ \\widetilde{a_{j}} $ is defined as: \\newline <equation> $ \\centering Sim(\\widetilde{t_{i}},\\widetilde{a_{j}})=\\frac{n}{\\sum_{x}dif(% \\widetilde{t_{i}}[x],\\widetilde{a_{j}})}.\\@add@centering $ </equation> $ n $ is the number of extremums in $ \\widetilde{t_{i}} $ and $ dif(\\widetilde{t_{i}}[x],\\widetilde{a_{j}}) $ is defined as: \\newline <equation> $ \\centering dif(\\widetilde{t_{i}}[x],\\widetilde{a_{j}})=\\left\\{\\begin{array}[]{% lr}0,&\\widetilde{t_{i}}[x]=0;\\\\ |y-x|,&\\widetilde{t_{i}}[x]\\neq 0andyexists;\\\\ 1.5\\times d,&otherwise.\\\\ \\end{array}\\right.\\@add@centering $ </equation> Here, we scan each binary value $ \\widetilde{t_{i}}[x] $ of $ \\widetilde{t_{i}} $ .", "If $ \\widetilde{t_{i}}[x]=0 $ , then $ dif(\\widetilde{t_{i}}[x],\\widetilde{a_{j}}) $ returns $ 0 $ .", "If $ \\widetilde{t_{i}}[x]\\neq 0 $ , $ dif(\\widetilde{t_{i}}[x],\\widetilde{a_{j}}) $ traverse $ \\widetilde{a_{j}} $ in the range $ x-d $ to $ x+d $ .", "$ y $ , a position in the search range, is the nearest position from $ x $ and has $ \\widetilde{a_{j}}[y]=\\widetilde{t_{i}}[x] $ .", "If such $ y $ exists in the search range, $ dif(\\widetilde{t_{i}}[x],\\widetilde{a_{j}}) $ returns $ |y-x| $ ; if not, $ 1.5\\times d $ is returned.", "Dividing $ n $ by the sum of these differences gives the similarity score between $ \\widetilde{t_{i}} $ and $ \\widetilde{a_{j}} $ .", "\\newline </subsection> <subsection> <title> 2.4 Object-ID Pairing Module </title> After similarity scoring, we get $ Sim $ .", "$ Sim $ is a two-dimensional array recording all the similarity scores until frame $ f $ . Let $ P_{f} $ be the Object-ID pairing result until frame $ f $ .", "The pairing problem is now formulated as a different expression of linear sum assignment problem (LSAP) [@bib:assignment] : \\newline <equation> $ \\centering max\\sum_{i\\in O}{\\sum_{j\\in S}sim_{ij}p_{ij}},\\@add@centering $ </equation> $ sim_{ij} $ is the similarity score between $ i $ th human object in $ O $ and $ j $ th sensor in $ S $ , and the assignment constraints are: \\newline <equation> $ \\centering\\begin{split}\\sum_{i\\in O}p_{ij}\\leq 1&% \\forall j\\in S,\\\\ \\sum_{j\\in S}p_{ij}\\leq 1&% \\forall i\\in O,\\\\  p_{ij}\\in\\{0,1\\}&\\forall i% \\in O,j\\in S.\\end{split}\\@add@centering $ </equation> We use hungarian algorithm to solve this problem.", "$ p_{ij}=1 $ means that human object $ i $ is paired to sensor $ j $ ; $ p_{ij}=0 $ means that human object $ i $ cannot be paired to sensor $ j $ .", "In our work, each frame $ f $ can have a pairing result $ P_{f} $ , and we call the pairing result at this stage as Raw Pair stage result.", "\\newline However, in practice, the identification result is unstable if we base on our Raw Pair stage result.", "For example, we may identify one person as Sansa when one frame comes in, but we may identify this person as Jack when next frame comes in, and this person may be identified as Lucy when the frame after the next frame comes in.", "This problem, which is especially serious when the trace of a person is still short, makes the result rough and hard to see.", "For this consideration, we propose a Refined Pair stage.", "In Refined Pair stage, the identification result of a trace not just depends on $ P_{f} $ , but $ P_{1} $ to $ P_{f} $ . Let $ RP_{f} $ be the result generated in the Refined Pair stage for frame $ f $ . Let $ RSim $ be a two-dimensional array, and the value of $ rsim_{ij} $ is the number of times that object $ i $ has been paired to sensor $ j $ .", "The refined pairing problem can be formulated as a LSAP: \\newline <equation> $ \\centering max\\sum_{i\\in O}{\\sum_{j\\in S}rp_{ij}}\\log_{2}{(1+rsim_{ij})},\\@add@centering $ </equation> subject to: \\newline <equation> $ \\centering\\begin{split}\\sum_{i\\in O}rp_{ij}\\leq 1&{% }\\forall j\\in S,\\\\ \\sum_{j\\in S}rp_{ij}\\leq 1&% \\forall i\\in O,\\\\  rp_{ij}\\in\\{0,1\\}&\\forall i% \\in O,j\\in S.\\end{split}\\@add@centering $ </equation> Different from $ sim_{ij} $ , $ rsim_{ij} $ is the number of pairing times.", "$ sim_{ij} $ is small, but $ rsim_{ij} $ can be very large if the trace of human object $ i $ is long.", "The logarithmic function, shown in Eq. [@ref:LABEL:eq:rpairing] , is used to weaken the impact of the length of traces on pairing.", "As $ p_{ij} $ , $ rp_{ij}=1 $ means that human object $ i $ is paired to sensor $ j $ ; $ rp_{ij}=0 $ means that human object $ i $ is not paired to sensor $ j $ .", "\\newline </subsection>  </section>"], ["<section> <title> 3 Performance Evaluation </title>  We have developed a prototype system with one video camera and multiple mobile devices.", "The camera is Logitech webcam with the resolution of $ 640\\times 480 $ .", "To prove that our solution is not device-dependent, we have tried different models of smartphones, including Redmi Note 4X, ASUS ZenFone 3, HTC 10 Evo.", "The server is a personal computer with an Intel(R) Core(TM) i7-3770 CPU and an NVIDIA GeForce GT 620 graphics card.", "All devices used in our system are synchronized by the same network time server.", "We conduct a number of experiments on our WPID method.", "The average speed of our tracing and WPID method on different pairing stages is around 120 fps.", "Apparently, our WPID method on two different stages only consumes a few server resources.", "\\newline To show the robustness of our WPID method, experiments are carried out under different areas and viewing angles.", "A downward viewing angle and outdoor area is set up as shown in Fig. [@ref:LABEL:fig:variable:3] .", "The horizontal viewing angle and indoor area is set up as shown in Fig. [@ref:LABEL:fig:variable:4] .", "During our experiments, all the persons carry smartphones in their pockets or hands and wander around freely in their styles.", "As shown in Fig. [@ref:LABEL:fig:variable] , our WPID method can work under different areas, different view angles, different ways of carrying the smartphones, and different walking styles.", "The following statistics are all the cases of two persons, and the result of each condition is generated from at least 2000 continuous frames.", "\\newline To measure the accuracy of our WPID method, let $ O $ be the number of persons having shown in front of the camera until the latest frame.", "Let $ N^{ID}_{i} $ be the number of frames that the $ i $ th person is identified by our program, and $ N^{CD}_{i} $ be the number of frames that the $ i $ th person is correctly identified by our program.", "We define our correctly identification rate $ R_{cd} $ as: \\newline <equation> $ \\centering R_{cd}=\\frac{\\sum_{i=1}^{O}N^{CD}_{i}}{\\sum_{i=1}^{O}N^{ID}_{i}}.\\@add@centering $ </equation> \\newline Let $ TL $ be the length of time that a person is continuously detected by YOLO.", "If $ TL $ is too small, the sequences extracted is too short to be considered as a step pattern.", "As a result, we set a threshold $ TS $ for $ TL $ .", "Only when the lengths of two sequences are both larger than $ TS $ , we do our matching processes.", "By setting $ TS $ from $ 0.33 $ to $ 4 $ seconds, Table [@ref:LABEL:table:rid] shows the $ R_{cd} $ on two stages."]], "target": "From Table , the increase of $ TS $ leads to the increase of $ R_{cd} $ in most cases. However, the increase of $ R_{cd} $ is not obvious. Also, Refined stage achieves better performance than Raw stage, especially in visual performance."}, {"tabular": ["  Methods  &  Cora  &  CiteSeer  &  PubMed ", " GAT  &  $ 83.0\\pm 0.7\\% $  &  $ 72.5\\pm 0.7\\% $  &  $ 79.0\\pm 0.3\\% $ ", " GraphNAS  &  $ 84.2\\pm 1.0\\% $  &  $ 73.1\\pm 0.9\\% $  &  $ 79.6\\pm 0.4\\% $ ", " AGNN  &  $ 83.6\\pm 0.3\\% $  &  $ \\mathbf{73.8\\pm 0.7\\%} $  &  $ \\mathbf{79.7\\pm 0.4\\%} $ ", " PDNAS  &  $ \\mathbf{84.5\\pm 0.6\\%} $  &  $ 73.5\\pm 0.3\\% $  &  $ \\mathbf{79.7\\pm 0.6\\%} $  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Graphs are a ubiquitous structure and are widely used in real-life problems, e.g. computational biology [@bib:zitnik2017predicting] , social networks [@bib:hamilton2017inductive] , knowledge graphs [@bib:lin2015learning] , etc.", "Graph Neural Networks (GNNs) follow a message passing (node aggregation) scheme to gradually propagate information from adjacent nodes at every layer.", "However, due to the varieties of non-Euclidean data structures, GNNs tend to be less adaptive than traditional convolutional neural networks, thus it is common to re-tune the network architecture for each new dataset.", "For instance, GraphSage [@bib:hamilton2017inductive] shows networks are sensitive to the number of hidden units on different datasets; jumping knowledge networks demonstrate that the optimal concatenation strategy between layers varies for different datasets [@bib:xu2018representation] .", "Furthermore, the challenge of designing a new GNN architecture typically involves a considerably larger design space.", "A single graph block normally comprises multiple connecting sub-blocks, such as linear layers, aggregation, attention, etc. , each sub-block can have multiple candidate operations, and thus provides a large combinatorial architecture search space.", "The formidable search space and the lack of transferability of GNN architectures present a great challenge in deploying GNNs rapidly to various real-life scenarios.", "\\newline Recent advances in neural network architecture search (NAS) methods show promising results on convolutional neural networks and recurrent neural networks [@bib:zoph2016neural,liu2018darts,casale2019probabilistic] .", "NAS methods are also applicable to graph data, recent work uses NAS based on reinforcement learning (RL) for GNNs and achieves state-of-the-art accuracy results [@bib:gao2019graphnas,zhou2019auto] .", "RL-based NAS, however, has the following shortcomings.", "First, RL requires a full train and evaluate cycle for each architecture that is considered; making it computational expensive [@bib:casale2019probabilistic] .", "Second, existing GNN search methods focus only on the micro-architecture.", "For instance, only the activation function, aggregation method, hidden unit size, etc.", "of each graph convolutional block are considered in the search.", "However, it has been observed that performance can be improved if shortcut connections, similar to residual connections in CNNs [@bib:he2016deep] , are added to adapt neighborhood ranges for a better structure-aware representation [@bib:xu2018representation] .", "This macro-architecture configuration of how blocks connect to each other via shortcuts is not considered in previous Graph NAS methods.", "\\newline To address these shortcomings we propose a probabilistic dual architecture search.", "Instead of evaluating child networks from a parent network iteratively using RL, we train a superset of operations with probabilistic priors generated from a NAS controller.", "The controller then learns the probabilistic distributions of candidate operators and picks the most effective one from the superset.", "For the macro-architecture, we use the Gumbel-sigmoid trick [@bib:jang2016categorical,maddison2016concrete] to relax discrete decisions to be continuous, so that a set of continuous variables can represent the connections between graph blocks.", "The proposed probabilistic, gradient-based NAS framework optimises both the micro- and macro-architecture of GNNs.", "Furthermore, we introduce several tricks to improve both the search quality and speed.", "First, we design the NAS controller to produce multi-hot decision vectors to reduce the combinatorial micro-architecture search dimensions.", "Second, we use temperature annealing for Gumbel-sigmoid to balance between exploration and convergence.", "Third, our differentiable search is single-path, where only a single operation from the superset is evaluated during each training iteration This reduces the computation cost of NAS to the same as normal training.", "In short, we make the following contributions in this paper: \\newline <list> \\ We propose the first probabilistic dual network architecture search (PDNAS) method for GNNs.", "The proposed method uses Gumbel-sigmoid to relax the discrete architectural decision to be continuous for the macro-architecture search.", "\\newline \\ \\ To our knowledge, this is the first NAS that explores the macro-architecture space.", "We demonstrate how this helps deeper GNNs to achieve state-of-the-art results.", "\\newline \\ \\ We show several tricks (multi-hot controller, temperature annealling and single-path search) to improve the NAS search speed and quality.", "\\newline \\ \\ We present the performance of the networks discovered by PDNAS and show that they achieve superior accuracy and F1 scores in comparison to other hand-designed and NAS-generated networks \\newline \\ </list> \\newline  </section>"], ["<section> <title> 2 Background </title>  <subsection> <title> 2.1 Network Architecture Search (NAS) </title> DNNs achieve state-of-the-art results on a wide range of tasks, but tuning the architectures of DNNs on custom datasets is increasingly difficult.", "One challenge is the increase in the number of different possible operations that may be employed, e.g. in the field of computer vision, simple convolutions and fully connected layers [@bib:krizhevsky2012imagenet] have expanded to include depth-wise separable convolutions [@bib:howard2017mobilenets] , grouped convolutions [@bib:zhang2017interleaved] , dilated convolutions [@bib:yu2017dilated] , etc. .", "This opens up a much larger design space for neural network architectures.", "Network Architecture Search (NAS) seeks to automate this search for the best DNN architecture.", "Initially NAS methods employed reinforcement-learning (RL) [@bib:zoph2016neural,tan2019mnasnet] .", "A recurrent neural network acts as a controller and maximises the expected accuracy of the search target on the validation dataset.", "However, each update of the controller requires a few hours to train a child network to convergence which significantly increases the search time.", "Alternatively, [@bib:liu2018darts] proposed Differentiable Architecture Search (DARTS) that is a purely gradient-based search; each candidate operation\u2019s importance is scored using a trainable scalar and updated using Stochastic Gradient Descent (SGD).", "Subsequently, [@bib:casale2019probabilistic] approached the NAS problem from a probabilistic view, transforming concrete trainable scalars used by DARTS [@bib:liu2018darts] to probabilistic priors and only train a few architectures sampled from these priors at each training iteration.", "[@bib:wu2019fbnet] and [@bib:xie2018snas] used the Gumbel-softmax trick to relax discrete operation selection to continuous random variables.", "Existing NAS methods focus mainly on finding optimal operation choices inside each candidate block (micro-architecture), in our work, we extend the search to consider how blocks are interconnected, i.e. the network\u2019s macro architecture.", "\\newline </subsection> <subsection> <title> 2.2 NAS for GNNs </title> While NAS methods have been developed using image and sequence data, few recent work has applied them to graph-structured data.", "[@bib:gao2019graphnas] first proposed GraphNAS, a RL-based NAS on graph data.", "[@bib:zhou2019auto] used a similar RL-based approach (AutoGNN) with a constrained parameter sharing strategy.", "However, both of these NAS methods for graphs focus solely on the micro-architecture space \u2014 they search only which operations to apply on individual graph blocks and do not learn how large graph blocks connect to each other.", "Moreover, these methods are RL-based; to fully train the RL controller, they require many iterations of child network training to convergence.", "\\newline In this work we focus on GNNs applied to node classification tasks based on Message-Passing Neural Networks [@bib:gilmer2017neural] .", "Most of the manually designed architectures proposed for these tasks fall into this category, such as GCN [@bib:kipf2016semi] , GAT [@bib:velickovic2018graph] , LGCN [@bib:gao2018large] and GraphSage [@bib:hamilton2017inductive] .", "\\newline </subsection>  </section>"], ["<section> <title> 3 Method </title>  Figure [@ref:LABEL:fig:overview] shows an overview of PDNAS.", "In this framework, we formulate the search space for GNN as a stack of Graph Blocks ( [@ref:LABEL:fig:overview] ), with shortcut connections allowing information to skip an arbitrary number of blocks, similar to DenseNet [@bib:huang2017densely] .", "A Graph Block is essentially a GNN layer composed from four sub-blocks, including a linear layer, an attention layer, an aggregation and an activation function ( [@ref:LABEL:fig:gb] ).", "Each sub-block has a set of candidate operations to search over.", "A NAS controller determines which operators are active in these sub-blocks during each training iteration.", "While searching in the micro-architecture space of operations within Graph Blocks, PDNAS also searches in the macro-architecture space of shortcut connections( [@ref:LABEL:fig:router] ).", "Shortcut connections are controlled by gating functions parameterised by a routing probability matrix.", "We discuss the micro-architecture search of a Graph Block in [@ref:LABEL:sec:search_space] , the macro-architecture search of shortcut connection routing in [@ref:LABEL:sec:routing] and dual optimisation of architectural parameters in [@ref:LABEL:sec:optimisation] .", "\\newline <subsection> <title> 3.1 Micro-Architecture Search </title> In this work, we consider GNNs based on the message-passing mechanism.", "In each GNN layer, nodes aggregate attention weighted messages from their neighbours and combine these messages with their own feature.", "Formally, each GNN layer can be described as: \\newline <equation> $ \\begin{split}e^{k}_{i}&=\\mathsf{AGGREGATE}_{j\\in N(i)}(a^{k}_{ij}F^{k}(h^{k-1}% _{j})),\\\\ h^{k}_{i}&=\\sigma(\\mathsf{COMBINE}(e^{k}_{i},F^{k}(h^{k-1}_{i}))).\\end{split} $ </equation> Here $ F^{k} $ is a transformation operation for features.", "In GNNs, $ F^{k}(x) $ is typically a linear transformation in the form of $ W^{k}x $ .", "$ N(i) $ is the set of neighbouring nodes of node $ i $ .", "$ a^{k}_{ij} $ are the attention parameters for messages passed from neighbouring nodes.", "$ \\mathsf{AGGREGATE} $ is an aggregation operation for the messages received.", "$ \\mathsf{COMBINE} $ is an operation for combining aggregated messages with features of the current node.", "$ \\sigma $ is a non-linear activation.", "For each of the above operations, there are several candidates to search amongst.", "In this work, we consider the following micro-architecture search space: \\newline <list> \\ {Transformation function} : we formulate $ F^{k}(x) $ as $ W^{k}_{2}\\sigma(W^{k}_{1}x) $ where $ W^{k}_{1}\\in\\mathbb{R}^{D_{E}\\times D_{I}} $ and $ W^{k}_{2}\\in\\mathbb{R}^{D_{O}\\times D_{E}} $ .", "$ D_{I} $ and $ D_{O} $ are the input and output dimensions for $ F^{k} $ respectively, and $ D_{E} $ is the expansion dimension, which is similar to [@bib:tan2019mnasnet] .", "We let $ D_{E} $ be multiples of $ D_{I} $ .", "The search space for $ D_{E} $ is thus $ \\{D_{I},2D_{I},4D_{I},8D_{I}\\} $ .", "While it is possible to search for the output dimension of $ F^{k} $ , this incurs large memory costs because a quadratic number of candidate operators are needed for each layer.", "Let the number of candidate hidden dimensions be $ M $ .", "For each layer we will have to use $ M\\times M $ candidate operators for each layer to map $ M $ input dimensions to $ M $ output dimensions.", "In our setup, we thus leave input dimensions as hyper-parameters determined via a grid search.", "\\newline \\ \\ {Attention mechanism} : attention parameter $ a^{k}_{ij} $ is computed by attention functions that may depend on the features of the current node and its neighbours.", "While any attention function can be included in the set of candidate operators, we use attention functions that appear in GraphNAS [@bib:gao2019graphnas] and AGNN [@bib:zhou2019auto] to make a fair comparison.", "[@ref:LABEL:tab:attn_types] lists all attention functions considered in our search.", "\\newline \\ \\ {Attention head} : multi-head attention [@bib:vaswani2017attention] means that multiple attention heads are used and computed in parallel.", "For PDNAS, the numbers of heads searched are $ \\{1,2,4,8,16\\} $ .", "\\newline \\ \\ {Aggregation function} : messages from neighbouring node are aggregated by the function $ \\mathsf{AGGREGATE} $ .", "In our experiments, we include three widely-used options: $ \\{\\mathsf{SUM},\\mathsf{MEAN},\\mathsf{MAX\\_POOLING\\}} $ .", "\\newline \\ \\ {Combine function} : aggregated neighbouring messages are combined into the current node feature with the function $ \\mathsf{COMBINE} $ .", "We examined two options, $ {\\mathsf{ADD}} $ and $ {\\mathsf{CONCAT\\_MLP}} $ .", "Here, $ \\mathsf{ADD} $ is simply the addition of aggregated messages from neighbouring nodes to current node feature, while $ \\mathsf{CONCAT\\_MLP} $ concatenates aggregated messages with node feature and then processes the result with a multi-layer perceptron (MLP).", "In practice, we found that $ \\mathsf{ADD} $ consistently outperforms the other, and thus removed the search for the combine function in our final implementation.", "\\newline \\ \\ {Activation function} : the final output of a GNN layer passes through a non-linear activation function $ \\sigma $ .", "The candidate functions for $ \\sigma $ include \u201cNone\u201d, \u201cSigmoid\u201d, \u201cTanh\u201d, \u201cSoftplus\u201d, \u201cReLU\u201d, \u201cLeakyReLU\u201d, \u201cReLU6\u201d and \u201cELU\u201d.", "Please refer to Appendix A for details of each activation function.", "\\newline \\ </list> \\newline A Graph Block is similar to a cell employed in the CNN NAS algorithm DARTS [@bib:liu2018darts] .", "DARTS uses a weighted sum to combine outputs of all candidate operators.", "In PDNAS, we use the $ \\operatorname*{arg\\,max} $ function, which allows only one candidate operator to be active in each training iteration.", "Let $ \\bar{o}_{i,k} $ be the $ k^{th} $ sub-block in Graph Block $ i $ , and $ o_{i,k,t} $ be the $ t^{th} $ candidate operator for $ \\bar{o}_{i,k} $ .", "$ \\bar{o}_{i,k} $ is then computed as: \\newline <equation> $ \\bar{o}_{i,k}=o_{i,k,t^{max}_{i,k}},\\text{where}t^{max}_{i,k}=\\operatorname% *{arg\\,max}_{t\\in T}P^{g}_{i,k,t}. $ </equation> Here, $ P^{g}_{i,k,t} $ is the probability of the $ t^{th} $ candidate operator of sub-block $ k $ and layer $ i $ assigned by the NAS Controller.", "This hard-max approach considerably reduces memory and computational cost since only one operation is active at any training iterations, whilst still converges, as shown by [@bib:wu2019fbnet] and [@bib:xie2018snas] .", "While the $ \\operatorname*{arg\\,max} $ function is non-differentiable, we use a differentiable approximation which ensures that the controller receives learning signals.", "The operator selection is implemented by casting $ t^{max}_{i,k} $ as a one-hot vector $ V_{i,k} $ to select from the outputs of each candidate operators.", "We multiply this vector ( $ V_{i,k} $ ) with $ P^{g}_{i,k} $ to allow gradients to be back-propagated through $ P^{g}_{i,k} $ to the controller.", "This is the same as adding winner-takes-all to the softmax-weighted summation used in DARTS [@bib:liu2018darts] , and also known as single-path NAS.", "In a single-path NAS, only the winning operation is evaluated during each training iteration, the forward and backward passes through the unselected operators are thus not evaluated.", "It in turn reduces the computational and memory costs of each iteration to the same as normal training.", "\\newline NAS Controller : [@ref:LABEL:fig:controller] illustrates the design of our micro-architecture search controller.", "The controller is conditioned on two possible inputs, which are a trainable prior vector $ z $ and a graph embedding $ B_{g} $ produced by the graph summarisation module.", "Graph summarisation module, as its name suggests, summarises the whole graph into a single vector embedding containing the entire dataset statistics.", "In this work, we use a simple module with two GCN layers [@bib:kipf2016semi] and two pooling layers after each GCN.", "The first pooling layer is a self-attention pooling layer [@bib:lee2019self] while the last layer is a global average pooling.", "The graph summarisation module allows the NAS controller to be conditioned on input data.", "We found that the performance improvement provided by a graph summarisation path in the controller is minimal ( $ <0.2\\% $ ), but it caused considerable additional computational and memory costs.", "We then make this conditioning on data optional, and report experiment results without this branch of data conditioning.", "\\newline We combine $ z $ and $ B_{g} $ by $ W_{B}B_{g}+z $ , thereby treating $ z $ as a trainable bias to the data statistics.", "The final part of the NAS controller is an MLP, which computes $ L\\times K $ vectors for every $ K $ possible sub-block in each of the $ L $ layers.", "Each vector is passed through a softmax function to produce a probability vector $ \\bar{P}^{g}_{i,k} $ that controls which operator is active with the $ \\mathsf{argmax} $ function described in equation [@ref:LABEL:eq:op_select] .", "This multi-hot vector approach reduces parameters of the controller considerably compared to the one-hot vector approach where each whole-architecture configuration is represented as a separate entry in the output vector.", "The one-hot approach will have an output layer of size complexity $ O(T^{LK}) $ , whereas our multi-hot approach only requires an output layer of size $ O(LKT) $ .", "\\newline In initial experiments, we found that when selecting the attention mechanism, the NAS controller usually converges to operators that do not have trainable parameters, such as GCN\u2019s normalised message weighting and constant attention.", "We hypothesise this is because operators with trainable parameters, such as GAT, take many training iterations to achieve similar performance to parameter-less operators like GCN.", "The controller thus at the start of training greedily converge to these parameter-less operators due to a faster improvement in performance.", "To enforce more \u201cexploration\u201d, we add noise to the probability distribution for operators generated by our NAS controller at the start of the searching, and gradually anneal the noise to 0.", "Specifically the noise-added probability vector $ P^{g}_{i,k} $ is computed as: \\newline <equation> $ P^{g}_{i,k}=\\frac{\\bar{P}^{g}_{i,k}+\\tau U(0,1)}{Z}. $ </equation> Here, $ U $ is a uniform distribution to sample noise from, $ \\tau $ is the temperature which decreases during search to anneal noise, and $ Z $ is a normalising factor to ensure $ P_{i,k} $ is still a valid probability distribution.", "While it is possible to use Gumbel-Softmax [@bib:jang2016categorical,maddison2016concrete] to achieve the same goal.", "In practice, we found that the controller greedily increase the scale of logits inputs, making the Gumbel noise too small to make any effect.", "Thus we enforce inputs and the noise to be at the same numerical scale using [@ref:LABEL:eq:noise] .", "\\newline </subsection> <subsection> <title> 3.2 Macro-architecture Search </title> The macro-architecture search determines how graph blocks connect to each other, in this case, we call them {shortcut connections} following the naming conventions in computer vision [@bib:huang2017densely] .", "As mentioned earlier, shortcut connections on graph data have been explored in Jumping Knowledge networks [@bib:xu2018representation] .", "\\newline We define $ \\bm{\\mathit{\\bar{P}^{r}}}\\in\\mathbb{R}^{L\\times L} $ to be a square matrix of trainable priors for shortcut connections, and $ L $ is the number of possible graph blocks.", "Additionally, $ \\bm{\\mathit{P^{r}}} $ denotes a collection of the probabilities of connection between the inputs and outputs of graph blocks through shortcut connections, and has the same dimension as $ \\bm{\\mathit{\\bar{P}^{r}}} $ .", "In addition, cyclic connections are not permitted.", "$ \\bm{\\mathit{I}} $ is a collection of $ L $ inputs, where $ I_{i} $ represents a single graph input from a previous layer and $ 0\\leq i\\leq L $ .", "Similarly, $ \\bm{\\mathit{O^{\\prime}}} $ is a collection of $ L $ output graphs; these are the original outputs of graph blocks.", "With $ O_{j}^{\\prime} $ being a single graph output, we have $ 0\\leq j\\leq L $ ; $ \\bm{\\mathit{O}} $ has the same dimension as $ \\bm{\\mathit{O^{\\prime}}} $ , and it is the combination between shortcut connections and the original outputs.", "For producing the probabilities $ \\bm{\\mathit{P^{r}}} $ of shortcut connections from trainable priors $ \\bm{\\mathit{\\bar{P}^{r}}} $ , we apply the Gumbel-Sigmoid trick [@bib:jang2016categorical,maddison2016concrete] (denoted as $ \\mathsf{gs} $ ) on each individual element of $ \\bm{\\mathit{P^{r}}} $ so as to approximate discrete sampling from a binomial distribution.", "Gumbel-Sigmoid has the form of: \\newline <equation> $ y=\\frac{\\mathsf{exp}(\\frac{\\mathsf{log}\\,a+g}{\\tau})}{1+\\mathsf{exp}(\\frac{% \\mathsf{log}\\,a+g}{\\tau})}, $ </equation> where $ g $ is noise sampled from the Gumbel distribution $ \\mathsf{Gumbel}(0,1) $ , and $ \\tau $ is the temperature controlling the randomness for the Gumbel statistics.", "As $ \\tau $ decreases, $ \\mathsf{gs} $ samples values that are more \u2018discrete\u2019, meaning that values are closer to extreme boundary of 0 and 1, $ \\mathsf{row\\_sum} $ reduces the matrix by summing all row elements, and $ \\bm{\\odot} $ is the element-wise product between matrices.", "\\newline <equation> $ \\begin{split}\\bm{\\mathit{O}}&=\\bm{\\mathit{O^{\\prime}}}+G(\\bm{\\mathit{I}},\\bm{% \\mathit{\\bar{P}^{r}}},\\tau)\\\\ &=\\bm{\\mathit{O^{\\prime}}}+\\mathsf{row\\_sum}(\\mathsf{gs}(\\bm{\\mathit{\\bar{P}^{% r}}},\\tau)\\bm{\\odot}G^{\\prime}(\\bm{\\mathit{I}}))\\\\ &=\\bm{\\mathit{O^{\\prime}}}+\\mathsf{row\\_sum}(\\bm{\\mathit{P^{r}}}\\bm{\\odot}G^{% \\prime}(\\bm{\\mathit{I}})).\\end{split} $ </equation> Here, $ G^{\\prime} $ is a collection of shortcut connections, which is simply a fully connected layer that transforms the hidden unit size.", "In addition $ G^{\\prime} $ is an upper triangular matrix because shortcuts are forward connections \u2014 no graph blocks can connect backwards: \\newline <equation> $ G^{\\prime}(\\bm{\\mathit{I}})=\\begin{bmatrix}g_{00}(I_{0})&g_{01}(I_{1})&\\dots&g% _{0j}(I_{j})\\\\ 0&g_{11}(I_{1})&\\dots&g_{1j}(I_{j})\\\\ {4}\\\\ 0&0&\\dots&g_{ij}(I_{j})\\end{bmatrix}. $ </equation> We also have the following probability matrix $ \\bm{\\mathit{\\bar{P}^{r}}} $ , note that this is an upper triangular matrix with each $ \\bar{P}^{r}_{ij}=0 $ if $ i>j $ .", "This means input $ I_{i} $ cannot connect back to preceding $ O_{j} $ : \\newline <equation> $ \\bm{\\mathit{\\bar{P}^{r}}}=\\begin{bmatrix}\\bar{P}^{r}_{00}&\\bar{P}^{r}_{01}&% \\dots&\\bar{P}^{r}_{0j}\\\\ 0&\\bar{P}^{r}_{11}&\\dots&\\bar{P}^{r}_{1j}\\\\ {4}\\\\ 0&0&\\dots&\\bar{P}^{r}_{ij}\\end{bmatrix}. $ </equation> For the $ \\mathsf{gs} $ (Gumbel-sigmoid) function, we anneal the temperature to balance between random choices and concrete discrete decisions.", "With $ e $ being the number of training epochs, $ e_{m} $ being the maximum number of epochs, $ \\alpha $ being a constant and $ e_{s} $ is the starting epoch; we use the following annealing strategy, where in practice, we set $ \\alpha=1.0 $ , $ e_{s}=80 $ : \\newline <equation> $ \\tau=\\begin{cases}1,&\\text{if }e<e_{s}\\\\ \\mathsf{exp}^{-\\frac{\\alpha}{e_{m}}(e-e_{s})},&\\text{otherwise}\\end{cases} $ </equation> \\newline </subsection> <subsection> <title> 3.3 Dual Optimisation </title> We formulate PDNAS as a bi-level optimisation problem, similar to DARTS [@bib:liu2018darts] : \\newline <equation> $ \\begin{split}\\min_{a}&\\,\\mathcal{L}_{val}(w^{\\star}(a),a)\\\\ s.t.&\\,w^{\\star}(a)=\\operatorname*{arg\\,min}_{w}(\\mathcal{L}_{train}(w,a))\\end% {split} $ </equation> Here $ w $ are the parameters of all candidate operators, $ w^{\\star}(a) $ is the optimal parameters given $ a $ , where $ a $ represents parameters of the micro-architecture search controller $ a_{\\mathsf{micro}} $ and the trainable routing matrices $ a_{\\mathsf{macro}} $ .", "$ L_{train} $ is a training loss on the training data split, while $ L_{val} $ is validation loss on the validation data split.", "The parameters $ w $ and $ a $ are trained iteratively with their own gradient descent optimisers.", "Since it is computationally intractable to compute $ w^{\\star}(a) $ for each update of $ a $ , we approximate $ w^{\\star} $ with a few training steps, which are shown to be effective in DARTS [@bib:liu2018darts] , gradient-based hyper-parameter tuning [@bib:luketina2016scalable] and unrolled Generative Adversarial Network training [@bib:metz2016unrolled] .", "The full procedure is shown in Algorithm [@ref:LABEL:alg:opt] .", "Here $ x $ is input data, $ y $ is label, $ \\mathsf{MaxIter} $ is the maximum number of search iterations, and $ \\mathsf{TrainStep} $ is the number of training steps to approximate $ w^{\\star} $ .", "In each search iteration, we first sample noise $ N $ for the controller (recall this noise is to encourage more exploration at the start of training), and then compute probabilities of the candidate operators $ P^{g} $ and indices of operators with the highest probabilities $ \\mathsf{Index} $ .", "We then approximate $ w^{\\star} $ in $ \\mathsf{TrainStep} $ steps.", "In the training steps, $ w $ of operators receives gradients from the optimiser $ \\mathsf{Opt}_{w} $ using the training loss $ \\mathcal{L}_{train} $ .", "Next we update both sets of architectural parameters (controller and router parameters), $ a_{\\mathsf{micro}} $ and $ a_{\\mathsf{macro}} $ , with respect to the validation loss $ \\mathcal{L}_{val} $ .", "Note here $ \\mathsf{Index} $ is changed to $ P^{g}[\\mathsf{Index}] $ to provide gradients to the controller, as discussed in [@ref:LABEL:sec:search_space] .", "In practice we use the Adam optimiser [@bib:kingma2014adam] , noted as $ \\mathsf{Opt} $ .", "\\newline <float> Dual Architecture Optimisation \\ Input: $ x_{\\mathsf{train}} $ , $ y_{\\mathsf{train}} $ , $ x_{\\mathsf{val}} $ , $ y_{\\mathsf{val}} $ , $ \\mathsf{MaxIter} $ , $ \\mathsf{TrainStep} $ \\ \\ $ \\mathsf{Init}(w,a_{\\mathsf{micro}},a_{\\mathsf{macro}},P^{r}) $ \\ \\ for $ e=0 $ to $ \\mathsf{MaxIter}-1 $ do \\ \\ $ \\tau $ = TempAnneal( $ e $ ) \\ \\ $ N $ = SampleNoise( $ \\tau $ ) \\ \\ $ P^{g} $ = Controller( $ x_{\\mathsf{val}} $ , $ N $ ) \\ \\ $ \\mathsf{Index}_{i,k}=\\operatorname*{arg\\,max}_{t}(P^{g}_{i,k,t}) $ \\ \\ for $ i=0 $ to $ \\mathsf{TrainStep}-1 $ do \\ \\ $ \\mathcal{L}_{train}=\\mathsf{Loss}(x_{\\mathsf{train}},y_{\\mathsf{train}},% \\mathsf{Index},P^{r}) $ \\ \\ $ w $ = $ \\mathsf{Opt}_{w}(\\mathcal{L}_{train}) $ \\ \\ end for \\ \\ $ \\mathcal{L}_{val}=\\mathsf{Loss}(x_{\\mathsf{val}},y_{\\mathsf{val}},P^{g}[% \\mathsf{Index}],P^{r}) $ \\ \\ $ a_{\\mathsf{micro}} $ = $ \\mathsf{Opt}_{{\\mathsf{micro}}}(\\mathcal{L}_{val}) $ \\ \\ $ a_{\\mathsf{macro}} $ = $ \\mathsf{Opt}_{{\\mathsf{macro}}}(\\mathcal{L}_{val}) $ \\ \\ end for \\ </float> \\newline </subsection>  </section>"], ["<section> <title> 4 Results </title>  We implemented PDNAS using PyTorch [@bib:paszke2019pytorch] .", "Operations in Graph Blocks are modified from the GNN implementations in PyTorch Geometric (PyG) [@bib:fey2019fast] .", "For the Cora dataset, to ensure a consistent comparison to GraphNAS [@bib:gao2019graphnas] , we used the data splits provided by the Deep Graph Library [@bib:wang2019dgl] .", "The data splits from all other datasets are from PyG. For all search and training, we used a single Nvidia Tesla V100 GPU unless specified otherwise.", "We evaluated PDNAS on two learning settings, namely transductive and inductive settings.", "For the transductive setting we used the citation graph datasets [@bib:sen2008collective] including Cora, Citeseer and PubMed.", "For the inductive setting, we considered the Protein-Protein Interaction (PPI) dataset [@bib:zitnik2017predicting] .", "In addition, we provide an evaluation of the citation datasets in a fully supervised setting, similar to [@bib:xu2018representation] .", "\\newline <subsection> <title> 4.1 Citation Datasets </title> For Citation datasets, we conducted the experiment with two widely-used settings with the former according to [@bib:yang2016revisiting] and the latter according to [@bib:xu2018representation] .", "In this section, we describe the results for both settings.", "\\newline In the first setting, training data only contains 20 labelled nodes for each category in the dataset.", "Validation data contains 500 nodes, while test data contains 1000 nodes.", "We used a learning rate of $ 0.005 $ for model parameters $ w $ and $ 0.002 $ for architectural parameters $ a $ , and ran search for 400 epochs."]], "target": "In , we present the results of PDNAS for this setting in comparison to graph attention networks (GAT) , GraphNAS and AGNN . The results demonstrate that PDNAS outperforms all existing methods on Cora and PubMed, however, is $ 0.3\\% $ lower on Citeseer compared to AGNN. In addition to accuracy, we also measured the search wall clock times of GraphNAS using their open sourced code . Unfortunately AGNN does not have an open source implementation, nor reports wall clock times, making it impossible to compare against."}, {"tabular": ["  Method  &  flower <ln> pot  &  book- <ln> shelf  &  bowl  &  cup  &  plant  &  vase ", " DGCNN  &  0.15  &  0.05  &  0.00  &  0.00  &  0.55  &  0.25 ", " LLE  &  0.05  &  0.00  &  0.05  &  0.05  &  0.65  &  0.20 ", " MP  &  0.20  &  0.00  &  0.00  &  0.00  &  0.55  &  0.25  "], "ref_sec": [["<section> <title> Introduction </title>  With the developments of laser radar and other imaging instruments, three-dimensional (3D) data is becoming much more easily available.", "Consequently, the effective processing and analysis methods should be investigated for 3D-related applications.", "As the representative 3D data, point cloud has been widely adopted in indoor navigation, autopilot, and augmented reality, etc.", "The effective classification of point clouds can be helpful for the better understanding of intelligent systems to different complicated environments.", "Therefore, the accurate classification of point clouds plays an important role in related practical applications.", "\\newline With the improvement of computing power and the substantial increase of data, deep learning [@bib:lecun2015deep] technology has become more and more popular for point cloud classification [@bib:maturana2015voxnet,qi2016volumetric,su2015multi] .", "Particularly, graph neural network [@bib:zhang2018graphsurvey] develops rapidly, where many data sources can be effectively represented as graphs for modeling and analysis, such as two-dimensional (2D) image, social networking, 3D point sets.", "Due to the fact that deep learning has the powerful capability in fitting potential relationship among graph nodes, it can fulfill the complicated modeling tasks for high-dimensional data.", "For 3D point cloud, the properties of data can be actually suitable for graph representation, and therefore the graph neural networks-based analysis method has emerged as a promising exploration direction [@bib:zhang2018PointgCN,wang2019dynamic,li2019deepgcns,xu2020grid] .", "\\newline Point clouds are mainly used to represent the surface shape of objects.", "At present, the mainstream methods, e.g. [@bib:qi2017pointnet,wang2019dynamic] , directly use Euclidean distance when analyzing the local feature of point clouds, but Euclidean distance cannot accurately reflect the relationship between points due to the curvatures.", "Additionally, manifold is an extension of curve and surface in the original Euclidean space.", "Although manifold topological space can be locally treated as Euclidean space, it can be more powerful to evaluate all the elements and their connections.", "The core idea of manifold learning algorithm is to map data from high dimension to low dimension, which can remove data redundancy while preserving geometric topological relations.", "Using manifold learning method on point cloud can consider the continuity of the geometric surface of the object, then improve the description for the nature of the geometric shape.", "\\newline To introduce manifold learning for point cloud classification, we formulate a novel neural network architecture, named Manifold Learning Module, which consists of two alternative sub-modules, i.e., Locally Linear Embedding (LLE) Module and Manifold Projection (MP) Module.", "The functions of these two modules are similar.", "More specifically, the dimensionality of point cloud features is reduced by manifold learning, and then the new generated features are concatenated with the original features to enrich the input features for neural network-based classification.", "\\newline In the Locally Linear Embedding Module, we establish the correlation between high-dimensional and low-dimensional spaces by the local symmetries, and then reconstruct the points by neighborhood-preserving mapping.", "Hence, we can obtain a low-dimensional point set that maintain the continuity of the geometric surface.", "Additionally, to implement an end-to-end manifold learning method, we present a novel neural network architecture named Manifold Projection Module, which focuses on fitting nonlinear projection mapping from 3D to 2D.", "Experimental results on the ModelNet40 dataset demonstrate that our methods have better feature representation capability and can lead to better classification results.", "\\newline In summary, the main contributions of the proposed method are as follows: \\newline <list> \\ We propose a novel point cloud classification method with manifold learning and graph neural network, namely PointManifold.", "\\newline \\ \\ We introduce two manifold learning methods in point cloud classification task, where one is based on locally linear embedding, and the other is a novel manifold projection method based on the designed neural network.", "\\newline \\ \\ With the feature engineering of manifold learning and feature aggregation of graph neural network, compared with previous PointNet series methods, graph-based methods and other state-of-the-art methods, PointManifold get a competitive performance, and significant improvement from its baseline.", "Besides, we do some ablation study to explore the relationship between two manifold modules.", "\\newline \\ </list> \\newline  </section>"], ["<section> <title> Related Work </title>  In this section, we briefly review different categories of deep learning-based point cloud analysis methods.", "\\newline View-based and volumetric methods.", "In the task of deep learning-based classification and semantic segmentation of two-dimensional (2D) images, feature extraction and embedding are required.", "The most direct analysis method is rendering 3D point cloud into 2D images, and then uses conventional 2D image classification neural networks, e.g. [@bib:su2015multi,yavartanoo2018spnet,qi2016volumetric] .", "Moreover, 3D data is a generalization of 2D data, where voxel can be extended from pixel.", "Therefore, promoting 2D convolutional neural network to 3D convolution is another solution to deal with this task.", "However, 3D point clouds are sparse and disorderly, and such methods as VoxelNet [@bib:maturana2015voxnet] require a large amount of computations.", "In addition, due to the sparse and uneven density distribution of point clouds, both of view-based and volumetric methods are not sufficiently effective to obtain satisfactory performances.", "Specifically, large-scale scenes may lead to incredible computation complexity, and the data type transformation from point cloud to voxel will inevitably cause information loss.", "\\newline Point cloud-based methods (PointNet Series).", "To overcome the defects of view-based and volumetric methods, processing each point independently is feasible.", "The milestone of deep learning-based point cloud analysis is PointNet [@bib:qi2017pointnet] , which uses the multi-layer perceptron (MLP) to extract point feature with high dimension, then uses max pooling to obtain the representative feature vector, which solves the disorder of point cloud simultaneously.", "Compared with the previous methods, PointNet avoids the huge computation of 3D voxel convolution and shows excellent classification and segmentation performances at a higher speed.", "On the basis of PointNet, [@bib:qi2017pointnet++] then propose PointNet++ containing down sampling and up sampling architecture, which enriches the collection of global features and solves the problem of uneven point cloud density.", "These two methods lay the foundation for the application of deep learning on point cloud analysis in recent years.", "Additionally, there are derived PointSIFT [@bib:jiang2018Pointsift] which focuses on uniform sampling to establish local descriptor, and PointASNL [@bib:yan2020pointasnl] which focuses on adaptive sampling.", "\\newline Graph-based methods.", "With the development of graph neural network, applying graph to point cloud analysis has become an emerging research direction.", "There are some representative works [@bib:zhang2018PointgCN,wang2019dynamic,li2019deepgcns] .", "DGCNN [@bib:wang2019dynamic] uses graph to express point features and utilizes convolution operation.", "This work makes a summary for the graph-based point cloud analysis method and expresses the frameworks in formula.", "\\newline Geometry-based methods.", "Geometry-based point cloud analysis network is also developed these years.", "TangentConv [@bib:tatar2018tangent] projects point cloud into tangent planes, then 2D convolution is adopted.", "FPConv [@bib:Lin2020FPConv] learns a local weight matrix to flatten point cloud to 2D grid.", "MoNet [@bib:monti2017geometric] gives a unified framework for generalizing traditional convolutional neural network to non-Euclidean geometric data in spatial domain.", "ShapeContextNet [@bib:Liu2018Attentional] applies the shape context description in traditional computer vision field to point cloud representation.", "SPLATNet [@bib:su2018splatnet] and SO-Net [@bib:li2018so] also focus on the representation of point cloud.", "Meanwhile, [@bib:Hermosilla2018Monte,Thomas2019KPConv,Li2018PointCNN,Shen2018mining] focus on migrating convolution operation to point cloud with geometric consideration.", "\\newline  </section>"], ["<section> <title> The Proposed Method </title>  In this section, we introduce PointManifold for point cloud classification.", "Inspired by DGCNN [@bib:wang2019dynamic] , PointManifold uses graph neural network to embed the point features, and then uses convolution operation to extract features for classification task.", "Meanwhile, to get the geometric nature of point cloud, we apply manifold learning to enrich the dimension of point features.", "The main architecture of our method is shown in Fig. [@ref:LABEL:fig:main_architecture] .", "\\newline <subsection> <title> Locally Linear Embedding Module </title> In fact, a lot of redundancies still exist in many data representation methods, and each data may even have thousands of features, but they can acutally be well represented by limited parameters.", "As an efficient method for obtaining these parameters, manifold learning algorithm can give the low dimensional representation for data.", "There are many methods to solve this problem, such as Isomap, locally linear embedding (LLE) , laplacian eigenmaps, etc.", "Isomap is a generalization of principal content analysis (PCA) algorithm on manifolds, and it is necessary to calculate the distance between all point pairs.", "Hence, Isomap requires a large amount of calculation.", "Since LLE only concerns the equality of distances in local range, it will have less computation overhead.", "Moreover, LLE can also benefit the local to global neural network-based analysis for point clouds.", "For the sake of low computation complexity and effectiveness of analysis, we choose locally linear embedding algorithm for point cloud dimension reduction.", "\\newline Notation. Let $ P $ be a point set, $ r $ and $ d $ are the dimensions of the original space and the new space, respectively, thus $ P=\\{p_{1},...,p_{n}\\},p_{i}\\in\\mathbb{R}^{r} $ .", "The aim of locally linear embedding is to get a new points representation in lower dimension space, denoted as $ \\hat{P}\\in\\mathbb{R}^{d\\times n},d<r $ .", "\\newline Calculate distance matrix.", "The locally linear embedding algorithm requires that the relative distance of the points in the local range should be as unchanged as possible.", "In other words, one point can be reconstructed by using the features of its adjacent points, which is in fact consistent with the nearest neighbor relationship of point cloud analysis.", "Let $ p_{i} $ be a central point in local range, $ \\mathbb{N}_{i} $ is the $ n $ range neighbor of $ p_{i} $ , and weighted matrix $ W=[w_{1},...,w_{n}],w_{i}\\in\\mathbb{R}^{n} $ is the distance matrix of point pairs.", "The central point can be represented as: \\newline <equation> $ p_{i}=\\sum_{j\\in\\mathbb{N}_{i}}W_{ij}p_{j},\\ s.t.\\sum_{j}W_{ij}=1,\\forall i\\in% \\{1,...,n\\}, $ </equation> \\newline where $ W_{ij} $ denoted the distance weight between $ p_{i} $ and $ p_{j} $ , and the constraint is for normalization.", "$ W $ can be obtained by solving: \\newline <equation> $ \\mathop{min}\\limits_{W}\\sum_{i}||p_{i}-\\sum_{j\\in\\mathbb{N}_{i}}W_{ij}p_{j}||_% {2}^{2}. $ </equation> \\newline Get new point representations.", "In order to obtain the expression of points in the new feature space $ \\hat{P} $ , the optimized objective function of locally linear embedding algorithm is: \\newline <equation> $ \\mathop{min}\\limits_{\\hat{P}}\\sum_{i}||\\hat{p}_{i}-\\sum_{j\\in\\mathbb{N}_{i}}W_% {ij}\\hat{p}_{j}||_{2}^{2}, $ </equation> \\newline where $ \\hat{p}_{i} $ and $ \\hat{p}_{j} $ are the points of $ \\hat{P} $ .", "\\newline The detailed steps of locally linear embedding algorithm are shown in Alg.", "[@ref:LABEL:algo:lle] .", "In the overall network, point cloud data is firstly feed to the devised LLE Module, the structure of which is shown in Fig. [@ref:LABEL:fig:lle_module] .", "Using LLE to reduce the standardized coordinates to two-dimensional space, the 2D features are then concatenated with the originals.", "Let $ \\mathcal{L} $ represent locally linear embedding, $ F\\in\\mathbb{R}^{b\\times n} $ be the input feature vector of point set $ P $ , where $ b $ is the feature dimension, and $ b=r+d=5 $ .", "We can get the equation of $ F $ as: \\newline <equation> $ F_{LLE}=\\{\\mathbf{x},\\mathbf{y},\\mathbf{z},\\mathcal{L}_{x^{^{\\prime}}}(P),% \\mathcal{L}_{y^{^{\\prime}}}(P))\\}, $ </equation> \\newline where $ x^{^{\\prime}},y^{^{\\prime}} $ represent the new coordinates of points, and $ \\mathcal{L}\\in\\mathbb{R}^{2\\times n} $ .", "\\newline <float> \\ Input: (points set $ P $ , neighborhood range $ K $ , new dimension $ D $ ) \\ \\ Output: new representation $ Y $ of points set in new space \\ \\ /* Using kNN to get the neighborhood */ \\ \\ for {Each point $ p_{i} $ in $ P $} do \\ \\ $ N_{i}=knn(p_{i},K) $ \\ \\ for {Each point $ p_{i} $ in $ P $} do \\ \\ $ P_{i}=repeat(p_{i},K) $ ; \\ \\ $ S_{i}=(P_{i}-N_{i})^{T}(P_{i}-N_{i}) $ ; \\ \\ $ w_{i}=solve\\_lagrange\\_multipliers(w_{i}^{T}S_{i}w_{i}+\\lambda(w_{i}^{T}1_{k}-% 1)) $ ; \\ \\ \\ \\ /* Solve for a low-dimensional mapping */ \\ \\ $ W^{\\prime}=new\\_matrix(N,N) $ ; \\ \\ for {Each point $ p_{i} $ in $ P $} do \\ \\ for {$ j\\ in\\ range(N) $} do \\ \\ if {$ j\\in N_{i} $} then \\ \\ $ W^{\\prime}_{ji}=w_{ji} $ ; \\ \\ \\ \\ else \\ \\ $ W^{\\prime}_{ji}=0 $ ; \\ \\ \\ \\ \\ \\ \\ \\ /* The minimum distance loss is obtained by using the Lagrange multiplier method, in this case, $ Y $ is a matrix composed of the eigenvectors of $ M $ */ \\ \\ $ Y=new\\_matrix(D,N) $ ; \\ \\ for {$ i\\ in\\ range(N) $} do \\ \\ $ M_{i}=(I_{i}-W_{i})(I_{i}-W_{i})^{T} $ ; \\ \\ $ eigen\\_vec,eigen\\_val=eigens(M_{i},D) $ ; \\ \\ $ Y_{i}=eigen\\_vec(2:D+1) $ ; \\ \\ \\ \\ return {$ Y $} \\ Locally Linear Embedding </float> \\newline </subsection> <subsection> <title> Manifold Projection Module </title> The core idea of manifold learning algorithm is to find a mapping from high-dimensional space to low-dimensional space.", "Different from the traditional manifold learning algorithms, which use the distance measurement in different spaces to reduce dimension, we design a novel neural network architecture for this task.", "\\newline Projection in Euclidean space. Let $ Ax+By+Cz+D=0 $ be a plane in 3-dimensional Euclidean space, $ p_{i}(x_{i},y_{i},z_{i}) $ is a point, $ p_{i}^{^{\\prime}}(x_{i}^{^{\\prime}},y_{i}^{^{\\prime}},z_{i}^{^{\\prime}}) $ is the projection of point $ p_{i} $ on the plane.", "According to the vertical relation, the parametric equation of the vertical line is: \\newline <equation> $ \\cases{x_{i}^{^{\\prime}}=x_{i}-At\\cr y_{i}^{^{\\prime}}=y_{i}-Bt\\cr z_{i}^{% ^{\\prime}}=z_{i}-Ct}. $ </equation> \\newline Since $ p_{i}^{^{\\prime}} $ is on the plane, $ t $ can be solved by the plane equation: \\newline <equation> $ t=\\frac{Ax_{i}+By_{i}+Cz_{i}+D}{A^{2}+B^{2}+C^{2}}. $ </equation> \\newline Nonlinear projection by neural network.", "We can get the linear projection function $ S $ by Eq. [@ref:LABEL:eq:projection] and Eq. [@ref:LABEL:eq:t] .", "As manifold learning is a nonlinear dimensionality reduction method, we set a nonlinear function $ \\mathcal{S} $ for this process: \\newline <equation> $ \\mathcal{S}_{\\beta}(x,y,z)=\\mathcal{X}_{\\beta}(x,y,z)S, $ </equation> \\newline where $ \\beta $ is the projection plane, and $ \\mathcal{X} $ is a nonlinear function defined as follows: \\newline <equation> $ \\mathcal{X}(\\cdot)=\\mathcal{F}(Q_{\\Theta}(\\cdot)), $ </equation> \\newline where $ \\mathcal{F} $ is an activation function, and $ Q_{\\Theta} $ is a function to fit the mapping.", "Here, we implement it by multi-layer perceptron.", "Then, we can get the full definition of manifold projection $ \\mathcal{S} $ : \\newline <equation> $ \\mathcal{S}_{\\beta}(x,y,z)=\\mathcal{F}(Q_{\\Theta}(x,y,z,\\beta))S_{\\beta}(x,y,z).", "$ </equation> \\newline Finally, since all data of ModelNet40 are standardized, we take three projection planes $ x=0,y=0,z=0 $ to get a multi-view of the point cloud, as shown in Fig. [@ref:LABEL:fig:projection] .", "Similar with the LLE Module, we concatenate the new manifold features with the original features.", "Then, we can get the input feature vector $ F $ as: \\newline <equation> $ F_{MP}=\\{\\mathbf{x},\\mathbf{y},\\mathbf{z},\\mathcal{S}_{x=0}(P),\\mathcal{S}_{y=% 0}(P),\\mathcal{S}_{z=0}(P)\\}, $ </equation> \\newline where $ \\mathcal{S}\\in\\mathbb{R}^{6\\times n} $ .", "here $ d=2 $ , thus the dimension of new feature $ b=r+3\\times d=9 $ .", "The architecture of manifold projection module is shown in Fig. [@ref:LABEL:fig:mp_module] .", "\\newline </subsection> <subsection> <title> EdgeConv Module </title> The EdgeConv Module is mainly based on DGCNN [@bib:wang2019dynamic] , and the structure is shown in Fig. [@ref:LABEL:fig:edge_conv] .", "Let $ f_{i} $ be the feature vector of central point $ i $ , $ \\mathbb{N}_{i} $ be the neighbor of $ i $ , which is selected by k nearest neighbor (kNN).", "We denote $ e_{ij} $ as the edge feature of $ i $ and its neighbor $ j $ , and the definition is: \\newline <equation> $ e_{ij}=h_{\\Theta}(f_{i},f_{j}),j\\in\\mathbb{N}_{i}, $ </equation> \\newline where $ h_{\\Theta}(\\cdot,\\cdot) $ is the edgeconv function.", "We implement it by multi-layer perceptron.", "Then, we can get the new feature vector $ f_{i}^{^{\\prime}} $ : \\newline <equation> $ f_{i}^{^{\\prime}}=g(e_{ij})=\\mathop{g}\\limits_{j\\in\\mathbb{N}_{i}}(h_{\\Theta% }(f_{i},f_{j})), $ </equation> \\newline where $ g(\\cdot) $ is a symmetric function, and here we use maximum.", "Finally, we achieve the full definition of edgeconv: \\newline <equation> $ f_{i}^{^{\\prime}}=\\mathop{max}\\limits_{j\\in\\mathbb{N}_{i}}(LeakyReLU(\\theta_% {m}\\cdot f_{i}+\\phi_{m}\\cdot(f_{j}-f_{i}))), $ </equation> \\newline where $ \\Theta=(\\theta_{1},...,\\theta_{M},\\phi_{1},...,\\phi_{M}) $ is the parameters to be learnt, and $ M $ is the number of convolution kernels.", "\\newline Since the dimension of input feature vector is higher than that in [@bib:wang2019dynamic] , we add a dynamic channel control block on the backbone network, which can adjust the channel size of each layer to fit different dimensions of input data.", "In Experiments section, we will analyse the influence of channel size on classification performance.", "\\newline </subsection>  </section>"], ["<section> <title> Experiments </title>  In this section, to demonstrate the effectiveness of PointManifold, we design a set of experiments on ModelNet40 [@bib:wu20153d] , and compare PointManifold with a series of state-of-the-art methods.", "Additionally, we do several ablation experiments to deeply explore the operation mechanism of Manifold Learning Module and Channel Control Block.", "\\newline <subsection> <title> Classification on ModelNet40 </title> Data.", "We select ModelNet40 for the classification task, which contains 12308 models and a total of 40 categories.", "All the models are sampled from the computer-aided design (CAD) models.", "Each model provides 2048 sampling points pre-processed with standardization, and each point contains 3D position information.", "In training process, 9840 models are used as the training set, and the remaining 2468 models are used as the test set.", "In order to speed up the training process and avoid repeated processing of the same data between epochs, we use locally linear embedding algorithm to pre-process the data.", "This work can reduce the standardized coordinates to two-dimensional space, and then the new features can be concatenated to the original features.", "\\newline Environment.", "The code implementation of the proposed method is based on Pytorch framework (version 1.1.0) and Python (version 3.6).", "The experimental computing platform includes one NVIDIA RTX 2070 and four NVIDIA Tesla V100.", "The operating system is Ubuntu (version 16.04), CUDA (version 10.1) and cuDNN (version 7.4).", "\\newline Hyper-parameters.", "We use SGD as optimizer with a momentum of 0.9, and the learning rate is 0.1 with a cosine annealing scheduler.", "To enhance the fitting ability of the proposed model, we add dropout layer with 0.5 dropout ratio.", "For the classification activation function, we select softmax.", "For LLE Module, we set training epochs as 250, batch size as 32, channel time $ t $ as 1, and the neighbor range $ k $ of edgeconv is 20, while the $ k $ of LLE is 12.", "Specifically, both of the range parameters will be doubled in 2048 points experiments.", "For MP Module, our model is trained with 300 epochs, and the channel time $ t $ are set as 2 and 4 for 1024 and 2048 points experiments, respectively.", "\\newline Result.", "Following [@bib:wang2019dynamic] , we report the mean class accuracy (mA) and overall accuracy (oA) on ModelNet40.", "Results are shown in Table.", "[@ref:LABEL:tab:modelnet40] , as we can see the proposed methods achieve a competitive result.", "PointManifold is better than the mainstream state-of-the-art point cloud analysis methods in classification task, and have a significant improvement compared with the DGCNN baseline.", "In addition, we test the class-level result for point cloud classification and give more explorations about the relationship between shape and model performance, which is provided in the Supplementary Material.", "For fair comparison, the results of DGCNN is tested by ourselves, with the same hyper-parameters settings as its open source code [@bib:wang2019dynamic] , and the same environment as our methods.", "Besides, because of the limitation of our experiment platform, we cannot train MP Module (2048 points) with the batch size of 32, and we set it as 24 instead.", "We believe that the classification performance could be better if the batch size is larger.", "\\newline </subsection> <subsection> <title> Manifold Learning Effectiveness </title> PCA is a common dimension reduction method, which computes principal components and uses them to perform the changes on the basis of the data.", "In order to verify the effectiveness of manifold learning in geometric feature extraction, we conduct a controlled experiment between PCA and our methods, and the results are shown in Table.", "[@ref:LABEL:tab:pca] .", "The PCA algorithm makes no improvement compared with the baseline, while LLE and MP module can take into account the geometric properties when reducing dimensions.", "Hence, they can perform better than the DGCNN baseline.", "\\newline </subsection> <subsection> <title> Ablation Study </title> As mentioned above, we add a channel control block, thus we set an ablation experiment to explore the influence of channel control parameter $ t $ on the model performance.", "In addition, we also would like to investigate the relationship between the two manifold learning methods, and therefore we set up several sets of ablation experiments.", "\\newline From Table. [@ref:LABEL:tab:ablation] , it can be seen that, with the additional input features, an appropriate increase in the channel numbers of the entire model can improve the classification performance.", "Furthermore, due to the function overlapping, using LLE and MP modules for feature extraction simultaneoulsy cannot fully improve the classification performance, and using either of them can get a similar improvement compared with the baseline.", "In other words, the ablation study results prove that the proposed neural network architecture can implement the function of manifold learning.", "\\newline </subsection>  </section>"], ["<section> <title> Conclusion </title>  In this work, we propose a novel point cloud classification method with manifold learning and graph neural network.", "Using the proposed locally linear embedding algorithm or nonlinear neural network projection, we can get low dimension point features according to the geometric correlation.", "These new features are concatenated with the original 3D features, and we extracted them by using graph neural network.", "The experiments demonstrate that our methods with different manifold learning strategies can improve the point cloud classification performances when compared with the DGCNN baseline method.", "It can be seen that, in the proposed method, the effectiveness of extracted features are guaranteed by considering the surface continuity of point cloud during the 3D-to-2D projection.", "Therefore, we believe that, besides manifold learning, many other feature analysis approaches will also be very helpful for the feature representation learning in the point cloud data analysis and understanding tasks.", "\\newline  </section>"], ["<section> <title> Supplementary Material </title>  <subsection> <title> More Results on Classification Task </title> In order to further explore the effectiveness of Manifold Learning Module on classification task, we test the classification performance of 40 categories of ModelNet40 in detail, and we report three metrics for each category, i.e., precision, recall and f1-score, the results are shown in Table.", "[@ref:LABEL:tab:classification_detail] , from which we can see: \\newline <list> \\ In most categories, compared with the DGCNN [@bib:wang2019dynamic] baseline, our methods make improvement or achieve the same result.", "However, in four categories, i.e., bench, curtain, door and night_stand, our approaches are not better than the baseline.", "\\newline \\ \\ On some of the categories in which the physical features are prominent, our methods make significant improvement, such as bookshelf, cup, dresser, radio, sink and xbox.", "\\newline \\ \\ The classification performance of flower_pot is extremely poor, in spite of 4% improvement by MP Module.", "We visualize some samples to find out the reason.", "\\newline \\ </list> \\newline </subsection> <subsection> <title> Visualization and Analysis </title> We attempted to explain the above results by visualization.", "\\newline <subsubsection> <title> Shape-similar Categories.", "</title> The classification of shape-similar categories is difficult."]], "target": "To explain the bad classification performance of flower_pot category, we calculate the confusion matrixes of the baseline and our methods, and the results of specific classes are shown in Table. ."}, {"tabular": ["    &  Normalization  &  Normalization + Scale as Feature ", " MASE  &  0.9497  &  0.9479 ", " MAE  &  1.0213  &  0.9959  "], "ref_sec": [["<section> <title> 1 Introduction </title>  \u201c Unus pro omnibus, omnes pro uno.", "\u201d \u2014 D\u2019Artagnan \\newline Consider the problem of having to forecast many time series as a group.", "We might need to forecast tourist arrivals at all our resorts for next season, the demand for all products we offer at our retailer every week, server loads within a data center, the number of completed ride shares for all zones within a city on a hourly basis, and so on.", "The safest way (making fewest assumptions) to approach this problem is to assume each of the time series in the set potentially comes from a different data generating process so it should be modeled individually, as a separate regression problem of finding a function to predict future values from the observed part of the series.", "This is the standard univariate time series forecasting problem; we call it the local approach to the problem.", "\\newline From a statistical/machine learning perspective, the local approach suffers from one shortcoming: sample size.", "Temporal dependence and the short length of the series makes time series forecasting a notoriously difficult problem.", "Individual time series cannot be modeled in a data-driven way because even basic models (e.g., linear) will suffer from over-fitting.", "To overcome over-fitting, an excessive burden is placed on manually expressing prior knowledge of the phenomena at hand (assuming seasonal patterns, looking for external explanatory variables, calendar effects, separate long/short term effects, etc.) and restricting the fitting.", "This limits accuracy, since finding appropriate simple models is not always possible; it also limits scalability, since modeling each time series requires human supervision.", "As a result, the last four decades of automatic time series forecasting (i.e. without prior information) have been dominated by the ensembling of simple forecast models.", "\\newline A univariate alternative to the local approach, called the global approach, has been introduced to exploit the natural scenario where all series in the set are \u201csimilar\u201d, \u201canalogous\u201d or \u201crelated\u201d (e.g. the demand for fiction books follows a similar pattern for all subgenres, stores or cover designs).", "The idea behind the global approach is to introduce the strong assumption of all time series in the set coming from the same process, because even when not true, it will pay off in terms of forecasting accuracy.", "Global methods pool the data of all series together and fit a single univariate forecasting function.", "The global approach overcomes the main limitation of the local approach: it prevents over-fitting because a larger sample size is used for learning compared to a local counterpart.", "On the other hand, the same function must be used to forecast all time series in the set, even when the series are different, which seems restrictive (and less general than local).", "The wider adoption of global methods has been prevented by the underlying assumption that they offer benefits over local methods only when time series in the set come from intuitively similar or related data generating processes.", "\\newline However, recent empirical results show puzzlingly good performance of global methods applied over sets of time series that cannot be considered related [@bib:laptev2017extreme] .", "Notably, top results in the M4 Competition [@bib:makridakis2020m4] use some form of globality, mostly in combination with local parts [@bib:smyl2020hybrid,montero2020fforma] .", "Good performance with purely global methods [@bib:gasthaus2019probabilistic,oreshkin2019nbeats] has soon followed these initial results.", "Because heterogeneous datasets are general (we can always add series from other sources to get a heterogeneous set), the implications of global methods working well for heterogeneous datasets can have a profound impact in forecasting practice.", "This can set a new state-of-the-art for automatic methods and open the possibilities of adopting data-driven techniques that are inapplicable for local methods, thus keeping up with the advances in machine learning.", "\\newline Nevertheless, all cited pieces of empirical evidence are closely tied to the specific models used to achieve them, which differ among themselves, sometimes making contradictory claims about the causes of this performance.", "There is a lack of understanding of the underlying general principles behind this good performance (even if they exist).", "These principles can help solidify existing knowledge, accelerate technology transfer to real-world applications and guide future improvements in the field.", "\\newline Motivated by these possibilities and needs, in this paper we compare global and local forecasting algorithms from the perspective of statistics and machine learning applied to a finite number of series, each of finite length, and for a finite horizon of interest.", "This leads to the following contributions.", "\\newline <list> \\ In a formal setting of forecasting a set of time series, we show that local and global algorithms can produce the same forecasts, so they can approximate the series equally well (Section [@ref:LABEL:sec:equivalence] ).", "A local algorithm might learn a different function to forecast each series in the set, but its forecasts can always be replicated by a single function learnt by a global algorithm.", "Global algorithms in the general setting of supervised learning (i.e. pooling together regression problems with arbitrary input-output pairs) do not exhibit this property.", "This result can be understood as an existence result that motivates the use of global algorithms for a wider range of problems than previously thought, since we require no assumptions about similarity of the series in the set.", "\\newline \\ \\ A key contribution of the paper is the derivation of generalization bounds of local and global algorithms for forecasting sets of time series (Section [@ref:LABEL:sec:genbounds] ).", "These bounds relate model complexity (measured as the number of functions that can be fit to data) and sample size to the difference between training (in-sample) error and testing (out-of-sample) error.", "The bounds are agnostic of specific models and the distribution of the data, allowing us to reason without knowing the specifics.", "We show that the complexity of local algorithms grows with the size of the set, so it can easily surpass the constant complexity of global algorithms.", "For example, for sets of moderate size, a local algorithm such as fitting simple exponential smoothing models to each series in the set is (surprisingly) more complex than a single global deep network with thousands of parameters.", "When higher complexity of a model leads to poorer generalization, this means that global models generalize better .", "\\newline \\ \\ Derived from the complexity analysis, we provide principles for designing forecasting algorithms for sets of time series that lead to improved forecasting accuracy.", "These principles can serve as a \u201ctoolbox\u201d which can be adapted to specific forecasting problems.", "Furthermore, these principles unify local and global approaches under the common framework of controlling model complexity.", "\\newline \\ \\ We motivate the use of global algorithms with large complexity (Section [@ref:LABEL:sec:altcomplex] ).", "Complexity can be increased in many ways; we highlight three: \\newline <list> \\ For example, adding manual features such as high degree polynomials, or considering alternate model classes such as nonparametric/kernel methods, deep networks or regression trees.", "This in turn is a strong theoretical support for the current empirical evidence based on deep learning.", "\\newline \\ \\ Restricting the class of models to finite memory autoregressions, larger complexity of global models can be reached by increasing the memory/order of autoregression (Section [@ref:LABEL:sec:largemem] ).", "In addition to benefits of better fitting, this shows that long memory patterns might be easier to pick with global models.", "\\newline \\ \\ We cast the problem of forecasting a set of time series as a spectrum between two extremes based on how the set is partitioned.", "Partitioning the set into single series leads to the local approach, while the global approach works on the trivial partition that keeps the set intact.", "We show that the complexity of a learning algorithm can be controlled by the granularity of the partitioning (Section [@ref:LABEL:sec:parti] ).", "This result highlights the trade-off in sophisticated ways of partitioning, such as data-driven partitioning, leading to clustering and its fuzzy weighted alternatives.", "\\newline \\ </list> \\newline \\ \\ We showcase the strength of these theoretically derived principles in a large empirical study on benchmark datasets (Sections [@ref:LABEL:sec:experisetup] \u2013 [@ref:LABEL:sec:experires] ).", "We incorporate these principles in global forecasting methods based on existing classes such as linear models, high order polynomials and deep networks (MLP ReLu).", "To isolate the contribution of the principles, these methods are na\u00efve in the sense that they do not rely on feature engineering, seasonality, advanced deep learning architectures, hyperparameter tuning, preprocessing steps or model selection/combination.", "These methods achieve good accuracy through a wide range of benchmark datasets.", "We find compelling empirical evidence towards global methods in the performance of linear models: while theoretically the complexity of a global model must be larger than the one a local algorithms assigns to each individual series, we find that in practice it does not need to be much larger.", "This means that global methods can be both simpler (3 orders of magnitude fewer parameters) and more accurate.", "\\newline \\ \\ We provide a theoretical explanation for recent empirical results on the performance of global methods (Section [@ref:LABEL:sec:related] ).", "The main cause we propose \u2014 global methods can have higher complexity and still generalize better \u2014 differs from the explanations given in related literature, which we show are too narrow.", "We continue with a critical analysis of related literature claims about clustering, memory and preprocessing from the theoretical point of view of the elements involved in the bounds.", "\\newline \\ </list> \\newline  </section>"], ["<section> <title> 2 Equivalence of global and local approaches for forecasting a set of time series </title>  \u201c Each forecast that can be expressed by a local algorithm can also be expressed by a global algorithm.", "\u201d \\newline <subsection> <title> 2.1 Local and global learning algorithms </title> We compare two approaches for forecasting a set of time series.", "The local approach fits a function to each time series in the set.", "The global approach fits the same function to all time series in the set.", "Both approaches are learning algorithms, functions that take data as input and produce forecasting functions as output.", "These forecasting functions, in turn, take the observed part of a time series as input and produce the future part (forecast) as output.", "Because the global approach is restricted to producing the same function for all time series in a set while the local can use a different function for each series, we might think the global is more limited than the local approach.", "It turns out that under realistic assumptions this is not true: local and global approaches do not differ in the forecasts they are able to produce.", "\\newline Let $ \\mathbb{S} $ be the set of univariate time series of size $ K $ , $ \\mathbb{S}=\\{X_{i}\\in\\mathbb{R}^{T},i=1\\dots K\\} $ , and we allow $ \\mathbb{S} $ to have repeated time series.", "$ X_{i} $ are the observed time series, vectors of real numbers, assumed to be of the same finite length $ T $ without loss of generality.", "We are interested in the future of each time series until a finite number of time steps $ H $ ; i.e. each time series $ X_{i} $ has a future part which is a vector in $ \\mathbb{R}^{H} $ .", "Forecasting functions are functions from the observed time series to the future part: \\newline <equation> $ f:\\mathbb{R}^{T}\\to\\mathbb{R}^{H}. $ </equation> Let $ A_{L} $ be a local learning algorithm: a function that takes a time series $ X_{i} $ and returns a forecasting function $ f_{i} $ .", "That is, \\newline <equation> $ A_{L}:\\mathbb{R}^{T}\\to(\\mathbb{R}^{T}\\to\\mathbb{R}^{H}).", "$ </equation> The same local algorithm is applied to each time series in $ \\mathbb{S} $ , producing a different function for each $ X_{i} $ .", "\\newline A global method $ A_{G} $ is also a learning algorithm, but it only produces a single forecasting function, $ g $ , for the whole $ \\mathbb{S} $ , \\newline <equation> $ A_{G}:\\mathbb{S}\\to(\\mathbb{R}^{T}\\to\\mathbb{R}^{H}) $ </equation> \\newline <theorem> Proposition 1 (Equivalence of Local and Global Algorithms for Time Series Forecasting).", "Let \\newline <list> \\ $ \\mathbb{A}_{L} $ = set of all local learning algorithms; \\newline \\ \\ $ \\mathbb{A}_{G} $ = set of all global learning algorithms; \\newline \\ \\ $ \\mathbb{F}_{L,\\mathbb{S}}=\\{[(A_{L}(X_{i}))(X_{i})|\\ X_{i}\\in\\mathbb{S}],A_{L}% \\in\\mathbb{A}_{L}\\} $ , the set of all possible local forecasts of $ \\mathbb{S} $ ; \\newline \\ \\ $ \\mathbb{F}_{G,\\mathbb{S}}=\\{(A_{G}(\\mathbb{S}))(X_{i})|\\ X_{i}\\in\\mathbb{S},A_% {G}\\in\\mathbb{A}_{G}\\} $ , the set of all possible global forecasts of $ \\mathbb{S} $ .", "\\newline \\ </list> Then \\newline <equation> $ \\mathbb{F}_{L,\\mathbb{S}}=\\mathbb{F}_{G,\\mathbb{S}}. $ </equation> \\newline </theorem> To prove Proposition 1 we show these two sets must include one another.", "\\newline 1) \\newline <equation> $ \\text{Set of possible local forecasts}\\supseteq\\text{Set of possible global % forecasts}. $ </equation> \\newline For any $ g=A_{G}(\\mathbb{S}) $ , an $ A_{L} $ that sets every $ f_{i}=g $ would produce the same forecasts.", "\\newline 2) \\newline <equation> $ \\text{Set of possible local forecasts}\\subseteq\\text{Set of possible global % forecasts}. $ </equation> \\newline In this scenario, we fix the output of the local algorithm, $ \\{f_{i},i=1,\\dots,K\\} $ , and show that there is a $ g $ that can approximate them.", "We consider two possibilities: \\newline a) $ X_{i}\\neq X_{j} $ for all $ i\\neq j $ .", "\\newline This means every $ X_{i} $ is unique in $ \\mathbb{S} $ .", "The set of all $ f_{i}(X_{i}) $ is finite since $ \\mathbb{S} $ is finite, with cardinality less than or equal to $ K $ .", "Then $ g $ must be a function that maps from a finite set to another of less or equal size, and such a function exists.", "The codomain of $ g $ is equal or smaller than its domain, so there is a function that hits every element of the codomain at least once (the pigeonhole principle).", "We can even explicitly construct $ g $ if we are given all the $ f_{i} $ , by our favourite universal approximator: polynomials, kernels, etc.", "\\newline b) $ X_{i}=X_{j} $ for some $ i\\neq j $ but $ f_{i}(X_{i})\\neq f_{j}(X_{j}) $ \\newline In this case there is no global function $ g $ because it would need to produce two different values for the same input, which goes against the definition of a function.", "This is why global methods are more restrictive than local for regression problems in general.", "In the context of supervised learning, regression deals with finding a function mapping from $ X_{i} $ , to arbitrary \u201ctargets\u201d $ y_{i} $ , with both $ X_{i} $ and $ y_{i} $ being the inputs to the algorithm.", "Therefore it can happen that $ X_{i}=X_{j} $ but $ y_{i}\\neq y_{j} $ .", "A local method would be able to find such $ f_{i} $ and $ f_{j} $ so that $ f_{i}(X_{i})=y_{i} $ and $ f_{j}(X_{j})=y_{j} $ , but there is no single function $ g $ that can produce such a mapping.", "In time series forecasting, this situation cannot happen because there is no arbitrary mapping to be found.", "The only inputs to the algorithm are the $ X_{i} $ .", "Because a learning algorithm is also a function, equal input produces equal output.", "For a local algorithm $ A_{L} $ we have $ X_{i}=X_{j}\\Rightarrow A_{L}(X_{i})=f_{i}=A_{L}(X_{j})=f_{j} $ , so situation b) is not possible.", "$ \\qed $ \\newline </subsection> <subsection> <title> 2.2 Finite memory </title> Proposition 1 refers to forecasting functions that take the whole series into account, its $ T $ observed time periods.", "It is often the case that interest is restricted to forecasting functions using only the most recent $ M $ observations of the series, $ M<T $ .", "These are called finite memory models, autoregressive models or Markov models.", "In some contexts, $ M $ is called the order of the autoregression, the size of the memory or the receptive field.", "Finite memory models are useful because they deliver a powerful simplification of the world, are easier to fit to data and to analyze.", "Many natural phenomena can be explained by these models.", "\\newline In the setting of Proposition 1, there is no guarantee of the equivalence of local and global approaches if both produce finite memory functions.", "A simple example are two time series having the same $ M $ recent observations, but differing at some other point in the $ T $ observed time points.", "A local approach might produce different functions for these two series since they are different, so their forecast could be different, but any global method will produce the same forecasts for these two series.", "This is interesting because to guarantee equivalence, the global approach must use longer memory than the local approach.", "This is a key concept that leads to a guiding principle in the design of global methods: longer memory to approximate the expressive power of local methods.", "\\newline </subsection>  </section>"], ["<section> <title> 3 Generalization relationship between local and global approaches </title>  The main goal of forecasting is to produce accurate predictions on unseen data according to some error measure.", "We have seen in the previous Section [@ref:LABEL:sec:equivalence] that local and global algorithms can produce the same forecasts, and therefore potentially achieve the same accuracy, but Proposition 1 does not tell us about how two fixed algorithms compare in practice.", "\\newline <subsection> <title> 3.1 Generalization error bounds </title> We will study how well local and global algorithms generalize.", "The goal of studying generalization is to say something about how far the expected error on unseen (out-of-sample) data can be from the error an algorithm makes in the observed (in-sample) data.", "The difference between out-of-sample error and in-sample error is named generalization error or generalization gap .", "\\newline Low generalization error does not imply low out-of-sample error, only that it will be close to the in-sample.", "High generalization error is usually related to over-fitting.", "Theoretical analysis of generalization produces results in the form of probabilistic bounds for the generalization error; it gives us the probability that the out-of-sample error lies within a desired distance of the in-sample error.", "The bound can also be interpreted as a confidence interval for the expected out-of-sample error.", "\\newline We will use a basic result in machine learning about generalization error [@bib:abu2012learning] that relates how far the out-of-sample error, $ E_{\\textit{out}} $ , can be from the in-sample error, $ E_{\\textit{in}} $ , in terms of an i.i.d. dataset and a model $ \\mathcal{H} $ (also termed hypothesis class).", "The model $ \\mathcal{H} $ is a finite set of functions that can be potentially fit to data.", "The size of $ \\mathcal{H} $ , denoted by $ |\\mathcal{H}| $ , is the complexity of $ \\mathcal{H} $ .", "The basic bound has the form: \\newline <equation> $ E_{\\textit{out}}<E_{\\textit{in}}+\\sqrt{\\frac{\\log(|\\mathcal{H}|)+\\log(\\frac{2}% {\\delta})}{2N}}, $ </equation> with probability at least $ 1-\\delta $ .", "\\newline To simplify notation, we are assuming $ E_{\\textit{in}} $ to be the in-sample average and $ E_{\\textit{out}} $ to be its expectation, both calculated over loss values of the predictions of one forecasting function.", "This function is chosen from $ \\mathcal{H} $ , picked after exploring all alternatives (e.g. the one that minimizes $ E_{\\textit{in}} $ ).", "We can think of a learning algorithm as the way of picking this function from $ \\mathcal{H} $ , though in practice a learning algorithm is tied to a specific $ \\mathcal{H} $ .", "We assume that the error measure, also named loss function, takes values in $ [0,1] $ .", "\\newline To apply this bound we only need information about the sample size, maximum and minimum values for the error, and the number of functions which we consider in our model.", "It is a good compromise of generality: introducing additional assumptions makes the scope too narrow, making it more general leads to vacuous statements.", "\\newline This bound assumes the worst possible situation with the information we have.", "It is valid for any distribution of errors taking values in $ [0,1] $ , in fact the worst distribution is either min or max error with half probability each.", "The model $ \\mathcal{H} $ can be any set of functions and the algorithm can pick from it in any way possible, for which the worst case is testing the error of all functions $ \\mathcal{H} $ before picking one.", "\\newline The assumption of bounded loss seems limiting but is of great general applicability for what we get from it.", "We highlight three situations where, after rescaling, the bound can be applied naturally: \\newline <list> \\ The measurement units have maximum and minimum values, e.g. number of patients arriving at a hospital has a clear lower bound and an upper bound can be reasonably defined.", "\\newline \\ \\ The error measure is relative, e.g. sMAPE is between 0 and 200 even when we do not know the bounds of the variable.", "\\newline \\ \\ We are interested in errors over a certain threshold, in which case we can assume the error is bounded.", "The bounds assume the worst-case scenario where maximum and minimum errors each have a 50% chance of happening, so it is a safe worst-case scenario (depending on our needs).", "\\newline \\ </list> \\newline More sophisticated notions of complexity other than the size of $ \\mathcal{H} $ exist, which can make the bound tighter.", "These require additional information about $ \\mathcal{H} $ or the way of choosing a function from $ \\mathcal{H} $ .", "For example, the relation between the number of steps in stochastic gradient descent and generalization error [@bib:hardt2016train] could be adapted to get equivalent analyses, provided we know certain properties of our models.", "In the context of time series, [@bib:mariet2019foundations] analyze the sequence-to-sequence models (an scenario not unlike the one studied in this paper) using the concepts of Rademacher complexity and discrepancy, a notion of the nonstationarity series that includes model and loss function.", "\\newline The insights derived from our results do not depend on an accurate notion of complexity, since they come from examining relative performance.", "This bound is particularly useful for reasoning at a general level, we do not need information about the distribution of the data (just min and max error values) and about the hypothesis class (as long as we know its finite size).", "\\newline To use this bound in the context of a time series, where observations are not i.i.d, we need to make the extra assumption of $ N $ being an effective sample size, which somehow grows with the length of the series $ T $ , but is less than $ T $ in general.", "This is a feasibility requirement; if we cannot guarantee that the longer we observe a time series, the better we can approximate it, then it is not possible to learn from time series data.", "See Theorem 1 in [@bib:kuznetsov2016forecasting] for a discussion on the notion effective sample size in non i.i.d processes; also [@bib:mcdonald2017nonparametric] (Theorem 4) and [@bib:kuznetsov2017generalization] .", "In our case $ N $ \u201cencapsulates\u201d or \u201cabstracts away\u201d important details about the underlying processes (degree of nonstationarity, dependence structure, etc.) which must be assumed otherwise.", "Arguably, we use automatic time series forecasting precisely because we do not know these details.", "Moreover, because we are focusing on the relative performance of local and global approaches, it is not important to know the exact effective sample size, as $ N $ will be the same for both.", "\\newline </subsection> <subsection> <title> 3.2 Comparing local and global methods on a single time series </title> We would like to say something about the effect of locality and globality on generalization at an abstract level.", "We can directly apply this bound to compare local and global approaches in the context of out-of-sample error of one isolated time series in the set.", "We will adopt the common practice of considering one approach is better than the other if its bound is better.", "This is an heuristic, better bounds do not guarantee better out-of-sample error.", "We can view this heuristic as a form of penalization for model selection, similar to Akaike\u2019s Information criterion, though we will not use it as such.", "\\newline We can show a result that confirms intuition and the main rationale behind the preference for local methods: \\newline \u201cFor a time series in isolation and local and global algorithms with the same hypothesis class, the local approach has a better worst-case out-of-same error than the global.", "\u201d \\newline This occurs because the best local in-sample error will be at most the same as the best global in-sample loss.", "The global approach must pick the function from $ \\mathcal{H} $ that minimizes the in-sample loss of all time series in the set, while the local approach only focuses on the current time series of interest.", "The remaining terms in the bound are equal for both approaches, so it follows that the bound is better for the local.", "One could argue that the hypothesis class of the global approach is effectively smaller because it needs to fit to other data.", "Nothing can be said in this regard at this level of generality, since we are making no assumptions on the distributional relationship between series in the set, not even independence.", "Without the independent series assumption, the set could have been chosen to be adversarial for global methods.", "The assumption of independence is necessary in the mainstream machine learning literature in order to make claims about generalization (e.g. we are already assuming independent observations within a series), so it follows that it should be introduced at the between-series level.", "\\newline </subsection> <subsection> <title> 3.3 Comparing local and global methods of independent time series </title> When we introduce the assumption of series in $ \\mathbb{S} $ being independent and focus on average error across all time series in the set, the comparison changes.", "The assumption of independence between series is not strong, in the sense that dependent time series can be analyzed from a multivariate point of view, e.g. with vector autoregression, rather than with a global model.", "On the other hand, averaging errors across different time series might be pointless in some scenarios, such as when time series have different scales or are measuring different units.", "\\newline We name $ E_{\\textit{in}}^{\\textit{Local}} $ the average in-sample error across all time series of the local approach, and $ E_{\\textit{out}}^{\\textit{Local}} $ its out-of-sample expectation.", "The equivalent terms for the global approach are $ E_{\\textit{in}}^{\\textit{Global}} $ and $ E_{\\textit{out}}^{\\textit{Global}} $ .", "The local approach uses hypothesis class $ \\mathcal{H}_{i} $ for time series $ X_{i} $ , and the global approach uses only one hypothesis class, $ {\\mathcal{J}} $ , for the whole set of series.", "\\newline In this scenario we can say something about the respective bounds for local and global approaches.", "\\newline <theorem> Proposition 2 (Generalization bounds for local and global algorithms of finite hypothesis class).", "Local and global approaches have the following generalization bounds: \\newline <equationgroup> <equation> $  E_{\\textit{out}}^{\\textit{Local}}<E_{\\textit{in}}^{\\textit{Local% }}+\\sqrt{\\frac{\\log\\big{(}\\prod_{i=1}^{K}|\\mathcal{H}_{i}|\\big{)}+\\log(\\frac{2% }{\\delta})}{2NK}} $ $  E_{\\textit{out}}^{\\textit{Local}} $ $ <E_{\\textit{in}}^{\\textit{Local}}+\\sqrt{\\frac{\\log\\big{(}\\prod_{i% =1}^{K}|\\mathcal{H}_{i}|\\big{)}+\\log(\\frac{2}{\\delta})}{2NK}} $ </equation> <equation> $  E_{\\textit{out}}^{\\textit{Global}}<E_{\\textit{in}}^{\\textit{% Global}}+\\sqrt{\\frac{\\log(|{\\mathcal{J}}|)+\\log(\\frac{2}{\\delta})}{2NK}}, $ $  E_{\\textit{out}}^{\\textit{Global}} $ $ <E_{\\textit{in}}^{\\textit{Global}}+\\sqrt{\\frac{\\log(|{\\mathcal{J}% }|)+\\log(\\frac{2}{\\delta})}{2NK}}, $ </equation> </equationgroup> with probability at least $ 1-\\delta $ .", "\\newline </theorem> Assuming independence between time series in $ \\mathbb{S} $ , and effective sample size $ N $ in each time series, we can follow the same reasoning that results in the original bound.", "This follows from the Hoeffding inequality [@bib:hoeffding1963inequality] , restated here as: \\newline <equation> $ P(\\bar{Y}-\\mathbb{E}(\\bar{Y})\\geq t)\\leq 2e^{-2Nt^{2}}, $ </equation> for independent random variables $ Y_{1},\\dots,Y_{N} $ , where $ Y_{i} $ might come from any probability distribution with bounded support in $ [0,1] $ , $ \\bar{Y}=N^{-1}\\sum Y_{i} $ , and $ t>0 $ .", "We can apply the Hoeffding inequality by considering $ Y_{i} $ equivalent to the in-sample errors made by one a priori fixed function, in a time series of effective sample size $ N $ .", "Then $ \\bar{Y} $ will be the average in-sample error and its expectation $ \\mathbb{E}(\\bar{Y}) $ the expected out-of-sample error.", "\\newline Instead of fixing the hypothesis, if we pick one hypothesis over all possible in a set $ \\mathcal{H} $ , the bound relaxes.", "We can apply the union bound (Boole\u2019s inequality) to bound the error when picking between many functions, getting: \\newline <equation> $ P(\\bar{Y}-\\mathbb{E}(\\bar{Y})\\geq t)\\leq|\\mathcal{H}|2e^{-2Nt^{2}}. $ </equation> This last step is similar to the Bonferroni correction in multiple hypothesis testing.", "\\newline When we move from one time series to averaging over $ K $ independent time series in the set, we get $ NK $ samples, assuming for simplicity that all series have the same effective sample size.", "\\newline For the local approach, the size of the hypothesis class is the size of the Cartesian product of all the local hypotheses $ \\mathcal{H}_{i} $ used to fit the series, while for the global approach, the size is $ |{\\mathcal{J}}| $ .", "For example, if the local approach picks between three functions for each series ( $ |\\mathcal{H}_{i}|=3 $ ), it is equivalent to picking between $ 3^{K} $ functions for the full set of $ K $ series.", "\\newline For the local approach: \\newline <equation> $ P(E_{\\textit{in}}^{\\textit{Local}}-E_{\\textit{out}}^{\\textit{Local}}\\geq t)% \\leq\\prod_{i=1}^{K}|\\mathcal{H}_{i}|2e^{-2KNt^{2}}. $ </equation> To get to Proposition 2, we rewrite the right-hand side of the previous inequality as our tolerance level $ \\delta $ .", "\\newline <equation> $ \\prod_{i=1}^{K}|\\mathcal{H}_{i}|2e^{-2KNt^{2}}=\\delta\\qquad\\Rightarrow\\qquad t% =\\sqrt{\\frac{\\log\\big{(}\\prod_{i=1}^{K}|\\mathcal{H}_{i}|\\big{)}+\\log(\\frac{2}{% \\delta})}{2NK}}. $ </equation> So \\newline <equation> $ P\\Bigg{(}E_{\\textit{in}}^{\\textit{Local}}-E_{\\textit{out}}^{\\textit{Local}}% \\geq\\sqrt{\\frac{\\log\\big{(}\\prod_{i=1}^{K}|\\mathcal{H}_{i}|\\big{)}+\\log(\\frac{% 2}{\\delta})}{2NK}}\\Bigg{)}\\leq\\delta.", "$ </equation> The complementary event corresponds to the result in Proposition 2.", "The reasoning for the global approach is analogous.", "\\newline Key to this result is the fact that the Hoeffding bound does not require samples to be identically distributed, so series in $ \\mathbb{S} $ may vary wildly, can have any distribution as long as they are independent (and the error is bounded between 0 and 1).", "The bound is applicable to independent copies of $ \\mathbb{S} $ .", "To apply it to new observations from the same series in $ \\mathbb{S} $ , these should come in the same proportion as the effective sample sizes.", "\\newline The bounds derived in Proposition 2 allow us to say something about how local and global algorithms generalize in a (probabilistic) worst-case sense before we even see the data and hypothesis classes.", "We can predict how altering the elements involved in these bounds will affect generalization, and propose algorithms inspired on these predictions.", "\\newline </subsection> <subsection> <title> 3.4 Relative complexity of local and global approaches hypothesis classes </title> Imagine we are given a local algorithm and we want to find a global algorithm that has the same or better performance in a given dataset.", "Under the paradigm (or heuristic) of \u201cbetter bounds means better algorithm\u201d, we can try to find a global algorithm that produces the same in-sample error as the local reference, and then from Proposition 2 it follows that the relative performance is totally determined by the respective complexity terms.", "Proposition 1 becomes relevant now because it shows that a global algorithm exists that can match the errors of a fixed local approach.", "In practice, we can think of having a \u201cbudget of complexity\u201d to reach the in-sample loss equivalent to the local.", "If get to it within the budget, we get better generalization than the local alternative and therefore better performance.", "We aim for equal in-sample loss to isolate the effect of the complexity, which is what we can control before seeing the data.", "\\newline Assuming $ E_{\\textit{in}}^{\\textit{Local}}=E_{\\textit{in}}^{\\textit{Global}} $ and $ E_{\\textit{out}}^{\\textit{Local}}=E_{\\textit{out}}^{\\textit{Global}} $ , we can match the two bounds in Proposition 2 to get: \\newline <equation> $ \\prod_{i=1}^{K}|\\mathcal{H}_{i}|=|{\\mathcal{J}}|, $ </equation> with the $ = $ symbol overloaded to mean they have the same worst-case guarantees.", "We can read this result as saying that the complexity of the local approach grows with the size of the set, while the complexity of the global approach remains constant.", "Assuming a state-of-the-art local algorithm as baseline (such as an ARIMA fit to each series), a global approach can be at least as complex as the sum of all individual ARIMAs in the set.", "\\newline This leads us to prescribe the use of comparatively more complex hypothesis classes for global algorithms.", "The common ways of increasing complexity is by adding features/variables (such as nonlinear transformations) or changing the model family altogether (e.g. from linear to a neural network).", "The experiment in Section [@ref:LABEL:sec:expalter] shows empirical evidence of this principle.", "\\newline </subsection> <subsection> <title> 3.5 Relative memory of local and global autoregressive models </title> In our analysis of finite memory models (Section [@ref:LABEL:sec:finitemem] ) we saw that global autoregressive methods must have larger memory than local methods to be able to express the same forecasts.", "Increasing the memory of an autoregressive model can be analyzed from Proposition 2, it increases the complexity of the hypothesis class.", "It can be seen as a form of featurization more specific to time series than other forms of complexity control.", "\\newline We can use a reasoning analogous to Section [@ref:LABEL:sec:altcomplex] to isolate how memory affects generalization.", "Assume the local and global approaches use autoregressive models (which can be nonlinear), with one parameter per order of autoregression (or size of the memory).", "Then the complexity of the hypothesis class is completely determined by the order of the autoregression.", "Even though in theory there are infinite autoregressive models that can be fit to data (thus the bounds in Proposition 2 become infinitely loose), we can restrict ourselves to the realistic scenario of using double floating point numbers for the parameters.", "This limits the number of possible models that can be fit, since there are roughly $ 2^{64} $ possible values for each parameter.", "If we consider the memory of the local model fit to each series $ X_{i} $ to be $ L_{i} $ and the memory of the global approach $ G $ , we can explicitly compare the complexities for the local and global algorithms.", "Substituting in the result of Section [@ref:LABEL:sec:altcomplex] : \\newline <equation> $ \\prod_{i=1}^{K}2^{64L_{i}}=2^{64G}, $ </equation> and then taking logarithms and simplifying, we obtain \\newline <equation> $ \\sum_{i=1}^{K}L_{i}=G. $ </equation> \\newline \u201cLocal and global autoregressive algorithms with the same performance have the same total memory\u201d \\newline As in Section [@ref:LABEL:sec:altcomplex] , it follows that the global approach can have much larger memory than that used by a local approach for each time series.", "This leads us to prescribe the use of global algorithms with large memory.", "Empirical results of this prescription can be found in Section [@ref:LABEL:sec:experires] , particularly in Section [@ref:LABEL:sec:largememexp] .", "\\newline </subsection> <subsection> <title> 3.6 Relative Complexity of Partitioning S </title> From a higher level of abstraction, we can see local and global as special cases of an algorithm that acts on a partition of $ \\mathbb{S} $ , instead of on $ \\mathbb{S} $ .", "This algorithm pools together the series in each element of the partition of $ \\mathbb{S} $ , fits a single model within each partition, and forecasts each series in that subset using that function.", "Therefore, the \u201clocal version\u201d of this algorithm works on the atomic partition ( $ \\{\\text{all subsets of }\\mathbb{S}\\text{of size }1\\} $ ) and the \u201cglobal version\u201d works on the trivial partition ( $ \\left\\{\\mathbb{S}\\right\\} $ ).", "\\newline The bounds in Proposition 2 can be adapted to this new level of generality.", "Introducing the cardinality of the partition as $ P $ , the bounds become: \\newline <equation> $ E_{\\textit{out}}^{Part}<E_{\\textit{in}}^{Part}+\\sqrt{\\frac{\\log(\\prod_{i=1}^{P% }|\\mathcal{H}_{i}|)+\\log(\\frac{2}{\\delta})}{2NK}}, $ </equation> with probability at least $ 1-\\delta $ .", "As in previous bounds, to simplify notation we are assuming that all $ P $ elements of the partition contain the same number of series.", "For the trivial partition $ P=1 $ we recover the global algorithm, for the atomic partition $ P=K $ we recover the local algorithm.", "\\newline Considering all other possible partitions of $ \\mathbb{S} $ leads to another way of controlling complexity.", "A global algorithm may increase its complexity by partitioning, in addition to exploring alternate hypothesis classes or increasing its memory.", "Similarly, local algorithms can reduce their complexity by pooling together time series in small groups.", "\\newline Partitioning a set is also specific to time series forecasting, similar to the result in Proposition 1, because we are not interested in forecasting new time series, just the unobserved part of the given set.", "\\newline These bounds refer to the complexity for a specific partition of $ \\mathbb{S} $ fixed before seeing the data, in the same sense as the Hoeffding inequality considers a single hypothesis set beforehand.", "Choosing between different partitions based on data is commonly called clustering and leads to an increase in complexity.", "While clustering can be analyzed with Hoeffding-based bounds, the worst-case analysis (agnostic of the clustering algorithm) leads to vacuous bounds due to the combinatorial explosion of the number of partitions in a set.", "Partitioning is also related to multi-task learning (as a form of soft partitioning), discussed in Section [@ref:LABEL:sec:relatparti] .", "\\newline We leave clustering outside the scope of the paper.", "Instead, to showcase the practical usefulness of the principle of partitioning, we propose the most na\u00efve form partitioning: random partitioning into subsets of equal size.", "Even this simple idea can be effective when the global model cannot reach good in-sample loss levels due to the size of the set.", "Section [@ref:LABEL:sec:exparti] shows empirical evidence of this prescription.", "\\newline </subsection>  </section>"], ["<section> <title> 4 Experimental Setup </title>  We describe in this section the common elements of the experiments, such as the local and global algorithms we are going to compare, datasets and error metrics.", "\\newline <subsection> <title> 4.1 Local benchmark methods </title> We consider some methods implemented in the forecast R package [@bib:hyndman2008forecast,Rforecast] for the benchmark local methods.", "\\newline <list> \\ auto.arima : Seasonal ARIMA with model selection by AICc.", "\\newline \\ \\ ets : Variants of Exponential Smoothing selected by AICc.", "\\newline \\ \\ theta : Implementation of the Theta method, equivalent to simple exponential smoothing with drift.", "\\newline \\ \\ TBATS : Automatic multi-seasonal state space model with ARMA errors.", "\\newline \\ \\ STL-AR : STL decomposition with AR errors.", "\\newline \\ </list> \\newline The first three (auto.arima, ets and theta), are general-purpose methods particularly well-suited for monthly, quarterly and annual data.", "TBATS and STL will also handle multiple seasonalities such as arise in daily and weekly data.", "All these methods require the frequency of the series to be pre-specified, unlike the global methods we will consider.", "\\newline We consider these methods state-of-the art based on the results of the M4 competition [@bib:makridakis2020m4] .", "The top entries in that competition achieved their accuracy through ensembling these methods [@bib:montero2020fforma,pawlikowski2020weighted,jaganathan2020combination] or by combining them with neural networks [@bib:smyl2020hybrid] .", "\\newline We do not consider ensembling as a benchmark local method, since ensembling is a technique that can also be applied to global methods.", "The more accurate the individual models that enter the ensemble, the more accurate the results of the ensemble, so the target accuracy is that of the individual methods.", "\\newline </subsection> <subsection> <title> 4.2 Global methods </title> All global methods are based on autoregressive or finite memory models.", "Each series is lag-embedded into a matrix at the given AR order and then these matrices are stacked together to create one big matrix, achieving data pooling.", "The different model classes minimize a loss on this large global matrix as in a standard regression problem, with the final column of the matrix representing the target values or dependent variable and the remaining columns the input or predictor variables.", "All global model produce one-step-ahead forecasts, longer forecasting horizons are achieved through recursive forecasting.", "\\newline The specific global methods we use are as follows.", "\\newline <list> \\ Linear Autoregressive : A linear model fit by least squares.", "We consider this method to be the baseline of global models.", "Linear models fit by least squares are important as a benchmark because they do not include any advanced machine learning technique (such as implicit regularization by SGD, bagging, or ensembling) and overlap the model class with the ARIMA model (a common local approach).", "Therefore, they are ideal to isolate the effect of globality.", "\\newline \\ \\ Featurized Linear Autoregressive : A linear model fit by least squares with increased complexity by adding nonlinear features in the form of polynomials of degree 2 and 3.", "This is a relatively na\u00efve way of increasing complexity, and subsumes the linear autoregressive model.", "\\newline \\ \\ Deep Network Autoregressive : Deep Networks are a model class that achieves outstanding results in many applications.", "The implementation is Keras [@bib:chollet2015keras] , a ReLu MLP 5 layers, 32 units width, linear activation in the final layer, fit by the Adam optimizer with default learning rate.", "Fitting is done by early stopping on a cross-validation set at 15% of the dataset (the stacked matrix).", "The batch size is set to 1024 for speed, and the loss function is the mean absolute error (MAE).", "\\newline \\ \\ Regression Tree Autoregressive : Regression trees are another model class that produces great success in machine learning.", "Implementation is XGboost [@bib:chen2016xgboost] , with default parameters subsampling=0.5 and col_sampling=0.5 .", "Fitting is done by early stopping on a cross-validation set at 15% of the dataset.", "The loss function is RMSE and the validation error is MAE.", "\\newline \\ \\ Partitioned Linear : The dataset is initially randomly partitioned into subsets, then a global linear AR model is applied to each subset.", "This method is a simple representative of the alternative way of increasing model complexity suggested by our theory; i.e. by partitioning instead of featurization or alternative model class.", "\\newline \\ </list> \\newline We highlight the simplicity or na\u00efvety of each model.", "We use no seasonality information, tests for stationarity, batch normalization, dropout, residual layers, advanced architectures such as LSTM or convolutional layers, attention, time dilation, ensembling, etc.", "No hyperparameter search has been used.", "\\newline Other notable families of methods, such as nearest neighbors or kernel methods, are left out for computational reasons, but we expect qualitatively equivalent results.", "\\newline </subsection> <subsection> <title> 4.3 Errors and preprocessing </title> We focus on MASE as a popular scale-free error measure which rarely divides by zero, and is therefore less prone to numerical errors than SMAPE.", "Furthermore, the scaling done by the MASE can be applied to data as a preprocessing normalizing step, which we apply to each series.", "Then minimizing the MASE is equivalent to minimizing the mean absolute error in the preprocessed time series.", "Compared to SMAPE, MASE is easier to fit with off-the-shelf optimizers (it is convex), and it therefore isolates better the effect of the model class rather than the optimization procedure used to fit it.", "\\newline </subsection> <subsection> <title> 4.4 Datasets </title> We compare the methods across a collection of datasets which have been used in many peer-reviewed publications as standard benchmarks, from local methods to recent literature for global models.", "We have added some examples of our own.", "We loosely and subjectively categorize each data set as heterogeneous or homogeneous, based on the nature of the domains (single vs multiple domains) and the descriptions by the original publishers.", "\\newline <list> \\ M1 : Heterogeneous dataset from a forecasting competition, 1001 series, subdivided into Monthly, Yearly and Quarterly periodicity.", "\\newline \\ \\ M3 : Similar to M1, with 3003 time series and an extra \u201cOther\u201d category of periodicity.", "\\newline \\ \\ tourism : Homogeneous series from a tourism forecasting competition, subdivided into Monthly, Yearly and Quarterly data.", "\\newline \\ \\ M4 : Heterogeneous dataset of 100,000 time series, subdivided into Monthly, Yearly, Quarterly, Weekly, Daily and Hourly periodicities.", "\\newline \\ \\ NN5 : From the webpage of the competition [@bib:nn5url] : The data consists of 2 years of daily cash demand at various automated teller machines (ATMs, or cash machines) at different locations in England.", "Homogeneous in data types but heterogeneous in patterns.", "111 time series.", "\\newline \\ \\ Wikipedia : Daily visits of pages within the Wikipedia domain, from a Kaggle Competition [@bib:wikikaggle] . 115084 time series of 803 observations each.", "Homogeneous in data type, heterogeneous patterns.", "\\newline \\ \\ FRED-MD : 107 monthly macroeconomic indicators from the Federal Reserve Bank, already differenced and log transformed according to literature consensus [@bib:mccraken2018fredmd] .", "Heterogeneous.", "\\newline \\ \\ weather : Daily weather variables: \u201crain\u201d, \u201cmintemp\u201d, \u201cmaxtemp\u201d, \u201csolar radiation\u201d measured at weather stations across Australia.", "3010 time series from the Bureau of Meteorology and the bomrang R package [@bib:Rbomrang] .", "Heterogeneous.", "\\newline \\ \\ dominick : 115704 Time series of weekly profit of individual SKUs from a retailer.", "Homogeneous.", "From [@bib:dominicks] , similar dataset to [@bib:gasthaus2019probabilistic] .", "\\newline \\ \\ traffic : Each series in the set is hourly occupancy in a highway lane.", "Between 0 an 1.", "Homogeneous.", "\\newline \\ \\ electricity : Hourly time series of the electricity consumption of 370 customers.", "Homogeneous.", "\\newline \\ \\ car parts : Monthly sales car parts.", "2674 series.", "Jan 1998 - Mar 2002.", "Intermittent demand.", "From the expsmooth R package [@bib:Rexpsmooth] .", "\\newline \\ \\ hospital : Monthly patient count for products that are related to medical problems.", "There are 767 time series that had a mean count of at least 10 and no zeros.", "From the expsmooth R package [@bib:Rexpsmooth] .", "\\newline \\ \\ CIF2016 : From [@bib:vstvepnivcka2017cif] : \u201c72 time series with monthly frequency, from which 24 were real time series from the banking domain and 48 artificially generated.", "The real banking domain time series had length from 23 to 69 values and the forecasting horizon was 8 or 16 values.", "\u201d .", "Heterogeneous.", "\\newline \\ \\ Pedestrian : Hourly pedestrian count across different streets in Melbourne.", "Homogeneous.", "66 series ranging from 264 to 35000+ hours.", "\\newline \\ \\ Double Pendulum : Experiment generating a chaotic time series [@bib:asseman2018learning] .", "Positions of the pendulums were extracted from the video at 400Hz, the task is to predict 200 future positions from past positions.", "Each time series represents a different run of the experiment or the same run sufficiently separated in time.", "The example of homogeneous series all come from the same \u201cgenerative process\u201d.", "\\newline \\ \\ COVID19 : Per-region daily cumulative COVID19 deaths, each of the 56 time series representing one region.", "Dataset taken from the Johns Hopkins repository, featuring the first 90 days since 22 January 2020.", "Forecast horizon is the last 14 days.", "\\newline \\ </list> \\newline </subsection>  </section>"], ["<section> <title> 5 Experiments </title>  We show empirical evidence of the principles derived in Section [@ref:LABEL:sec:genbounds] by comparing forecast accuracy state-of-the-art local methods to global methods.", "For the sake of clarity we analyze some results from our experiments, a comprehensive summary of experimental results is provided in the Appendix.", "\\newline <subsection> <title> 5.1 Large memory </title> We first illustrate the effect in forecasting accuracy of increasing the memory of a global model, one of the principles coming from the complexity analysis in Section [@ref:LABEL:sec:largemem] .", "We test this design principle in the most basic class of models, linear models.", "Given a dataset, we fit a global linear model for all possible orders of autoregression, and compare the average forecast error against the state-of-the art local models.", "For each dataset, the maximum order of autoregression is the length of the shortest time series in the set, because it cannot be time-delay embedded at larger orders.", "\\newline We show the results for the M1 Monthly dataset in Figure [@ref:LABEL:fig:outsampleM1] .", "We observe a clear pattern of reduction of the out-of-sample error as the order of the global AR model increases (solid black line).", "The global model outperforms all local benchmark methods (horizontal lines) at about AR(25).", "The M1 Monthly dataset has been available since the 1980s and the technology behind the global model is even older: linear least squares.", "This dataset has been extensively used for testing new methods, yet a na\u00efve global method, derived from the basic bounds, is able to outperform state-of-the-art local forecasting algorithms, which leverage sophisticated ideas from time series analysis and are based on accumulated empirical evidence.", "The M1 Monthly dataset has 617 time series.", "A single AR(25) \u2014 i.e., 25 parameters \u2014 can \u201csummarize\u201d the dataset better than models that at least use 1 parameter per series, e.g. auto.arima needs approximately 1600 parameters to fit the whole set.", "This means a reduction in the number of parameters close to 2 orders of magnitude while achieving better accuracy.", "Intuitively, the M1 dataset can be considered heterogeneous; it exhibits different patterns (seasonality, long time trends, structural breaks, etc.) and represents different domains (macro, micro, demographics, etc.).", "\\newline <paragraph> <title> Longer memory leads global linear models to outperform local </title> We extend the analysis to the rest of the datasets in the experimental setting.", "As mentioned earlier, when a dataset contains time series of different lengths the maximum memory of a global AR model is limited to the length of the shortest time series.", "This artificial difficulty can be overcome with recurrent algorithms such as Recurrent Neural Networks, but this would obfuscate the effects of the memory.", "To study the effects of longer memories we modify the experiment in the following way.", "For a given memory level, we analyze on each dataset only the series with length above this level.", "This methodology is only applied to the M1 Quarterly, M3 Monthly and M4 Quarterly and M4 Monthly datasets.", "\\newline The experimental results can be seen in the Appendix.", "A global linear model outperforms local approaches for virtually all datasets, including all frequencies of M1, M3, tourism and M4 (Figure [@ref:LABEL:fig:longmemextra] ).", "It also holds for the NN5 (Figure [@ref:LABEL:fig:nn5] ), electricity (Figure [@ref:LABEL:fig:electricity] ), traffic (Figure [@ref:LABEL:fig:traffic] ), hospital (Figure [@ref:LABEL:fig:hospital] ), parts (Figure [@ref:LABEL:fig:parts] ), dominick (Figure [@ref:LABEL:fig:dominick] ), Wikipedia (Figure [@ref:LABEL:fig:wiki] ), weather (Figure [@ref:LABEL:fig:weather] ), pendulum (Figure [@ref:LABEL:fig:pendulum] ), pedestrian (Figure [@ref:LABEL:fig:pedestrian] ) and COVID19 (Figure reffig:COVID19) datasets.", "The exceptions are CIF2016 (Figure [@ref:LABEL:fig:CIF2016] ) and FREDMD-Monthly (Figure [@ref:LABEL:fig:FREDMD] ); even in these datasets the global linear model outperforms two of the three local methods.", "\\newline The pattern of improving accuracy when increasing memory holds for the majority of datasets.", "At very long memories, we see some form of convergence in accuracy until the error explodes because even the global model gets into an over-fitting regime.", "This behavior is exemplified in the hospital dataset, Figure [@ref:LABEL:fig:hospital] , but would happen for all datasets when the potential maximum memory is much larger than the number of series in the set.", "This type of over-fitting can be prevented in practice by simple cross-validation or regularization.", "\\newline Notable exceptions to the pattern of \u201clonger memory, better accuracy\u201d are the dominick and parts datasets.", "We do not have a good explanation of why this happens, but both these datasets are intermittent data.", "It is also interesting that very low memory orders of a global model outperform local models by a great margin.", "\\newline Another peculiar effect can be seen in datasets with heavy seasonal components, such as monthly and quarterly periodicities.", "In these datasets, the accuracy improves with the memory, but then it stops improving or suddenly degrades at memory levels that are multiple of the seasonal frequency.", "After the memory level is over a seasonal frequency multiple, the accuracy substantially improves.", "Figure [@ref:LABEL:fig:outsampleM1] clearly illustrates this effect, at around 10 lags the accuracy does not improve and then it improves almost by 30% between lags 12 and 13.", "At lag 24 (two seasonal patterns) the accuracy experiences a \u201cbump\u201d and then improves again.", "The electricity hourly dataset (Figure [@ref:LABEL:fig:electricity] showcases a similar phenomenon, the accuracy improvement stops at lag 24 (1 day cycle) and then improves again.", "When the memory gets close to a one week cycle (lag 168) the accuracy degrades and after that it gets another big improvement.", "We explain this effect as an over-fitting phenomena related to the heterogeneity of seasonal strengths in the datasets.", "In those datasets that contain both strongly seasonal and non seasonal series (or different seasonal periods), a global model tends to favor the seasonality at memory levels that are multiples of the frequency because it produces good results in-sample.", "When the memory is over the seasonal period, the global model can use its coefficients to fit both seasonal and non seasonal patterns.", "\\newline </paragraph> <paragraph> <title> Global models fit long memory patterns </title> Fitting long memory patterns with local models in a completely data-driven way is difficult.", "For example, local models require observing several complete seasonal cycles to discover if a series has strong seasonality.", "Alternatively, a priori knowledge of the seasonal cycle can be added to the local model.", "One of the advantages of global models is the ability to pick these patterns without prior knowledge, or requiring less data per series.", "\\newline We analyze how global models capture long memory by studying the fitted coefficients.", "Figure [@ref:LABEL:fig:ARcoef] shows the coefficients of the global linear model for the M1, M3, tourism and M4 datasets on yearly, quarterly and monthly frequencies.", "We can see that the coefficients are very similar among datasets, and the effect is consistent across datasets.", "The coefficients corresponding to long memory levels are large for quarterly and monthly frequencies, particularly at lags coinciding with seasonal periods, indicating that longer memories get significant contribution to the predictions.", "There is a slight damping effect for longer memories.", "The seasonality is being automatically discovered by the global model, and is not part of the model specification.", "The memory orders that produce the best of accuracy cannot be fitted locally without prior information.", "For example, to fit a na\u00efve local linear AR(40) to a series we would need 80 observations.", "Realistically, we would need 10\u2013100 times more observations than parameters in a single series to fit it by ordinary least squares.", "Global methods use the whole dataset to fit these coefficients.", "\\newline </paragraph> </subsection> <subsection> <title> 5.2 Nonlinear models: polynomials, deep networks and regression trees </title> This experiment considers increasing complexity by changing the model class of global models.", "We add nonlinear features such as polynomials of orders 2 and 3, and consider deep networks and regression trees instead of linear combinations of past values.", "Polynomials and deep networks represent an incremental or parsimonious increase in complexity with model classes that are a superset of the linear class.", "Regression trees represent a different model family.", "We test the nonlinear models for all valid orders of autoregression to isolate the effects of the model class from the effects of expanding memory.", "\\newline Figure [@ref:LABEL:fig:nonlinear] shows the effects of changing the model class on the M3 Monthly dataset.", "The global linear model (black solid line) improves in accuracy as its memory increases until it reaches the maximum order for this dataset (equal to the length of the shortest series).", "Unlike the M1 results shown earlier, the global linear model applied to the monthly M3 data does not get close to the accuracy of local benchmark methods (horizontal dashed lines).", "The downward trend pattern of the error is suddenly stopped when we reach the maximum memory level in this dataset, suggesting that the linear model is limited in complexity, it is under-fitting.", "Increasing the model complexity by adding nonlinear features in the form of polynomials of degree 2 (orange line) has a small negative impact on accuracy relative to the simple linear model.", "A polynomial of degree 3 (pink line) has clearly better performance than the linear model.", "\\newline Recursive forecasting makes polynomials numerically unstable (e.g. an 18-step-ahead forecast for this dataset is equivalent to a 57 degree polynomial) and are not recommended in the literature for automatic time series forecasting.", "Nevertheless, we show that even polynomials can improve results over linear models when applied globally.", "Regression Trees (yellow line) are also more complex than linear models but have worse performance in this dataset.", "They are an example of inappropriate model class, we can detect it in-sample through simple cross-validation.", "Finally, the Deep Network (dark blue line) also improves over linear, getting the best results of the global models, close to the local models in this scenario.", "Deep networks also suffer from the problem of instability for recursive forecasting, and the literature recommends direct forecasting (modeling each horizon separately) [@bib:taieb2012review] , yet we show here that already recursive forecasting is competitive.", "\\newline Both polynomials and deep networks demonstrate that nonlinear model classes can improve accuracy, and in this example outperform the linear model consistently for all values of memory over 8.", "\\newline We show the results of an extended experiment in the Appendix, applying the same methodology to the M1, M3, tourism and M4 datasets.", "Figure [@ref:LABEL:fig:totalyearly] shows the yearly results, Figure [@ref:LABEL:fig:totalquart] the quarterly, Figure [@ref:LABEL:fig:totalmonth] the monthly and Figure [@ref:LABEL:fig:totalweek] the weekly.", "Daily and hourly are not considered for computational reasons, but results of the global linear can be seen in Figure [@ref:LABEL:fig:longmemextra] and Figure [@ref:LABEL:fig:partitioningextra] .", "\\newline In agreement with the M3 Monthly, global models such as third degree polynomials and deep networks outperform linear models for the majority of datasets (the only exception is Tourism yearly).", "Comparing to local models, the nonlinear global models are able to outperform local models in the majority of datasets.", "The results of global models are especially strong in the large datasets of the M4 competition.", "In the M4 yearly an AR(12) polynomial of second degree not only outperforms the local benchmarks, it would have scored second in the M4 competition according to its MASE of 3.01.", "This means that 24 numbers that specify the model can forecast the 23000 time series of the M4 Yearly better than most of the methods that participated in the competition.", "For the M4 Quarterly, the deep neural network would achieve third best ranking.", "\\newline We interpret these results as strong empirical evidence towards globality for the design of new learning algorithms.", "We can increase the complexity of a baseline global model (linear) in na\u00efve ways (polynomials) and the learning algorithm such as least squares can succeed in finding better forecasting functions.", "Modern machine learning algorithms such as deep networks produce outstanding results consistently across multiple datasets.", "\\newline These results should not be interpreted as a recommendation or preference of specific model class over the others, e.g. regression trees could perform better with some hyperparameter tuning.", "\\newline Model complexity vs memory In terms of the effect of memory we highlight two phenomena.", "The main is that both sources of complexity, memory and model class, are effective at improving forecast accuracy.", "When both are included, model class interacts with memory in different ways depending on the dataset, but in general a more complex model class requires less memory to achieve the same level of accuracy than the more simple class.", "\\newline </subsection> <subsection> <title> 5.3 Partitioning </title> We experiment with another method of increasing complexity: partitioning the set of series.", "We split the dataset randomly into 10 groups of equal size, each group is fit by and forecasted by a global model.", "\\newline The implications of this experiment are quite interesting, since partitioning is equivalent to reducing the sample size, something not usually recommended in statistics and machine learning.", "Since partitioning is done at random (not clustering), it is strong evidence towards the benefit of raw complexity in a model rather than finding the \u201cright\u201d model, and it shows that having similar series is not the cause of the good performance of global methods.", "Beyond the possibility of more accurate results, partitioning might also result in faster training times through \u201cembarrassing\u201d parallelism.", "\\newline More examples of this effect for the M3 Monthly and Quarterly data can be found in the Appendix (Figure [@ref:LABEL:fig:partitioningextra] ), but the effect holds (with more or less beneficial impact) in the majority of datasets where the global model is complexity-constrained.", "\\newline We do not endorse the use of partitioning for increasing forecasting accuracy in a production setting, the experiments in this section are meant to showcase the strength of theoretical results because they predict a counter-intuitive effect.", "\\newline </subsection> <subsection> <title> 5.4 In-sample vs out-of-sample loss </title> This experiment shows that the ability of simple local methods (e.g. ets) to approximate the data generating processes is not the main limiting factor of their performance in many practical situations.", "The superior accuracy of global methods is more likely attributable to their better generalization.", "This can be considered one of the main predictions from the theory: when we introduce some complexities for specific local and global algorithms in the bounds of Proposition 2, we get that the aggregate complexity of local models is higher than global.", "\\newline We can expect the following.", "\\newline <list> \\ Local models should get smaller in-sample error than global for comparable model classes (e.g. in the linear case, auto.arima and the global linear).", "\\newline \\ \\ Higher complexity implies higher risk of over-fitting, we should see more over-fitting from local models (difference between in-sample and out-of-sample errors).", "\\newline \\ </list> \\newline We compare the average in-sample loss that local and global methods produce against their respective one-step-ahead out-of-sample loss for the M1, M3, tourism and M4 datasets.", "We use in-sample loss as a measure of the capacity of a given model class to approximate the data.", "It measures how well an ideal function within the model class can fit the data, even though in practice we might not be able to find this function.", "We focus on one-step-ahead forecast loss, instead of longer horizons, because it is the measure that both local and global methods minimize when training.", "Theoretical results relate training to testing losses when they measure the same quantity and at the same time we remove the confounding factors of longer horizons.", "\\newline When a model is limited in capacity, it is not able to fit the data well so its in-sample error is large.", "We see in Figure [@ref:LABEL:fig:invsout] the average in-sample error (light bar) superimposed over the out-of-sample error (darker bar) for each method and each datasets.", "The difference between these two bars is the generalization error.", "Local models have better average in-sample loss than the global alternatives.", "Local models suffer from over-fitting, rather than from being unable to fit complex series.", "The global linear model exhibits the smallest generalization error, a result that can be predicted by the theory, since it is by far the simplest of the model classes.", "Even a global deep network has less difference between in-sample and out-of-sample errors than local models, although it is a quite complex model class.", "\\newline The more common explanation for global models (see Section [@ref:LABEL:sec:relglobloc] ) is that classical local models cannot pick \u201ccomplex patterns\u201d in the data.", "However, this experiment suggests a different explanation for the empirical performance of global and local methods.", "The more likely reason for performance is the over-fitting of local models; we can fit the series well with simple local models but do not know how to control their complexity.", "For global methods, standard complexity control techniques are more successful or not even needed.", "\\newline </subsection> <subsection> <title> 5.5 Heterogeneous datasets </title> We show empirical evidence of the capacity of global methods to adapt to heterogeneous datasets by increasing the complexity of the model class.", "We consider the full M4 dataset as the heterogeneous set for our tests.", "When we take the M4 as a single set of time series, we expect is to be highly heterogeneous, because it contains 100K time series from different domains (measuring different units), and at different frequencies (from hourly to yearly measurements).", "\\newline We compare average out-of-sample error of the one-step-ahead forecasts for the local benchmark methods and the global linear and deep network, fixed at a memory level of AR(12), we are limited by the length of the shortest series in the set.", "We add two additional global models that introduce information about the heterogeneity.", "\\newline <list> \\ The first model cluster the data by its frequency before fitting a global model to each cluster.", "\\newline \\ \\ The second model adds information about the frequency and other features [@bib:hyndman2019tsfeatures] as extra features of the model in addition to the last 12 observations, but it does not partition the dataset.", "\\newline \\ </list> \\newline The purpose is to compare \u201chomogeneous manual clusters\u201d with \u201cheterogeneous with some manual information\u201d.", "The dataset with the added features is still heterogeneous, and all extra features are functions of the data (but the frequency).", "\\newline We can see in Table [@ref:LABEL:tab:clusterheterog] that the \u201cplain\u201d global models are outperformed by the local models.", "Even though they are overshadowed by local models, this result is already interesting because global models outperform na\u00efve forecasting by a large margin (a na\u00efve seasonal method would have a MASE of roughly 1), something that is not trivial.", "In particular the global linear is fitting 12 numbers to 100000 time series, more than 4 orders of magnitude fewer parameters that an ARIMA.", "\\newline When we cluster the datasets, the global models substantially improve performance, in particular the deep network already outperforms 2 of the three local models.", "These results are to be expected because we know from other other experiments that global models outperform local in the M4 for each individual frequency, but here we are severely limiting them in terms of memory.", "When we add the extra features, we see that the deep network improves accuracy, outperforming all local and the clustered global.", "We see this result as strong evidence towards the power of complex model classes for global models; they can automatically find good forecasting functions even in very heterogeneous datasets.", "\\newline </subsection> <subsection> <title> 5.6 Scale normalization as preprocessing </title> We compare the effect of scaling as a means of preprocessing the dataset before applying global models, to show that scale information can be relevant.", "Scaling each series can make the dataset more homogeneous but at the same time removes information about scale, which can be helpful in some scenarios.", "Scale invariance is appropriate in most benchmark datasets because they have been arbitrarily re-scaled or mix series with different units (e.g. tourist arrivals and unemployment rates).", "Moreover, popular error measures (MASE or SMAPE) are scale invariant, artificially emphasizing the impact of scale normalization.", "We expect real applications to exhibit none of these issues.", "Since there seem to be no real reason for scale invariance and some good reasons for not normalizing, it is interesting to experiment with scale invariance.", "\\newline In order to keep the \u201cbest of both worlds\u201d we experiment with scale normalization, but we add the scale of each series as an additional variable to each series.", "Scale normalization will remove information from each series, by dividing its scale, but this information is added back into the dataset as an extra variable.", "\\newline We use the global deep network of AR(12) (we cannot use linear methods because they are scale invariant).", "For each of the datasets, and measure the error in a one-step-ahead forecast horizon."]], "target": "Table shows average errors, both in MASE and also plain mean average error (MAE). We can see that adding scale information has a positive effect in reducing the error.c"}, {"tabular": ["  Expression  &  Informal Semantics ", " $ C(a,b,p,q):_{i}F $  &  $ C $ is probative evidence for $ F $ for agent $ i $ . ", " $ \\neg C(a,b,p,q):_{i}F $  &  $ C $ is not probative justification for $ F $ for agent $ i $ . ", " $ (\\neg C(a,b,p,q)):_{i}F $  &  The absence of $ C $ is a justification for $ F $ for agent $ i $ . ", " $ C(a,b,p,q):_{i}\\neg F $  &  $ C(a,b,p,q) $ is evidence for $ \\neg F $ for the agent $ i $ .  "], "ref_sec": [["<section> <title> 1 Introduction </title>  The institutional economics demands a clear account of a fuzzy world and is therefore in accordance [@bib:Morgan11JIE] with the dictum attributed to Keynes: \"it is better to be roughly right than precisely wrong\".", "As many multi-agent systems are organized in some kind of institution, judging the behavior of agents in such contexts requires sometimes understanding of how their actions stand vis-a-vis to the goals of the overall system.", "\\newline Habermas [@bib:Morgan11JIE] proposed different types of discourses dealing with different validity claims.", "In the interaction between agents we can thus have an explicative discourse, when communicating knowledge, and a normative discourse, when considering normative knowledge.", "For justifying their actions our agents are endowed with a Justification and Explanation Logic ( $ \\mathcal{JEL} $ ), capable to cover both the justification for their commitments and explanations why they had to act in that way, due to the current situation in the environment.", "The distinction between factual and normative knowledge is important in argumentative agents since facts of various kinds might not provide agents with any choice, while norms are possible to be bent and eventually changed.", "\\newline The difference between explanation and justification has not been clearly delimited in computational models of arguments.", "From this perspective, there is a gap between argumentation in the philosophy of science and computational-based argumentation.", "Given the idea that argumentation is a means to justify claims or to persuade other agents of these claims [@bib:Jennings98] , there are two approaches when defining what \"good argumentation\" represents: i) argumentation able to justify its target claims and ii) argumentation able to convince an audience.", "These two lines form the basis for investigating the contrast between justificatory arguments and explanatory arguments .", "\\newline The philosophy of science distinguishes between explanatory reasons and normative or justificatory reasons [@bib:sep-reasons-just-vs-expl] .", "While explanations are reasons why events occur, justifying reasons are \"considerations which count in favor\" or \"explanations of ought facts\".", "Differently, in the computation models of arguments there is a blurred distinction between explanation-based argumentation and justification-based argumentation, as in [@bib:Lu2011946] , where explanations and evidence are used to construct justifications.", "\\newline In many practical domains the distinction between explanation and justification has pragmatic force.", "Many examples come from the legal domain, where an illegal action can be explained, but in many cases the action is not justified.", "For instance, a theft can be explained by the loss of money because the person lost his job, but it does not have normative justificatory power.", "Another common example is based on the well known lack of time explanatory pattern: \"I could not finalize the task due to lack of time\", with its many instantiations: \"I could not review the paper because I was at a conference during the deadline\" or \"I could not finalize the article, because input data arrived too late\".", "In most situations, this explanation pattern does not have justificatory power at all.", "In other words, something can explain a behavior but it cannot always justify it.", "\\newline In this paper we investigate the inter-living of explanations and justifications in business-oriented situations.", "Current business interactions are affected by postmodern ideas like post-structuralism and heterogeneity at different levels.", "In line with postructuralism, business commitments act as a flexible framework for guiding business interactions, agents preferring soft law against the hard law governance, whilst the idea of heterogeneity of individuals is reflected at the business policy level through the concept of heterogeneity of customers [@bib:Yan10] .", "Consider the contractual clause in which the debtor $ a $ promises to deliver an item to the creditor $ b $ within a pre-agreed deadline.", "Not meeting the deadline, the agent $ a $ provides an explanation: \"I could not deliver the product because my supplier $ c $ has not delivered the parts yet\".", "This explanation provides the creditor $ b $ with some insights on the current situation, but it does not have enough justificatory power in order to justify the behavior of agent $ a $ for not delivering the item.", "It may be a case in which the supplier $ c $ has no normative obligation to deliver the components of the product: either a commitment $ C(s,a,pay,parts) $ for delivering the parts does not exist between $ a $ and the supplier $ c $ , or the agent $ a $ did not pay the components in due time.", "Valid justifications should be normative, like: \"emergency situation forces me not to deliver the item\", where emergency is a normative concept.", "Observe that the $ emergency $ justifier does not help the debtor $ a $ to understand the situation.", "The agent can ask for further explanations for the conveyed justifier, but also for further normative justifications for it.", "\\newline The paper advances the state-of-the-art in logic of argumentation in three ways: i) proposing $ \\mathcal{JEL} $ for handling both justificatory and explanatory arguments; ii) introducing commitments as proof terms; and iii) formalising several justificatory and explanatory patterns.", "The remaining of the paper is organised as follows: Section [@ref:LABEL:sec:logic] extends justification logic [@bib:Artemov08] with explanatory capabilities and introduces commitments as proof terms.", "The expressivity of social commitments is exploited in section [@ref:LABEL:sec:patterns] to represent both justificatory and explanatory patterns.", "Section [@ref:LABEL:sec:agents] describes types of argumentative agents based on the combination of justificatory and explanatory attitudes, whilst section [@ref:LABEL:sec:scenario] illustrates the developed instrumentation through an illustrative scenario.", "We end the paper with related work and conclusions.", "\\newline  </section>"], ["<section> <title> 2 Commitment-Based Justification and Explanation </title>  The first part of this section extends the justification logic with explanatory capabilities.", "The second part illustrates how social commitments are used to represent proof terms in justification logic.", "\\newline <subsection> <title> 2.1 Enhancing Justification Logic with Explanation </title> In order to model justificatory and explanatory arguments we propose an extended version of the Justification Logic (JL).", "Justification Logic combines ideas from epistemology and the mathematical theory of proofs.", "It provides an evidence-based foundation for the logic of knowledge, according to which \"F is known\" is replaced by \"F has an adequate justification\".", "\\newline Simply, instead of \"X is known\" ( $ KX $ ) consider $ t:X $ , that is, \"X is known for the explicit reason t\" [@bib:Artemov08] .", "Justification logic lacks this component of interpretation.", "It also lacks the capability to express explanation or partial justification.", "This section extends the justification logic with explanatory capabilities, by introducing the explanatory operator $ t\\triangleleft F $ , where $ t $ is an explanation for $ F $ .", "\\newline <theorem> Definition 1 The language of Justification and Explanation Logic $ \\mathcal{JEL} $ contains proof terms $ t\\in\\mathcal{T} $ and formulas $ F\\in\\mathcal{F} $ \\newline hline \\ $ t: $ & $ =x|c|t\\cdot t|t+t|!t|?t|t\\gtrdot t $ \\ $ F: $ & $ =p|F\\vee F|\\neg F|t:F|t\\triangleleft F $ \\ hline \\newline </theorem> Proof terms $ t $ are abstract objects that have structure.", "They are built up from axiom constants $ c\\in Cons $ , proof variables $ x\\in Vars $ , and operators on justifications and explanations $ \\cdot $ , $ + $ , $ ! $ , $ ? $ , $ \\gtrdot $ .", "The application operator $ \\cdot $ takes two proof terms and constructs a new justification based on them.", "The sum operator $ + $ concatenates the given proofs, whilst the unary operators $ ! $ and $ ? $ are used to request for positive and negative proof terms for a formula in $ \\mathcal{JEL} $ .", "The operator precedence decreases as follows: $ !,\\cdot,+,:,\\triangleleft,\\neg,\\vee $ , and $ \\cdot,+ $ are left associative, and $ :,\\triangleleft $ right associative.", "To express that $ t $ is not probative justification for supporting $ F $ one uses $ \\neg t:F $ .", "Parentheses are needed to express that $ \\neg t $ is a justification for $ F $ : $ (\\neg t):F $ .", "Note that justification is used to support negated sentences too, as in $ t:\\neg F $ .", "Similar semantics applies for the explanation operator $ \\triangleleft $ .", "\\newline The axioms of $ \\mathcal{JEL} $ are shown in figure [@ref:LABEL:fig:axioms] , where axiom $ A_{1} $ forces all formulas $ F $ to have a justification or an explanation $ t $ .", "The compounds $ t:F $ or $ t\\triangleleft F $ represent a formula, which should have their own justification.", "This corresponds to the principle of inferential justification : for sentence $ F $ to be justified on the basis of $ t $ one must justify $ t $ and justify that $ t $ makes $ F $ plausible.", "Constants are used to stop the ad infinitum justification chain by representing a kind of justification that does not depend on other justifiers.", "\\newline The application axiom $ A_{2} $ takes a justifier $ s $ of an implication $ F\\rightarrow G $ and a justifier $ t $ of its antecedent $ F $ , and produces a justification $ s\\cdot t $ of the consequent $ G $ .", "If at least one of the terms $ s $ , $ t $ represents an explanation, the formula $ G $ is considered only explained, but not justified (axioms $ A^{\\prime}_{2} $ , $ A^{\\prime\\prime}_{2} $ , and $ A^{\\prime\\prime\\prime}_{2} $ ).", "\\newline The j-sum axiom says that if a formula $ F $ is justified by the justifier $ s $ , than for a new justifier $ t $ , the formula is still justified.", "Thus, justification reasoning is monotonic, new justification not defeating the existing one.", "The corresponding axiom for explanation is missing, leaving space for contradictory explanations and non-monotonic explanatory reasoning.", "The rationality behind this is that norms are considered static at a given moment and assumed apriori known by the participants, whilst explanations are constructed dynamically during a dialog.", "\\newline Justifications and explanations are assumed to be verified.", "Based on axiom $ A_{4} $ , a justifier $ t $ for formula $ F $ can be further justified by the term $ !t $ , but it can also be explained.", "The axiom $ A^{\\prime}_{4} $ limits the possibility to justify an explanation, an explanation can only be further explained.", "The negative proof checker $ A_{5} $ forces agents to provide justifications or explanations why they are not able to justify a particular formula $ F $ .", "Justifiers cannot be used to justify why the formula $ F $ is not explained by the explanandum $ t $ , as axiom $ A^{\\prime}_{5} $ states that only explanans can be used.", "A proof term can be stronger than another one, given by the operator $ \\gtrdot $ .", "\\newline </subsection> <subsection> <title> 2.2 Commitment Based Proof Terms </title> One of the issues regards what sort of things can be a justifier.", "In a normative framework regulated only by social commitments, a justifier can be represented by such commitments.", "In the proposed approach, by restricting the acceptable justifications and explanations to commitments, it means that the proof terms $ t $ in the $ \\mathcal{JEL} $ language represent commitments.", "\\newline The classical definition of a conditional commitment states that the debtor $ x $ promises to creditor $ y $ to bring about a particular formula $ P $ under the condition $ Q $ , encapsulated as $ C(x,y,Q,P) $ .", "In multi-agent systems, a justification accepted as probative evidence for an agent may not meet the standard of proof for another agent, which rejects it.", "To model this, we link the justification and explanatory operators to the agent accepting the evidence."]], "target": "Thus, the construction $ C(a,b,p,q):_{i}F $ says that commitment $ C $ is a probative justification for agent $ i $ regarding the sentence $ F $ (see table ). A commitment may be preferred to another one by the agent $ i $ when choosing an explanation, formalized as $ (C\\succ C)\\triangleleft_{i}F $ . If one of the terms in the commitment is not constrained in any aspect, \u201cdo not care\u201d sign \u201c $ \\_ $ \u201d is used."}, {"tabular": ["  {Task requesters}  &  50  &  100  &  150  &  200  &  250  &  300 ", " {Task executers}  &  500  &  1000  &  1500  &  2000  &  2500  &  3000 ", " {Bid value range} (for UD)  &  [80, 150]  &  [80, 150]  &  [80, 150]  &  [80, 150]  &  [80, 150]  &  [80, 150] ", " {Budget distribution}  &  [400, 600]  &  [400, 600]  &  [400, 600]  &  [400, 600]  &  [400, 600]  &  [400, 600]  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Over the past decades, most of the works in {crowdsourcing} [@bib:Howe2006] [@bib:Slivkins:2014:ODM:2692359.2692364] mainly circumvent around tackling one of the major challenges of {how to motivate the crowd workers to participate in the system?} One solution that is appreciated a lot in this direction is, to incentivize the task executers.", "This gave rise to several other open questions: 1) Which task executers to be hired? 2) How the task requester(s) can be aware about the quality of the task executers (or crowd workers)?", "3) What amount is to be paid to the task executers for their services, so that they are not dishearten and are motivated to participate in future, in similar type of systems?", "Answering to the above raised questions, substantial amount of works have been done in these directions [@bib:Bhat:2016:TMB:2937029.2937172] [@bib:DBLP:journals/corr/abs-1305-6705] [@bib:DBLP:conf/hcomp/GoelNS14] [@bib:JAIN201844] [@bib:Jain:2016:DMM:2936924.2936941] [@bib:Luo:2016:IMD:2885506.2837029] [@bib:10.1109:MIC.2012.70] .", "Unlike the works in [@bib:Xu:2017:BOA:3091125.3091431] [@bib:5466993] , in this paper, we have investigated the set-up somehow close to the set-up discussed in [@bib:DBLP:conf/hcomp/GoelNS14] [@bib:DBLP:journals/corr/AssadiHJ15] but with additional constraints: 1) the task executers are the IoT devices instead of human agents, and 2) in order to be aware about the quality of IoT devices, we have utilized the technique of peer grading, that is different from the general practice for identifying the quality of the human agents [@bib:JAIN201844] [@bib:Bhat:2016:TMB:2937029.2937172] .", "It is to be noted that, till date, in the crowdsourcing literature this tedious work of determining the quality of the crowd workers is mostly done by the platform or in some cases by the task requesters.", "This leads to an extra burden on the platform or the task requesters.", "Also, this scenario makes the process of quality determination centralized.", "In our peer grading approach, we use to distribute the task executed by the subset of IoT devices to their peers (other IoT devices) for grading purpose.", "Based on the peers report, the quality IoT devices are selected.", "The detailing of our proposed model is depicted in Figure [@ref:LABEL:fig:model] .", "In our model, we have multiple task requesters and multiple IoT devices (as task executers); where each task requester is endowed with a single task and the maximum amount he/she (henceforth he) can pay is termed as {budget} (or capital).", "Each IoT device has independent private cost(s) for each task that they will charge for executing.", "It is to be noted that, the participating IoT devices are intelligent and rational.", "Due to their rational behaviour they will try to strategize the system.", "By {strategizing} we mean that these devices can manipulate their private information in order to gain.", "Given this set-up, our goal is to select the subset of IoT devices for each task such that the total payment made to the IoT devices are within the allotted quota of budget for the task while attaining a threshold quality.", "\\newline Following the general work flow of the crowdsourcing, firstly, each task requester submits the endowed task and the publicly known budget to the platform.", "On receiving the tasks and the endowed capital for the respective task from the task requesters, the platform publishes the tasks to the outside world for the execution purpose.", "Now, each IoT device present on the other side of the market opts for the subset of tasks of their interest for execution and report to the platform along with the amount they will charge for executing each task.", "Based on their reported interests, the platform assigns the tasks to the IoT devices.", "Without loss of generality, it is assumed that each IoT device will execute all of its tasks for which it has shown interest and each IoT device executes single task at a time.", "Now, the immediate question is: {How to preserve the assumptions made for the problem under investigation?} One solution that can be thought of is to place each of the task of an IoT device on which it has shown interest into different time slots (here, time slots could be thought of as {morning} , {afternoon} , and {evening} for a day) that will help in keeping our assumptions alive. {Say, for example an IoT device has shown his interest over 3 tasks.", "In such case, one task will be scheduled in the morning, another task in the afternoon, and the third task could be scheduled in the evening.} After the distribution of tasks into different time slots, the IoT devices executes the assigned task(s) and submit to the platform as depicted in Figure [@ref:LABEL:fig:model] .", "Now, the next challenge that comes into the pocket of the {platform} is to determine the quality of the IoT devices.", "For this purpose, the idea of peer grading [@bib:DBLP:journals/corr/AlfaroSP16] [@bib:T.roughgarden_201617] is utilized in our set-up.", "It is to be noted that, in each time slot and for each task, the process of {peer grading} is carried out iteratively.", "The process iterates until each IoT device is not graded by the peers.", "At the end of each iteration of the peer grading phase, the IoT device top rated (or graded) by most of the peers, is selected.", "Finally, the peer grading process returns a set of quality IoT devices for each task.", "Now, given the set of quality IoT devices for each task, we have to select a subset of IoT devices such that the total payment made are within the allotted quota of budget.", "As the IoT devices are {strategic} in our setting, so for this reason we have modelled the above discussed set-up using mechanism design.", "In this paper, we have carefully crafted a {t ruthful b u dget feasi b le m e chanism} for the {t ask a llocation p roblem} (TUBE-TAP) motivated by [@bib:Singer_2016] [@bib:8432319] , that also allow us to have the true information about the {quality} of the IoT devices .", "\\newline <subsection> <title> 1.1 Summary of Key Contributions </title> The main contributions of this paper are: \\newline <list> \\ We have investigated the heterogeneous task assignment problem in IoT based crowdsourcing through the lens of mechanism design.", "\\newline \\ \\ We have developed a {truthful budget feasible} mechanism; namely TUBE-TAP motivated by [@bib:Singer_2016] [@bib:8432319] for the problem under investigation.", "\\newline \\ \\ We prove that TUBE-TAP satisfies several economic properties such as {truthfulness} , and {budget feasibility} .", "\\newline \\ \\ The simulations are done for comparing the TUBE-TAP with a carefully crafted benchmark mechanism.", "\\newline \\ </list> \\newline </subsection> <subsection> <title> 1.2 Paper Organization </title> The remainder of this paper is organized as follows.", "In section [@ref:LABEL:sec:rw] the prior works explored in the direction of crowdsourcing is discussed.", "In Section [@ref:LABEL:s:prelim] , we describe our proposed system model in detailed manner.", "We then present our proposed mechanism namely TUBE-TAP for the problem discussed in section [@ref:LABEL:s:pm] .", "Further analysis of TUBE-TAP is carried out in section [@ref:LABEL:sec:faba] .", "In section [@ref:LABEL:sec:ef] the experimental results are presented and discussed.", "In section [@ref:LABEL:se:cons] the paper is concluded and the future directions are coined.", "\\newline </subsection>  </section>"], ["<section> <title> 2 Related Works </title>  This section contains a short description of the previous works and developments in this area.", "The discussion will mainly circumvent around the works regarding {incentive} policies utilized in the past for dragging large number of participants, and {quality} of the executed works supplied by the task executers, in crowdsourcing.", "In order to get the detailed overview of the field and the current research trends we recommend readers to go through [@bib:Howe2006] [@bib:6113213] [@bib:Slivkins:2014:ODM:2692359.2692364] [@bib:Mazlan2018] .", "In past there have been an extensive body of works discussing about the major challenges in crowdsourcing [@bib:Slivkins:2014:ODM:2692359.2692364] and in some cases providing the solution approach [@bib:Bhat:2016:TMB:2937029.2937172] [@bib:Jain:2016:DMM:2936924.2936941] [@bib:Luo:2016:IMD:2885506.2837029] .", "The two major challenges in crowdsourcing that have dragged the interest of large community are: 1) How to motivate large group of common people to participate in this system as they are {rational} .", "2) How to verify that the executed tasks supplied by the agents are upto the mark.", "Answering to the issue raised in point 1 several schemes are proposed that incentivizes the participating agents in some sense [@bib:Luo:2016:IMD:2885506.2837029] [@bib:DBLP:conf/hcomp/GoelNS14] [@bib:Bhat:2016:TMB:2937029.2937172] [@bib:8031314] .", "In [@bib:Reddy:2010:EMP:1864349.1864355] the {fixed price scheme} is proposed in which the platform or in some applications task requesters provide some fixed amount to the crowd workers.", "The drawback to such approach is that the agents are paid less than the effort supplied.", "This pricing structure has resolved the issue raised in point 1 to some extent but not completely.", "In [@bib:5466993] reverse auction based incentive scheme called {\u2019RADP\u2019} is proposed for the setting with single task requester having single task that is to be given to the multiple crowd workers on the other side of the market.", "In this, some pre-defined number of task executers with lowest bid values are selected and paid their revealed bid price.", "One issue with this solution approach is that the participants those who are giving much high effort may bid high and may not be reaching in the selection zone.", "In some sense, this pricing model may demotivate the quality agents.", "To overcome the issue raised in [@bib:5466993] , in [@bib:Lee2010PMC] a reverse auction based incentive scheme with virtual participant credit (RADP-VPC) is proposed.", "Here, the idea is, the participant who lost in the current iteration is provided a specific reward for the participation and if the loser participate further then this virtual credit will be subtracted from his original bid value that may lead to the consideration of participants in further auction rounds.", "One drawback with this strategy is that the participant can set the high bid value as his/her payment.", "Following works in [@bib:Reddy:2010:EMP:1864349.1864355] [@bib:Lee2010PMC] , a better auction models were proposed [@bib:Zhao2014CCC] [@bib:7218673] [@bib:6848055] .", "In [@bib:DBLP:conf/hcomp/GoelNS14] , an effort has been made to design a truthful budget feasible mechanism for crowdsourcing in an online environment for the set-up consisting of single task requester endowed with multiple tasks and there are multiple task executers on the other side of the market.", "The task executers along with the private cost have different skills based on which they show their interest to perform certain subset of tasks.", "The goal is to select subset of task executers so that the total payment made to the task executers are within budget.", "In the similar line, the work by [@bib:Xu:2017:BOA:3091125.3091431] is carried out where, the set-up consists of multiple tasks with deadlines that are to be executed by the pool of workers that arrive online.", "Each of the worker has the known set of tasks that he/she can perform and based on that the task is assigned to the workers before its deadline.", "The goal is to design an online-assignment policy such that the total expected profit is maximized subject to budget and deadline constraint.", "However, one of the major set back of the literature covered till now is that the quality of the data supplied or more formally, the quality of the crowd workers are not taken into picture.", "Some quality adaptive schemes are discussed in [@bib:JAIN201844] [@bib:DBLP:journals/corr/abs-1305-6705] .", "In this paper, an effort has been made to design a quality adaptive truthful budget feasible mechanism for one of the scenarios of \u2019crowdsourcing\u2019.", "We have utilized the concept of \u2019 {peer grading} \u2019 for determining the quality of the IoT devices.", "\\newline  </section>"], ["<section> <title> 3 System Model and Problem Formulation </title>  In this section, we present the formal statement of our problem.", "We consider {n} task requesters $ \\mathbb{R}=\\{\\mathbb{R}_{1},\\mathbb{R}_{2},\\ldots,\\mathbb{R}_{n}\\} $ each carrying a single distinct task.", "The set of tasks is represented as $ \\mathbb{T}=\\{\\mathbb{T}_{1},\\mathbb{T}_{2},\\ldots,\\mathbb{T}_{n}\\} $ ; where $ \\mathbb{T}_{i} $ is the $ i^{th} $ task held by $ \\mathbb{R}_{i} $ task requester.", "The set-up, where each {task requester} carrying multiple tasks is reserved for our future work.", "Also, along with a task, each task requester $ \\mathbb{R}_{i}\\in\\mathbb{R} $ has an upper bound on the amount he/she (henceforth he) can pay for getting his task executed, known as {budget} represented as $ \\mathbb{B}_{i} $ .", "The budget vector for all the task requesters is given as $ \\mathbb{B}=\\{\\mathbb{B}_{1},\\mathbb{B}_{2},\\ldots,\\mathbb{B}_{n}\\} $ .", "Each of the task requester submits the endowed task along with their publicly known budget to the {platform} .", "The {platform} projects these tasks to the IoT devices present on the other side of the market.", "In our set-up, we have {m} IoT devices represented by the set $ \\mathbb{E}=\\{\\mathbb{E}_{1},\\mathbb{E}_{2},\\ldots,\\mathbb{E}_{m}\\} $ .", "It is considered that $ m\\gg n $ .", "Afterwards, each IoT device shows its interest over the set of tasks for execution purpose to the platform along with the maximum value it can charge for executing each task.", "Utilizing the submitted information by the IoT devices, we can have the set of IoT devices that are interested to execute the task $ \\mathbb{T}_{j} $ and is given as $ \\mathbb{\\boldsymbol{I}}^{j}=\\{\\mathbb{E}_{1},\\mathbb{E}_{2},\\ldots,\\mathbb{E}_% {k_{j}}\\} $ ; where $ k_{j} $ is the number of IoT devices associated with task $ \\mathbb{T}_{j} $ .", "The set $ \\mathbb{\\boldsymbol{I}} $ = $ \\{\\mathbb{\\boldsymbol{I}}^{1},\\mathbb{\\boldsymbol{I}}^{2},\\ldots,\\mathbb{% \\boldsymbol{I}}^{n}\\} $ represents the associated set of IoT devices for all the {n} tasks.", "The maximum value an IoT device $ \\mathbb{E}_{i} $ will charge for executing a task $ \\mathbb{T}_{j} $ is given as $ v_{i}^{j} $ called the valuation.", "The valuations of the IoT devices are {private} in nature.", "It is to be noted that the IoT devices are {strategic} in nature.", "By {strategic} we mean that the IoT devices can misreport their private valuation in order to gain.", "So, it is better to represent the bid value of each IoT device $ \\mathbb{E}_{i} $ for executing the task $ \\mathbb{T}_{j} $ as $ b_{i}^{j} $ .", "$ b_{i}^{j}=v_{i}^{j} $ represents the fact that the IoT device $ \\mathbb{E}_{i} $ report its private valuation $ b_{i}^{j} $ for the task $ \\mathbb{T}_{j} $ in a {truthful} manner.", "The bid vector for each task $ \\mathbb{T}_{j} $ is given as $ b_{j}=\\{b_{1}^{j},b_{2}^{j},\\ldots,b_{k_{j}}^{j}\\} $ .", "The set $ b=\\{b_{1},b_{2},\\ldots,b_{n}\\} $ represents the set of bid vectors of the IoT devices for all the tasks.", "Based on the set $ \\mathbb{\\boldsymbol{I}} $ , a non-conflict graph $ \\mathbb{G}(\\mathcal{V},\\mathcal{E}) $ is constructed; where $ \\mathcal{V} $ is the set of vertices representing the tasks.", "An edge $ (i,j)\\in\\mathcal{E} $ between the tasks {i} and {j} represents the fact that the pair $ (i,j) $ have at least one IoT device that is associated to both the tasks.", "Once the graph is constructed, next target is to place the tasks along with their respective IoT devices to different time slots so as to preserve the assumptions made.", "The set of time slots to which all the tasks are placed in, is given as $ \\tau=\\{1,2,\\ldots,\\kappa\\} $ ; where $ \\kappa $ is the number of time slots available.", "Afterwards, in {peer grading} phase, each IoT device $ \\mathbb{E}_{i} $ provides a ranked list over the subset of IoT devices associated with task $ \\mathbb{T}_{j} $ denoted by $ \\succ_{i}^{j} $ , where $ \\mathbb{E}_{\\ell} $ $ \\succ_{i}^{j} $ $ \\mathbb{E}_{k} $ means that the IoT device $ \\mathbb{E}_{i} $ ranks $ \\mathbb{E}_{\\ell} $ above $ \\mathbb{E}_{k} $ .", "For each task $ \\mathbb{T}_{j} $ , this {peer grading} process will result in the quality IoT devices.", "Now, the next target is to select the subset of IoT devices from the quality IoT devices for each task and decide their payment.", "The allocation vector for all the tasks is given as $ \\mathbb{A}=\\{\\mathbb{A}_{1},\\mathbb{A}_{2},\\ldots,\\mathbb{A}_{n}\\} $ ; where $ \\mathbb{A}_{i} $ contains the IoT devices selected for task $ \\mathbb{T}_{i} $ .", "Similarly, the payment vector of all the IoT devices for {n} tasks is given as $ \\mathbb{\\boldsymbol{P}}=\\{\\mathbb{\\boldsymbol{P}}_{1},\\mathbb{\\boldsymbol{P}}_% {2},\\ldots,\\mathbb{\\boldsymbol{P}}_{n}\\} $ .", "Here, $ \\mathbb{\\boldsymbol{P}}_{j} $ is the payment vector of IoT devices associated with task $ \\mathbb{T}_{j} $ and is given as $ \\mathbb{\\boldsymbol{P}}_{j}=\\{\\mathbb{\\boldsymbol{P}}_{1}^{j},\\ldots,\\mathbb{% \\boldsymbol{P}}_{k_{j}}^{j}\\} $ ; where $ \\mathbb{\\boldsymbol{P}}_{i}^{j} $ is the payment received by IoT device $ \\mathbb{E}_{i} $ for executing task $ \\mathbb{T}_{j} $ .", "The utility achieved by any $ i^{th} $ IoT device for each task $ \\mathbb{T}_{j} $ could be defined as the payment it received for executing task $ \\mathbb{T}_{j} $ minus the valuation of an IoT device for task $ \\mathbb{T}_{j} $ , if it is considered for task $ \\mathbb{T}_{j} $ ; otherwise 0.", "This can be represented formally as: \\newline <equation> $ u_{i}^{j}=\\begin{cases}\\mathbb{\\boldsymbol{P}}_{i}^{j}-v_{i}^{j},&\\textit{if $% \\mathbb{E}_{i}$ is considered for task $\\mathbb{T}_{j}$}\\\\ 0,&\\textit{Otherwise}\\end{cases} $ </equation> \\newline <theorem> Definition 1 (Incentive Compatible (IC) ) .", "A mechanism is said to be truthful or IC if reporting true valuation by any agent {i} will maximize its utility irrespective of the valuations of other agents.", "Formally in our case, for any arbitrary IoT device $ \\mathbb{E}_{i} $ for task $ \\mathbb{T}_{j} $ the utility relation is $ u_{i}^{j}=\\mathbb{\\boldsymbol{P}}_{i}^{j}-v_{i}^{j}\\geq\\mathbb{\\boldsymbol{P}}% _{i}^{j}-b_{i}^{j}=\\hat{u}_{i}^{j} $ ; where $ u_{i}^{j} $ is the utility when $ \\mathbb{E}_{i} $ reports true value and $ \\hat{u}_{i}^{j} $ is the utility when reporting the bid other than the true value $ b_{i}^{j}\\neq v_{i}^{j} $ .", "\\newline </theorem> <theorem> Definition 2 (Individual Rationality (IR) ) .", "A mechanism is said to be individually rational if every agent {i} results in a non-negative utility.", "More formally in our case, $ u_{i}^{j}\\geq 0 $ when participating in the system \\newline </theorem> <theorem> Definition 3 (Budget Feasibility (BF) ) .", "A mechanism is said to be budget feasible if the total payment made to the agents are within total budget.", "More formally in our case, fix a task $ \\mathbb{T}_{j} $ we have, $ \\sum\\limits_{i=1}^{k_{j}}\\mathbb{\\boldsymbol{P}}_{i}^{j}\\leq\\mathbb{B}_{j} $ .", "\\newline </theorem>  </section>"], ["<section> <title> 4 Proposed Mechanism: TUBE-TAP </title>  In this section, we have proposed a {truthful} mechanism namely TUBE-TAP for the problem under investigation.", "The main components of the TUBE-TAP are: {Time slot allocation heuristic} , {Quality determination rule} , and {Allocation and payment rule} .", "\\newline <subsection> <title> 4.1 Time slot allocation heuristic </title> The underlying idea behind proposing {Time Slot Allocation Heuristic} motivated by is to distribute the tasks into different time slots, so that: (a) the IoT devices gets the privilege to execute all the tasks for which they have shown their interest; (b) each IoT device executes a single task at a time.", "\\newline <subsubsection> <title> 4.1.1 Outline of Time slot allocation heuristic </title> {mdframed} [backgroundcolor=gray230] \\newline Time slot allocation heuristic \\newline <paragraph> <title> First Phase: </title> <list> \\ Pick a task $ \\mathbb{T}_{i} $ which has less than $ \\kappa $ adjacent tasks in a graph $ \\mathbb{G} $ .", "\\newline \\ \\ Put $ \\mathbb{T}_{i} $ on the stack and remove it along with the incident edges from the graph $ \\mathbb{G} $ .", "\\newline \\ \\ Repeat step 1 and 2, until the graph $ \\mathbb{G} $ is non-empty.", "\\newline \\ </list> \\newline </paragraph> <paragraph> <title> Second Phase: </title> In each iteration: \\newline <list> \\ Pop the task present at the top of the stack.", "\\newline \\ \\ Assign it the lowest numbered time slot that is not assigned to any of its neighbouring tasks.", "\\newline \\ </list> \\newline </paragraph> </subsubsection> <subsubsection> <title> 4.1.2 Detailed Time slot allocation heuristic </title> This section explains the detailing of the {Time Slot Allocation Heuristic} presented in the Algorithm [@ref:LABEL:algo:1] .", "As in the outline of the {Time Slot Allocation Heuristic} in subsection [@ref:LABEL:subsec:1] , it is discussed that it is a two phase mechanism.", "The first phase of the mechanism is depicted in line $ 2-9 $ of Algorithm [@ref:LABEL:algo:1] .", "In each iteration of {while} loop in line $ 2-9 $ , a task with neighbours less than the $ \\kappa $ ( $ \\kappa $ time slots are available) is picked-up and is pushed into the stack $ S $ .", "Next, the recently pushed task is removed from the graph $ \\mathbb{G} $ along with its incident edges.", "In the second phase, shown in line $ 10-14 $ of Algorithm [@ref:LABEL:algo:1] , the actual process of time slots allocation is carried out.", "For each iteration of {while} loop in line 10-14, the currently present top element is popped out of the stack $ S $ and held in $ \\Bbbk $ data structure.", "The element held in $ \\Bbbk $ data structure is added back to graph $ \\mathbb{G} $ .", "\\newline <float> \\ $ \\mathbb{G}^{\\prime}\\leftarrow\\mathbb{G} $ , {S} $ \\leftarrow $ $ \\phi $ \\ \\ while {$ \\mathbb{G}\\neq\\phi $} do \\ \\ foreach {$ \\mathbb{T}_{j} $ $ \\in $ $ \\mathcal{V} $} do \\ \\ if {$ |adj(\\mathbb{T}_{j})| $ $ < $ $ \\kappa $} then \\ \\ Push( $ S $ , $ \\mathbb{T}_{j} $ ) //", "Task $ \\mathbb{T}_{j} $ is pushed into the stack $ S $ \\ \\ $ \\mathbb{G}\\leftarrow\\mathbb{G}\\setminus\\{\\mathbb{T}_{j}\\} $ // Task $ \\mathbb{T}_{j} $ is removed from $ \\mathbb{G} $ \\ \\ \\ \\ end if \\ \\ \\ \\ end foreach \\ \\ \\ \\ end while \\ \\ while {$ S\\neq\\phi $} do \\ \\ $ \\Bbbk $ $ \\leftarrow $ Pop( $ S $ ) //", "$ \\Bbbk $ holds an element popped-up from stack $ S $ \\ \\ $ \\mathbb{G}\\leftarrow\\mathbb{G}\\cup\\{\\Bbbk\\} $ // Construct graph $ \\mathbb{G} $ by utilizing the neighbours information from $ \\mathbb{G}^{\\prime} $ \\ \\ Assign $ \\Bbbk $ the lowest numbered time slot that is not assigned to any of its neighbours.", "\\ \\ end while \\ \\ return $ \\mathbb{G} $ \\ \\ \\ Time slot allocation heuristic ( $ \\mathbb{G} $ , $ \\kappa $ ) </float> \\newline Each time a task is added in a graph $ \\mathbb{G} $ the information about neighbouring tasks is fetched from $ \\mathbb{G}^{\\prime} $ graph.", "Now, the task added in current iteration is assigned a lowest numbered time slot that is not assigned to its neighbours using line 13.", "The {while} loop terminates once the stack is empty, or in other words each task is assigned a time slot.", "Finally, in line 15 a graph $ \\mathbb{G} $ containing the information about the assigned time slot to each of the task is returned.", "\\newline <theorem> Example 1 .", "For the understanding purpose, we have considered 5 tasks and 20 IoT devices.", "\\newline Let the budget associated with the 5 tasks are: $ \\mathbb{B}_{1}=50\\$ $ , $ \\mathbb{B}_{2}=25\\$ $ , $ \\mathbb{B}_{3}=30\\$ $ , $ \\mathbb{B}_{4}=60\\$ $ , and $ \\mathbb{B}_{5}=15\\$ $ .", "For each task, the interested set of IoT devices is depicted in Figure [@ref:LABEL:fig:1(a)] .", "Figure [@ref:LABEL:fig:1(a)] will be read as, say for example consider task $ \\mathbb{T}_{3} $ .", "The IoT devices that are interested to execute task $ \\mathbb{T}_{3} $ are $ \\mathbb{E}_{12} $ , $ \\mathbb{E}_{16} $ , and $ \\mathbb{E}_{19} $ .", "Based on the configuration shown in Figure [@ref:LABEL:fig:1(a)] , a graph $ \\mathbb{G} $ is formed as shown in Figure [@ref:LABEL:fig:1(b)] .", "Note that the tasks $ \\mathbb{T}_{1} $ and $ \\mathbb{T}_{3} $ do not share any common IoT devices, so they do not have an edge between them.", "The result of which they can be placed in the same time slot.", "In our case the tasks $ \\mathbb{T}_{1} $ and $ \\mathbb{T}_{3} $ belong to the same time slot, say time slot 1.", "Tasks $ \\mathbb{T}_{2} $ , $ \\mathbb{T}_{4} $ , and $ \\mathbb{T}_{5} $ share a common IoT devices so they have an edge between them and will be placed in three different time slots.", "Also, these tasks have an edge with $ \\mathbb{T}_{1} $ and $ \\mathbb{T}_{3} $ so they can not be placed in time slot 1.", "Let the task $ \\mathbb{T}_{2} $ , $ \\mathbb{T}_{4} $ , and $ \\mathbb{T}_{5} $ are placed in time slot 2, time slot 3, and time slot 4 respectively.", "\\newline </theorem> </subsubsection> </subsection> <subsection> <title> 4.2 Quality Determination Mechanism </title> As the quality of the IoT devices are unknown, in this section a mechanism is proposed for determining the quality of the IoT devices.", "First, the outline of the {Quality Determination Mechanism} is presented in sub section [@ref:LABEL:subsec:qdr] and in sub section [@ref:LABEL:subsec:qdrd] the detailed version of the mechanism is discussed.", "\\newline <subsubsection> <title> 4.2.1 Outline of The Quality Determination Mechanism </title> {mdframed} [backgroundcolor=gray230] \\newline Quality Determination Mechanism \\newline Repeat: \\newline <list> \\ For each task $ T_{i} $ , assign {r} IoT devices to $ r^{\\prime} $ other IoT devices for the ranking purpose; here $ r^{\\prime}\\gg r $ .", "\\newline \\ \\ Select an IoT device that appears at first place in most of the rankings.", "\\newline \\ </list> Until: Each IoT device is considered for the ranking.", "\\newline </subsubsection> <subsubsection> <title> 4.2.2 Detailed Quality Determination Mechanism </title> This section presents the detailing of the {Quality Determination Mechanism} .", "Prior to this mechanism, the {Main Routine} is presented in Algorithm [@ref:LABEL:algo:4] .", "The idea behind providing the {Main Routine} is to capture each task of the system present in different time slots.", "\\newline <float> \\ Output : $ \\mathbb{A} $ , $ \\mathbb{\\boldsymbol{P}} $ \\ \\ foreach {$ i\\in\\tau $} do \\ \\ foreach {$ \\mathbb{T}_{j}\\in i $} do \\ \\ ( $ \\pi^{j} $ , $ \\tilde{b}_{j} $ ) $ \\leftarrow $ Quality Determination Mechanism ( $ \\mathbb{T}_{j} $ , $ \\mathbb{\\boldsymbol{I}}^{j} $ ) \\ \\ ( $ \\mathbb{A}^{\\prime}_{j},\\mathbb{\\boldsymbol{P}}^{\\prime}_{j} $ ) $ \\leftarrow $ Allocation and Payment Rule ( $ \\pi^{j} $ , $ \\tilde{b}_{j} $ , $ \\mathbb{B}_{j} $ ) \\ \\ $ \\mathbb{A}\\leftarrow\\mathbb{A}\\cup\\mathbb{A}^{\\prime}_{j} $ \\ \\ $ \\mathbb{\\boldsymbol{P}}\\leftarrow\\mathbb{\\boldsymbol{P}}\\cup\\mathbb{% \\boldsymbol{P}}^{\\prime}_{j} $ \\ \\ \\ \\ end foreach \\ \\ \\ \\ end foreach \\ \\ return $ \\mathbb{A} $ , $ \\mathbb{\\boldsymbol{P}} $ \\ \\ \\ Main Routine ( $ \\mathbb{G} $ , $ \\mathbb{B} $ , $ \\mathbb{\\boldsymbol{I}} $ , $ \\tau $ , $ \\mathbb{T} $ , $ b $ ) </float> \\newline In main routine, line $ 1-8 $ keeps track of each time slot and in each time slot each task is taken care by line $ 2-7 $ .", "Line 9 returns the allocation and payment vectors for all the tasks in the system.", "In Algorithm [@ref:LABEL:algo:2] , initialization of data structures are done in line 1.", "In line 2, $ \\Psi^{\\prime}_{j} $ and $ \\Psi_{j} $ data structures keeps the copy of the IoT devices that execute the task $ \\mathbb{T}_{j} $ .", "The {do while} loop in line 3-14 iterates until all the IoT devices got ranked.", "Using line 4, {r} random IoT devices are picked up that are to be ranked and stored in the data structure $ \\Psi $ .", "Similarly, in line 5, the $ r^{\\prime} $ IoT devices other than that are selected by line 4 of Algorithm [@ref:LABEL:algo:2] are considered for the ranking process and stored in data structure $ \\varphi $ .", "Here, $ r^{\\prime}\\gg r $ .", "Line 6 assigns the completed task of each IoT device in set $ \\Psi $ to each of the IoT device $ \\mathbb{E}_{i} $ in $ \\varphi $ for ranking purpose.", "\\newline <float> \\ Output : $ \\mathbf{\\Phi}_{j}\\leftarrow\\phi $ \\ \\ $ \\Psi\\leftarrow\\phi $ , $ \\varphi\\leftarrow\\phi $ , $ \\mathcal{N}^{\\prime}\\leftarrow\\phi $ , $ \\beta\\leftarrow\\phi $ \\ \\ $ \\Psi^{\\prime}_{j}=\\Psi_{j}=\\mathbb{\\boldsymbol{I}}^{j} $ // $ \\Psi^{\\prime}_{j} $ and $ \\Psi_{j} $ keeps the copy of IoT devices that executes $ \\mathbb{T}_{j} $ .", "\\ \\ do \\ \\ $ \\Psi $ $ \\leftarrow $ Pick_random ( $ \\Psi_{j} $ , $ r $ ) //", "Pick {r} IoT devices from $ \\Psi_{j} $ .", "\\ \\ $ \\varphi $ $ \\leftarrow $ Pick_random ( $ \\Psi^{\\prime}_{j}\\setminus\\Psi $ , $ r^{\\prime} $ ) //", "Pick $ r^{\\prime} $ IoT devices from $ \\Psi^{\\prime}_{j}\\setminus\\Psi $ .", "\\ \\ Assign the completed task $ \\mathbb{T}_{j} $ of each IoT devices in $ \\Psi $ to the IoT devices in $ \\varphi $ .", "\\ \\ forall {$ \\mathbb{E}_{i}\\in\\varphi $} do \\ \\ $ \\beta\\leftarrow $ Select_best( $ \\succ_{i}^{j} $ ) //", "Select top ranked IoT device from $ {\\mathbb{E}_{i}}^{\\prime}s $ ranked list for task $ \\mathbb{T}_{j} $ given as $ \\succ_{i}^{j} $ .", "\\ \\ $ \\mathcal{N}^{\\prime}\\leftarrow\\mathcal{N}^{\\prime}\\cup\\{\\beta\\} $ // $ \\mathcal{N}^{\\prime} $ data structure allows the duplication of elements.", "\\ \\ \\ \\ end forall \\ \\ $ \\mathbf{\\Phi}_{j}\\leftarrow\\mathbf{\\Phi}_{j}\\cup\\{\\max\\limits_{\\mathbb{E}_{k}% \\in\\mathcal{N}^{\\prime}}\\{|S_{k}|\\}\\} $ // $ S_{k} $ is the set of $ {E_{k}}^{\\prime}s $ in $ \\mathcal{N}^{\\prime} $ .", "\\ \\ $ \\tilde{b}_{j} $ $ \\leftarrow $ $ \\tilde{b}_{j} $ $ \\cup $ $ \\{b_{k}^{j}\\} $ // $ \\tilde{b}_{j} $ maintains the bid values of the quality IoT devices.", "\\ \\ $ \\Psi_{j}\\leftarrow\\Psi_{j}\\setminus\\Psi $ \\ \\ while {$ \\Psi_{j}\\neq\\phi $} return $ \\mathbf{\\Phi}_{j} $ , $ \\tilde{b}_{j} $ \\ Quality Determination Mechanism ( $ \\mathbb{T}_{j} $ , $ \\mathbb{\\boldsymbol{I}}^{j} $ ) </float> \\newline Using line 7-10 for each iteration of {for} loop record about the top ranked IoT device by each $ \\mathbb{E}_{i}\\in\\varphi $ is kept in the $ \\mathcal{N}^{\\prime} $ data structure.", "In line 11, $ \\mathbf{\\Phi}_{j} $ data structure captures the IoT device that was ranked top by most of the IoT devices for task $ \\mathbb{T}_{j} $ .", "Line 13 removes the IoT devices that are ranked in the current iteration from $ \\Psi_{j} $ .", "Finally, line 14 returns $ \\mathbf{\\Phi}_{j} $ that contains the quality IoT devices for task $ \\mathbb{T}_{j} $ .", "\\newline <theorem> Example 2 .", "For the detailed illustration of Algorithm [@ref:LABEL:algo:2] we have considered the set-up discussed \\newline in Example [@ref:LABEL:sub:ncgf] .", "In this example, we have illustrated Algorithm [@ref:LABEL:algo:2] for one task, say task $ \\mathbb{T}_{1} $ .", "However, one can follow the similar procedure for the remaining tasks.", "For the $ 1^{st} $ iteration of the peer grading process, we have randomly selected 3 IoT devices ( $ r=3 $ ) say $ \\mathbb{E}_{3} $ , $ \\mathbb{E}_{9} $ , and $ \\mathbb{E}_{15} $ and assigned to the remaining IoT devices for the grading purposes.", "Next, following the Algorithm [@ref:LABEL:algo:2] , we have to check which IoT device among $ \\mathbb{E}_{3} $ , $ \\mathbb{E}_{9} $ , and $ \\mathbb{E}_{15} $ has been top ranked by the majority of the peers.", "From Figure [@ref:LABEL:fig:3(a)] one can see that $ \\mathbb{E}_{3} $ has been top ranked by the majority of the peers.", "So, for the time being $ \\mathbf{\\Phi}_{1}=\\{\\mathbb{E}_{3}\\} $ .", "In the similar fashion, we can follow the other iterations of the peer grading process as shown in Figure [@ref:LABEL:fig:3(b)] and Figure [@ref:LABEL:fig:3(c)] and determine the quality IoT devices.", "At the end of the peer grading process, the set of quality IoT devices for task $ \\mathbb{T}_{1} $ is given as $ \\mathbf{\\Phi}_{1}=\\{\\mathbb{E}_{3},\\mathbb{E}_{4},\\mathbb{E}_{6}\\} $ .", "\\newline </theorem> </subsubsection> </subsection> <subsection> <title> 4.3 Allocation and Payment Rule </title> <float> \\ Output : $ \\mathbb{A}_{j} $ , $ \\mathbb{\\boldsymbol{P}}_{j} $ \\ \\ /* Allocation Rule */ \\ \\ Sort( $ \\pi^{j} $ , $ \\tilde{b}_{j} $ ) //", "Sort $ \\pi^{j} $ based on $ \\tilde{b}_{j} $ as $ b_{1}^{j}\\leq b_{2}^{j}\\leq\\ldots\\leq b_{\\tilde{k}_{j}}^{j} $ ; such that $ \\tilde{k}_{j}<k_{j} $ \\ \\ $ k\\leftarrow 1 $ \\ \\ while {$ b_{i}^{j}\\leq\\frac{\\mathbb{B}_{j}}{k} $} do \\ \\ $ \\mathbb{A}_{j}\\leftarrow\\mathbb{A}_{j}\\cup\\{\\mathbb{E}_{i}\\} $ \\ \\ $ k\\leftarrow k+1 $ \\ \\ end while \\ \\ /* Payment Rule */ \\ \\ foreach {$ \\mathbb{E}_{i}\\in\\mathbb{A}_{j} $} do \\ \\ $ \\mathbb{\\boldsymbol{P}}_{i}^{j}\\leftarrow\\{min\\{\\frac{\\mathbb{B}_{j}}{k},b_% {k+1}^{j}\\}\\} $ \\ \\ $ \\mathbb{\\boldsymbol{P}}_{j}\\leftarrow\\mathbb{\\boldsymbol{P}}_{j}\\cup\\{\\mathbb{% \\boldsymbol{P}}_{i}^{j}\\} $ \\ \\ end foreach \\ \\ return $ \\mathbb{A}_{j} $ , $ \\mathbb{\\boldsymbol{P}}_{j} $ \\ \\ \\ Allocation and Payment Rule ( $ \\pi^{j} $ , $ \\tilde{b}_{j} $ , $ \\mathbb{B}_{j} $ ) </float> \\newline This section explains the {Allocation and Payment Rule} presented in the Algorithm [@ref:LABEL:algo:5] .", "Considering the allocation rule, in line 1 first the quality IoT devices in $ \\pi^{j} $ is sorted in increasing order based on the bid vector $ \\tilde{b}_{j} $ .", "The variable {k} is initialized to 1.", "The {while} loop in line $ 3-6 $ determines the largest index {k} that satisfies the stopping condition of the {while} loop.", "The $ \\mathbb{A}_{j} $ data structure in line 4 keeps track of winning IoT devices.", "Talking about the payment rule, for each $ \\mathbb{E}_{i} $ in $ \\mathbb{A}_{j} $ the minimum among $ \\frac{\\mathbb{B}_{j}}{k} $ and $ b_{k+1}^{j} $ is taken as the payment.", "Finally, line 11 returns the allocation and payment for the task $ \\mathbb{T}_{j} $ .", "\\newline <theorem> Example 3 .", "For understanding the allocation and payment rule, let us continue with the quality IoT devices resulted from Example [@ref:LABEL:sub:ncgf2] .", "The budget given for task $ \\mathbb{T}_{1} $ is 50 $.", "The quality IoT devices along with their bid values is depicted in Figure [@ref:LABEL:fig:3a] .", "Utilizing Algorithm [@ref:LABEL:algo:5] in the set-up shown in Figure [@ref:LABEL:Fig:3a] , first the IoT devices are sorted in decreasing order of their bid value as shown in Figure [@ref:LABEL:fig:3b] .", "In our case, from the ordering, first $ \\mathbb{E}_{4} $ is picked up and considered as the check $ 10\\leq\\frac{50}{1} $ is satisfied for $ \\mathbb{E}_{4} $ .", "Next, $ \\mathbb{E}_{3} $ is picked up from the ordering and is also considered because of the similar reason.", "Next, $ \\mathbb{E}_{6} $ is picked up from the ordering and will be not be considered as the check $ 30\\leq\\frac{50}{3} $ is not satisfied.", "\\newline So, we have $ \\mathcal{A}_{1}=\\{\\mathbb{E}_{4},\\mathbb{E}_{3}\\} $ as the winning set.", "So, we get the {k} value as 2 for our example.", "Next, the payment calculation of the $ \\mathbb{E}_{4} $ and $ \\mathbb{E}_{3} $ is presented in Figure [@ref:LABEL:fig:3c] .", "For $ \\mathbb{E}_{4} $ we have $ \\mathbb{\\boldsymbol{P}}_{4}^{1}=min\\{\\frac{50}{2},30\\}=25 $ , and for $ \\mathbb{E}_{3} $ we have $ \\mathbb{\\boldsymbol{P}}_{3}^{1}=min\\{\\frac{50}{2},30\\}=25 $ .", "\\newline </theorem> <theorem> Example 4 .", "As in the above example, it can be seen that the payment for both the IoT devices is the left term of the payment rule, so the remaining budget is zero.", "In order to see when the right term of the payment rule will be coming into picture the example in Figure [@ref:LABEL:Fig:3] is repeated for different bid configuration in Figure [@ref:LABEL:Fig:4] .", "\\newline In this example, the allocation set will be similar to what we obtained for Example [@ref:LABEL:sec:ex] as shown in Figure [@ref:LABEL:fig:4b] .", "The payment calculation of the IoT devices $ \\mathbb{E}_{4} $ and $ \\mathbb{E}_{3} $ is presented in Figure [@ref:LABEL:fig:4c] .", "For $ \\mathbb{E}_{4} $ we have $ \\mathbb{\\boldsymbol{P}}_{4}^{1}=min\\{\\frac{50}{2},21\\}=21 $ , and for $ \\mathbb{E}_{3} $ we have $ \\mathbb{\\boldsymbol{P}}_{3}^{1}=min\\{\\frac{50}{2},21\\}=21 $ .", "\\newline </theorem> </subsection>  </section>"], ["<section> <title> 5 Analysis of TUBE-TAP </title>  This section presents the analysis of TUBE-TAP.", "\\newline <theorem> Proposition 5.1 .", "The proposed mechanism in [@bib:Singer_2016] has an approximation ratio of 2.", "\\newline </theorem> <theorem> Lemma 5.2 .", "TUBE-TAP is truthful.", "\\newline </theorem> <proof> Proof.", "The proof is divided into two cases.", "In the first case, we have taken an arbitrary winning IoT device into consideration and discuss the impact on its gain (or utility), when it {deviates} from its true valuation.", "In second case, we have considered any arbitrary losing IoT device and analysis similar to Case 1 is done.", "Fix a task $ \\mathbb{T}_{j} $ .", "\\newline </proof> <paragraph> <title> Case 1: </title> Let us suppose that $ i^{th} $ winning IoT device deviates from its true value and reports a bid value $ b_{i}^{j}<v_{i}^{j} $ .", "As the IoT device $ \\mathbb{E}_{i} $ was winning with $ v_{i}^{j} $ it will continue to win with $ b_{i}^{j} $ because by reporting value lesser than the true value, it will be appearing early in the ordering.", "So, its utility will be $ \\hat{u}_{i}^{j}=\\mathbb{\\boldsymbol{P}}_{i}^{j}-v_{i}^{j} $ which is same as $ u_{i}^{j} $ . But, if it reports $ b_{i}^{j}>v_{i}^{j} $ , this gives rise to two possibilities.", "One possibility could be, it would continue to win by appearing later in the ordering and in that case his utility will be $ \\hat{u}_{i}^{j}=\\mathbb{\\boldsymbol{P}}_{i}^{j}-v_{i}^{j}=u_{i}^{j} $ .", "Another possibility could be, it may lose by appearing later in the ordering in that case its utility will be $ \\hat{u}_{i}^{j} $ = 0.", "\\newline </paragraph> <paragraph> <title> Case 2: </title> Let us suppose that $ i^{th} $ losing IoT device deviates from its true value and reports a bid value $ b_{i}^{j}>v_{i}^{j} $ .", "As the IoT device $ \\mathbb{E}_{i} $ was losing with $ v_{i}^{j} $ it will continue to lose by $ b_{i}^{j} $ because by deviating this way it will be appearing later in the ordering.", "So, its gain will be $ \\hat{u}_{i}^{j} $ = 0 which is same as $ u_{i}^{j} $ . But, if it reports $ b_{i}^{j}<v_{i}^{j} $ , then the two possibilities arises.", "One possibility could be, by deviating this way it could appear early in the ordering but still continue to lose and in that case $ \\hat{u}_{i}^{j} $ = 0 which is same as $ u_{i}^{j} $ .", "Another possibility could be, it could win, in that case it had defeated the IoT device $ \\mathbb{E}_{k} $ with valuation $ v_{k}^{j}<v_{i}^{j} $ and hence $ b_{i}^{j}<v_{k}^{j} $ .", "In this case, its payment will be less as compared to its true valuation.", "So, its utility $ \\hat{u}_{i}^{j}=\\mathbb{\\boldsymbol{P}}_{i}^{j}-v_{i}^{j}<0 $ .", "Hence, no gain is achieved.", "Considering Case 1 and Case 2, it can be concluded that the IoT devices cannot gain by misreporting their true value.", "So, TUBE-TAP is truthful.", "\u220e \\newline <theorem> Lemma 5.3 .", "In TUBE-TAP, for each task requester $ \\mathbb{R}_{j} $ the total payment $ \\mathbb{\\boldsymbol{P}}_{j} $ made to the IoT devices are within available budget $ \\mathbb{B}_{j} $ .", "More formally, $ \\mathbb{\\boldsymbol{P}}_{j} $ = $ \\sum\\limits_{\\mathbb{E}_{i}\\in\\mathcal{A}_{j}}\\mathbb{\\boldsymbol{P}}_{i}^{j}% \\leq\\mathbb{B}_{j} $ .", "Also, $ \\sum\\limits_{\\mathcal{A}_{j}\\in\\mathcal{A}}\\sum\\limits_{\\mathbb{E}_{i}\\in% \\mathcal{A}_{j}}\\mathbb{\\boldsymbol{P}}_{i}^{j}\\leq\\sum\\limits_{\\mathbb{T}_{j}% \\in\\mathbb{T}}\\mathbb{B}_{j} $ .", "\\newline </theorem> <proof> Proof.", "Fix a task requester $ \\mathbb{R}_{j} $ and a task $ \\mathbb{T}_{j} $ .", "From the construction of TUBE-TAP, it is clear that, the maximum payment that any winning IoT device will be paid is $ \\frac{\\mathbb{B}_{j}}{k} $ ; where {k} is the largest index obtained in the ordering of IoT devices that satisfies $ b_{k}^{j}\\leq\\frac{\\mathbb{B}_{j}}{k} $ .", "Now, the total payment $ \\mathbb{\\boldsymbol{P}}_{j} $ is given as: \\newline <equation> $ \\mathbb{\\boldsymbol{P}}_{j}=\\sum\\limits_{\\mathbb{E}_{i}\\in\\mathcal{A}_{j}}% \\mathbb{\\boldsymbol{P}}_{i}^{j}\\leq\\sum_{\\mathbb{E}_{i}\\in\\mathcal{A}_{j}}% \\frac{\\mathbb{B}_{j}}{k}=\\frac{\\mathbb{B}_{j}}{k}\\times k=\\mathbb{B}_{j} $ </equation> From here we can say that, $ \\mathbb{\\boldsymbol{P}}_{j}\\leq\\mathbb{B}_{j} $ .", "As this is true for any task $ \\mathbb{T}_{j} $ , so the budget feasibility will hold for all the available tasks $ i.e. $ $ \\sum\\limits_{\\mathcal{A}_{j}\\in\\mathcal{A}}\\sum\\limits_{\\mathbb{E}_{i}\\in% \\mathcal{A}_{j}}\\mathbb{\\boldsymbol{P}}_{i}^{j}\\leq\\sum\\limits_{\\mathbb{T}_{j}% \\in\\mathbb{T}}\\mathbb{B}_{j} $ .", "This completes the proof.", "\u220e \\newline </proof> <theorem> Lemma 5.4 .", "The allocation resulted by TUBE-TAP is at most 2 allocation away from the optimal one $ i.e. $ $ OPT\\leq 2\\times OM $ ; where OPT is the optimal allocation and OM is the allocation resulted by TUBE-TAP.", "\\newline </theorem> <proof> Proof.", "Fix a task requester $ \\mathbb{R}_{i} $ and task $ \\mathbb{T}_{i} $ .", "Let us suppose for the sake of contradiction that the OPT consists of {k} IoT devices $ i.e. $ $ |OPT|=k $ and OM consists of less than $ \\frac{k}{2} $ IoT devices $ i.e. $ $ |OM|<\\frac{k}{2} $ .", "It implies that, $ b_{\\frac{k}{2}}^{i}>\\frac{\\mathbb{B}_{i}}{k/2} $ .", "Note however, that this is impossible since we assume that $ b_{\\frac{k}{2}}^{i}\\leq\\ldots\\leq b_{k}^{i} $ , and $ \\sum_{j=\\frac{k}{2}}^{k}b_{j}^{i}\\leq\\mathbb{B}_{i} $ which implies that $ b_{\\frac{k}{2}}^{i}\\leq\\frac{\\mathbb{B}_{i}}{k/2} $ .", "Hence a contradiction.", "\u220e \\newline </proof> <theorem> Lemma 5.5 . Let $ \\mathbb{U} $ be the event given as $ \\mathbb{U}=\\{\\mathbb{E}_{i} $ is considered for task $ \\mathbb{T}_{j} $ } and $ X_{j}^{i} $ is an indicator random variable defined as $ X_{j}^{i} $ = I $ \\{\\mathbb{U}\\} $ .", "Then, the expectation is just the probability of the corresponding event $ i.e. $ $ E[X_{j}^{i}] $ = Pr {$ \\mathbb{U} $ } [@bib:Coreman_2009] .", "\\newline </theorem> <proof> Proof.", "By the definition of indicator random variable, we can write $ X_{j}^{i} $ is 1 when $ \\mathbb{U} $ occurs and 0 when $ \\mathbb{U} $ does not occurs.", "So, as $ X_{j}^{i} $ = I{$ \\mathbb{U} $ }.", "Taking expectation both side, we get \\newline <equation> $ E[X_{j}^{i}]=E[I\\{\\mathbb{U}\\}] $ </equation> <equation> $ \\hskip 99.584646pt=1\\cdot Pr\\{\\mathbb{U}\\}+0\\cdot Pr\\{\\mathbb{\\bar{U}}\\} $ </equation> <equation> $ E[X_{j}^{i}]=Pr\\{\\mathbb{U}\\} $ </equation> where, $ \\mathbb{\\bar{U}} $ denotes $ S-\\mathbb{U} $ such that $ S $ is the sample space.", "\u220e \\newline </proof> <theorem> Lemma 5.6 .", "The expected number of times any arbitrary $ \\mathbb{E}_{i} $ is considered (or winning) is given as $ p\\cdot k_{i} $ ; where $ k_{i} $ is the number of tasks for which the $ i^{th} $ IoT device has shown interest and p is the probability with which $ \\mathbb{E}_{i} $ is considered for a task.", "In other words, $ E[X^{i}]=p\\cdot k_{i} $ ; where $ X^{i} $ is the random variable measuring the number of times $ \\mathbb{E}_{i} $ is considered out of $ k_{i} $ .", "\\newline </theorem> <proof> Proof.", "Fix an IoT device $ \\mathbb{E}_{i} $ , we now wish to compute the expected number of times the $ \\mathbb{E}_{i} $ is considered.", "We capture the total number of times $ \\mathbb{E}_{i} $ is considered out of $ k_{i} $ by $ X^{i} $ random variable.", "So, the expected number of times $ \\mathbb{E}_{i} $ is considered is given as $ E[X^{i}] $ .", "Our sample space for $ \\mathbb{E}_{i} $ IoT device for any task $ \\mathbb{T}_{j} $ is $ S $ = $ \\{\\mathbb{E}_{i} $ is considered for task $ \\mathbb{T}_{j} $ , $ \\mathbb{E}_{i} $ not considered for task $ \\mathbb{T}_{j}\\} $ .", "So, we have Pr{$ \\mathbb{E}_{i} $ is considered for task $ \\mathbb{T}_{j} $ }= $ p $ and Pr{$ \\mathbb{E}_{i} $ is not considered for task $ \\mathbb{T}_{j} $ } = $ 1-p $ .", "We define the indicator random variable $ X_{j}^{i} $ as $ X_{j}^{i} $ = I{$ \\mathbb{E}_{i} $ is considered for task $ \\mathbb{T}_{j} $ }; where \\newline <equation> $ X_{j}^{i}=\\begin{cases}1,&\\textit{if $\\mathbb{E}_{i}$ is considered for task $% \\mathbb{T}_{j}$}\\\\ 0,&\\textit{Otherwise}\\end{cases} $ </equation>", "The expected number of times $ \\mathbb{E}_{i} $ is considered for task $ \\mathbb{T}_{j} $ is simply the expected value of our indicator random variable $ X_{j}^{i} $ : \\newline <equation> $ E[X_{j}^{i}]=E[I\\{\\mathbb{E}_{i}isconsideredfortask\\mathbb{T}_{% j}\\}] $ </equation>", "As always with the indicator random variable, the expectation is just the probability of the corresponding event (using lemma [@ref:LABEL:lemma:4] ): \\newline <equation> $ E[X_{j}^{i}]=1\\cdot Pr\\{X_{j}^{i}=1\\}+0\\cdot Pr\\{X_{j}^{i}=0\\} $ </equation> <equation> $ \\hskip-42.679134pt=1\\cdot p+0\\cdot(1-p) $ </equation> <equation> $ \\hskip-99.584646pt=1\\cdot p $ </equation> <equation> $ \\hskip-142.26378ptE[X_{j}^{i}]=p $ </equation> Now, let us consider the random variable that we are interested in and is given by $ X^{i}=\\sum\\limits_{j=1}^{k_{i}}X_{j}^{i} $ .", "We can compute $ E[X^{i}] $ by taking expectation both side, we get: \\newline <equation> $ E[X^{i}]=E\\bigg{[}\\sum_{j=1}^{k_{i}}X_{j}^{i}\\bigg{]} $ </equation> By linearity of expectation, we get \\newline <equation> $ E[X^{i}]=\\sum_{j=1}^{k_{i}}E[X_{j}^{i}] $ </equation> From lemma [@ref:LABEL:lemma:4] it can be seen that, the expected value of any random variable is equal to the probability of the corresponding event.", "So, \\newline <equation> $ E[X^{i}]=\\sum_{j=1}^{k_{i}}Pr\\{\\mathbb{E}_{i}isconsideredfortask{% }\\mathbb{T}_{j}\\} $ </equation> <equation> $ \\hskip-128.037402pt=\\sum_{j=1}^{k_{i}}p $ </equation> <equation> $ \\hskip-128.037402pt=p\\cdot k_{i}. $ </equation>", "Hence, the claim survived.", "It is to be noted that if $ p=\\frac{1}{2} $ , then the value of $ E[X^{i}] $ boils down to $ \\frac{k_{i}}{2} $ .", "It means that, any arbitrary $ \\mathbb{E}_{i} $ in expectation will be considered for half of number of tasks on which it has shown interest.", "\u220e \\newline </proof> <theorem> Lemma 5.7 .", "For any arbitrary IoT device $ \\mathbb{E}_{i} $ the expected number of longest contiguous rejection out of $ k_{i} $ tasks after which the IoT device is considered is given as $ \\Theta(\\log_{p}k_{i}) $ .", "More formally, we can say $ E[Y]=\\Theta(\\log_{p}k_{i}) $ ; where $ Y $ is a random variable that captures the longest continuous rejection of any IoT device.", "\\newline </theorem> <proof> Proof.", "Fix an IoT device $ \\mathbb{E}_{i} $ .", "In similar line the proof is illustrated in [@bib:Coreman_2009] .", "Our proof is divided into two cases.", "From Lemma [@ref:LABEL:lemma:5] it can be seen that the probability that $ \\mathbb{E}_{i} $ will be considered for any task $ \\mathbb{T}_{j} $ is $ p $ . Let $ X^{i}_{kl}=I\\{A_{kl}^{i}\\} $ be the indicator random variable associated with an event that the IoT device $ \\mathbb{E}_{i} $ is rejected for at least {l} tasks starting form $ k^{th} $ task.", "It is to be noted that, the participation in one time slot by the IoT device is independent of the participation in other time slots.", "So, for any given event $ X^{i}_{kl} $ , the probability that for all {l} tasks the IoT device is rejected is given as \\newline <equation> $ Pr\\{A_{kl}^{i}\\}=p\\cdot p\\cdot\\cdot\\cdot ltimes=p^{l} $ </equation> As in our case, {k} varies from 1 to $ k_{i}-l+1 $ (i.e. $ 1\\leq k\\leq k_{i}-l+1 $ ), so the total number of such rejections could be formulated as: \\newline <equation> $ Y=\\sum\\limits_{k=1}^{k_{i}-l+1}X^{i}_{kl} $ </equation> Taking expectation both side, we get \\newline <equation> $ E[Y]=E\\bigg{[}\\sum\\limits_{k=1}^{k_{i}-l+1}X^{i}_{kl}\\bigg{]} $ </equation> By linearity of expectation, we get \\newline <equation> $ \\hskip 19.916929pt=\\sum\\limits_{k=1}^{k_{i}-l+1}E[X^{i}_{kl}] $ </equation> From the definition of expectation in Lemma [@ref:LABEL:lemma:4] , we have \\newline <equation> $ E[Y]=\\sum\\limits_{k=1}^{k_{i}-l+1}Pr\\{A_{kl}^{i}\\} $ </equation> Using equation [@ref:LABEL:equation:17] , we get \\newline <equation> $ =\\sum\\limits_{k=1}^{k_{i}-l+1}p^{l} $ </equation> <equation> $ E[Y]=(k_{i}-l+1)\\cdot p^{l} $ </equation> Now, for $ l=c\\log_{p}k_{i} $ and for some positive constant $ c $ , we obtain \\newline <equation> $ E[Y]=(k_{i}-c\\log_{p}k_{i}+1)\\cdot p^{c\\log_{p}k_{i}} $ </equation> <equation> $ \\hskip 8.535827pt=(k_{i}-c\\log_{p}k_{i}+1)\\cdot k_{i}^{c} $ </equation> <equation> $ \\hskip 17.071654pt=k_{i}^{c+1}-ck_{i}^{c}\\log_{p}k_{i}+k_{i}^{c} $ </equation> <equation> $ \\hskip-62.596063pt=\\Theta(k_{i}^{c}) $ </equation> From here we can conclude that, for some constant $ c\\geq 1 $ the longest continuous rejection boils down to $ \\Theta(\\log_{p}k_{i}) $ .", "Hence, the claim survived.", "\u220e \\newline </proof> <theorem> Lemma 5.8 .", "In our system, the probability that any arbitrary IoT device $ \\mathbb{E}_{i} $ is considered (or wins) for at least one time out of $ k_{i} $ is greater than or equal to $ 1-\\frac{1}{e^{p\\cdot k_{i}}} $ ; where $ k_{i} $ is the number of tasks for which the $ i^{th} $ IoT device has shown interest.", "In other words, $ Pr[X^{i}\\geq 1]\\geq\\bigg{(}1-\\frac{1}{e^{p\\cdot k_{i}}}\\bigg{)} $ ; where $ X^{i} $ is the random variable measuring the number of times $ \\mathbb{E}_{i} $ IoT device is considered out of $ k_{i} $ .", "\\newline </theorem> <proof> Proof.", "Fix an IoT device $ \\mathbb{E}_{i} $ .", "As $ \\mathbb{E}_{i} $ has shown interest on $ k_{i} $ tasks that are present in different time slots.", "The probability that $ \\mathbb{E}_{i} $ will be considered for task $ \\mathbb{T}_{j} $ is $ p $ (Pr{$ \\mathbb{E}_{i} $ is not considered for task $ \\mathbb{T}_{j} $ } = $ 1-p $ ).", "Also, it can be seen that, the consideration of $ \\mathbb{E}_{i} $ in any time slot is independent of other time slots.", "So, the probability that $ \\mathbb{E}_{i} $ will not be considered at all for any of the $ k_{i} $ tasks is given as: \\newline <equation> $ Pr[X^{i}<1]=(1-p)\\cdot(1-p)\\ldots k_{i}times $ </equation> <equation> $ \\hskip-34.143307pt=(1-p)^{k_{i}} $ </equation> Following the inequality $ 1+x\\leq e^{x} $ , we get \\newline <equation> $ Pr[X^{i}<1]\\leq e^{-p\\cdot k_{i}}=\\frac{1}{e^{p\\cdot k_{i}}} $ </equation> Now, the probability that any $ \\mathbb{E}_{i} $ will be considered at least once is given as \\newline <equation> $ Pr[X^{i}\\geq 1]\\geq\\bigg{(}1-\\frac{1}{e^{p\\cdot k_{i}}}\\bigg{)} $ </equation>", "Hence, the claim survives.", "Also, for $ p=\\ln 2 $ , we can see that \\newline <equation> $ Pr[X^{i}\\geq 1]\\geq\\bigg{(}1-\\frac{1}{e^{\\ln 2\\cdot k_{i}}}\\bigg{)} $ </equation> <equation> $ \\hskip 42.679134pt=\\bigg{(}1-\\frac{1}{2k_{i}}\\bigg{)} $ </equation> It can be concluded that, the term $ \\frac{1}{2k_{i}} $ represents that any arbitrary $ \\mathbb{E}_{i} $ will not be considered at all is very small, and can say that it is very unlikely to occur.", "So, the term $ (1-\\frac{1}{2k_{i}}) $ will be quite large and hence can say that any IoT device could be considered for at least once with larger probability.", "\u220e \\newline </proof> </paragraph>  </section>"], ["<section> <title> 6 Experimental Findings </title>  In this section, we measure the efficacy of our proposed mechanism called TUBE-TAP via simulation.", "It is to be noted that, the TUBE-TAP is compared with the carefully crafted benchmark mechanism that is {non-truthful} in nature.", "The manipulative behaviour of the IoT devices in case of benchmark mechanism can be seen evidently in the simulation results.", "It is to be noted that, our benchmark mechanism differs in terms of {allocation} and {payment} policy from the TUBE-TAP.", "In the benchmark mechanism, for each task, first the IoT devices are sorted in increasing order of their bid value.", "Afterwards, the IoT devices are picked up sequentially one at a time from the ordering and check is made that: whether {the sum of the valuation of the IoT device next to it in the ordering and some small constant value (say $ \\epsilon $ ) is less than or equal to the remaining budget associated with the task} or not.", "If the stopping condition is satisfied, then the IoT device will be declared as winner, otherwise not.", "After the declaration of winner set, the payment of any IoT device in the winning set is the sum of the bid value of the IoT device following it in the sorted ordering and the $ \\epsilon $ value.", "More formally, the payment of any $ i^{th} $ IoT device for the task $ \\mathbb{T}_{j} $ is given as $ \\mathbb{\\boldsymbol{P}}_{i}^{j}=b_{i+1}^{j}+\\epsilon $ ; where $ b_{i+1}^{j} $ is the bid value of the IoT device following {i} in the sorted ordering.", "It is to be noted that the $ \\epsilon $ value is same throughout the system, it is taken as $ \\epsilon=10 $ in our case.", "The unit of bid value and the budget is taken as $.", "The experiments are carried out using Python.", "\\newline <subsection> <title> 6.1 Simulation Set-up </title> For our simulation purpose, we have varied the number of task requesters and the number of IoT devices so as to analyse the results in a more better sense."]], "target": "Table shows the configuration of different values of number of task requesters and number of IoT devices that has been utilized for the simulation purpose. For each configuration, the experiment runs for 50 rounds ad the required values are plotted by taking average over these 50 rounds. Other than this, in order to strengthen our claim, we have simulated the mechanisms for two different probability distributions independently; namely, {uniform distribution} (UD) and {normal distribution} (ND). Throughout the experiment, the bid value range (in case of UD) for IoT devices and the budget range for the tasks are kept fixed. It is to be noted that, budget is uniformly distributed within the given range for both ND and UD. Considering the case of ND, for generating the bid values of the IoT devices the mean is taken as 110 and standard deviation is taken as 15."}, {"tabular": ["    &  Vertices  &  Edges  &  Communities ", " Youtube  &  1,134,890  &  2,987,624  &  8,385 ", " LiveJournal  &  3,997,962  &  34,681,189  &  287,512 ", " Orkut  &  3,072,441  &  117,185,083  &  6,288,363 ", " Friendster  &  65,608,366  &  1,806,067,135  &  957,154  "], "ref_sec": [["<section> <title> I Introduction </title>  Due to the generality of the graph as a data structure, graphs correspond well to many different systems in the real world, like social networks, molecules, road maps, and more; and many problems can be expressed intuitively and solved using a graph representation.", "One such problem whose solution has many applications is that of {community detection} \u2013 automatically identifying groups of vertices that are tightly connected among themselves and loosely connected with the rest of the graph.", "In social networks, for example, the identification of communities can help with targeted marketing; or in a network of items that are frequently purchased together, community detection could be used to make recommendations.", "\\newline As the graphs being operated on become larger and larger, the ability to process them in memory on one machine becomes infeasible due to both time and memory constraints.", "For these two reasons, complexity and size, distributed algorithms have become necessary to solve problems on large graphs.", "In this paper, we present a distributed algorithm for optimizing WCC [@bib:wcc] , a recently proposed metric for judging the quality of community partitionings.", "The algorithm scales well on real graphs of up to 1.8 billion edges and outperforms a parallel, centralized algorithm that also seeks to optimize WCC [@bib:scd] .", "The algorithm follows the vertex-centric paradigm introduced by the Pregel platform [@bib:pregel] , and to the best of our knowledge, it is the first distributed algorithm for optimizing the WCC metric.", "\\newline The structure of the paper is as follows.", "In Section [@ref:LABEL:sec:relwork] , we begin by presenting an overview of related work in community detection and distributed community detection.", "Next, in Section [@ref:LABEL:sec:background] , we introduce background material and the terminology used in the rest of the paper.", "Following this, the proposed algorithm is explained in Section [@ref:LABEL:sec:algorithm] , followed by experimentation in Section [@ref:LABEL:sec:experimentation] .", "We conclude with a discussion of future work.", "\\newline  </section>"], ["<section> <title> II Related Work </title>  Most of the research on community detection algorithms has focused on single threaded algorithms on SMP machines.", "The list of proposals is rich and diverse, with those based on modularity maximization forming the most prominent family of community detection algorithms [@bib:newman2004finding] .", "Modularity is a community detection metric that rewards those partitions with communities with an internal edge density larger than that expected in a null model.", "Several strategies have been proposed for its optimization, such as agglomerative greedy [@bib:clauset2004finding] or simulated annealing [@bib:medus2005detection] .", "One of the most famous and widely used community detection algorithms based on modularity maximization is the {Louvain} method [@bib:blondel2008fast] , a multilevel approach that scales to graphs with hundreds of millions of objects.", "However, the quality of its results decreases considerably as the size of the graph increases [@bib:lancichinetti2009community] .", "More importantly, it has been reported that modularity has resolution limits [@bib:fortunato2007resolution,bagrow2012communities] , which means that modularity is unable to detect small and well-defined communities when the graph is large.", "Related to this, recent studies have proven not only that modularity has detectability issues [@bib:nadakuditi2012graph] (i.e. it is not able to identify communities even if they are well defined), but also that the identification of well-defined communities is more difficult than ill-defined ones [@bib:radicchi2014paradox] .", "Although it has not been studied whether or not $ WCC $ also suffers from these problems, properties presented in [@bib:wcc] suggest that algorithms based on $ WCC $ are able to deliver cohesive and structured communities regardless of the size of the graph.", "\\newline There also exist several proposals based on random walks.", "The intuition is that in a random walk, the probability of remaining inside of a community is higher than going outside, due to the higher density of internal edges.", "This strategy is the main idea exploited in Walktrap [@bib:Pons06] .", "Another algorithm based on random walks that is highly adopted in the literature is Infomap [@bib:rosvall2008maps] , which searches for a codification for describing random walks based on communities.", "The codification that requires the least amount of memory (attains the highest compression rates) is selected.", "According to the comparison performed by Lancichinetti et al. [@bib:lancichinetti2009community] , Infomap stands as one of the best community detection algorithms in the literature.", "\\newline Another category of algorithms is formed by those capable of finding overlapping communities, which have gained significant interest during the last years.", "We find several proposals, such as Oslom [@bib:lancichinetti2011finding] , which uses the {significance} as a fitness measure in order to assess the quality of a community.", "Similar to modularity, the significance is defined as the probability of finding a given cluster in a random null model.", "Another algorithm that falls into this category is the Link Clustering Algorithm (LCA) [@bib:ahn2010link] .", "This algorithm is based on the idea of taking edges instead of vertices to form a community.", "The similarity of adjacent vertices is assessed by looking at the Jaccard coefficient of the adjacency lists of the two vertices of the edges.", "Those edges connecting vertices with high similarity are assigned to the same community, and so overlapping communities emerge naturally.", "Finally, a recently proposed algorithm is BigClam by Yang et al. [@bib:YangL13] .", "This algorithm is based on computing an affiliation of vertices to communities that maximizes an objective function using non-negative matrix factorization.", "The objective function is based on the intuition that the probability of an edge existing between two vertices increases with the number of communities the vertices share (i.e. the number of communities in which the vertices overlap).", "\\newline Most of the work regarding the exploitation of parallelism for community detection has the form of multithreaded algorithms for SMP machines.", "In [@bib:lu2014parallel] , authors propose a parallel version of the {Louvain} method, which achieves an speedup of 16x using 32 threads.", "Similarly, in [@bib:riedy2012scalable] Riedy et al. propose an agglomerative modularity optimization algorithm for the Cray XMT and Intel based machines, capable of analyzing a graph with 100 million nodes and 3.3 billion edges in 500 seconds.", "Finally, in [@bib:bae2013scalable] the authors propose a parallel version of Infomap, called RelaxMap that relaxes concurrency assumptions of the original method, achieving a parallel efficiency of about 70%.", "\\newline There has been little work regarding distributed algorithms for community detection.", "One family of algorithms that fit well into the vertex-centric model are those based on label propagation [@bib:raghavan2007,xie2012] .", "In label propagation, each vertex is initialized with a unique label, and then, they define rules that simulate the spread of these labels in the network similarly to infections.", "Label propagation has the advantage of being asymptotically efficient, but no theoretical guarantees are given regarding the quality of the results, especially in networks where communities are not well-defined.", "\\newline  </section>"], ["<section> <title> III Background & Terminology </title>  Informally stated, the goal of community detection is, given a graph, to divide the graph into groups (communities) of vertices such that, within a group, vertices are tightly connected, and between groups, there are few connections.", "For non-overlapping community detection, which is the focus of this paper, no two communities contain the same vertex.", "There are two primary aspects of this problem.", "First, it is necessary to give a formal definition of a metric that defines the quality of a given grouping, or partitioning , of a graph.", "The next step is to create an algorithm to find one or more partitionings of the graph that optimize this metric.", "\\newline In this paper, we address the second part of this problem by proposing a scalable, distributed algorithm for the optimization of the WCC metric proposed in [@bib:wcc] .", "This metric is defined on unweighted, undirected graphs.", "Inspired by properties of real-life networks, the basic idea behind the metric is that within a community, vertices should have a high concentration of triangles among themselves, and they should close more triangles with other vertices in the community than with vertices outside of the community.", "Using this idea, given an undirected, unweighted graph $ G(V,E) $ , the quality of a community may then be defined as the average cohesion of each of its member vertices to the other vertices in the community, where the cohesion of a vertex $ x $ to a set of vertices $ S $ is defined as \\newline <equation> $ WCC(x,S)=\\begin{cases}\\frac{t(x,S)}{t(x,V)}\\cdot\\frac{vt(x,V)}{|S\\backslash\\{x% \\}|+vt(x,V\\backslash S)}&\\text{if }t(x,V)\\neq 0\\\\ 0&\\text{if }t(x,V)=0\\end{cases} $ </equation>", "The function $ t(x,S) $ here gives the number of triangles closed by $ x $ with other vertices in $ S $ , and the function $ vt(x,S) $ gives the number of unique vertices contained in all such triangles.", "This cohesion metric therefore rewards a high ratio of triangles closed within the community versus triangles closed outside of the community (the left-hand term) and punishes vertices that have a high number of vertices in its community with which it does not close any triangle (the right-hand term).", "In other words, the left term promotes that the communities are well defined and isolated from the rest of the graph; and the right term promotes that all nodes in the community are interconnected and form triangles.", "\\newline The quality of a partitioning is the average quality of each vertex in its assigned community.", "So, for a set $ S $ , $ WCC(S) $ is defined as the average $ \\forall x\\in S $ of $ WCC(x,S) $ , and the final $ WCC $ of a partitioning $ \\mathcal{P}=\\{C_{1},\\dots,C_{n}\\} $ of $ V $ is then defined as \\newline <equation> $ WCC(\\mathcal{P})=\\frac{1}{|V|}\\sum_{S\\in\\mathcal{P}}\\sum_{x\\in S}WCC(x,S).", "$ </equation> In practice, the optimization of this metric results in high quality partitionings that correspond well to ground-truth communities, and it satisfies a number of desirable theoretical properties.", "For more information on the metric itself see [@bib:wcc] .", "\\newline  </section>"], ["<section> <title> IV Presentation of Algorithm </title>  Our algorithm for optimizing this metric consists of three basic phases: preprocessing, community initialization, and WCC iteration.", "In the first phase, the values of $ t(x,V) $ and $ vt(x,V) $ are computed for every vertex, and all edges that do not belong to any triangles are removed from the graph.", "Next, the local clustering coefficient of each vertex is computed, and an initial partitioning of the graph is determined based on these coefficients.", "From this initial partitioning, the WCC iteration process is repeatedly applied, where each vertex chooses a new community simultaneously based on a heuristic and the global WCC value is computed.", "The algorithm halts when the WCC value converges.", "An overview of the algorithm can be seen in Figure [@ref:LABEL:fig:alg_overview] .", "\\newline <subsection> <title> IV-A Preprocessing </title> The preprocessing portion of the algorithm is responsible for two things: counting, for each vertex, the total of number of triangles it belongs to in the graph ( $ t(x,V) $ ), and removing all edges which do not belong to any triangles.", "After removing all such edges, $ vt(x,V) $ is simply the degree of the vertex $ x $ .", "This filtering step improves performance and allows simplifying assumptions later when deciding whether to transfer a vertex from one community to another.", "Note that these two values are constant throughout computation and therefore only need to be calculated once.", "\\newline Given two vertices $ u $ and $ v $ , a standard way to compute the number of triangles they form together (the number of triangles in which the edge $ (u,v) $ is included) is to intersect their adjacency lists in order to count the number of their common neighbors.", "If the two vertices have no common neighbors, the edge $ (u,v) $ is removed from the graph, because it does not affect the computation of WCC.", "To count all of the triangles in the graph in which node $ u $ is contained, one must do this process for every neighbor $ v $ of $ u $ .", "In a centralized setting, this is relatively straightforward to implement.", "However, in a vertex-centric distributed setting, vertices do not have access to the adjacency lists of their neighbors, and therefore adjacency lists must be sent between vertices via message passing.", "With a large graph, if every vertex sends its adjacency list to every one of its neighbors in one superstep, this may lead to an excessive amount of time being spent in communication, or in the worst case, to memory problems that cause worker failures.", "\\newline In order to address this problem, we propose two optimizations.", "First, we observe that in real life graphs, there tend to be a few \u2018hub\u2019 vertices with a very high degree and many vertices with a much lower degree [@bib:DBLP:conf/kdd/LeskovecKF05] .", "This means that when these hub vertices send out their adjacency sets, it incurs a high communication cost in comparison with the messages sent by non-hub vertices.", "For this reason, in the first superstep, each vertex sends its degree to all of its neighbors, and following this, vertices only send their adjacency sets to neighbor vertices with a higher degree.", "The higher degree vertex in an edge then counts the triangles formed with the lower degree vertex, and responds with a message containing the triangle count.", "\\newline Secondly, to reduce the occurrence of memory problems, this phase may be split into several subphases, where each vertex only sends its adjacency list to a subset of its neighbors in each subphase.", "The number of subphases is chosen by counting the total number of vertices that will be sent in messages during preprocessing and using this to estimate the approximate overhead required to send these messages, yielding the model \\newline <equation> $ nPrepPhases=\\Bigg{\\lceil}{\\frac{vertexSize\\cdot\\sum_{v\\in V}|adj(v)||hdn(v)|}{% nWorkers\\cdot availWorkerMemory}}\\Bigg{\\rceil}, $ </equation> where $ adj(v) $ is the adjacency set of vertex $ v $ (the contents of a preprocessing message), $ hdn(v) $ is the set of neighbors of $ v $ that have a higher degree than it (the destinations of the message), and $ vertexSize $ is an estimate of the amount of memory taken to send one vertex id. For a given vertex $ v $ , $ |adj(v)||hdn(v)| $ gives the total number of elements (vertex ids) that will be sent during preprocessing.", "The numerator therefore estimates the total amount of memory that will be taken by all messages sent across all preprocessing phases.", "This sum is computed with aggregators just after the computation of $ hdn $ for each vertex.", "The denominator estimates the total amount of memory available for preprocessing overhead in the cluster, assuming an even degree distribution across workers.", "The value for $ availWorkerMemory $ is chosen based on the resources available for preprocessing, and the number of preprocessing phases is thus chosen such that each subphase operates with an overhead less than this value.", "\\newline Together, these two optimizations together greatly reduce the cost of communication during preprocessing.", "\\newline </subsection> <subsection> <title> IV-B Community Initialization </title> Following preprocessing, the graph consists only of edges that are part of at least one triangle.", "The next step is to create an initial partitioning of the graph from which to begin the process of WCC optimization, meaning that each vertex must decide its initial community.", "We make the assumption that the higher the clustering coefficient of a vertex, the more likely its neighbors are to belong to its community, because a high clustering coefficient indicates that these vertices are tightly connected.", "This assumption is also applied in [@bib:scd] , but the computation method presented there is not adapted to the vertex centric processing model.", "\\newline We require that the initial communities fulfill the following properties: \\newline <list> \\ Every community contains a single center vertex and a set of border vertices connected to the center vertex.", "\\newline \\ \\ The center vertex has the highest clustering coefficient of any vertex in the community.", "\\newline \\ \\ Given a center vertex $ y $ and a border vertex $ x $ in a community, the clustering coefficient of $ y $ must be higher than the clustering coefficient of any neighbor $ z $ of $ x $ that is the center of its own community.", "\\newline \\ </list> The process for obtaining such initial communities is shown in Figure [@ref:LABEL:fig:comm_init] .", "First, each vertex sends a message with its id, its clustering coefficient, its degree , and its initial community (its vertex id) to all of its neighbors.", "Each vertex then saves its incoming messages for use in future steps.", "Following this step, a vertex chooses its new community to be the id of the neighbor who has the highest clustering coefficient, considering as candidates only the neighbors that are currently centers.", "If its own clustering coefficient is higher then that of any neighbor or if none of its neighbors are currently centers, it chooses to be the center of its own community.", "\\newline In the example in the figure, this means that after the communication of clustering coefficients, each vertex chooses the id of the vertex to its right as its community.", "However, after this step, the third desired property above is violated; the first three nodes belong to the communities of the vertices to their right, none of which are center nodes.", "So, it is then necessary for any vertex $ x $ that has changed communities to communicate its new community to all of its neighbors with lower clustering coefficients.", "These neighbors are the only ones that need to be notified because only vertices with a lower coefficient can become border nodes of $ x $ .", "After receiving the new communities of their neighbors, vertices redetermine their communities based on which neighbors have become borders and centers in the previous step.", "This iterative process continues until no vertices change communities, in which case all three properties above are satisfied.", "\\newline </subsection> <subsection> <title> IV-C WCC Iteration </title> The main idea behind WCC iteration is to have each vertex repeatedly update its community based on an improvement heuristic and to evaluate the overall WCC between each update, and after a prespecified number of steps where the WCC does not improve more than a certain amount, the computation halts.", "\\newline <subsubsection> <title> IV-C1 Choosing a new community </title> When updating its community, the vertex has three options: \\newline <list> \\ Transfer: The vertex moves from its community to the community of a neighboring vertex.", "\\newline \\ \\ Remove: The vertex removes itself from its current community and becomes the sole member of its own isolated community.", "\\newline \\ \\ Stay: The vertex remains in its current community.", "\\newline \\ </list> In order to choose which of these actions to perform, the vertex must decide which of the actions will most likely lead to the biggest improvement in the global WCC value.", "In [@bib:scd] , the authors present a heuristic for the WCC improvement induced by each action, using aggregate community statistics for a vertex\u2019s current and neighbor communities (the size and edge density of the community and the number of edges leaving the community), the graph\u2019s clustering coefficient, and a vertex\u2019s knowledge of its neighbors\u2019 communities.", "The heuristic is an approximation of the WCC that does not require the computation of the internal triangles, and thus is computationally more efficient.", "Due to its effectiveness, we use this heuristic as well.", "More details on the heuristic can be found in [@bib:scd] .", "Because this update process occurs independently within each vertex, every vertex may perform the update simultaneously, meaning that this portion of the algorithm very effectively exploits parallelism.", "\\newline </subsubsection> <subsubsection> <title> IV-C2 WCC Computation </title> In order to compute the actual global WCC, the values $ t(x,C_{x}) $ and $ vt(x,C_{x}) $ must be calculated for each vertex $ x $ and its community $ C_{x} $ .", "This follows the same distributed triangle-counting process as in preprocessing, except that messages are only sent between vertices in the same community, and thus this step is less computationally expensive than global triangle counting.", "These local WCC values are then aggregated and averaged to obtain the global WCC.", "If a new best WCC has been obtained, vertices save their current communities, and when the WCC value converges, vertices output their saved community that led to the best overall WCC.", "\\newline </subsubsection> </subsection>  </section>"], ["<section> <title> V Experimentation </title>  For experimentation, we chose to perform tests on a variety of real life graphs, taken from the SNAP graph repository ."]], "target": "Information about each graph can be found in Table . Experiments were performed on a 40 node cluster with 2.40GHz Xeon E5-2630L processors and 128G of RAM each, and a 1 Gigabit Ethernet connection between nodes. In terms of software, we use Giraph release 1.1.0 and Hadoop version 0.20.203 (the default for Giraph)."}, {"tabular": ["  System  &  $ \\xi^{\\star} $  &  OSF  &  OIF  &  O $ {}^{2} $ S ", " $ \\xi_{alg} $  &  Outcome  &  $ \\xi_{alg} $  &  Outcome  &  $ \\xi_{alg} $  &  Outcome ", " $ \\mathcal{S}_{1} $  &  5  &  6  &  Over-Fitting  &  5  &  Exact-Fitting  &  5  &  Exact-Fitting ", " $ \\mathcal{S}_{2} $  &  4  &  4  &  Exact-Fitting  &  4  &  Exact-Fitting  &  4  &  Exact-Fitting ", " $ \\mathcal{S}_{3} $  &  4  &  4  &  Exact-Fitting  &  4  &  Exact-Fitting  &  4  &  Exact-Fitting ", " $ \\mathcal{S}_{4} $  &  5  &  5  &  Exact-Fitting  &  5  &  Exact-Fitting  &  5  &  Exact-Fitting ", " $ \\mathcal{S}_{5} $  &  4  &  4  &  Exact-Fitting  &  4  &  Exact-Fitting  &  4  &  Exact-Fitting ", " $ \\mathcal{S}_{6} $  &  5  &  5  &  Exact-Fitting  &  5  &  Exact-Fitting  &  5  &  Exact-Fitting  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Over the last several decades, researchers from various fields of science and engineering have developed several methods to construct mathematical models from measured input-output data ( popularly known as system identification) [@bib:Billings:2013,Ljung:1999] .", "Since most of the practical systems are nonlinear, the first step in the process of fitting the models is the choice of the model amongst various available models (e.g., Volterra, Wiener, Polynomial/Rational) which can effectively capture the dynamics in input-output data.", "In this study, the focus is on the identification of nonlinear systems represented by polynomial nonlinear auto-regressive with exogenous inputs (NARX) models [@bib:Billings:2013] .", "Note that the identification of system is a two stage process which involves 1) Determination of the significant terms and 2) Estimation of the corresponding parameters.", "While the parameters can be estimated using least-squares based algorithms, the determination of the significant terms is a challenging task and often referred to as \u2018structure selection\u2019 .", "\\newline A close examination of the structure selection problem in nonlinear system identification reveals that this problem has significant similarities with the feature selection problem encountered in the pattern recognition.", "In essence, both problems belong to a broader class of combinatorial optimization problem which is referred here as the attribute selection problem.", "To understand this further, consider a superset of \u2018 $ n $ \u2019 number of \u2018attributes\u2019 , denoted by: $ \\mathcal{X}_{model}=\\{x_{1},x_{2},\\dots x_{n}\\} $ , where any attribute (say \u2018 $ x_{i} $ \u2019), could represent either a feature (in pattern recognition ) or a term of the NARX model (in system identification ).", "The goal of the attribute selection is to determine a subset of significant attributes, $ \\mathcal{X}^{\\star}\\subset\\mathcal{X}_{model} $ , by maximizing a suitable criterion function,\u2018 $ J(\\cdotp) $ \u2019, as follows: {linenomath*} \\newline <equationgroup> <equation> $  J(\\mathcal{X}^{\\star})=\\max\\limits_{\\mathcal{X}\\subset\\mathcal{X% }_{model}}J(\\mathcal{X}) $ $  J(\\mathcal{X}^{\\star})=\\max\\limits_{\\mathcal{X}\\subset\\mathcal{X% }_{model}}J(\\mathcal{X}) $ </equation> </equationgroup> An exhaustive search to solve such combinatorial problem is often intractable even for a moderate number of attributes, \u2018 $ n $ \u2019, as it requires the evaluation of $ 2^{n} $ subsets.", "\\newline Over the years several approaches have been proposed to address the structure selection problem of NARX models, e.g. , see [@bib:Hong:Mitchell:2008,Billings:Chen:Korenberg:1989,Baldacchino:Kadirkamanathan:2012,Baldacchino:Kadirkamanathan:2013,Falsone:Piroddi:2015,Tang:Long:2019] .", "Among these, the Orthogonal Forward Regression (OFR) [@bib:Korenberg:Billings:1988,Chen:Billings:1989,Billings:Chen:Korenberg:1989] is, arguably, computationally the most effective.", "Perhaps, for this reason, it has been extensively applied in many applications [@bib:Chiras:Evans:2001,Billings:2013] .", "The central idea of this approach is to decouple the terms in the orthogonal space so that the contribution of each term to the output variance can individually be determined.", "From the search perspective, the OFR is a sequential greedy approach where the term with the highest performance metric, referred to as Error-Reduction-Ratio (ERR), is included in each step and it has proven to be very effective in various applications [@bib:Chiras:Evans:2001,Hong:Mitchell:2008] .", "However, it has been shown that under certain conditions the OFR may yield sub-optimal term subsets [@bib:Mao:Billings:1997,Piroddi:Spinelli:2003,Wei:Billings:2006,Guo:Billings:2015,Guo:Guo:2016] .", "The reason for such suboptimal performance is often attributed to the performance metric, ERR.", "For example, Mao and Billings [@bib:Mao:Billings:1997] have shown that for the given term, the value of ERR is dependent on the orthogonalization path , i.e. , the order in which the terms are orthogonalized.", "This may lead to the selection of spurious terms, when there is an information overlap among the non-orthogonal terms, especially in the earlier stages of the search [@bib:Guo:Billings:2015] .", "\\newline To alleviate these issues, several approaches have been proposed to extend/modify the classical OFR algorithm.", "These can be categorized mainly into two approaches: 1) Two-step approach [@bib:Mao:Billings:1997,Li:Peng:2006,Guo:Billings:2015] and 2) Improved performance metric [@bib:Piroddi:Spinelli:2003,Wei:Billings:2006,Guo:Guo:2016] .", "\\newline In the two-step approach, OFR is applied first to identify the initial term subset which is further refined by a secondary search procedure.", "For example, in [@bib:Mao:Billings:1997] , the initial term subset is refined by applying Genetic Algorithm (GA) to identify the optimal orthogonalization path .", "However, the explosive growth of the search space limits the application of this approach, e.g. , for \u2018 $ n $ \u2019 number of terms, the total number of possible orthogonalization paths becomes \u2018 $ n!", "$ \u2019.", "In comparison, if GA (or any suitable algorithm) is applied directly to select term subset the search space reduces from $ n!", "$ to $ 2^{n} $ [@bib:Hafiz:Swain:CEC:2018] .", "The \u2018iterative OFR\u2019 (iOFR) algorithm [@bib:Guo:Billings:2015] uses each term in the initial term subset as a pivot to identify new, and possibly better, term subsets in the secondary search.", "In [@bib:Li:Peng:2006] , a backward elimination approach is proposed as the secondary search to remove the spurious terms contained in the initial term subset.", "Most of the two-step approach, e.g. [@bib:Li:Peng:2006] , are usually effective provided all the system/significant terms are identified in the initial term subset.", "\\newline The focus of the second approach is to replace the performance metric, \u2018ERR\u2019 [@bib:Piroddi:Spinelli:2003,Wei:Billings:2006,Guo:Guo:2016] .", "For this purpose, several performance metrics have been proposed based on Simulation Error [@bib:Piroddi:Spinelli:2003] , Mutual Information [@bib:Wei:Billings:2006] and Ultra-orthogonal least squares [@bib:Guo:Guo:2016] .", "While these metrics improve the search performance of OFR in many cases, they often increase the computational complexity of OFR.", "\\newline It is worth to emphasize that the aforementioned approaches to improve OFR are based on the prevailing belief that the sub-optimal performance of OFR is due only to its performance metric, ERR.", "However, in this study, it is argued that this may be in part due to the uni-directional sequential search nature of OFR where terms are progressively added into the term subset until pre-specified ERR threshold is reached.", "This leads to the \u2018nesting effect\u2019 , i.e. , once a term is included in the subset, it cannot be removed from the term subset.", "This imposes a hierarchy of terms, whereas in practice, all significant terms are equally important.", "Note that the nesting effect is not new and it has been well-known among the feature selection community since the early seventies [@bib:Michael:Lin:1973,Stearns:1976,Kittler:1978] .", "Over the years, state-of-the-art \u2018floating\u2019 feature selection algorithms have specifically been developed to address the nesting effect [@bib:Pudil:1994,Somol:Pudil:1999,Somol:Pudil:2000,Nakariyakul:Casasent:2009] .", "Since there already exist a class of floating feature selection algorithms and given that both structure selection and feature selection share a common search objective, the question arises: Can the feature selection algorithms be adapted to address the structure selection problem? \\newline The present study aims to address this apropos question.", "In particular, the proposed Orthogonal Floating Search Framework integrates the key properties of the classical Sequential Forward Floating Search (SFFS) and its variants such as Improved Forward Floating Search (IFFS) and Oscillating Search (OS) with the Error-Reduction-Ratio (ERR) to determine the structure of nonlinear systems.", "In each step of these algorithms, after adding a \u2018significant\u2019 term (discussed in Section [@ref:LABEL:s:termsig] ), the selected terms are re-examined to identify and remove the \u2018least significant\u2019 term (discussed in Section [@ref:LABEL:s:termsig] ).", "Thus, the spurious terms can eventually be replaced by the system/significant terms during the search process.", "The search performance is therefore significantly improved without the need for a second search procedure or a complicated performance measure.", "The efficacy of the proposed approach is demonstrated on several benchmark non-linear systems.", "The worst case scenario ( non-persistent excitation ) and the identification of a discrete-time model of a continuous-time system are also considered.", "The results of this investigation convincingly demonstrate that the feature selection algorithms can indeed be tailored for the purpose of structure selection.", "\\newline The rest of the article is organized as follows: The polynomial NARX model and the OFR approach are discussed briefly in Section [@ref:", "LABEL:s:background] .", "Next, the proposed Orthogonal Floating Search Framework is discussed in detail in Section [@ref:LABEL:s:proposedOFS] .", "The framework of this investigation is described in Section [@ref:LABEL:s:IF] .", "Finally, the results of this investigation are discussed at length in Section [@ref:LABEL:s:res] .", "\\newline  </section>"], ["<section> <title> 2 Preliminaries </title>  In the following, the polynomial NARX model and the orthogonal regression approach are briefly discussed.", "\\newline <subsection> <title> 2.1 The Polynomial NARX Model </title> The NARX model represents a non-linear system as a function of recursive lagged input and output terms as follows: {linenomath*} \\newline <equationgroup> <equation> $  y(k)=F^{n_{l}}\\ \\{\\ y(k-1),\\ldots,y(k-n_{y}),u(k-1),\\ldots,u(k-n% _{u})\\ \\}+e(k) $ $  y(k) $ $ =F^{n_{l}}\\", "\\{\\ y(k-1),\\ldots,y(k-n_{y}),u(k-1),\\ldots,u(k-n_{u})% \\ \\}+e(k) $ </equation> </equationgroup> where $ y(k) $ and $ u(k) $ respectively represent the output and input at time intervals $ k $ , $ n_{y} $ and $ n_{u} $ are corresponding lags and $ F^{n_{l}}\\{\\cdotp\\} $ is some nonlinear function of degree $ n_{l} $ .", "\\newline The total number of possible terms or model size ( $ n $ ) of the NARX model is given by, {linenomath*} \\newline <equationgroup> <equation> $  n=\\sum_{i=0}^{n_{l}}n_{i},\\ n_{0}=1\\ \\textit{and \\ }n_{i}=\\frac{% n_{i-1}(n_{y}+n_{u}+i-1)}{i},\\ i=1,\\ldots,n_{l} $ $  n $ $ =\\sum_{i=0}^{n_{l}}n_{i},\\ n_{0}=1\\ \\textit{and \\ }n_{i}=\\frac{n_% {i-1}(n_{y}+n_{u}+i-1)}{i},\\ i=1,\\ldots,n_{l} $ </equation> </equationgroup> This model is essentially linear-in-parameters and can be expressed as: {linenomath*} \\newline <equationgroup> <equation> $  y(k)=\\sum_{i=1}^{n}\\theta_{i}x_{i}(k)+e(k),\\ \\ k=1,2,\\dots% \\mathcal{N} $ $  y(k) $ $ =\\sum_{i=1}^{n}\\theta_{i}x_{i}(k)+e(k),\\ \\ k=1,2,\\dots\\mathcal{N} $ </equation> <equation> $ \\text{where, }x_{1}(k)=1,\\ \\ \\text{and \\ }x_{i}(k)=\\prod_{j=1}^{p% _{y}}y(k-n_{y_{j}})\\prod_{k=1}^{q_{u}}u(k-n_{u_{k}})\\,\\ i=2,\\ldots,n, $ $ \\text{where, }x_{1}(k) $ $ =1,\\ \\ \\text{and \\ }x_{i}(k)=\\prod_{j=1}^{p_{y}}y(k-n_{y_{j}})% \\prod_{k=1}^{q_{u}}u(k-n_{u_{k}})\\,\\ i=2,\\ldots,n, $ </equation> </equationgroup> $ p_{y},q_{u}\\geq 0 $ ; $ 1\\leq p_{y}+q_{u}\\leq n_{l} $ ; $ 1\\leq n_{y_{j}}\\leq n_{y} $ ; $ 1\\leq n_{u_{k}}\\leq n_{u} $ ; $ n_{l} $ is the degree of polynomial expansion; \u2018 $ \\mathcal{N} $ \u2019 denotes the total number of data points.", "\\newline </subsection> <subsection> <title> 2.2 Orthogonal Regression </title> In this study, the orthogonalization is used to determine the significance of a particular term, which will be discussed in Section [@ref:LABEL:s:termsig] .", "It is, therefore, pertinent to briefly discuss the concept of orthogonal regression introduced by Billings et al. [@bib:Korenberg:Billings:1988,Chen:Billings:1989,Billings:Chen:Korenberg:1989] .", "In the orthogonal regression, as the name suggests, the original terms are replaced by the corresponding orthogonal terms.", "Given that the orthogonal terms are decoupled, the significance of each term can be determined independently in the orthogonal space.", "This could be achieved by a simple Gram-Schmidt orthogonalization: {linenomath*} \\newline <equationgroup> <equation> $  w_{1}=x_{1},\\ \\ w_{i}=x_{i}-\\sum\\limits_{m=1}^{i-1}\\frac{\\langle w% _{m}x_{i}\\rangle}{w_{m}^{T}w_{m}} $ $  w_{1}=x_{1},\\ \\ w_{i}=x_{i}-\\sum\\limits_{m=1}^{i-1}\\frac{\\langle w% _{m}x_{i}\\rangle}{w_{m}^{T}w_{m}} $ </equation> </equationgroup> Consequently, the NARX model ( [@ref:LABEL:eq:NARXmodel] ) can be represented in the orthogonal space as follows: {linenomath*} \\newline <equationgroup> <equation> $  y(k)=\\sum_{i=1}^{n}w_{i}(k)g_{i}+e(k),\\ \\ k=1,2,\\dots\\mathcal{N} $ $  y(k) $ $ =\\sum_{i=1}^{n}w_{i}(k)g_{i}+e(k),\\ \\ k=1,2,\\dots\\mathcal{N} $ </equation> </equationgroup> Given that, in the orthogonal space, $ w_{i}^{T}w_{j}=0 $ holds for $ i\\neq j $ , the significance of the $ i^{th} $ term, $ x_{i} $ , can be easily be determined using the Error-Reduction-Ratio (ERR) metric as follows: {linenomath*} \\newline <equationgroup> <equation> $  ERR(x_{i})=\\frac{g_{i}^{2}w_{i}^{T}w_{i}}{y^{T}y},\\ \\ \\text{% where, \\ }g_{i}=\\frac{w_{i}^{T}y}{w_{i}^{T}w_{i}},\\ i\\in[1,n] $ $  ERR(x_{i})=\\frac{g_{i}^{2}w_{i}^{T}w_{i}}{y^{T}y},\\ \\ \\text{% where, \\ }g_{i}=\\frac{w_{i}^{T}y}{w_{i}^{T}w_{i}},\\ i\\in[1,n] $ </equation> </equationgroup> \\newline </subsection>  </section>"], ["<section> <title> 3 Proposed Orthogonal Floating Search Framework </title>  This study aims to investigate whether the existing feature selection algorithms can be tailored to address the non-linear system identification problem.", "For this purpose, a new search framework is being proposed which integrates the term orthogonalization into \u2018 floating \u2019 feature selection algorithms and therefore referred to as \u2018 Orthogonal Floating Search Framework \u2019.", "\\newline The term orthogonalization decouples the structure selection and the parameter estimation, which are crucial steps of the nonlinear system identification.", "It is, therefore, a vital first step to adapt the feature selection algorithms for system identification.", "Further, the following \u2018 floating \u2019 feature selection algorithms have been adapted: Sequential Forward Floating Search (SFFS) [@bib:Pudil:1994] , Improved Forward Floating Search (IFFS) [@bib:Nakariyakul:Casasent:2009] and Oscillating Search (OS) [@bib:Somol:Pudil:2000] .", "The motivation for the selection of these methods is two-fold: 1) The term orthogonalization can be integrated with relative ease into the floating search methods.", "2) The step-wise subset building approach of the sequential floating methods ( e.g. , SFFS and IFFS) is similar to that of the Orthogonal Forward Regression (OFR-ERR) [@bib:Billings:Chen:Korenberg:1989] .", "Further, in OS, the depth of the search process can easily be controlled as per the prevailing requirements, as will be discussed in Section [@ref:LABEL:s:o2s] .", "\\newline The concept of feature significance is central to the floating search methods.", "In this study, we extend this concept in the context of system identification and integrate the term orthogonalization to determine the significance of a term/term subset.", "This is discussed in Section [@ref:LABEL:s:termsig] .", "Further, each search method and associated adaption are discussed in the context of the system identification in Section [@ref:LABEL:s:OSF] , Section [@ref:LABEL:s:OIF] and Section [@ref:", "LABEL:s:o2s] .", "Note that the adapted versions of SFFS, IFFS and OS are referred to respectively as Orthogonal Sequential Floating search (OSF), Orthogonal Improved sequential Floating search (OIF) and Orthogonal Oscillating Search (O $ ^{2} $ S).", "\\newline <subsection> <title> 3.1 Term Significance </title> Determination of feature significance is the core of the floating search methods [@bib:Pudil:1994,Somol:Pudil:1999,Somol:Pudil:2000,Nakariyakul:Casasent:2009] , where in each search step, the most significant feature/features are selected from the pool of available features and then the least significant feature/features are removed, from the selected feature subset.", "If a similar approach is to be applied to address the structure selection problem, it is essential to determine first the \u2018 significance \u2019 of a term/term subset.", "For this purpose, in this study, we extend the definitions of feature significance developed by Pudil, Somol and co-workers [@bib:Pudil:1994,Somol:Pudil:1999,Somol:Pudil:2000] as follows: \\newline Let $ \\mathcal{X}_{k}=\\{x_{1},x_{2},\\dots x_{k}\\} $ be the term subset selected by the search algorithm at particular search step from the superset of NARX terms, $ \\mathcal{X}_{model}=\\{x_{1},x_{2},\\dots x_{n}\\} $ .", "Consequently, the subset of available terms is given by $ \\mathcal{X}_{model}\\setminus\\mathcal{X}_{k} $ .", "Let $ \\mathcal{X}_{o}^{i} $ denote $ i^{th} $ subset containing \u2018 $ o $ \u2019 number of terms.", "The criterion function corresponding to the term subset $ \\mathcal{X}_{k} $ is denoted by $ J(\\mathcal{X}_{k}) $ and is given by \\newline <equationgroup> <equation> $  J(\\mathcal{X}_{k})=\\sum\\limits_{i=1}^{k}ERR(x_{i}),\\ \\ \\forall x% _{i}\\in\\mathcal{X}_{k} $ $  J(\\mathcal{X}_{k})=\\sum\\limits_{i=1}^{k}ERR(x_{i}),\\ \\ \\forall x% _{i}\\in\\mathcal{X}_{k} $ </equation> </equationgroup> where, $ ERR(x_{i}) $ is given by ( [@ref:LABEL:eq:err] ).", "\\newline For these subsets, the significance of term/term subset is defined as follows: \\newline <theorem> Definition 1 .", "The most significant term with respect to $ \\mathcal{X}_{k} $ is denoted as \u2018 $ x^{MS} $ \u2019 and is defined as: \\newline <equationgroup> <equation> $  x^{MS}=\\{x_{i}\\ |\\ J(\\mathcal{X}_{k}\\cup x_{i})=\\max\\limits_{i}J% (\\mathcal{X}_{k}\\cup x_{i}),x_{i}\\in\\mathcal{X}_{model}\\setminus\\mathcal{X}_{k% }\\},\\ \\forall i\\in[1,n] $ $  x^{MS}=\\{x_{i}\\ |\\ J(\\mathcal{X}_{k}\\cup x_{i})=\\max\\limits_{i}J% (\\mathcal{X}_{k}\\cup x_{i}),x_{i}\\in\\mathcal{X}_{model}\\setminus\\mathcal{X}_{k% }\\},\\ \\forall i\\in[1,n] $ </equation> </equationgroup> \\newline </theorem> <theorem> Definition 2 .", "The least significant term in $ \\mathcal{X}_{k} $ is denoted as \u2018 $ x^{LS} $ \u2019 and is defined as: \\newline <equationgroup> <equation> $  x^{LS}=\\{x_{i}\\ |\\ J(\\mathcal{X}_{k}\\setminus x_{i})=\\max\\limits% _{i}J(\\mathcal{X}_{k}\\setminus x_{i}),x_{i}\\in\\mathcal{X}_{k}\\},\\ \\forall i\\in% [1,n] $ $  x^{LS}=\\{x_{i}\\ |\\ J(\\mathcal{X}_{k}\\setminus x_{i})=\\max\\limits% _{i}J(\\mathcal{X}_{k}\\setminus x_{i}),x_{i}\\in\\mathcal{X}_{k}\\},\\ \\forall i\\in% [1,n] $ </equation> </equationgroup> \\newline </theorem> <theorem> Definition 3 .", "The most significant subset of \u2018 $ o $ \u2019 number of terms with respect to $ \\mathcal{X}_{k} $ is denoted as \u2018 $ \\mathcal{X}_{o}^{MS} $ \u2019 and is defined as: \\newline <equationgroup> <equation> $ \\mathcal{X}_{o}^{MS}=\\{\\mathcal{X}_{o}^{i}\\ |\\ J(\\mathcal{X}_{k}% \\cup\\mathcal{X}_{o}^{i})=\\max\\limits_{i}J(\\mathcal{X}_{k}\\cup\\mathcal{X}_{o}^{% i}),\\ \\mathcal{X}_{o}^{i}\\in\\mathcal{X}_{model}\\setminus\\mathcal{X}_{k}\\} $ $ \\mathcal{X}_{o}^{MS}=\\{\\mathcal{X}_{o}^{i}\\ |\\ J(\\mathcal{X}_{k}% \\cup\\mathcal{X}_{o}^{i})=\\max\\limits_{i}J(\\mathcal{X}_{k}\\cup\\mathcal{X}_{o}^{% i}),\\ \\mathcal{X}_{o}^{i}\\in\\mathcal{X}_{model}\\setminus\\mathcal{X}_{k}\\} $ </equation> </equationgroup> \\newline </theorem> <theorem> Definition 4 .", "The least significant subset of \u2018 $ o $ \u2019 number of terms in $ \\mathcal{X}_{k} $ is denoted as \u2018 $ \\mathcal{X}_{o}^{LS} $ \u2019 and is defined as: \\newline <equationgroup> <equation> $ \\mathcal{X}_{o}^{LS}=\\{\\mathcal{X}_{o}^{i}\\ |\\ J(\\mathcal{X}_{k}% \\setminus\\mathcal{X}_{o}^{i})=\\max\\limits_{i}J(\\mathcal{X}_{k}\\setminus% \\mathcal{X}_{o}^{i}),\\ \\mathcal{X}_{o}^{i}\\in\\mathcal{X}_{k}\\} $ $ \\mathcal{X}_{o}^{LS}=\\{\\mathcal{X}_{o}^{i}\\ |\\ J(\\mathcal{X}_{k}% \\setminus\\mathcal{X}_{o}^{i})=\\max\\limits_{i}J(\\mathcal{X}_{k}\\setminus% \\mathcal{X}_{o}^{i}),\\ \\mathcal{X}_{o}^{i}\\in\\mathcal{X}_{k}\\} $ </equation> </equationgroup> \\newline </theorem> <float> \\ Input : Input-output Data, $ (u,y) $ ; Number of required terms, \u2018 $ \\xi $ \u2019 \\ \\ Output : Identified Structure, $ \\mathcal{X} $ \\ \\ Begin with the empty subset: $ \\mathcal{X}\\leftarrow\\varnothing $ , $ k=0 $ , $ J(\\mathcal{X}_{i})=0,\\forall i\\in[1,\\xi] $ \\ \\ while {$ k<\\xi $} do \\ \\ */ Sequential Forward Selection \\ \\ Add the most significant term to $ \\mathcal{X} $ , i.e. , $ \\hat{\\mathcal{X}}\\leftarrow\\{\\mathcal{X}\\cup x^{MS}\\} $ \\ \\ if {$ J(\\hat{\\mathcal{X}})>J(\\mathcal{X}_{k+1}) $ } then \\ \\ $ \\mathcal{X}\\leftarrow\\hat{\\mathcal{X}} $ ; $ J(\\mathcal{X})\\leftarrow J(\\hat{\\mathcal{X}}) $ \\ \\ else \\ \\ $ \\mathcal{X}\\leftarrow\\mathcal{X}_{k+1} $ ; $ J(\\mathcal{X})\\leftarrow J(\\mathcal{X}_{k+1}) $ \\ \\ end if \\ \\ $ k\\leftarrow k+1 $ \\ \\ */ Backwards Elimination \\ \\ Set the first exclusion flag , $ f_{1}=1 $ \\ \\ while {$ k>2 $ } do \\ \\ Identify the least significant term, $ x^{LS} $ , in $ \\mathcal{X} $ \\ \\ if {$ (f_{1}=1\\ \\wedge\\ x^{LS}=x^{MS}) $ OR $ J(\\mathcal{X}\\backslash x^{LS})\\leq J(\\mathcal{X}_{k-1}) $} then \\ \\ Stop Elimination.", "\\ \\ else \\ \\ Remove the least significant term, i.e. , \\ \\ $ \\mathcal{X}\\leftarrow\\mathcal{X}\\backslash x^{LS} $ ; $ J(\\mathcal{X})\\leftarrow J(\\mathcal{X}\\backslash x^{LS}) $ ; $ k\\leftarrow k-1 $ \\ \\ end if \\ \\ $ f_{1}=0 $ \\ \\ end while \\ \\ */ Term Swapping : Included only in OIF \\ \\ for {$ i=1 $ to $ k $ } do \\ \\ Remove the $ i^{th} $ term, i.e. , $ \\hat{\\mathcal{X}}^{i}\\leftarrow\\mathcal{X}\\backslash x_{i} $ \\ \\ Add the most significant term to $ \\hat{\\mathcal{X}}^{i} $ , i.e. , $ \\hat{\\mathcal{X}}^{i}\\leftarrow\\{\\hat{\\mathcal{X}}^{i}\\cup x^{MS}\\} $ \\ \\ end for \\ \\ Select the best swapping subset, i.e. , $ \\hat{\\mathcal{X}}=\\{\\hat{\\mathcal{X}}^{i}|J(\\hat{\\mathcal{X}}^{i})=\\max\\limits% _{i=1:k}J(\\hat{\\mathcal{X}}^{i})\\} $ \\ \\ if {$ J(\\hat{\\mathcal{X}})>J(\\mathcal{X}_{k}) $ } then \\ \\ $ \\mathcal{X}\\leftarrow\\hat{\\mathcal{X}} $ ; $ J(\\mathcal{X})\\leftarrow J(\\hat{\\mathcal{X}}) $ \\ \\ if {$ k>2 $} then \\ \\ Go To Step [@ref:LABEL:l:oif2] for the Backward Elimination \\ \\ end if \\ \\ \\ \\ end if \\ \\ \\ \\ end while \\ \\ \\ Orthogonal Floating Structure Selection.", "</float> \\newline </subsection> <subsection> <title> 3.2 Orthogonal Sequential Floating Search </title> The principle of the generalized floating search was introduced by Pudil et al. in [@bib:Pudil:1994] which is essentially a sequential approach with a distinct ability to \u2018 backtrack \u2019, i.e. , the selected / discarded term can be discarded / selected in later stages.", "It is worth to note that the floating search can proceed either in forward (bottom-up) or backward (top-down) direction.", "In this study, we focus on the forward or bottom-up approach.", "This is referred to as Orthogonal Sequential Floating (OSF) search.", "The pseudo code for OSF is shown in Algorithm [@ref:LABEL:al:oif] .", "Note that the OSF does not include \u2018 term swapping \u2019 procedure (Line [@ref:LABEL:l:oif4] - [@ref:LABEL:l:oif5] , Algorithm [@ref:LABEL:al:oif] ), in contrast to the improved floating search approach (which will be discussed in Section [@ref:LABEL:s:OIF] ).", "\\newline The search process in OSF begins with an empty term subset and is continued till the term subset with the desired cardinality \u2018 $ \\xi $ \u2019 is obtained.", "Each search step essentially involves two procedures: inclusion of the most significant term followed by the removal of the least significant term/terms through backtracking .", "This procedure is discussed briefly in the following: \\newline Let $ \\mathcal{X}_{k} $ denote a term subset with $ k $ number of terms at a particular search step.", "First, following Definition [@ref:LABEL:def:1] , the most significant term ( $ x^{MS} $ ) with respect to $ \\mathcal{X}_{k} $ , is identified from the pool of available terms.", "This term is included in the term subset provided it leads to a better criterion function, i.e. , $ J(\\mathcal{X}_{k}\\cup x^{MS})>J(\\mathcal{X}_{k+1}) $ .", "This procedure is outlined in Lines [@ref:LABEL:l:oif1] - [@ref:LABEL:l:oif11] , Algorithm [@ref:LABEL:al:oif] .", "After including a term, the focus is on removing least-significant terms present in the selected term subset through adaptive backtracking, as shown in Lines [@ref:LABEL:l:oif21] - [@ref:LABEL:l:oif22] , Algorithm [@ref:LABEL:al:oif] .", "It is worth to emphasize that the backtracking continues to remove the least significant term until an improvement in the criterion function is obtained, i.e. , $ J(\\mathcal{X}_{k}\\setminus x^{LS})>J(\\mathcal{X}_{k-1}) $ .", "\\newline To gain an insight into the search dynamics of the proposed OSF, consider the following system.", "\\newline <equationgroup> <equation> $ \\mathcal{S}_{1}:y(k)=0.5+0.5y(k-1)+0.8u(k-2)-0.05y(k-2)^{2}+u(k-1% )^{2}+e(k) $ $ \\mathcal{S}_{1}:y(k)=0.5+0.5y(k-1)+0.8u(k-2)-0.05y(k-2)^{2}+u(k-1% )^{2}+e(k) $ </equation> </equationgroup> For identification purposes, $ 1000 $ input-output data-points are generated by exciting the system $ \\mathcal{S}_{1} $ with zero-mean uniform white noise sequence with unit variance, $ u\\sim WUN(0,1) $ and Gaussian white noise, $ e\\sim WGN(0,0.05) $ .", "The model set of $ 165 $ NARX terms is obtained with the following specifications: $ [n_{u},n_{y},n_{l}]=[4,4,3] $ .", "\\newline The OSF is applied to identify six significant terms of $ \\mathcal{S}_{1} $ , i.e. , $ \\xi=6 $ .", "Note that the floating search methods require a priori specification of subset size, \u2018 $ \\xi $ \u2019.", "A simple approach to select the appropriate subset size $ \\xi $ and the associated issues will be discussed in Section [@ref:LABEL:s:XiSel] .", "The search behavior of OSF is explained as follows: In each search step, the term subset, its cardinality and the corresponding criterion function are recorded, which are shown in Table [@ref:LABEL:t:sbosf] and Fig. [@ref:LABEL:f:SB1] .", "For the sake of clarity, the system terms and spurious terms are respectively denoted by \u2018 $ x $ \u2019 and \u2018 $ \\mathcal{T} $ \u2019.", "Further, a better subset for the given cardinality is annotated by \u2018 $ ^{+} $ \u2019, e.g. , $ \\mathcal{X}_{2}^{+} $ indicates that $ J(\\mathcal{X}_{2}^{+})>J(\\mathcal{X}_{2}) $ .", "\\newline The positive effects of backtracking are clearly evident in Fig. [@ref:LABEL:f:SB1] .", "The backtracking occurs after the subset $ \\mathcal{X}_{5} $ is obtained.", "Note that the subsets obtained after backtracking ( $ \\mathcal{X}_{2}^{+},\\mathcal{X}_{3}^{+},\\mathcal{X}_{4}^{+} $ and $ \\mathcal{X}_{5}^{+} $ ) yield improved criterion function in comparison to the previous subsets with the similar cardinality ( $ \\mathcal{X}_{2},\\mathcal{X}_{3},\\mathcal{X}_{4} $ and $ \\mathcal{X}_{5} $ ).", "A closer examination of subsets given in Table [@ref:LABEL:t:sbosf] reveals that the backtracking could remove the spurious term \u2018 $ \\mathcal{T}_{1} $ \u2019 which is first included at Step 2 and remains in the selected subsets till Step 5.", "Further, the subset containing all the system terms, $ \\mathcal{X}_{5}^{+}=\\{x_{1},x_{2},x_{3},x_{4},x_{5}\\} $ , is obtained during backtracking at Step 6.", "This subset is eventually selected at Step 9 when the forward inclusion procedure failed to yield a better subset, i.e. , the search is restored to previous best subset (in this case $ \\mathcal{X}_{5}^{+} $ , as $ J(\\mathcal{X}_{4}^{+}\\cup x^{MS})<J(\\mathcal{X}_{5}^{+}) $ ; see Line [@ref:LABEL:l:oif10] - [@ref:LABEL:l:oif11] , Algorithm [@ref:LABEL:al:oif] ).", "\\newline </subsection> <subsection> <title> 3.3 Orthogonal Improved Floating Search </title> The next algorithm considered in this study is based on the improved floating search proposed in [@bib:Nakariyakul:Casasent:2009] .", "This algorithm adds a new procedure referred to as \u2018 swapping \u2019 to replace a weak feature, besides retaining both the procedures of the floating search.", "The improved floating search is adapted for the structure selection by including the ERR metric associated with orthogonal least square algorithms of [@bib:Billings:Chen:Korenberg:1989] .", "This is referred to as Orthogonal Improved Floating (OIF) search and discussed briefly in the following.", "\\newline The procedures involved in OIF are shown in Algorithm [@ref:LABEL:al:oif] .", "As discussed earlier, OIF retains the \u2018 forward inclusion \u2019 (Line [@ref:LABEL:l:oif1] - [@ref:LABEL:l:oif11] , Algorithm [@ref:LABEL:al:oif] ) and \u2018 backtracking \u2019 (Line [@ref:LABEL:l:oif21] - [@ref:LABEL:l:oif22] , Algorithm [@ref:LABEL:al:oif] ) procedures of the OSF and the same discussions are valid here.", "In addition, the swapping procedure is introduced after backtracking as shown in Line [@ref:LABEL:l:oif4] - [@ref:LABEL:l:oif5] .", "The objective of this procedure is to replace a weak/non-significant term which is explained as follows: \\newline Assume that $ \\mathcal{X}_{k}=\\{x_{1},x_{2},\\dots x_{k}\\} $ is the term subset obtained after backtracking .", "To replace a non-significant term, several new candidate term subsets are generated from $ \\mathcal{X}_{k} $ .", "The $ i^{th} $ candidate term subset (denoted as $ \\hat{\\mathcal{X}^{i}} $ ) is generated from $ \\mathcal{X}_{k} $ in the following two steps: \\newline <list> \\ First, the $ i^{th} $ term is removed from $ \\mathcal{X}_{k} $ , i.e. , $ \\hat{\\mathcal{X}^{i}}\\leftarrow\\{\\mathcal{X}_{k}\\setminus x_{i}\\} $ \\newline \\ \\ Next, the most significant term with respect to $ \\hat{\\mathcal{X}^{i}} $ is included, i.e. , $ \\hat{\\mathcal{X}^{i}}\\leftarrow\\{\\hat{\\mathcal{X}^{i}}\\cup x^{MS}\\} $ \\newline \\ </list> Following these steps, a total of \u2018 $ k $ \u2019 candidate term subsets are obtained from $ \\mathcal{X}_{k} $ and the subset with the highest criterion function, $ J(\\cdotp) $ , is referred to as \u2018 swapping subset \u2019(denoted by $ \\hat{\\mathcal{X}} $ ).", "If the swapping subset yields an improved criterion function, then it replaces the current term subset $ \\mathcal{X}_{k} $ and sent for backtracking, as outlined in Line [@ref:LABEL:l:oif50] - [@ref:LABEL:l:oif5] , Algorithm [@ref:LABEL:al:oif] .", "\\newline Thus, OIF takes a two-pronged approach to remove weak/non-significant terms: the backtracking removes the weak term/terms and the swapping replaces a weak term.", "Especially, the swapping procedure encourages the exploration of new term subsets which is likely to yield improved search performance in comparison to OSF.", "To investigate this further, the OIF is applied to identify the significant terms of the system $ \\mathcal{S}_{1} $ considered in ( [@ref:LABEL:eq:numExample] ) under the similar test conditions.", "\\newline The final subsets obtained in each step and the corresponding criterion function are shown in Table [@ref:LABEL:t:sboif] .", "The variations in the criterion function are shown in Fig. [@ref:LABEL:f:SB2] .", "Though, the overall search dynamics of both OSF (Fig. [@ref:LABEL:f:SB1] ) and OIF (Fig. [@ref:LABEL:f:SB2] ) may appear similar in nature, it is interesting to note that the backtracking in OIF occurs one step earlier (Step 5, Table [@ref:LABEL:t:sboif] ) in comparison to OSF (Step 6, Table [@ref:LABEL:t:sbosf] ).", "This could be explained by the swapping procedure of OIF which enables the inclusion of missing system term \u2018 $ x_{2} $ \u2019 one step earlier.", "\\newline <float> \\ Input : Input-output Data, $ (u,y) $ ; Number of required terms, \u2018 $ \\xi $ \u2019 \\ \\ Output : Identified Structure, $ \\mathcal{X}_{\\xi} $ \\ \\ */ Initialize \\ \\ Select the maximum search depth, $ \\mathcal{O}_{max} $ \\ \\ Set the search depth, $ o=1 $ and \u2018 flags \u2019, $ f_{1}=0 $ , $ f_{2}=0 $ \\ \\ $ \\mathcal{X}_{\\xi}\\leftarrow\\varnothing $ for {i=1 to $ \\xi $ } do \\ \\ Add the most significant term to $ \\mathcal{X}_{\\xi} $ , i.e. , $ \\mathcal{X}_{\\xi}\\leftarrow\\{\\mathcal{X}_{\\xi}\\cup x^{MS}\\} $ \\ \\ end for \\ \\ while {$ o<\\mathcal{O}_{max} $} do \\ \\ */ Down Swing \\ \\ Remove \u2018 $ o $ \u2019 number of least significant terms from $ \\mathcal{X}_{\\xi} $ , i.e. , $ \\mathcal{X}_{\\xi-o}\\leftarrow\\mathcal{X}_{\\xi}\\backslash\\mathcal{X}_{o}^{LS} $ \\ \\ Add \u2018 $ o $ \u2019 number of most significant terms to $ \\mathcal{X}_{\\xi-o} $ , i.e. , $ \\hat{\\mathcal{X}}_{\\xi}\\leftarrow\\{\\mathcal{X}_{\\xi-o}\\cup\\mathcal{X}_{o}^{MS}\\} $ \\ \\ if {$ J(\\hat{\\mathcal{X}}_{\\xi})>J(\\mathcal{X}_{\\xi}) $} then \\ \\ $ \\mathcal{X}_{\\xi}\\leftarrow\\hat{\\mathcal{X}}_{\\xi} $ ; $ J(\\mathcal{X}_{\\xi})\\leftarrow J(\\hat{\\mathcal{X}}_{\\xi}) $ ; $ f_{1}\\leftarrow 0 $ */ better subset is found \\ \\ else \\ \\ $ f_{1}\\leftarrow 1 $ */ down swing is unsuccessful \\ \\ end if \\ \\ if {$ f_{1}=1\\ \\wedge\\ f_{2}=1 $} then \\ \\ $ o=o+1 $ */ increase search depth \\ \\ end if \\ \\ */ Up Swing \\ \\ Add \u2018 $ o $ \u2019 number of most significant terms to $ \\mathcal{X}_{\\xi} $ , i.e. , $ \\mathcal{X}_{\\xi+o}\\leftarrow\\{\\mathcal{X}_{\\xi}\\cup\\mathcal{X}_{o}^{MS}\\} $ \\ \\ Remove \u2018 $ o $ \u2019 number of least significant terms from $ \\mathcal{X}_{\\xi+o} $ , i.e. , $ \\hat{\\mathcal{X}}_{\\xi}\\leftarrow\\mathcal{X}_{\\xi+o}\\backslash\\mathcal{X}_{o}^% {LS} $ \\ \\ if {$ J(\\hat{\\mathcal{X}}_{\\xi})>J(\\mathcal{X}_{\\xi}) $} then \\ \\ $ \\mathcal{X}_{\\xi}\\leftarrow\\hat{\\mathcal{X}}_{\\xi} $ ; $ J(\\mathcal{X}_{\\xi})\\leftarrow J(\\hat{\\mathcal{X}}_{\\xi}) $ ; $ f_{2}\\leftarrow 0 $ */ better subset is found \\ \\ else \\ \\ $ f_{2}\\leftarrow 1 $ */ up swing is unsuccessful \\ \\ end if \\ \\ if {$ f_{1}=1\\ \\wedge\\ f_{2}=1 $} then \\ \\ $ o=o+1 $ */ increase search depth \\ \\ end if \\ \\ \\ \\ end while \\ \\ \\ Orthogonal Oscillating Search (O $ ^{2} $ S) for Structure Selection </float> \\newline </subsection> <subsection> <title> 3.4 Orthogonal Oscillating Search </title> The third algorithm considered in this study is the oscillating search introduced by Somol and Pudil in [@bib:Somol:Pudil:2000] which is the natural successor of the floating search principle.", "It retains one of the key properties of floating search, i.e. , the ability to backtrack .", "Unlike the floating search principle, where the focus is on the individual feature, the oscillating search focuses on a subset of features.", "The basic search engine in this method is the \u2018 swing \u2019 procedure where the subset under consideration is perturbed by successive addition / removal and removal / addition of multiple features.", "In this study, the oscillating search is also adapted for the structure selection by the introduction of \u2018orthogonalization\u2019 and referred to as Orthogonal Oscillating Search (O $ ^{2} $ S).", "The steps involved in O $ ^{2} $ S are outlined in Algorithm [@ref:LABEL:al:o2s] and discussed briefly in the following: \\newline Let \u2018 $ \\xi $ \u2019 denote the required number of terms.", "The search is initialized with a subset, $ \\mathcal{X}_{\\xi} $ , containing $ \\xi $ number of terms.", "This initial subset is obtained by successively adding the most significant terms (See Definition [@ref:LABEL:def:1] ) as outlined Line [@ref:LABEL:l:o2s10] - [@ref:LABEL:l:o2s11] , Algorithm [@ref:LABEL:al:o2s] .", "Subsequently, this subset is perturbed throughout the search process by the \u2018 swing \u2019 procedures.", "The rationale behind the swing procedure is that a better subset could be obtained by replacing multiple (say, \u2018 $ o $ \u2019) number of weak or non-significant terms present in the current subset with the similar number of relevant or significant terms.", "This could be achieved by the following two \u2018swing\u2019 procedures: 1) Down Swing and 2) Up Swing.", "\\newline During the \u2018 down swing \u2019, at first \u2018 $ o $ \u2019 number of least significant terms in $ \\mathcal{X}_{\\xi} $ are removed which yields a subset of $ (\\xi-o) $ terms, $ \\mathcal{X}_{\\xi-o} $ . Subsequently, \u2018 $ o $ \u2019 number of most significant terms are added to $ \\mathcal{X}_{\\xi-o} $ to yield a new, and possibly a better subset of $ \\xi $ terms, $ \\hat{\\mathcal{X}_{\\xi}} $ .", "This new subset is retained provided the criterion function is improved.", "The down swing procedure is outlined in Line [@ref:LABEL:l:ols20] - [@ref:LABEL:l:ols21] , Algorithm [@ref:LABEL:al:o2s] .", "\\newline The Up-swing procedure, as the name suggests, first adds \u2018 $ o $ \u2019 number of most significant terms to $ \\mathcal{X}_{\\xi} $ to yield a subset $ \\mathcal{X}_{\\xi+o} $ .", "Next, a new subset $ \\hat{\\mathcal{X}_{\\xi}} $ is obtained by removing the $ o $ number of least significant terms from $ \\mathcal{X}_{\\xi+o} $ .", "The other aspects are similar to the down swing.", "This procedure is outlined in Line [@ref:LABEL:l:o2s30] - [@ref:LABEL:l:o2s31] , Algorithm [@ref:LABEL:al:o2s] .", "\\newline It is clear that both swing procedures require identification of the following two subsets with respect to the term subset under consideration: the subset of \u2018 $ o $ \u2019 most significant terms (denoted as $ \\mathcal{X}_{o}^{MS} $ ; see Definition [@ref:LABEL:def:3] ) and the subset containing \u2018 $ o $ \u2019 weak/non-significant terms (denoted as $ \\mathcal{X}_{o}^{LS} $ ; see Definition [@ref:LABEL:def:4] ).", "In this study, $ \\mathcal{X}_{o}^{MS} $ is identified using OSF search procedure described in Section [@ref:LABEL:s:OSF] .", "The set of weak terms $ \\mathcal{X}_{o}^{LS} $ is identified using the top-down or backward search variant of OSF.", "\\newline Further, the \u2018search depth\u2019 (denoted by \u2018 $ o $ \u2019) determines the number of terms which are either to be added or to be removed in a particular swing.", "The search depth is adaptive and its value \u2018 $ o $ \u2019 is dependent on the search dynamics.", "The search begins with $ o=1 $ and if two successive swings fail to identify a better term subset then it is incremented by $ 1 $ .", "The search depth is reset to $ 1 $ whenever swing leads to an improved subset.", "The search is terminated when \u2018 $ o $ \u2019 reaches to a pre-specified maximum search depth, $ \\mathcal{O}_{max} $ .", "Consequently, the depth of search can easily be controlled by varying $ \\mathcal{O}_{max} $ .", "This is one of the distinct and important ability of O $ ^{2} $ S which regulates the search efforts as per the prevailing requirement.", "\\newline To analyze the search behavior of O $ ^{2} $ S, it is applied to identify system terms of the system $ \\mathcal{S}_{1} $ considered in the numerical example ( [@ref:LABEL:eq:numExample] ) with the following specifications: $ \\xi=5 $ and $ \\mathcal{O}_{max}=2 $ .", "During this search for system terms, the term subset and the corresponding criterion function obtained in each step are recorded and shown here in Table [@ref:LABEL:t:sbo2s] .", "The change in subset cardinality during the search process is shown in Fig. [@ref:LABEL:f:SBO2S] .", "\\newline The search is initialized by forward inclusion of $ 5 $ terms, as per Line [@ref:LABEL:l:o2s10] - [@ref:LABEL:l:o2s11] , Algorithm [@ref:LABEL:", "al:o2s] .", "This initial subset selects one spurious term, instead of the system term $ x_{2} $ , as shown in Step 1, Table [@ref:LABEL:t:sbo2s] .", "The search begins by the down swing procedure which does not improve the subset, as seen in Step 3, Table [@ref:LABEL:t:sbo2s] .", "However, in the subsequent up-swing, a better term subset, $ \\mathcal{X}_{5}^{+} $ , is identified, i.e. , $ J(\\mathcal{X}_{5}^{+})>J(\\mathcal{X}_{5}) $ .", "Note that at this stage, all the system terms have been identified and the spurious term is discarded, as seen in Step 5, Table [@ref:LABEL:t:sbo2s] .", "The subsequent down swing (Step 7) and up swing (Step 9) identifies the same subset with no improvement in the criterion function, $ J(\\cdotp) $ .", "Consequently, the search depth is increased by \u2018 $ 1 $ \u2019, i.e. , $ o=2 $ .", "The search terminates at Step 11 as the down swing could not find a better subset and any further increase in search depth will lead to $ o>\\mathcal{O}_{max} $ .", "\\newline Note that the variation in subset cardinality during the aforementioned swing procedures are clearly visible in Fig. [@ref:LABEL:f:SBO2S] .", "Especially, see the drop in subset cardinality at Step 10.", "The increase in search depth at this step requires the search for the term subset with $ \\{\\xi-o\\}=3 $ number of terms.", "\\newline </subsection> <subsection> <title> 3.5 Selection of Subset Cardinality (Model Order Selection) </title> The floating search algorithms require the specification of \u2018subset cardinality\u2019 or number of terms to be identified.", "Given that this is not known a priori , in this study, the following procedure is followed to estimate the subset cardinality or \u2018 model order \u2019.", "\\newline For the system under consideration, a search algorithm is applied to identify several term subsets of increasing cardinality in a predefined search interval, denoted by $ [\\xi_{min},\\xi_{max}] $ .", "A set of subsets thus obtained can be used to estimate the model order using an appropriate Information Criterion (IC).", "The objective here is to locate a \u2018 plateau \u2019 or \u2018 knee-point \u2019 in the information criteria which would indicate an acceptable compromise for the bias-variance dilemma.", "The term subsets corresponding to such knee-point or plateau can be selected as the system model.", "\\newline To further understand this procedure, consider the system $ \\mathcal{S}_{1} $ in numerical example ( [@ref:LABEL:eq:numExample] ).", "For this system, OIF is applied to identify term subsets of increasing cardinality in the range of $ [\\xi_{min},\\xi_{max}]=[2,20] $ .", "Thus, a family identified term subsets, denoted by \u2018 $ \\Omega $ \u2019, is obtained as follows: \\newline <equationgroup> <equation> $ \\Omega=\\{\\mathcal{X}_{\\xi_{min}},\\mathcal{X}_{\\xi_{min}+1},\\dots,% \\mathcal{X}_{\\xi_{max}}\\} $ $ \\Omega=\\{\\mathcal{X}_{\\xi_{min}},\\mathcal{X}_{\\xi_{min}+1},\\dots,% \\mathcal{X}_{\\xi_{max}}\\} $ </equation> </equationgroup> \\newline Next, for each identified subset, $ \\mathcal{X}_{\\xi}\\in\\Omega $ , the various information criteria given in [@ref:LABEL:s:appIC] are determined.", "Fig. [@ref:LABEL:f:modelorder] shows the variation in information criteria as cardinality is varied from $ \\xi_{min} $ to $ \\xi_{max} $ .", "It is observed that the \u2018 knee-point \u2019 for all the criteria is obtained at $ \\xi=5 $ .", "This coincides with the actual cardinality of the system $ \\mathcal{S}_{1} $ .", "\\newline In several comparative investigations [@bib:Stoica:Selen:2004a,Hafiz:Swain:CEC:2018] , the Bayesian Information Criterion (BIC) was found to be comparatively robust among the existing information criteria.", "Therefore, for the remainder of the study, the cardinality corresponding to the minimum BIC is selected as the model order.", "Although following this approach the correct model order could be obtained for all test system (as will be shown in Section [@ref:LABEL:s:compEval] ), in practice, we recommend the closer inspection of several term subsets surrounding the plateau or knee-point; as the existing research indicated that the information criteria tend to over-fit [@bib:Stoica:Selen:2004a] .", "\\newline Since the existing research suggest that the dynamics of many nonlinear systems can be captured with $ 15 $ or fewer significant terms [@bib:Chen:Billings:1989] , a pragmatic approach is followed in this study to fix the search interval of the cardinality as follows: $ [\\xi_{min},\\xi_{max}] $ = $ [2,20] $ .", "This can be considered as a thumb-rule.", "However, some exception may exist in certain non-linear systems.", "A simple procedure to determine the cardinality interval in such a scenario is discussed in Section [@ref:LABEL:s:commentModelOrder] .", "\\newline <float> \\ Input : Input-output Data, $ (u,y) $ \\ \\ Output : Identified Model, Structure and Coefficients \\ \\ */ Data Pre-processing \\ \\ Generate set of model terms by specifying $ n_{u},n_{y} $ and $ n_{l} $ of the NARX model \\ \\ */ Search for the system structure \\ \\ Select a orthogonal floating search algorithm: OSF, OIF (Algorithm [@ref:LABEL:al:oif] ) or O $ ^{2} $ S (Algorithm [@ref:LABEL:al:o2s] ) \\ \\ Select the search interval, $ [\\xi_{min},\\xi_{max}] $ \\ \\ $ \\Omega\\leftarrow\\varnothing $ for {each \u2018k\u2019, $ k\\in[\\xi_{min},\\xi_{max}] $} do \\ \\ Identify subset of \u2018 $ k $ \u2019 significant terms, $ \\mathcal{X}_{k} $ \\ \\ $ \\Omega\\leftarrow\\{\\Omega\\cup\\mathcal{X}_{k}\\} $ \\ \\ end for \\ \\ Select the term-subset ( $ \\mathcal{X}^{alg} $ ) with the minimum BIC, i.e. , $ \\mathcal{X}^{alg}=\\{\\mathcal{X}_{i}\\ |\\ BIC(\\mathcal{X}_{i})=\\arg\\min BIC(% \\mathcal{X}_{i}),\\ \\ \\forall\\ \\mathcal{X}_{i}\\in\\Omega $ } \\ \\ \\ Orthogonal Floating Structure Selection </float> \\newline </subsection>  </section>"], ["<section> <title> 4 Investigation Framework </title>  In the following, the framework of this investigation is discussed.", "The overall procedure followed for the structure selection is shown in Algorithm [@ref:LABEL:al:genfloat] .", "The test nonlinear system considered in this study are discussed in Section [@ref:LABEL:s:Data] .", "Further, the possible search outcomes are discussed in Section [@ref:LABEL:s:PM] , to evaluate the term subset found by the search algorithms qualitatively.", "\\newline <subsection> <title> 4.1 Test Non-linear Systems </title> In this study, a total of $ 6 $ non-linear system have been selected from the existing investigations on structure selection [@bib:Mendes:1995,Mao:Billings:1997,Bonin:Pirrodi:2010,Piroddi:Spinelli:2003,Baldacchino:Kadirkamanathan:2013,Falsone:Piroddi:2015] and shown here in Table [@ref:LABEL:t:sys] .", "The systems are excited by a white noise sequence having either uniform or Gaussian distribution as shown in Table [@ref:LABEL:t:sys] .", "For identification purposes, a total of $ 1000 $ input-output data points, $ (u,y) $ , are generated from each system.", "The structure selection is performed following the principle of cross-validation ; where $ 700 $ data points are selected for the estimation purpose and the remaining data points are used for validation, i.e. , $ \\mathcal{N}_{v}=300 $ .", "For each system, the NARX model is generated by setting the input-output lags and the degree of non-linearity to: $ [n_{u},n_{y},n_{l}]=[4,4,3] $ .", "This gives the NARX model set, $ X_{model} $ , with a total of $ 165 $ terms following ( [@ref:LABEL:eq:Nt] ), i.e. , $ n=165 $ .", "\\newline </subsection> <subsection> <title> 4.2 Search Outcomes </title> For comparative evaluation purposes, the term subset found by each search algorithm is qualitatively evaluated.", "For this purpose, the following term sets are defined with reference to the NARX model given by ( [@ref:LABEL:eq:NARXmodel] ), \\newline <list> \\ $ \\mathcal{X}_{model} $ : the set containing all terms of the NARX model \\newline \\ \\ $ \\mathcal{X}^{\\star} $ : the optimum term subset or the set of system terms, $ \\mathcal{X}^{\\star}\\subset\\mathcal{X}_{model} $ \\newline \\ \\ $ \\mathcal{X}^{alg} $ : subset of terms identified by the search algorithm, $ \\mathcal{X}^{alg}\\subset\\mathcal{X}_{model} $ \\newline \\ \\ $ \\mathcal{X}_{spur} $ : set of spurious terms which are selected by the search algorithm, but are not present in the actual system, i.e. , $ \\mathcal{X}_{spur}=\\mathcal{X}^{alg}\\setminus\\mathcal{X}^{\\star} $ \\newline \\ \\ $ \\varnothing $ : the null set \\newline \\ </list> \\newline On the basis of these definitions, one of the following four search outcome can be expected: \\newline <list> \\ Identification of the Correct Structure ( Exact Fitting ) : In this scenario the identified model contains all the system terms and does not include any spurious terms, i.e. , $ \\mathcal{X}^{alg}=\\mathcal{X}^{\\star} $ and $ \\mathcal{X}_{spur}=\\varnothing $ \\newline \\ \\ Over Fitting : The identified model contains all the system terms; however spurious terms are also selected , i.e. , $ \\mathcal{X}^{alg}\\supset\\mathcal{X}^{\\star} $ and $ \\mathcal{X}_{spur}\\neq\\varnothing $ \\newline \\ \\ Under Fitting-1 : The algorithm fails to identify all the system terms; though it does not include any spurious terms , i.e. , $ \\mathcal{X}^{alg}\\subset\\mathcal{X}^{\\star} $ and $ \\mathcal{X}_{spur}=\\varnothing $ \\newline \\ \\ Under Fitting-2 : The algorithm fails to identify all the system terms; however spurious terms are selected , i.e. , $ \\mathcal{X}^{alg}\\not\\supset\\mathcal{X}^{\\star} $ and $ \\mathcal{X}_{spur}\\neq\\varnothing $ \\newline \\ </list> \\newline Thus, qualitatively , the search is successful when all the system/significant terms are identified, i.e. , when the outcome is either Exact-Fitting or Over-Fitting .", "Note that at this stage, the structure identified by the algorithms are unaltered.", "The inclusion of few spurious terms can be tolerated provided that all significant terms are included ( i.e. Over-Fitting scenario) as the spurious terms can easily be identified and removed through a simple null-hypothesis test on the corresponding coefficients.", "\\newline </subsection>  </section>"], ["<section> <title> 5 Results </title>  The goal of this study is to investigate the suitability of existing feature selection algorithms for the task of non-linear system identification.", "For this purpose, 3-well known floating search algorithms have been adapted in the proposed orthogonal floating search framework: OSF, OIF and O $ ^{2} $ S, which are discussed in Section [@ref:LABEL:s:proposedOFS] .", "The adapted algorithms are initially applied to identify the significant terms of $ 6 $ test non-linear systems described in Section [@ref:LABEL:s:Data] .", "The search performance of the algorithms is compared on these systems from various perspectives in Section [@ref:LABEL:s:compEval] .", "The issues related to selection of cardinality interval $ [\\xi_{min},\\xi_{max}] $ are discussed in Section [@ref:LABEL:s:commentModelOrder] .", "\\newline Further, it is worth to note that while the proposed orthogonal floating search can work with any suitable criterion function, in this study, the Error-Reduction-Ratio (ERR) has been selected for this purpose due to its relative simplicity.", "However, ERR is often criticized for its \u2018 local \u2019 nature and blamed for the unsatisfactory search outcome.", "This issue is investigated via a numerical example in Section [@ref:LABEL:s:cERR] .", "\\newline Finally, the proposed orthogonal floating algorithms are applied to identify a discrete model of a continuous time system.", "The identified discrete model is validated through generalized frequency response functions.", "This part of the investigation is discussed in Section [@ref:LABEL:s:Duff] .", "\\newline <subsection> <title> 5.1 Comparative Evaluation </title> The objective of this part of the study is to compare the performance of orthogonal floating search algorithms.", "Following the procedure outlined Algorithm [@ref:LABEL:al:genfloat] , the significant terms of the system shown in Table [@ref:LABEL:t:sys] are identified.", "It is worth to note that while OSF and OIF do not have any control parameter, O $ ^{2} $ S requires the selection of maximum search depth, $ \\mathcal{O}_{max} $ .", "In this study, a maximum of $ 25\\% $ terms is allowed to be exchanged, i.e. , $ \\mathcal{O}_{max}=\\lceil 0.25\\times\\min\\{\\xi,n-\\xi\\}\\rceil $ .", "\\newline The outcomes of model order selection are shown in Fig [@ref:LABEL:f:mos] .", "Note that the \u2018knee-point\u2019 in BIC coincides with the known cardinality (actual number of terms) of the systems."]], "target": "The selected cardinality (number of terms) for each system is shown in Table along with the qualitative search outcomes. It is interesting to see that the best possible search outcome, \u2018 Exact-Fitting \u2019, is obtained for all combinations of system and search algorithm, except one."}, {"tabular": ["  Dataset  &  Model  &  Uncalibrated  &  TS  &  ETS  &  IRM  &  IROvA  &  IROvA-TS ", "  &    &    &    &  ( ours )  &  ( ours )  &    &  ( ours ) ", " CIFAR-10  &  DenseNet 40  &  3.20  &  1.44 (0.602)  &  1.44 (0.602)  &  1.44 (0.559)  &  1.34 (0.559)  &  1.32 (0.587) ", " CIFAR-10  &  LeNet 5  &  1.80  &  1.47 (0.035)  &  1.47 (0.036)  &  1.52 (0.021)  &  1.79 (-0.018)  &  1.80 (-0.002) ", " CIFAR-10  &  ResNet 110  &  4.25  &  2.89 (0.934)  &  2.89 (0.934)  &  1.60 (1.03)  &  1.54 (1.17)  &  1.51 (1.22) ", " CIFAR-10  &  WRN 28-10  &  2.57  &  2.59 (0.52)  &  2.59 (0.512)  &  1.23 (0.617)  &  1.19 (0.637)  &  1.11 (0.658) ", " CIFAR-100  &  DenseNet 40  &  12.17  &  1.64 (2.76)  &  1.61 (2.76)  &  3.31 (2.53)  &  4.29 (2.12)  &  2.16 (2.27) ", " CIFAR-100  &  LeNet 5  &  2.86  &  1.38 (0.081)  &  1.29 (0.089)  &  1.68 (0.036)  &  3.85 (-0.608)  &  3.14 (-5.98) ", " CIFAR-100  &  ResNet 110  &  13.60  &  2.99 (3.17)  &  2.33 (3.21)  &  5.00 (2.92)  &  5.39 (2.64)  &  3.23 (3.15) ", " CIFAR-100  &  WRN 28-10  &  4.25  &  3.17 (0.195)  &  2.86 (0.252)  &  3.01 (0.503)  &  3.30 (0.113)  &  2.72 (0.192) ", " ImageNet  &  DenseNet 161  &  4.93  &  1.95 (0.394)  &  1.76 (0.434)  &  2.18 (0.354)  &  3.64 (-0.553)  &  2.65 (-0.432) ", " ImageNet  &  ResNeXt 101  &  7.53  &  3.02 (0.984)  &  2.20 (1.07)  &  3.50 (0.961)  &  4.71 (0.169)  &  3.24 (0.382) ", " ImageNet  &  VGG 19  &  3.04  &  1.98 (0.130)  &  1.60 (0.157)  &  2.22 (0.095)  &  3.74 (-1.09)  &  2.87 (-1.06) ", " ImageNet  &  WRN 50-2  &  4.58  &  2.81 (0.280)  &  2.38 (0.340)  &  2.84 (0.326)  &  3.79 (-0.534)  &  3.06 (-0.551)  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Machine learning (ML) models, e.g., deep neural networks, are increasingly used for making potentially important decisions in applications ranging from object detection [@bib:girshick2015fast] , autonomous driving [@bib:chen2015deepdriving] to medical diagnosis [@bib:litjens2017survey] .", "Several of these applications are high-regret in nature and incorrect decisions have significant costs.", "Therefore, besides achieving high accuracy, it is also crucial to obtain reliable uncertainty estimates, which can help deciding whether the model predictions can be trusted [@bib:jiang2018trust,kendall2017uncertainties] .", "Specifically, a classifier should provide a calibrated uncertainty measure in addition to its prediction.", "A classifier is well-calibrated, if the probability associated with the predicted class label matches the probability of such prediction being correct [@bib:brocker2009reliability,dawid1982well] .", "Unfortunately, many off-the-shelf ML models are not well calibrated [@bib:niculescu-Mizil2005predicting,zadrozny2001learning,zadrozny2002transforming] .", "Poor-calibration is particularly prominent in highly complex models such as deep neural network classifiers [@bib:guo2017calibration,hein2019relu,lakshminarayanan2017simple,nguyen2015deep] .", "A popular calibration approach is to learn a transformation (referred to as a calibration map) of the trained classifier\u2019s predictions on a calibration dataset in a post-hoc manner.", "Pioneering work along this direction include Platt scaling [@bib:platt2000probabilistic] , histogram binning [@bib:zadrozny2001learning] , isotonic regression [@bib:zadrozny2002transforming] , Bayesian binning into quantiles [@bib:naeini2015obtaining] .", "Recently, calibration methods for multi-class deep neural network classifiers have been developed, which include: temperature, vector & matrix scaling [@bib:guo2017calibration] , Dirichlet scaling [@bib:kull2019beyond] , and Gaussian processes based calibration method [@bib:milios2018dirichlet,wenger2019non] .", "Besides post-hoc calibrations, there also exist approaches for training ab-initio well calibrated models [@bib:kumar2018trainable,lakshminarayanan2017simple,pereyra2017regularizing,seo2019learning,tran2019calibrating] , or representing the prediction uncertainty in a Bayesian framework [@bib:blundell2015weight,gal2016dropout,maddox2019simple] .", "Ideally, an uncertainty calibration method should satisfy the following properties: (a) accuracy-preserving \u2013 calibration process should not degrade the classification accuracy of the original classifier, (b) data-efficiency \u2013 the ability to achieve well-calibration without requiring a large amount of calibration data, and (c) high expressive power \u2013 the ability to approximate true calibration function given sufficient calibration data.", "Despite the popularity of post-hoc calibration, we found that none of the existing methods satisfy all three requirements simultaneously (see [@ref:LABEL:fig:summary] ).", "Yet given practical constraints, such as high data collection costs, high complexity of calibration tasks, and need for highly accurate classifiers, the development of calibration methods which satisfy all three requirements simultaneously is crucial for the success of real-world ML systems.", "After calibrating a classifier, the next equally important step is to reliably evaluate the calibration performance.", "Most of the existing works judge the calibration performance by the expected calibration error (ECE) [@bib:naeini2015obtaining] .", "ECE is usually estimated from a reliability diagram and its associated confidence histogram [@bib:guo2017calibration,kull2019beyond,milios2018dirichlet,naeini2015obtaining,nixon2019measuring,vaicenavicius2019evaluating] .", "However, histogram-based ECE estimators can be unreliable (e.g., asymptotically biased or noisy) due to their sensitivity to binning schemes [@bib:kumar2019verified,nixon2019measuring,vaicenavicius2019evaluating] .", "Additionally, as a density estimator, histogram is known to be less data-efficient than alternative choices, such as kernel density estimators [@bib:scott1992multivariate] .", "Therefore, it is of utmost importance to develop reliable and data-efficient methods to evaluate the calibration performance.", "To achieve the aforementioned objectives, this paper makes the following contributions: \\newline <list> \\ We introduce the following desiderata for uncertainty calibration \u2013 (a) accuracy-preserving, (b) data-efficient, and (c) expressive.", "\\newline \\ \\ We propose general ensemble and compositional calibration strategies to achieve high data-efficiency and expressive power while provably preserving accuracy.", "\\newline \\ \\ We propose a data-efficient kernel density estimator for a reliable evaluation of the calibration performance.", "\\newline \\ \\ Using extensive experiments, we show that the proposed Mix-n-Match calibration schemes achieve remarkably better data-efficiency and expressivity upon existing methods while provably preserve accuracy.", "\\newline \\ </list> \\newline  </section>"], ["<section> <title> 2 Definitions and Desiderata </title>  Consider a multi-class classification problem.", "The random variable $ X\\in\\mathcal{X} $ represents the input feature, and $ Y=(Y_{1},\\ldots,Y_{L})\\in\\mathcal{Y} $ represents the $ L $ -class one-hot encoded label.", "Let $ f:\\mathcal{X}\\rightarrow\\mathcal{Z}\\subseteq\\Delta^{L} $ be a probabilistic classifier that outputs a prediction probability (or confidence) vector $ z=f(x)=(f_{1}(x),\\ldots,f_{L}(x)) $ , where $ \\Delta^{L} $ is the probability simplex $ \\{(z_{1},\\ldots,z_{L})\\in[0,1]^{L}|\\sum_{l=1}^{L}z_{l}=1\\} $ . Let $ \\mathbb{P}(Z,Y) $ denote the joint distribution of the prediction $ Z $ and label $ Y $ .", "Expectations ( $ \\mathbb{E} $ ) are taken over this distribution unless otherwise specified.", "Let the canonical calibration function $ \\pi(z) $ represents the actual class probability conditioned on the prediction $ z $ [@bib:vaicenavicius2019evaluating] : \\newline <equation> $ \\begin{split}\\pi(z)&=(\\pi_{1}(z),\\ldots,\\pi_{L}(z))% \\\\ \\text{with }&\\pi_{l}(z)=\\mathbb{P}[Y_{l}=1|f(X)=z].% \\end{split} $ </equation> We would like the predictions to be calibrated, which intuitively means that it represents a true probability.", "The formal definition of calibration is as follows: \\newline <theorem> Definition 2.1 .", "The classifier $ f $ is perfectly calibrated , if for any input instances $ x\\in\\mathcal{X} $ , the prediction and the canonical calibration probabilities match: $ z=\\pi(z) $ [@bib:dawid1982well] .", "\\newline </theorem> We focus on a post-hoc approach for calibrating a pre-trained classifier, which consists of two steps: $ (1) $ finding a calibration map $ T:\\Delta^{L}\\rightarrow\\Delta^{L} $ that adjusts the output of an existing classifier to be better calibrated, based on a set of $ n_{c} $ calibration data samples; and $ (2) $ evaluate the calibration performance based on a set of $ n_{e} $ evaluation data samples.", "Next, we discuss both steps in detail and highlight shortcomings of current methods.", "\\newline <subsection> <title> 2.1 Calibration Step </title> The first task in the calibration pipeline is to learn a calibration map $ T $ based on $ n_{c} $ calibration data samples $ \\{(z^{(i)},y^{(i)})\\}_{i=1}^{n_{c}} $ .", "Existing calibration methods can be categorized into two groups: Parametric methods assume that the calibration map belongs to a finite-dimensional parametric family $ \\mathcal{T}=\\{T(z;\\theta)|\\theta\\in\\Theta\\ \\subseteq\\mathbb{R}^{M}\\} $ .", "As an example, for binary classification problems, Platt scaling [@bib:platt2000probabilistic] uses the logistic transformation to modify the prediction probability of a class (assuming $ z_{1} $ ): $ T(z_{1};a,b)=(1+\\exp{(-az_{1}-b)})^{-1} $ , where the scalar parameters $ a $ , $ b $ are learned by minimizing the negative log likelihood on the calibration data set.", "Parametric methods are easily extendable to multi-class problems, such as temperature, matrix scaling [@bib:guo2017calibration] and Dirichlet scaling [@bib:kull2019beyond] .", "Non-parametric methods assume that the calibration map is described with infinite-dimensional parameters.", "For binary classification problems, popular methods include: Histogram binning [@bib:zadrozny2001learning] which leverages histograms to estimate the calibration probabilities $ \\pi(z) $ as the calibrated prediction $ T(z) $ , Bayesian Binning [@bib:naeini2015obtaining] performs Bayesian averaging to ensemble multiple histogram binning calibration maps, and Isotonic regression [@bib:zadrozny2002transforming] learns a piecewise constant isotonic function that minimizes the residual between the calibrated prediction and the labels.", "A common way to extend these methods to a multi-class setting is to decompose the problem as $ L $ one-versus-all problems [@bib:zadrozny2002transforming] , separately identify the calibration map $ T_{l} $ for each class probability ( $ z_{l} $ ) in the binary manner, and finally normalize the calibrated predictions into $ \\Delta^{L} $ .", "While there are existing approaches tailored for calibrating multi-class deep neural network models, none of them satisfy all three proposed desiderata ( accuracy-preserving, data-efficient, expressive ) in Sec. [@ref:LABEL:intro] simultaneously.", "[@ref:LABEL:fig:summary] (top right) highlights that good calibration capability might come at the cost of classification accuracy for approaches such as isotonic regression.", "This motivates us to design provably accuracy-preserving calibration methods.", "Furthermore, the effectiveness of calibration method changes with the amount of calibration data.", "Parametric approaches are generally data-efficient but have very limited expressive power.", "On the other hand, non-parametric approaches are expressive but highly data-inefficient.", "Therefore, in [@ref:LABEL:fig:summary] (top left), we see that temperature scaling is the best calibration method in data-limited regime, while isotonic regression is superior in data-rich regime.", "It is thus naturally desirable to design a calibration method that is effective in both data-limited and data-rich regime.", "However, earlier studies examined calibration methods with fixed dataset size [@bib:guo2017calibration,kull2019beyond,wenger2019non] , and shed no light on this issue.", "\\newline </subsection> <subsection> <title> 2.2 Calibration Error Evaluation Step </title> The next task in the calibration pipeline is to evaluate the calibration performance based on $ n_{e} $ evaluation data points $ \\{(z^{(i)},y^{(i)})\\}_{i=1}^{n_{e}} $ .", "A commonly used statistics is the expected deviation from $ z $ to $ \\pi(z) $ , also called expected calibration error [@bib:naeini2015obtaining] : \\newline <equation> $ \\text{ECE}^{d}(f)=\\mathbb{E}\\lVert Z-\\pi(Z)\\rVert_{d}^{d}=\\int\\lVert z-\\pi(z)% \\rVert_{d}^{d}\\;p(z)\\mathop{dz} $ </equation> where $ \\lVert\\cdot\\rVert_{d}^{d} $ denotes the $ d $ -th power of the $ \\ell_{d} $ norm, and $ p(z) $ represents the marginal density function of $ Z=f(X) $ .", "The original ECE definition adopts $ d=1 $ [@bib:guo2017calibration,naeini2015obtaining] , while $ d=2 $ is also commonly used [@bib:brocker2009reliability,hendrycks2018deep,kumar2019verified] .", "Note that probabilities in Eq. ( [@ref:LABEL:pi] ) and Eq. ( [@ref:LABEL:cali] ) cannot be computed directly using finite samples, since $ \\pi(z) $ is a continuous random variable.", "This motivates the need of designing reliable ECE estimators.", "A popular estimation approach is based on histograms [@bib:naeini2015obtaining] .", "It partitions the evaluation data points into $ b $ bins $ \\{B_{1},\\ldots,B_{b}\\} $ according to the predictions $ z $ , calculate the average prediction $ \\bar{f}(B_{i}) $ and label $ \\bar{\\pi}(B_{i}) $ inside the bins $ B_{i} $ , and estimate ECE by: \\newline <equation> $ \\overline{\\text{ECE}}^{d}(f)=\\sum_{i=1}^{b}\\frac{\\#B_{i}}{n_{e}}\\lVert\\bar{f}(% B_{i})-\\bar{\\pi}(B_{i})\\rVert_{d}^{d}. $ </equation> where $ \\#B_{i} $ denotes the number of instances in $ B_{i} $ .", "Despite its simplicity, histogram-based estimator suffers from several issues.", "First, it has bias-variance dilemma with respect to the selection of bin amount and edge locations.", "For example, too few bins lead to under-estimation of ECE [@bib:kumar2019verified,vaicenavicius2019evaluating] .", "On the other hand, too many bins leads to noisy estimates as each bin becomes sparsely populated [@bib:nixon2019measuring] .", "Therefore, histogram-based ECE estimators are unreliable (e.g., asymptotically biased or noisy) due to their sensitivity to the binning scheme.", "Unfortunately, a consistently reliable scheme for choosing the optimal bin sets does not exist [@bib:scott1992multivariate,simonoff1997measuring] .", "Finally, histogram-based estimator is known to converge slower as compared to other advanced non-parametric density estimators [@bib:scott1992multivariate] , leading to a data-inefficient estimation of ECE.", "Next (in Sec. [@ref:LABEL:beyondts] ), we discuss proposed Mix-n-Match calibration strategies which satisfy the above discussed desiderata.", "Later (in Sec. [@ref:LABEL:Eval] ), we will address the issue of designing a reliable and data-efficient ECE estimator.", "\\newline </subsection>  </section>"], ["<section> <title> 3 Designing Calibration Methods </title>  We first present (in Sec. [@ref:LABEL:apcm] ) a general strategy to design provably accuracy-preserving calibration methods.", "Next, we discuss strategies for parametric (in Sec. [@ref:LABEL:tss] ) and non-parametric calibration methods (in Sec. [@ref:LABEL:ir] ) to fulfill remaining desiderata.", "\\newline <subsection> <title> 3.1 Accuracy-preserving Calibration </title> We present a general form of accuracy-preserving calibration maps and validate its accuracy-preserving property.", "\\newline <theorem> Definition 3.1 (Accuracy-Preserving Calibration Map) .", "Let $ g:[0,1]\\rightarrow\\mathbb{R}_{\\geq 0} $ be a non-negative strictly isotonic function.", "Then, an accuracy-preserving calibration map is given by: \\newline <equationgroup> <equation> $  T(z)={(g(z_{1}),g(z_{2}),\\ldots,g(z_{L}))}/{\\sum_{l=1}^{L}g(z_{l% })}.", "$ $  T(z)={(g(z_{1}),g(z_{2}),\\ldots,g(z_{L}))}/{\\sum_{l=1}^{L}g(z_{l% })}.", "$ </equation> </equationgroup> \\newline </theorem> In Eq. ( [@ref:LABEL:sharet] ), we apply the same function $ g $ to transform all entries in the prediction probability vector $ z $ to an un-normalized vector $ g(z)=(g(z_{1}),\\ldots,g(z_{L})) $ ; and normalize $ g(z) $ to a probability simplex $ \\Delta^{L} $ .", "The single strictly isotonic function $ g $ maintains the ordering of class prediction probabilities, and preserves the classification accuracy.", "\\newline <theorem> Proposition 3.1 .", "The calibration map in Eq. ( [@ref:LABEL:sharet] ) preserves the classification accuracy of the uncalibrated classifier.", "\\newline </theorem> <proof> Proof.", "Please see supplementary material Sec. [@ref:LABEL:potpa] .", "\u220e \\newline </proof> </subsection> <subsection> <title> 3.2 Parametric Calibrations </title> Parametric methods are already data-efficient, thus, one simply needs to enforce the accuracy-preserving requirement and improve their insufficient expressive power.", "\\newline <subsubsection> <title> 3.2.1 Preserving accuracy </title> As discussed in Proposition [@ref:LABEL:ppopta] , the use of a strictly isotonic function preserves the accuracy.", "Fortunately, several existing parametric methods, such as, Platt [@bib:platt2000probabilistic] or temperature scaling [@bib:guo2017calibration] , and beta scaling [@bib:kull2017beyond] , employ strictly isotonic functions \u2013 logistic function and beta function, respectively.", "Therefore, these methods are already accuracy-preserving.", "Otherwise, the general form as provided in Eq. ( [@ref:LABEL:sharet] ) can be used for designing accuracy-preserving calibration maps.", "\\newline </subsubsection> <subsubsection> <title> 3.2.2 Improving expressivity by model ensemble </title> We outline a strategy compatible with any parametric calibration method to improve its expressivity.", "The idea is to use an ensemble of calibration maps from the same accuracy-preserving parametric family, but with different parameters: \\newline <equation> $ T(z)=w_{1}T(z;\\theta_{1})+w_{2}T(z;\\theta_{2})+\\ldots+w_{M}T(z;\\theta_{M}), $ </equation> where $ w $ are non-negative coefficients summing up to one.", "The weighted sum preserves isotonicity, thus the ensemble inherits the accuracy-preserving property from its individual components.", "The increased expressivity stems from the fact that more parameters becomes adjustable, including $ \\theta_{j} $ and the weights $ w_{j} $ for each component $ j $ in the ensemble.", "We find the weights $ w $ and parameters $ \\theta $ by minimizing the loss $ R(.) $ between calibrated predictions $ T(z) $ and labels $ y $ : \\newline <equationgroup> <equation> $ \\underset{w,\\theta}{\\text{minimize}} $ $ \\underset{w,\\theta}{\\text{minimize}} $ $ \\sum_{i=1}^{n_{c}}R\\big{(}\\sum_{j=1}^{M}w_{j}T(z^{(i)};\\theta_{j}% ),y^{(i)}\\big{)} $ $ \\sum_{i=1}^{n_{c}}R\\big{(}\\sum_{j=1}^{M}w_{j}T(z^{(i)};\\theta_{j}% ),y^{(i)}\\big{)} $ </equation> <equation> $ \\mathbf{1}_{1\\times M}w=1;w\\geq\\mathbf{0}_{M\\times 1}. $ $ \\mathbf{1}_{1\\times M}w=1;w\\geq\\mathbf{0}_{M\\times 1}. $ </equation> </equationgroup> Using the above formulation, we show a specific generalization of temperature scaling ( TS ) [@bib:guo2017calibration] to satisfy the proposed desiderata.", "Ensemble Temperature Scaling (ETS).", "Note that TS is already accuracy-preserving and data-efficient.", "Next, we propose an ensemble formulation to improve the expressivity of TS while maintaining its accuracy-preserving and data-efficiency properties.", "Specifically, we propose a three-component ensemble as follows: \\newline <equation> $ T(z;w,t)=w_{1}T(z;t)+w_{2}z+w_{3}\\frac{1}{L}, $ </equation> where the calibration map for original TS is expressed by $ T(z;t)={(z_{1}^{1/t},z_{2}^{1/t},\\ldots,z_{L}^{1/t})}/{\\sum_{l=1}^{L}z_{l}^{1/% t}} $ .", "Interestingly, the remaining two components in the ensemble are also TS calibration maps but with fixed temperature $ t $ : \\newline <list> \\ TS calibration map with $ t=1 $ (outputs uncalibrated prediction $ z $ ).", "It increases the stability when the original classifier is well calibrated [@bib:kull2017beyond] .", "\\newline \\ \\ TS calibration map with $ t=\\infty $ (outputs uniform prediction $ z_{l}=1/L $ for each class).", "It \u2018smooths\u2019 the predictions, similar to how label-smoothing training technique smooths the one-hot labels [@bib:szegedy2016rethinking] , which has shown to be successful in training better calibrated neural networks [@bib:muller2019does] .", "\\newline \\ </list> The weight $ w $ and temperature $ t $ of ensemble is identified by solving the following convex optimization problem: \\newline <equationgroup> <equation> $ \\underset{t,w}{\\text{minimize}} $ $ \\underset{t,w}{\\text{minimize}} $ $ \\sum_{i=1}^{n_{c}}R\\big{(}w_{1}T(z^{(i)};t)+w_{2}z^{(i)}+w_{3}% \\frac{1}{L},y^{(i)}\\big{)} $ $ \\sum_{i=1}^{n_{c}}R\\big{(}w_{1}T(z^{(i)};t)+w_{2}z^{(i)}+w_{3}% \\frac{1}{L},y^{(i)}\\big{)} $ </equation> <equation> $  t>0;\\mathbf{1}_{1\\times 3}w=1;w\\geq\\mathbf{0}_{3\\times 1}. $ $  t>0;\\mathbf{1}_{1\\times 3}w=1;w\\geq\\mathbf{0}_{3\\times 1}. $ </equation> </equationgroup> ETS preserves the accuracy, as it uses a convex combination of (strictly) isotonic function $ g=z_{l}^{1/t} $ across all classes/components.", "Further, as ETS only has three additional parameters (the weights) compared to TS, we expect it to be data-efficient.", "We will see later in Sec. [@ref:LABEL:sec:cee] , ETS is significantly more expressive than TS while maintaining its accuracy-preserving and data-efficiency properties.", "\\newline </subsubsection> </subsection> <subsection> <title> 3.3 Non-parametric Calibrations </title> Since non-parametric methods are generally expressive, we focus on providing solutions to enforce the accuracy-preserving requirement, and to improve their data-efficiency.", "\\newline <subsubsection> <title> 3.3.1 Preserving Accuracy </title> Following Proposition [@ref:LABEL:ppopta] , in order to preserve accuracy, a strictly isotonic calibration function is needed to be constructed non-parametrically.", "For binary classification, this requirement is satisfied by the isotonic regression (IR) calibration [@bib:zadrozny2002transforming] : for class $ 1 $ (class $ 2 $ is the complement), it sorts data points according to their predictions ( $ z_{1}^{(1)}\\leq z_{1}^{(2)}\\ldots\\leq z_{1}^{(n_{c})} $ ), then fits an isotonic function $ g $ to minimize the residual between $ g(z_{1}) $ and $ y_{1} $ .", "The common way to extend this method to a multi-class setting is to decompose the problem as $ L $ one-versus-all problem, which we further denote as IROvA .", "Unfortunately, this formulation is neither accuracy-preserving nor data-efficient.", "To extend IR to multi-class problems while preserving accuracy, we use the accuracy-preserving calibration map as defined in Def.", "[@ref:LABEL:apc] .", "This calibration map work identically on all the classes and does not distinguish among them.", "Next, we explain how this procedure is also more data-efficient than the conventional IROvA approach.", "\\newline </subsubsection> <subsubsection> <title> 3.3.2 Improving Efficiency by Data Ensemble </title> We first explain the proposed multi-class isotonic regression ( IRM ) procedure, and then comment on its data-efficiency.", "IRM first ensembles the predictions and labels from all the classes, then learn a strictly isotonic function $ g $ that best fits the transformed predictions versus labels, as described next: Step 1 (Data ensemble) : extract all entries of prediction vector $ \\{z^{(i)}\\}_{i=1}^{n_{c}} $ and label vector $ \\{y^{(i)}\\}_{i=1}^{n_{c}} $ . Let $ \\{a^{(j)}\\}_{j=1}^{n_{c}L} $ and $ \\{b^{(j)}\\}_{j=1}^{n_{c}L} $ denote the set of $ n_{c}L $ prediction and label entries.", "Sort both vectors such that $ a^{(1)}\\leq a^{(2)}\\leq\\ldots a^{(n_{c}L)} $ .", "Step 2 (Isotonic regression) : learn an isotonic function $ g^{*} $ by minimizing the squared error loss between $ g(a) $ and $ b $ : \\newline <equationgroup> <equation> $ \\underset{g\\in\\mathcal{G}}{\\text{minimize}} $ $ \\underset{g\\in\\mathcal{G}}{\\text{minimize}} $ $ \\sum_{j=1}^{n_{c}L}[g(a^{(j)})-b^{(j)}]^{2}, $ $ \\sum_{j=1}^{n_{c}L}[g(a^{(j)})-b^{(j)}]^{2}, $ </equation> </equationgroup> where $ \\mathcal{G} $ is a family of piecewise constant isotonic functions [@bib:zadrozny2002transforming] .", "The pair-adjacent violator algorithm [@bib:ayer1955empirical] is used to find the best function.", "Step 3 (Imposing strict isotonicity) : the learned function $ g^{*} $ is only isotonic.", "To make it strictly isotonic, we modify it to $ \\hat{g}(a)=g^{*}(a)+\\epsilon a $ , where $ \\epsilon $ is a very small positive number, such that $ g(a)<g(a^{\\prime}) $ whenever $ a<a^{\\prime} $ .", "Plugging the strictly isotonic function $ \\hat{g} $ back to Eq. ( [@ref:LABEL:sharet] ), we can obtain the non-parametric calibration map.", "Remark .", "Comparing to IROvA, the proposed IRM preserves the accuracy .", "In addition, it is more data-efficient , since it uses $ n_{c}L $ data points to identify one isotonic function in contrast to $ n_{c} $ data points in IROvA. We should also highlight that these benefits do not come free: by enforcing the same calibration map on all the classes, the proposed approach is less expressive than IROvA. In fact, we expect an efficiency-expressivity trade-off for the proposed solution \u2013 with the number of classes $ L $ increasing, it will become more data-efficient but less expressive comparing to one-vs-all.", "This phenomenon is later verified in Sec. [@ref:LABEL:sec:cnnc] .", "\\newline </subsubsection> </subsection> <subsection> <title> 3.4 Combining Parametric and Non-parametric Calibration </title> To get the best of both worlds, i.e., high data-efficiency of parametric methods and high expressivity of non-parametric methods, we propose a compositional method as well.", "Specifically, we apply a data-efficient parametric calibration method first, and then conduct non-parametric calibration on the parametric calibrated entries.", "Intuitively, first fitting a parametric function acts like a baseline for variance reduction [@bib:kumar2019verified] and then conducting a non-parametric calibration enjoys higher data-efficiency than the non-parametric calibration alone.", "Expressivity is unaffected by the composition since no additional restriction is imposed on the non-parametric layer.", "Accuracy-preserving is satisfied if the adopted parametric and non-parametric calibration maps satisfy Def.", "[@ref:LABEL:apc] , since the composition of strictly isotonic functions remains strictly isotonic.", "\\newline </subsection>  </section>"], ["<section> <title> 4 Evaluating Calibration Errors </title>  Next step in the calibration pipeline is to evaluate the calibration performance by estimating the expected calibration error as given in Eq. ( [@ref:LABEL:cali] ).", "The primary challenge is the involvement of two unknown densities $ p(z) $ and $ \\pi(z) $ .", "Histogram-based estimator [@bib:naeini2015obtaining] replaces the unknown densities by their bin-discretized version as given in Eq. ( [@ref:LABEL:hist] ).", "It is easy to implement, but also inevitably inherits drawbacks from histograms, such as the sensitivity to the binning schemes, and the data-inefficiency.", "We alleviate these challenges by replacing histograms with non-parametric density estimators that are continuous (thus, avoid the binning step) and, are more data-efficient.", "Specifically, we use kernel density estimation (KDE) [@bib:parzen1962estimation,rosenblatt1956remarks] to estimate the ECE for its implementation easiness and tractable theoretical properties.", "\\newline <subsection> <title> 4.1 KDE-based ECE Estimator </title> Let $ K:\\mathbb{R}\\rightarrow\\mathbb{R}_{\\geq 0} $ denote a smoothing kernel function [@bib:tsybakov2008introduction] .", "Given a fixed bandwidth $ h>0 $ , we have $ K_{h}(a)=h^{-1}K(a/h) $ .", "Based on the evaluation dataset, the unknown probabilities are estimated using KDE as follows: \\newline <equationgroup> <equation> $ \\begin{split}\\tilde{p}(z)&=\\dfrac{h^{-L% }}{n_{e}}\\sum\\limits_{i=1}^{n_{e}}\\prod_{l=1}^{L}K_{h}(z_{l}-z_{l}^{(i)}),\\\\ \\tilde{\\pi}(z)&=\\dfrac{\\sum\\limits_{i=1}^{n_{e}}y^{(% i)}\\prod_{l=1}^{L}K_{h}(z_{l}-z_{l}^{(i)})}{\\sum\\limits_{i=1}^{n_{e}}\\prod_{l=% 1}^{L}K_{h}(z_{l}-z_{l}^{(i)})}.\\end{split} $ $ \\begin{split}\\tilde{p}(z)&=\\dfrac{h^{-L% }}{n_{e}}\\sum\\limits_{i=1}^{n_{e}}\\prod_{l=1}^{L}K_{h}(z_{l}-z_{l}^{(i)}),\\\\ \\tilde{\\pi}(z)&=\\dfrac{\\sum\\limits_{i=1}^{n_{e}}y^{(% i)}\\prod_{l=1}^{L}K_{h}(z_{l}-z_{l}^{(i)})}{\\sum\\limits_{i=1}^{n_{e}}\\prod_{l=% 1}^{L}K_{h}(z_{l}-z_{l}^{(i)})}.\\end{split} $ </equation> </equationgroup> Plugging them back in Eq. ( [@ref:LABEL:cali] ), we obtain the KDE-based ECE $ ^{d} $ estimator: \\newline <equation> $ \\widetilde{\\text{ECE}}^{d}(f)=\\int\\lVert z-\\tilde{\\pi}(z)\\rVert_{d}^{d}\\;% \\tilde{p}(z)\\mathop{dz}. $ </equation> The integration in Eq. ( [@ref:LABEL:np] ) can be performed numerically (e.g., using Trapzoidal rule).", "We next provide a theoretical analysis of statistical properties of the proposed KDE ECE estimator when $ d=1 $ .", "The results for $ d=2 $ can be obtained similarly.", "\\newline <theorem> Theorem 4.1 (Statistical properties) .", "Assuming the unknown densities $ p(z) $ and $ \\pi(z) $ are smooth ( $ \\beta $ -H\u00f6lder) and bounded, with the bandwidth $ h\\asymp n_{e}^{-1/(\\beta+L)} $ , the KDE ECE is asymptotically unbiased and consistent, with a convergence rate $ |\\mathbb{E}[\\widetilde{\\text{ECE}}^{1}(f)]-\\text{ECE}^{1}(f)|\\in O(n_{e}^{-% \\beta/(\\beta+L)}) $ .", "\\newline </theorem> <proof> Proof.", "Please see supplementary material Sec. [@ref:LABEL:sec:kdeproof] .", "\u220e \\newline </proof> As verifying these smoothness assumptions in practice is highly non-trivial [@bib:kumar2019verified] , we corroborate our theoretical results using empirical comparisons in Sec. [@ref:LABEL:sec:cee] .", "The implementation details for KDE is provided in the supplementary material Sec. [@ref:LABEL:kid] .", "Dimensional reduction for multi-class problems .", "Convergence rates of non-parametric density estimators depend undesirably on the class dimension $ L $ , making the estimation challenging for multi-class problems.", "A way around this curse of dimensionality problem is to use the {top-label} ECE $ ^{d} $ [@bib:guo2017calibration] or the class-wise ECE $ ^{d} $ [@bib:kull2019beyond,kumar2019verified] .", "Both reduce the effective dimension to one, but weaken the calibration notion in Def.", "[@ref:LABEL:perfect] , meaning that they can be zero even if the model is not perfectly calibrated [@bib:vaicenavicius2019evaluating] .", "\\newline </subsection> <subsection> <title> 4.2 A Dimensionality-Independent Ranking Method </title> In many practical situations, the main goal for evaluating calibration errors is to compare (or rank) calibration maps.", "However, rankings based on the approximations, e.g., top-label and class-wise ECE $ ^{d} $ , have been observed to be contradictory [@bib:kull2019beyond,nixon2019measuring] .", "This raises the question rankings based on these approximations are indicative of the ranking based on actual ECE $ ^{d} $ in Eq. ( [@ref:LABEL:cali] ).", "Next, we present a dimensionality-independent solution to compare calibration maps according to their actual calibration capabilities, rather than resorting to weaker variants.", "The solution relies on the well-known calibration refinement decomposition [@bib:murphy1973new] for the strictly proper scoring loss [@bib:gneiting2007strictly] .", "Thus, it is applicable only when $ d=2 $ , since the absolute loss ( $ d=1 $ ) is improper [@bib:buja2005] .", "Since ECE $ ^{1} $ and ECE $ ^{2} $ are closely related ( $ \\sqrt{\\text{ECE}^{2}}< $ ECE $ ^{1}<\\sqrt{L\\cdot\\text{ECE}^{2}} $ ), we anticipate comparisons based on ECE $ ^{2} $ and ECE $ ^{1} $ should be similar.", "Specifically, we propose to use calibration gain (defined next) for the comparison.", "\\newline <theorem> Definition 4.1 .", "The calibration gain is defined as the reduction in ECE $ ^{d} $ after applying a calibration map ( $ T\\circ f $ ): \\newline <equation> $ \\Delta\\text{ECE}^{2}(T)=\\text{ECE}^{2}(f)-\\text{ECE}^{2}(T\\circ f).", "$ </equation> \\newline </theorem> Higher gain indicates a better calibration map.", "\\newline <theorem> Proposition 4.2 .", "For accuracy-preserving maps in Def. [@ref:LABEL:apc] , the calibration gain equals the reduction of squared loss between predictions and labels after calibration: \\newline <equation> $ \\Delta\\text{ECE}^{2}(T)=\\mathbb{E}\\lVert Z-Y\\rVert_{2}^{2}-\\mathbb{E}\\lVert T(% Z)-Y\\rVert_{2}^{2}. $ </equation> \\newline </theorem> <proof> Proof.", "Please see supplementary material Sec. [@ref:LABEL:potceg] .", "\u220e \\newline </proof> For non accuracy-preserving methods ( [@ref:LABEL:top_cali] ), the squared loss reduction in Eq. ( [@ref:LABEL:ecet] ) bounds its actual calibration gain from below, and may not facilitate a fair comparison.", "Finally, given an evaluation dataset, Eq. ( [@ref:LABEL:ecet] ) is estimated by: \\newline <equation> $ \\Delta\\widehat{\\text{ECE}}^{2}(T)=\\frac{1}{n_{e}}{\\sum\\limits_{i=1}^{n_{e}}% \\big{(}\\lVert z^{(i)}-y^{(i)}\\rVert_{2}^{2}-\\lVert T(z^{(i)})-y^{(i)}\\rVert_{2% }^{2}\\big{)}} $ </equation> which converges at the rate of $ O(n_{e}^{-1/2}) $ independent of the class dimension $ L $ , and avoids the curse of dimensionality.", "\\newline </subsection>  </section>"], ["<section> <title> 5 Experiments </title>  <subsection> <title> 5.1 Calibration Error Evaluations </title> We compare the finite sample performance of proposed KDE-based ECE $ ^{d} $ estimator with histogram-based ones on a synthetic binary classification problem [@bib:vaicenavicius2019evaluating] .", "The classifier is parameterized by two parameters $ \\beta_{0},\\beta_{1} $ (described in detail in supplementary material Sec. [@ref:LABEL:sm] ).", "We consider a less-calibrated case $ \\beta_{0}=0.5,\\beta_{1}=-1.5 $ , and a better-calibrated case with $ \\beta_{0}=0.2,\\beta_{1}=-1.9 $ .", "The canonical calibration probability $ \\pi^{(f)}(z) $ has a closed-form expression (Eq. ( [@ref:LABEL:mixcali] )), allowing us to obtain the ground truth ECE (Eq. ( [@ref:LABEL:cali] )) using Monte Carlo integration with $ 10^{6} $ samples.", "We compare the ground truth to the estimation of ECE $ ^{1} $ using KDE and histogram-based estimators \u2013 one with $ 15 $ equal-width bins and other with data-dependent binning scheme [@bib:sturges1926choice] .", "In [@ref:LABEL:f61] , we vary the size of evaluation samples $ n_{e} $ from $ 64 $ to $ 1024 $ and plot the mean absolute error (averaged over $ 1000 $ independent experiments) between KDE/Histograms estimates and the ground truth.", "We see that KDE consistently outperforms histogram-based estimators regardless of the binning schemes.", "The discrepancy is particularly noticeable with small $ n_{e} $ , highlighting KDE\u2019s superior efficiency in data-limited regime.", "Additional results on distribution of the estimation errors are reported in the supplementary material [@ref:LABEL:f62] .", "In rest of the paper, we adopt KDE for estimating ECE, unless otherwise specified.", "\\newline </subsection> <subsection> <title> 5.2 Calibrating Neural Network Classifiers </title> We calibrate various deep neural network classifiers on popular computer vision datasets: CIFAR-10/100 [@bib:krizhevsky2009learning] with 10/100 classes and ImageNet [@bib:deng2009imagenet] with 1000 classes.", "For CIFAR-10/100, we trained DenseNet [@bib:huang2017densely] , LeNet [@bib:lecun1998gradient] , ResNet [@bib:he2016deep] and WideResNet (WRN) [@bib:zagoruyko2016wide] .", "The training detail is described in Sec. [@ref:LABEL:sec:ar] .", "We use 45000 images for training and hold out 15000 images for calibration and evaluation.", "For ImageNet, we acquired 4 pretrained models from [@bib:paszke2019pytorch] which were trained with $ 1.3 $ million images, and $ 50000 $ images are hold out for calibration and evaluation.", "We compare five calibration methods: for parametric approaches, we use TS and our proposed three-component model ensemble approach ETS.", "Following [@bib:kumar2019verified] , we use the squared error as our loss function to fit them.", "For non-parametric approaches, we compare IROvA and our proposed multi-class accuracy-preserving scheme IRM.", "For the composition method, we combine IROvA with TS as described in Sec. [@ref:LABEL:ir] and refer it as IROvA-TS .", "Both IROvA and IROvA-TS are not accuracy-preserving.", "\\newline For our first experiment, we adopt a standard calibration setup [@bib:guo2017calibration] with fixed-size calibration $ n_{c} $ and evaluation $ n_{e} $ datasets.", "We randomly split the hold-out dataset into $ n_{c}=5000 $ , $ n_{e}=10000 $ for CIFAR-10/100 and $ n_{c}=n_{e}=25000 $ for ImageNet.", "We use a random split to divide the hold-out dataset into $ n_{c} $ calibration points to learn the calibration map, and $ n_{e} $ evaluation points to evaluate ECE and classification accuracy.", "All the results are averaged over $ 100 $ independent runs."]], "target": "displays top-label ECE $ ^{1} $ and the calibration gain $ \\Delta $ ECE $ ^{2} $ . Overall the rankings of calibration methods by top-label ECE $ ^{1} $ or by $ \\Delta $ ECE $ ^{2} $ are very similar. Our proposed strategies consistently lead to better performance than the baseline implementations (ETS over TS; IRM and IROvA-TS over IROvA). Depending on the model/data complexity, either parametric or non-parametric variants may perform better. To explore this holistically, we next conduct a learning curve analysis by varying calibration dataset size and evaluate three properties (accuracy, data-efficiency and expressivity) of calibration approaches. We reserve the same set of $ 5000 $ data points for evaluation, and vary the number of calibration data from $ 128 $ to $ 10000 $ (CIFAR-10/100) or $ 45000 $ (ImageNet). This process is repeated 100 times."}, {"tabular": ["    &  $ 3 $ DIRCADb  &  Multi-Organ ", "  &  { DSC}  &  { ASSD}  &  { DSC}  &  { ASSD} ", " U-Net  &  90.4 $ \\pm $ 2.7  &  1.32 $ \\pm $ 1.21  &  91.2 $ \\pm $ 2.4  &  1.25 $ \\pm $ 1.20 ", " U-Net+Loss  &  91.9 $ \\pm $ 2.1  &  1.17 $ \\pm $ 1.10  &  92.3 $ \\pm $ 1.9  &  1.16 $ \\pm $ 1.06 ", " U-Net+Trans  &  92.3 $ \\pm $ 1.9  &  1.11 $ \\pm $ 0.99  &  92.7 $ \\pm $ 1.7  &  1.07 $ \\pm $ 0.95 ", " Joint-Train  &  90.9 $ \\pm $ 2.5  &  1.27 $ \\pm $ 1.17  &  91.8 $ \\pm $ 2.2  &  1.20 $ \\pm $ 1.14 ", " No-Refine  &  93.9 $ \\pm $ 1.7  &  1.01 $ \\pm $ 1.01  &  94.2 $ \\pm $ 1.8  &  0.97 $ \\pm $ 0.96 ", " No-Noise  &  84.2 $ \\pm $ 6.2  &  1.67 $ \\pm $ 2.12  &  85.1 $ \\pm $ 5.7  &  1.51 $ \\pm $ 1.97 ", " U-Net+Our  &  94.6 $ \\pm $ 1.5  &  0.93 $ \\pm $ 0.91  &  94.8 $ \\pm $ 1.6  &  0.90 $ \\pm $ 0.88  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Convolutional neural network (CNN), especially U-Net [@bib:ronneberger2015u] and its variants, has been proven to be the first choice for segmenting computed tomography (CT) images, a challenging task encountered frequently in clinic practice with a tremendous range of applications, e.g. diseases diagnosis, surgery simulation, therapeutic assistance, and radiotherapy planning, to mention a few [@bib:cerrolaza2019computational] .", "For training a CNN, ground truth (GT) images play a crucial role, telling the CNN what its output should be and accordingly telling the CNN how to adjust its parameters\u2019 value, both by the loss function which aims to measure the expectation of similarity between CNN\u2019s output and the GT image.", "However, exploiting GT images merely by the loss function often makes the properly trained CNN fail to segment two frequently seen and yet very difficult cases: ( $ 1 $ ) objects to be segmented having similar intensity values to other objects and ( $ 2 $ ) objects having ambiguous borders, mainly because expectation is a rather coarse statistic, unable to offer so rich supervised information for the CNN that these two challenging cases can be well handled.", "\\newline Related Work: In order to exploit more information from GT images, there are two types of methods reported.", "( $ 1 $ ) Regularization -based methods [@bib:oktay2017anatomically,ravishankar2017learning,mirikharaji2018star] focus on devising the loss function.", "They model or learn some properties of the objects, and devise those properties as a regularization term.", "This class of methods often is possible to obtain a slight performance improvement.", "However, it is usually difficult to design a regularization term that is general and optimization-friendly, which substantially weakens the practicability and applicability.", "( $ 2 $ ) Network Transfer -based methods [@bib:li2018bottleneck,sekuboyina2018btrfly,kakeya20183d] , which are free to design the regularization term, exploit GT images by enforcing the consistency of parameters of two CNNs that are trained respectively on raw CT images and GT images.", "Their underlying assumption is that these two CNNs should be similar, because they both are used to segment the same objects.", "The behind idea seems to be intuitively correct, but two CNNs might be similar on some unknown metric space, due to the different input spaces.", "\\newline Contribution: We present a network transfer-based approach, for exploiting GT images beyond the loss function.", "The main technical contribution is a feature similarity module (FSM) that is designed to learn the unknown similarity metric for measuring the similarity of two CNNs trained on raw CT and GT images.", "FSM measures the similarity of two CNNs\u2019 feature maps rather than the parameters, which seems to be more reasonable because mapping different input spaces into the same output space does need different functions.", "Also, FSM no longer requires that two CNNs have the same architecture, increasing the feasibility and practicability.", "We assess the proposed method on two CT data sets, and the experimental results show its superiority.", "\\newline  </section>"], ["<section> <title> 2 Methodology </title>  In order to exploit GT images beyond loss function, our idea is to transfer knowledge of a CNN, denoted by $ \\textbf{\\emph{N}}_{GT} $ , trained on GT images into the CNN, denoted by $ \\textbf{\\emph{N}}_{CT} $ , trained for segmenting CT images.", "To do so, we need to derive a metric to measure the similarity between $ \\textbf{\\emph{N}}_{GT} $ and $ \\textbf{\\emph{N}}_{CT} $ .", "We here learn the similarity metric, denoted by $ M $ , from data, and propose a technique, called feature similarity module (FSM), to fulfill this purpose.", "Fig. [@ref:LABEL:Fig.1] shows how we train the CNNs.", "We first train $ \\textbf{\\emph{N}}_{GT} $ , and then train $ \\textbf{\\emph{N}}_{CT} $ while requiring its feature maps in the encoder part to be similar (measured by $ M $ ) to that of $ \\textbf{\\emph{N}}_{GT} $ .", "We finally fine tune the decoder of $ \\textbf{\\emph{N}}_{CT} $ , which is initialized as the decoder of $ \\textbf{\\emph{N}}_{GT} $ .", "In what follows, we shall go into technical details.", "\\newline <subsection> <title> 2.1 Training Strategy </title> We first present our training strategy here, and we then introduce FSM in the next subsection.", "Our idea behind training is that feature maps of two CNNs, $ \\textbf{\\emph{N}}_{GT} $ and $ \\textbf{\\emph{N}}_{CT} $ trained respectively on GT and CT images, should be similar on some metric space, because they both are used to describe the same objects for the same purpose.", "Intuitively, there are two choices.", "The first one is to train two CNNs jointly.", "However, the experimental evidence does not show a satisfactory performance improvement (details are presented in the \u2018Experiments\u2019 section).", "We hence choose the second one, training two CNNs separately, as shown in Fig. [@ref:LABEL:Fig.1] .", "\\newline More specifically, we first train $ \\textbf{\\emph{N}}_{GT} $ that takes the GT image as the input and tries to output a segmentation result as similar to its input as possible (see the plot $ 1 $ in Fig. [@ref:LABEL:Fig.1] ).", "This CNN has the same role as auto-encoder [@bib:kingma2013auto] , aiming at learning a high-representative feature of the objects for the segmentation.", "Here we employ an U-Net [@bib:ronneberger2015u] similar architecture (both $ \\textbf{\\emph{N}}_{GT} $ and $ \\textbf{\\emph{N}}_{GT} $ ); more implementation details, such as network architecture, loss function, and optimization technique, are presented in the \u2018Experiments\u2019 section.", "\\newline Once $ \\textbf{\\emph{N}}_{GT} $ has been properly trained, we start to train $ \\textbf{\\emph{N}}_{CT} $ (the plot $ 2 $ in Fig. [@ref:LABEL:Fig.1] ).", "Given a pair of CT and GT images, denoted by $ x_{i} $ and $ y_{i} $ , from the training data set $ \\{x_{i},y_{i}\\}_{i=1}^{N} $ , $ y_{i} $ is passed through the encoder part of the learned $ \\textbf{\\emph{N}}_{GT} $ to generate feature maps, and $ x_{i} $ is passed through $ \\textbf{\\emph{N}}_{CT} $ .", "Training then is conducted by enforcing the similarity of two CNNs\u2019 feature maps, $ F(x_{i}) $ and $ F(y_{i}) $ , in the encoder part, that is, \\newline <equationgroup> <equation> $ \\{\\textbf{w}_{C}^{*},\\textbf{w}_{M}^{*}\\}=\\operatorname*{argmin}_% {\\{\\textbf{w}_{C},\\textbf{w}_{M}\\}}\\sum_{i=1}^{N}\\bigg{(}L\\big{(}f(x_{i}|% \\textbf{w}_{C}),y_{i}\\big{)} $ $ \\{\\textbf{w}_{C}^{*},\\textbf{w}_{M}^{*}\\}=\\operatorname*{argmin}_% {\\{\\textbf{w}_{C},\\textbf{w}_{M}\\}} $ $ \\sum_{i=1}^{N}\\bigg{(}L\\big{(}f(x_{i}|\\textbf{w}_{C}),y_{i}\\big{)} $ </equation> <equation> $ +\\xi M\\big{(}F(x_{i}|\\textbf{w}_{C}),F(y_{i})\\big{|}\\textbf{w}_{M% }\\big{)}\\bigg{)}, $ $ + $ $ \\xi M\\big{(}F(x_{i}|\\textbf{w}_{C}),F(y_{i})\\big{|}\\textbf{w}_{M}% \\big{)}\\bigg{)}, $ </equation> </equationgroup> where $ \\textbf{w}_{C} $ and $ \\textbf{w}_{M} $ denote parameters of $ \\textbf{\\emph{N}}_{CT} $ and the similarity metric $ M $ .", "The function $ L $ is to measure the similarity between $ \\textbf{\\emph{N}}_{CT} $ \u2019s output, $ f(x_{i}|\\textbf{w}_{C}) $ , and the ground truth image $ y_{i} $ .", "$ \\xi $ is a balance parameter to control the relative importance of two terms.", "The choice of $ L $ and the optimal value of $ \\xi $ are discussed in the \u2018Experiments\u2019 section, and details about $ M $ will be presented in the next subsection.", "\\newline We finally transfer decoder\u2019s knowledge (the plot $ 3 $ in Fig. [@ref:LABEL:Fig.1] ).", "We replace the decoder of the learned $ \\textbf{\\emph{N}}_{CT} $ with that of the learned $ \\textbf{\\emph{N}}_{GT} $ , and then fine tune it.", "We here directly transfer parameters, because features in the encoder part has been enforced to be consistent, so decoders should be similar in the sense of parameters\u2019 value.", "More implementation details are presented in the \u2018Experiments\u2019 section, and below we shall move on to FSM, the proposed feature similarity module.", "\\newline </subsection> <subsection> <title> 2.2 Feature Similarity Module </title> FSM aims to measure the similarity of two CNN\u2019s feature maps.", "Given $ F_{CT}^{\\ell_{i}} $ and $ F_{GT}^{\\ell_{j}} $ , feature maps of $ \\textbf{\\emph{N}}_{CT} $ at layer $ \\ell_{i} $ and of $ \\textbf{\\emph{N}}_{GT} $ at layer $ \\ell_{j} $ in the encoder part, FSM outputs a scalar between $ 0 $ and $ 1 $ to indicate the similarity, as shown in Fig. [@ref:LABEL:Fig.2] ; the more similar, the larger of the scalar is.", "As mentioned before, we allow that two CNNs have different architectures for fully exploiting information from their inputs, so", "it is possible that $ F_{CT}^{\\ell_{i}} $ and $ F_{GT}^{\\ell_{j}} $ have different size.", "We hence adjust $ F_{CT}^{\\ell_{i}} $ has the same size with $ F_{GT}^{\\ell_{j}} $ , by first adjusting the size of each feature map by nearest interpolating, and then adjusting the channel number by a convolution operation ( $ 3\\times 3 $ kernel and followed with $ ReLU $ [@bib:nair2010rectified] ) .", "\\newline As for $ F_{GT}^{\\ell_{j}} $ , we employ the convolution operations ( $ 3\\times 3 $ kernel and followed with $ ReLU $ ) to extract its channel and $ 2 $ D spatial statistics, denoted by $ S_{c}\\in\\mathbb{R}^{C} $ and $ S_{s}\\in\\mathbb{R}^{W\\times H} $ , where $ W $ , $ H $ , and $ C $ stand for the width, height, and channel number of $ F_{GT}^{\\ell_{j}} $ .", "Extracted statistics are then used to multiply the adjusted $ F_{CT}^{\\ell_{i}} $ (scalar and element-wise multiplications) for transferring channel and spatial knowledge of $ F_{GT}^{\\ell_{j}} $ into $ F_{CT}^{\\ell_{i}} $ .", "The multiplied feature maps next are concatenated together and then passed through a convolution operation ( $ 3\\times 3 $ kernel and followed with $ ReLU $ ) to reduce the channels to that of $ F_{CT}^{\\ell_{i}} $ .", "Finally, we compute Euclidean norm between the resulting feature maps and $ F_{CT}^{\\ell_{i}} $ as the similarity value.", "\\newline </subsection>  </section>"], ["<section> <title> 3 Experiments </title>  <subsection> <title> 3.1 Data Sets </title> We assess the proposed method on two CT data sets.", "The first one is called $ 3 $ DIRCADb , containing $ 20 $ CT volumes.", "Each volume has the same spatial resolutions ranging from $ 1.6 $ to $ 4.0 $ mm.", "The second one is called Multi-Organ Abdominal CT , containing $ 90 $ CT volumes.", "Each volume has resolutions ranging from $ 0.6 $ to $ 0.9 $ mm at in-plane and from $ 0.5 $ to $ 5.0 $ mm at inter-slice spacing.", "\\newline </subsection> <subsection> <title> 3.2 Evaluation Metrics </title> We employ two widely used metrics to evaluate the segmentation performance.", "The first one is Dice Similarity Coefficient ( $ DSC $ ), aiming at measuring the match degree of the segmentation result and the ground truth.", "The second one is Average Symmetric Surface Distance ( $ ASSD $ ), aiming at measuring the minimal distance of the segmentation result to the ground truth.", "The formal mathematical definition of $ DSC $ and $ ASSD $ is provided at [@bib:yeghiazaryan2015overview] .", "Note that a better segmentation algorithm has a larger value of $ DSC $ while a smaller value of $ ASSD $ .", "\\newline </subsection> <subsection> <title> 3.3 Implementation Details </title> For a fair comparison of the segmentation performance, both $ \\textbf{\\emph{N}}_{GT} $ and $ \\textbf{\\emph{N}}_{CT} $ are chosen as the original U-Net [@bib:ronneberger2015u] .", "The loss function employed in the training stage $ 1 $ and $ 3 $ ( $ \\textbf{\\emph{N}}_{GT} $ training and decoder refine) is $ DSC $ .", "The optimization technique is chosen as Adam [@bib:kingma2014adam] , with the initial learning rate as $ 0.0003 $ and the terminated epoch number as $ 100 $ in all three stages.", "In addition, in the stage $ 1 $ , in order to avoid $ \\textbf{\\emph{N}}_{GT} $ is just to copy the input rather than learning, we put random noise in the input.", "Specifically, we randomly set foreground pixels to background pixels with a probability $ p $ ; it is set to $ 0.2 $ by cross validation ( $ 5 $ -fold).", "In the stage $ 2 $ , we just enforce the bottom layer, and the balance parameter $ \\xi $ is set to $ 0.3 $ by cross-validation ( $ 5 $ -fold).", "\\newline </subsection> <subsection> <title> 3.4 Experimental Results </title> For evaluating the proposed method, we compare its performance to two methods [@bib:ravishankar2017learning] and [@bib:li2018bottleneck] , denoted respectively by U-Net+Loss and U-Net+Trans.", "U-Net+Loss exploits GT image by devising the loss function, while U-Net+Trans by transfer networks\u2019 parameters.", "For a fair comparison, all methods employ the same network (U-Net) and the same learning setting (the optimization technique and terminated epoch number), while hyper-parameters\u2019 value are chosen according to authors\u2019 recommendation.", "Results reported here are on liver, left kidney, and right kidney, by a $ 5 $ -fold cross validation.", "\\newline Quantitative Results: We first look at quantitative results, provided in Table."]], "target": "By following the conventional way, we calculate $ DSC $ to three decimal places and report in a percentage manner, while $ ASD $ to two decimal places and report its real number."}, {"tabular": ["  Method  &  VQA  &  GQA  &  $ \\text{NLVR}^{2} $ ", " LSTM + BUTD  &  63.1  &  50.0  &  52.6 ", " BERT + BUTD  &  62.8  &  52.1  &  51.9 ", " BERT + 1 CrossAtt  &  64.6  &  55.5  &  52.4 ", " BERT + 2 CrossAtt  &  65.8  &  56.1  &  50.9 ", " BERT + 3 CrossAtt  &  66.4  &  56.6  &  50.9 ", " BERT + 4 CrossAtt  &  66.4  &  56.0  &  50.9 ", " BERT + 5 CrossAtt  &  66.5  &  56.3  &  50.9 ", " Train + BERT  &  65.5  &  56.2  &  50.9 ", " Train + scratch  &  65.1  &  50.0  &  50.9 ", " Pre-train + BERT  &  68.8  &  58.3  &  70.1 ", " Pre-train + scratch  &  69.9  &  60.0  &  74.9  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Vision-and-language reasoning requires the understanding of visual contents, language semantics, and cross-modal alignments and relationships.", "There has been substantial past works in separately developing backbone models with better representations for the single modalities of vision and of language.", "For visual-content understanding, people have developed several backbone models [@bib:simonyan2014very,szegedy2015going,he2016deep] and shown their effectiveness on large vision datasets [@bib:deng2009imagenet,lin2014microsoft,krishna2017visual] .", "Pioneering works [@bib:girshick2014rich,xu2015show] also show the generalizability of these pre-trained (especially on ImageNet) backbone models by fine-tuning them on different tasks.", "In terms of language understanding, last year, we witnessed strong progress towards building a universal backbone model with large-scale contextualized language model pre-training [@bib:peters2018deep,radford2018improving,devlin2018bert] , which has improved performances on various tasks [@bib:rajpurkar2016squad,wang2018glue] to significant levels.", "Despite these influential single-modality works, large-scale pretraining and fine-tuning studies for the modality-pair of vision and language are still under-developed.", "\\newline Therefore, we present one of the first works in building a pre-trained vision-and-language cross-modality framework and show its strong performance on several datasets.", "We name this framework \u201cLXMERT: Learning Cross-Modality Encoder Representations from Transformers\u201d (pronounced: \u2018leksmert\u2019).", "This framework is modeled after recent BERT-style innovations while further adapted to useful cross-modality scenarios.", "Our new cross-modality model focuses on learning vision-and-language interactions, especially for representations of a single image and its descriptive sentence.", "It consists of three Transformer [@bib:vaswani2017attention] encoders: an object relationship encoder, a language encoder, and a cross-modality encoder.", "In order to better learn the cross-modal alignments between vision and language, we next pre-train our model with five diverse representative tasks: (1) masked cross-modality language modeling, (2) masked object prediction via RoI-feature regression, (3) masked object prediction via detected-label classification, (4) cross-modality matching, and (5) image question answering.", "Different from single-modality pre-training (e.g., masked LM in BERT), this multi-modality pre-training allows our model to infer masked features either from the visible elements in the same modality, or from aligned components in the other modality.", "In this way, it helps build both intra-modality and cross-modality relationships.", "\\newline Empirically, we first evaluate LXMERT on two popular visual question-answering datasets, VQA [@bib:antol2015vqa] and GQA [@bib:hudson2019gqa] .", "Our model outperforms previous works in all question categories (e.g., Binary, Number, Open) and achieves state-of-the-art results in terms of overall accuracy.", "Further, to show the generalizability of our pre-trained model, we fine-tune LXMERT on a challenging visual reasoning task, Natural Language for Visual Reasoning for Real ( $ \\text{NLVR}^{2} $ ) [@bib:suhr2018corpus] , where we do not use the natural images in their dataset for our pre-training, but fine-tune and evaluate on these challenging, real-world images.", "In this setup, we achieve a large improvement of $ 22\\% $ absolute in accuracy ( $ 54\\% $ to $ 76\\% $ , i.e., 48% relative error reduction) and $ 30\\% $ absolute in consistency ( $ 12\\% $ to $ 42\\% $ , i.e., 34% relative error reduction).", "Lastly, we conduct several analysis and ablation studies to prove the effectiveness of our model components and diverse pre-training tasks by removing them or comparing them with their alternative options.", "Especially, we use several ways to take the existing BERT model and its variants, and show their ineffectiveness in vision-and-language tasks, which overall proves the need of our new cross-modality pre-training framework.", "\\newline  </section>"], ["<section> <title> 2 Model Architecture </title>  We build our cross-modality model with self-attention and cross-attention layers following the recent progress in designing natural language processing models (e.g., transformers [@bib:vaswani2017attention] ).", "As shown in Fig. [@ref:LABEL:fig:model] , our model takes two inputs: an image and its related sentence (e.g., a caption or a question).", "Each image is represented as a sequence of objects, and each sentence is represented as a sequence of words.", "Via careful design and combination of these self-attention and cross-attention layers, our model is able to generate language representations, image representations, and cross-modality representations from the inputs.", "Next, we describe the components of this model in detail.", "\\newline <subsection> <title> 2.1 Input Embeddings </title> The input embedding layers in LXMERT convert the inputs (i.e., an image and a sentence) into two sequences of features: word-level sentence embeddings and object-level image embeddings.", "These embedding features will be further processed by the latter encoding layers.", "\\newline <paragraph> <title> Word-Level Sentence Embeddings </title> A sentence is first split into words $ \\left\\{w_{1},\\ldots,w_{n}\\right\\} $ with length of $ n $ by the same WordPiece tokenizer [@bib:wu2016google] in \\newcite devlin2018bert.", "Next, as shown in Fig. [@ref:LABEL:fig:model] , the word $ w_{i} $ and its index $ i $ ( $ w_{i} $ \u2019s absolute position in the sentence) are projected to vectors by embedding sub-layers, and then added to the index-aware word embeddings: \\newline <equationgroup> <equation> $ \\hat{w}_{i}=\\mathrm{WordEmbed}\\left(w_{i}\\right) $ $ \\hat{w}_{i} $ $ =\\mathrm{WordEmbed}\\left(w_{i}\\right) $ </equation> <equation> $ \\hat{u}_{i}=\\mathrm{IdxEmbed}\\left(i\\right) $ $ \\hat{u}_{i} $ $ =\\mathrm{IdxEmbed}\\left(i\\right) $ </equation> <equation> $  h_{i}=\\mathrm{LayerNorm}\\left(\\hat{w}_{i}+\\hat{u}_{i}\\right) $ $  h_{i} $ $ =\\mathrm{LayerNorm}\\left(\\hat{w}_{i}+\\hat{u}_{i}\\right) $ </equation> </equationgroup> \\newline </paragraph> <paragraph> <title> Object-Level Image Embeddings </title> Instead of using the feature map output by a convolutional neural network, we follow \\newcite anderson2018bottom in taking the features of detected objects as the embeddings of images.", "Specifically, the object detector detects $ m $ objects $ \\left\\{o_{1},\\ldots,o_{m}\\right\\} $ from the image (denoted by bounding boxes on the image in Fig. [@ref:LABEL:fig:model] ).", "Each object $ o_{j} $ is represented by its position feature (i.e., bounding box coordinates) $ p_{j} $ and its $ 2048 $ -dimensional region-of-interest (RoI) feature $ f_{j} $ .", "Instead of directly using the RoI feature $ f_{j} $ without considering its position $ p_{j} $ in \\newcite anderson2018bottom, we learn a position-aware embedding $ v_{j} $ by adding outputs of 2 fully-connected layers: \\newline <equationgroup> <equation> $ \\hat{f}_{j}=\\mathrm{LayerNorm}\\left(W_{\\textsc{f}}f_{j}+b_{% \\textsc{f}}\\right) $ $ \\hat{f}_{j} $ $ =\\mathrm{LayerNorm}\\left(W_{\\textsc{f}}f_{j}+b_{\\textsc{f}}\\right) $ </equation> <equation> $ \\hat{p}_{j}=\\mathrm{LayerNorm}\\left(W_{\\textsc{p}}p_{j}+b_{% \\textsc{p}}\\right) $ $ \\hat{p}_{j} $ $ =\\mathrm{LayerNorm}\\left(W_{\\textsc{p}}p_{j}+b_{\\textsc{p}}\\right) $ </equation> <equation> $  v_{j}=\\left(\\hat{f}_{j}+\\hat{p}_{j}\\right)/2 $ $  v_{j} $ $ =\\left(\\hat{f}_{j}+\\hat{p}_{j}\\right)/2 $ </equation> </equationgroup> In addition to providing spatial information in visual reasoning, the inclusion of positional information is necessary for our masked object prediction pre-training task (described in Sec. [@ref:LABEL:sec:vision_task] ).", "Since the image embedding layer and the following attention layers are agnostic to the absolute indices of their inputs, the order of the object is not specified.", "Lastly, in Equation [@ref:LABEL:eqn:object_emb] , the layer normalization is applied to the projected features before summation so as to balance the energy of the two different types of features.", "\\newline </paragraph> </subsection> <subsection> <title> 2.2 Encoders </title> We build our encoders, i.e., the language encoder, the object-relationship encoder, and the cross-modality encoder, mostly on the basis of two kinds of attention layers: self-attention layers and cross-attention layers.", "We first review the definition and notations of attention layers and then discuss how they form our encoders.", "\\newline <paragraph> <title> Background: Attention Layers </title> Attention layers [@bib:bahdanau2014neural,xu2015show] aim to retrieve information from a set of {context} vectors $ \\{y_{j}\\} $ related to a {query} vector $ x $ .", "An attention layer first calculates the matching score $ a_{j} $ between the {query} vector $ x $ and each {context} vector $ y_{j} $ .", "Scores are then normalized by softmax: \\newline <equationgroup> <equation> $ \\vspace{-5pt}a_{j}=\\mathrm{score}(x,y_{j}) $ $ \\vspace{-5pt}a_{j} $ $ =\\mathrm{score}(x,y_{j}) $ </equation> <equation> $ \\alpha_{j}=\\exp(a_{j})/\\sum\\nolimits_{k}\\exp(a_{k}) $ $ \\alpha_{j} $ $ =\\exp(a_{j})/\\sum\\nolimits_{k}\\exp(a_{k}) $ </equation> </equationgroup> The output of an attention layer is the weighted sum of the {context} vectors w.r.t.", "the softmax-normalized score: $ \\mathrm{Att}_{\\textsc{x}\\rightarrow\\textsc{y}}\\left(x,\\{y_{j}\\}\\right)=\\sum% \\nolimits_{j}\\alpha_{j}y_{j} $ .", "An attention layer is called {self-attention} when the {query} vector $ x $ is in the set of {context} vectors $ \\{y_{j}\\} $ .", "Specifically, we use the multi-head attention following Transformer [@bib:vaswani2017attention] .", "\\newline </paragraph> <paragraph> <title> Single-Modality Encoders </title> After the embedding layers, we first apply two transformer encoders [@bib:vaswani2017attention] , i.e., a language encoder and an object-relationship encoder , and each of them only focuses on a single modality (i.e., language or vision).", "Different from BERT [@bib:devlin2018bert] , which applies the transformer encoder only to language inputs, we apply it to vision inputs as well (and to cross-modality inputs as described later below).", "Each layer (left dashed blocks in Fig. [@ref:LABEL:fig:model] ) in a single-modality encoder contains a self-attention (\u2018Self\u2019) sub-layer and a feed-forward (\u2018FF\u2019) sub-layer, where the feed-forward sub-layer is further composed of two fully-connected sub-layers.", "We take $ \\textbf{N}_{\\textbf{L}} $ and $ \\textbf{N}_{\\textbf{R}} $ layers in the language encoder and the object-relationship encoder, respectively.", "We add a residual connection and layer normalization (annotated by the \u2018+\u2019 sign in Fig. [@ref:LABEL:fig:model] ) after each sub-layer as in \\newcite vaswani2017attention.", "\\newline </paragraph> <paragraph> <title> Cross-Modality Encoder </title> Each cross-modality layer (the right dashed block in Fig. [@ref:LABEL:fig:model] ) in the cross-modality encoder consists of two self-attention sub-layers, one bi-directional cross-attention sub-layer, and two feed-forward sub-layers.", "We stack (i.e., using the output of $ k $ -th layer as the input of $ (k\\mbox{+}1) $ -th layer) $ \\textbf{N}_{\\textbf{X}} $ these cross-modality layers in our encoder implementation.", "Inside the $ k $ -th layer, the bi-directional cross-attention sub-layer (\u2018Cross\u2019) is first applied, which contains two uni-directional cross-attention sub-layers: one from language to vision and one from vision to language.", "The query and context vectors are the outputs of the $ (k\\mbox{-}1) $ -th layer (i.e., language features $ \\{h_{i}^{k-1}\\} $ and vision features $ \\{v_{j}^{k-1}\\} $ ): \\newline <equationgroup> <equation> $ \\hat{h}^{k}_{i}=\\mathrm{CrossAtt}_{\\textsc{l}\\rightarrow\\textsc{r% }}\\left({h}^{k-1}_{i}{,}\\{{v}^{k-1}_{1}{,}\\ldots,{v}^{k-1}_{m}\\}\\right) $ $ \\hat{h}^{k}_{i} $ $ =\\mathrm{CrossAtt}_{\\textsc{l}\\rightarrow\\textsc{r}}\\left({h}^{k-% 1}_{i}{,}\\{{v}^{k-1}_{1}{,}\\ldots,{v}^{k-1}_{m}\\}\\right) $ </equation> <equation> $ \\hat{v}^{k}_{j}=\\mathrm{CrossAtt}_{\\textsc{r}\\rightarrow\\textsc{l% }}\\left({v}^{k-1}_{j}{,}\\{{h}^{k-1}_{1}{,}\\ldots,{h}^{k-1}_{n}\\}\\right) $ $ \\hat{v}^{k}_{j} $ $ =\\mathrm{CrossAtt}_{\\textsc{r}\\rightarrow\\textsc{l}}\\left({v}^{k-% 1}_{j}{,}\\{{h}^{k-1}_{1}{,}\\ldots,{h}^{k-1}_{n}\\}\\right) $ </equation> </equationgroup> The cross-attention sub-layer is used to exchange the information and align the entities between the two modalities in order to learn joint cross-modality representations.", "For further building internal connections, the self-attention sub-layers (\u2018Self\u2019) are then applied to the output of the cross-attention sub-layer: \\newline <equationgroup> <equation> $ \\tilde{h}^{k}_{i}=\\mathrm{SelfAtt}_{\\textsc{l}\\rightarrow\\textsc{% l}}\\left(\\hat{h}^{k}_{i},\\{\\hat{h}^{k}_{1},\\ldots,\\hat{h}^{k}_{n}\\}\\right) $ $ \\tilde{h}^{k}_{i} $ $ =\\mathrm{SelfAtt}_{\\textsc{l}\\rightarrow\\textsc{l}}\\left(\\hat{h}^% {k}_{i},\\{\\hat{h}^{k}_{1},\\ldots,\\hat{h}^{k}_{n}\\}\\right) $ </equation> <equation> $ \\tilde{v}^{k}_{j}=\\mathrm{SelfAtt}_{\\textsc{r}\\rightarrow\\textsc{% r}}\\left(\\hat{v}^{k}_{j},\\{\\hat{v}^{k}_{1},\\ldots,\\hat{v}^{k}_{m}\\}\\right) $ $ \\tilde{v}^{k}_{j} $ $ =\\mathrm{SelfAtt}_{\\textsc{r}\\rightarrow\\textsc{r}}\\left(\\hat{v}^% {k}_{j},\\{\\hat{v}^{k}_{1},\\ldots,\\hat{v}^{k}_{m}\\}\\right) $ </equation> </equationgroup> Lastly, the $ k $ -th layer output $ \\{h^{k}_{i}\\} $ and $ \\{v^{k}_{j}\\} $ are produced by feed-forward sub-layers (\u2018FF\u2019) on top of $ \\{\\hat{h}^{k}_{i}\\} $ and $ \\{\\hat{v}^{k}_{j}\\} $ .", "We also add a residual connection and layer normalization after each sub-layer, similar to the single-modality encoders.", "\\newline </paragraph> </subsection> <subsection> <title> 2.3 Output Representations </title> As shown in the right-most part of Fig. [@ref:LABEL:fig:model] , our LXMERT cross-modality model has three outputs for language, vision, and cross-modality, respectively.", "The language and vision outputs are the feature sequences generated by the cross-modality encoder.", "For the cross-modality output, following the practice in \\newcite devlin2018bert, we append a special token [CLS] (denoted as the top yellow block in the bottom branch of Fig. [@ref:LABEL:fig:model] ) before the sentence words, and the corresponding feature vector of this special token in language feature sequences is used as the cross-modality output.", "\\newline </subsection>  </section>"], ["<section> <title> 3 Pre-Training Strategies </title>  In order to learn a better initialization which understands connections between vision and language, we pre-train our model with different modality pre-training tasks on a large aggregated dataset.", "\\newline <subsection> <title> 3.1 Pre-Training Tasks </title> <subsubsection> <title> 3.1.1 Language Task: Masked Cross-Modality LM </title> On the language side, we take the masked cross-modality language model (LM) task.", "As shown in the bottom branch of Fig. [@ref:LABEL:fig:pretrain] , the task setup is almost same to BERT [@bib:devlin2018bert] : words are randomly masked with a probability of $ 0.15 $ and the model is asked to predict these masked words.", "In addition to BERT where masked words are predicted from the non-masked words in the language modality, LXMERT, with its cross-modality model architecture, could predict masked words from the vision modality as well, so as to resolve ambiguity.", "For example, as shown in Fig. [@ref:LABEL:fig:pretrain] , it is hard to determine the masked word \u2018carrot\u2019 from its language context but the word choice is clear if the visual information is considered.", "Hence, it helps building connections from the vision modality to the language modality, and we refer to this task as masked {cross-modality} LM to emphasize this difference.", "We also show that loading BERT parameters into LXMERT will do harm to the pre-training procedure in Sec. [@ref:LABEL:sec:bert_lxmert] since BERT can perform relatively well in the language modality without learning these cross-modality connections.", "\\newline </subsubsection> <subsubsection> <title> 3.1.2 Vision Task: Masked Object Prediction </title> As shown in the top branch of Fig. [@ref:LABEL:fig:pretrain] , we pre-train the vision side by randomly masking objects (i.e., masking RoI features with zeros) with a probability of $ 0.15 $ and asking the model to predict proprieties of these masked objects.", "Similar to the language task (i.e., masked cross-modality LM), the model can infer the masked objects either from visible objects or from the language modality.", "Inferring the objects from the vision side helps learn the object relationships, and inferring from the language side helps learn the cross-modality alignments.", "Therefore, we perform two sub-tasks: RoI-Feature Regression regresses the object RoI feature $ f_{j} $ with L2 loss, and Detected-Label Classification learns the labels of masked objects with cross-entropy loss.", "In the \u2018Detected-Label Classification\u2019 sub-task, although most of our pre-training images have object-level annotations, the ground truth labels of the annotated objects are inconsistent in different datasets (e.g., different number of label classes).", "For these reasons, we take detected labels output by Faster R-CNN [@bib:ren2015faster] .", "Although detected labels are noisy, experimental results show that these labels contribute to pre-training in Sec. [@ref:LABEL:sec:vision_analysis] .", "\\newline </subsubsection> <subsubsection> <title> 3.1.3 Cross-Modality Tasks </title> As shown in the middle-rightmost part of Fig. [@ref:LABEL:fig:pretrain] , to learn a strong cross-modality representation, we pre-train the LXMERT model with 2 tasks that explicitly need both language and vision modalities.", "\\newline <paragraph> <title> Cross-Modality Matching </title> For each sentence, with a probability of $ 0.5 $ , we replace it with a mis-matched sentence.", "Then, we train a classifier to predict whether an image and a sentence match each other.", "This task is similar to \u2018Next Sentence Prediction\u2019 in BERT [@bib:devlin2018bert] .", "\\newline </paragraph> <paragraph> <title> Image Question Answering (QA) </title> In order to enlarge the pre-training dataset (see details in Sec. [@ref:LABEL:sec:pretrain_data] ), around $ 1/3 $ sentences in the pre-training data are questions about the images.", "We ask the model to predict the answer to these image-related questions when the image and the question are matched (i.e., not randomly replaced in the cross-modality matching task).", "We show that pre-training with this image QA leads to a better cross-modality representation in Sec. [@ref:LABEL:sec:QA_analysis] .", "\\newline </paragraph> </subsubsection> </subsection> <subsection> <title> 3.2 Pre-Training Data </title> As shown in Table.", "[@ref:LABEL:table:pretrain] , we aggregate pre-training data from five vision-and-language datasets whose images come from MS COCO [@bib:lin2014microsoft] or Visual Genome [@bib:krishna2017visual] .", "Besides the two original captioning datasets, we also aggregate three large image question answering (image QA) datasets: VQA v2.0 [@bib:antol2015vqa] , GQA balanced version [@bib:hudson2019gqa] , and VG-QA [@bib:zhu2016visual7w] .", "We only collect train and dev splits in each dataset to avoid seeing any test data in pre-training.", "We conduct minimal pre-processing on the five datasets to create aligned image-and-sentence pairs.", "For each image question answering dataset, we take questions as sentences from the image-and-sentence data pairs and take answers as labels in the image QA pre-training task (described in Sec. [@ref:LABEL:sec:x_task] ).", "This provides us with a large aligned vision-and-language dataset of $ 9.18 $ M image-and-sentence pairs on $ 180 $ K distinct images.", "In terms of tokens, the pre-training data contain around $ 100 $ M words and $ 6.5 $ M image objects.", "\\newline </subsection> <subsection> <title> 3.3 Pre-Training Procedure </title> We pre-train our LXMERT model on the large aggregated dataset (discussed in Sec. [@ref:LABEL:sec:pretrain_data] ) via the pre-training tasks (Sec. [@ref:LABEL:sec:pretrain_task] ).", "The details about the data splits are in the Appendix.", "The input sentences are split by the WordPiece tokenizer [@bib:wu2016google] provided in BERT [@bib:devlin2018bert] .", "The objects are detected by Faster R-CNN [@bib:ren2015faster] which is pre-trained on Visual Genome (provided by \\newcite anderson2018bottom).", "We do not fine-tune the Faster R-CNN detector and freeze it as a feature extractor.", "Different from detecting variable numbers of objects in \\newcite anderson2018bottom, we consistently keep $ 36 $ objects for each image to maximize the pre-training compute utilization by avoiding padding.", "For the model architecture, we set the numbers of layers $ \\textbf{N}_{\\textbf{L}} $ , $ \\textbf{N}_{\\textbf{X}} $ , and $ \\textbf{N}_{\\textbf{R}} $ to $ 9 $ , $ 5 $ , and $ 5 $ respectively.", "More layers are used in the language encoder to balance the visual features extracted from $ 101 $ -layer Faster R-CNN.", "The hidden size $ 768 $ is the same as $ \\text{BERT}_{\\text{BASE}} $ .", "We pre-train all parameters in encoders and embedding layers from scratch (i.e., model parameters are randomly initialized or set to zero).", "We also show results of loading pre-trained BERT parameters in Sec. [@ref:LABEL:sec:bert_lxmert] .", "LXMERT is pre-trained with multiple pre-training tasks and hence multiple losses are involved.", "We add these losses with equal weights.", "For the image QA pre-training tasks, we create a joint answer table with $ 9500 $ answer candidates which roughly cover $ 90\\% $ questions in all three image QA datasets.", "\\newline We take Adam [@bib:kingma2014adam] as the optimizer with a linear-decayed learning-rate schedule [@bib:devlin2018bert] and a peak learning rate at $ 1e-4 $ .", "We train the model for $ 20 $ epochs (i.e., roughly $ 670 $ K optimization steps) with a batch size of $ 256 $ .", "We only pre-train with image QA task (see Sec. [@ref:LABEL:sec:x_task] ) for the last $ 10 $ epochs, because this task converges faster and empirically needs a smaller learning rate.", "The whole pre-training process takes $ 10 $ days on $ 4 $ Titan Xp.", "\\newline <paragraph> <title> Fine-tuning </title> Fine-tuning is fast and robust.", "We only perform necessary modification to our model with respect to different tasks (details in Sec. [@ref:LABEL:sec:implementation] ).", "We use a learning rate of $ 1e-5 $ or $ 5e-5 $ , a batch size of $ 32 $ , and fine-tune the model from our pre-trained parameters for $ 4 $ epochs.", "\\newline </paragraph> </subsection>  </section>"], ["<section> <title> 4 Experimental Setup and Results </title>  In this section, we first introduce the datasets that are used to evaluate our LXMERT framework and empirically compare our single-model results with previous best results.", "\\newline <subsection> <title> 4.1 Evaluated Datasets </title> We use three datasets for evaluating our LXMERT framework: VQA v2.0 dataset [@bib:goyal2017making] , GQA [@bib:hudson2019gqa] , and $ \\text{NLVR}^{2} $ . See details in Appendix.", "\\newline </subsection> <subsection> <title> 4.2 Implementation Details </title> On VQA and GQA, we fine-tune our model from the pre-trained snapshot without data augmentation (analysis in Sec. [@ref:LABEL:sec:QA_analysis] ).", "When training GQA, we only take raw questions and raw images as inputs and do not use other supervisions (e.g., functional programs and scene graphs).", "Since each datum in $ \\text{NLVR}^{2} $ has two natural images $ \\mathit{img}_{0},\\mathit{img}_{1} $ and one language statement $ s $ , we use LXMERT to encode the two image-statement pairs $ (\\mathit{img}_{0},s) $ and $ (\\mathit{img}_{1},s) $ , then train a classifier based on the concatenation of the two cross-modality outputs.", "More details in Appendix. \\newline </subsection> <subsection> <title> 4.3 Empirical Comparison Results </title> We compare our single-model results with previous best published results on VQA/GQA test-standard sets and $ \\text{NLVR}^{2} $ public test set.", "Besides previous state-of-the-art (SotA) methods, we also show the human performance and image-only/language-only results when available.", "\\newline <paragraph> <title> VQA </title> The SotA result is BAN+Counter in \\newcite kim2018bilinear, which achieves the best accuracy among other recent works: MFH [@bib:yu2018beyond] , Pythia [@bib:jiang2018pythia] , DFAF [@bib:Gao_2019_CVPR] , and Cycle-Consistency [@bib:shah2019cycle] .", "LXMERT improves the SotA overall {accuracy} (\u2018Accu\u2019 in Table [@ref:LABEL:table:result] ) by $ 2.1\\% $ and has $ 2.4\\% $ improvement on the \u2018Binary\u2019/\u2018Other\u2019 question sub-categories.", "Although LXMERT does not explicitly take a counting module as in BAN+Counter, our result on the counting-related questions (\u2018Number\u2019) is still equal or better.", "\\newline </paragraph> <paragraph> <title> GQA </title> The GQA [@bib:hudson2019gqa] SotA result is taken from BAN [@bib:kim2018bilinear] on the public leaderbaord.", "Our $ 3.2\\% $ {accuracy} gain over the SotA GQA method is higher than VQA, possibly because GQA requires more visual reasoning.", "Thus our framework, with novel encoders and cross-modality pre-training, is suitable and achieves a $ 4.6\\% $ improvement on open-domain questions (\u2018Open\u2019 in Table [@ref:LABEL:table:result] ).", "\\newline </paragraph> <paragraph> <title> NLVR 2 </title> $ \\text{NLVR}^{2} $ [@bib:suhr2018corpus] is a challenging visual reasoning dataset where some existing approaches [@bib:hu2017learning,perez2018film] fail, and the SotA method is \u2018MaxEnt\u2019 in \\newcite suhr2018corpus.", "The failure of existing methods (and our model w/o pre-training in Sec. [@ref:LABEL:sec:bert_lxmert] ) indicates that the connection between vision and language may not be end-to-end learned in a complex vision-and-language task without large-scale pre-training.", "However, with our novel pre-training strategies in building the cross-modality connections, we significantly improve the {accuracy} (\u2018Accu\u2019 of 76.2% on unreleased test set \u2018Test-U\u2019, in Table [@ref:LABEL:table:result] ) by $ 22\\% $ .", "Another evaluation metric {consistency} measures the proportion of unique sentences for which all related image pairs are correctly predicted.", "Our LXMERT model improves {consistency} (\u2018Cons\u2019) to 42.1% (i.e., by $ 3.5 $ times).", "\\newline </paragraph> </subsection>  </section>"], ["<section> <title> 5 Analysis </title>  In this section, we analyze our LXMERT framework by comparing it with some alternative choices or by excluding certain model components/pre-training strategies.", "\\newline <subsection> <title> 5.1 BERT versus LXMERT </title> BERT [@bib:devlin2018bert] is a pre-trained language encoder which improves several language tasks."]], "target": "As shown in Table , we discuss several ways to incorporate a $ \\text{BERT}_{\\text{BASE}} $ pre-trained model for vision-language tasks and empirically compare it with our LXMERT approach. Although our full model achieves accuracy of $ 74.9\\% $ on $ \\text{NLVR}^{2} $ , all results without LXMERT pre-training is around $ 22\\% $ absolute lower."}, {"tabular": ["  Benchmark  &  MNIST-CNN  &  CIFAR10-WRN ", " Setting  &  Baseline  &  Fine-tune without <ln> fingerprint  &  Fine-tune with <ln> fingerprint  &  Baseline  &  Fine-tune without <ln> fingerprint  &  Fine-tune with <ln> fingerprint ", " Test Accuracy (%)  &  99.52  &  99.66  &  99.72  &  91.85  &  91.99  &  92.03  "], "ref_sec": [["<section> <title> I Introduction </title>  The recent advance in deep learning and neural networks has provided a paradigm shift in various scientific fields.", "In particular, numerous deep neuron networks (DNNs) such as GoogLeNet [@bib:GooLeNet] , AlexNet [@bib:AlexNet] , Residual Network [@bib:ResNet] , and Neural Architecture Search networks [@bib:zoph2017learning] have become prevalent standards for applications including autonomous transportation, automated manufacturing, natural language processing, intelligent warfare and smart health [@bib:lecun2015deep,schmidhuber2015deep,collobert2008unified] .", "Meanwhile, open-sourced deep learning frameworks have enabled users to develop customized machine learning systems based on the existing models.", "PyTorch [@bib:PyTorch] , Tensorflow [@bib:abadi2016tensorflow] , Keras [@bib:chollet2015keras] , MXNet [@bib:chen2015mxnet] , and Caffe [@bib:jia2014caffe] are examples of such tools.", "\\newline The distribution of pre-trained neural networks is a promising trend and makes the utilization of DNNs easier.", "For instance, Caffe provides Model Zoo that includes built neural networks and pre-trained weights for various applications [@bib:caffe_modelZoo] .", "As the accessibility of models increases, a practical concern is the IP protection and Digital Right Management (DRM) of the distributed models.", "On the one hand, DL models are usually trained by allocating significant computational resources to process massive training data.", "The built models are therefore considered as the owner\u2019s IP and need to be protected to preserve the competitive advantages.", "On the other hand, malicious attackers may take advantage of the models for illegal usages.", "The potential problems need to be taken into account during the design and training of the DL models before the owners make their models publicly available.", "\\newline Previous works have identified the importance of IP protection in DL domain and propose watermarking methodologies for DNNs.", "The authors of [@bib:uchida2017embedding,nagai2018digital] present a new approach for watermarking DNNs by embedding the IP information in the weights.", "The embedded watermark can be extracted by the owner assuming the details of the models are available to the owner (\u2018white-box\u2019 setting).", "To provide IP protection for a remote neural network where the model is exposed as a service (\u2018black-box\u2019 setting), the paper [@bib:merrer2017adversarial] proposes a zero-bit watermarking methodology by tweaking the decision boundary.", "The paper [@bib:DeepSigns] presents a generic watermarking framework for IP protection in both white-box and black-box scenarios by embedding the watermarks in the pdf of the activation sets of the target layers.", "To the best of our knowledge, there is no prior work that has targeted fingerprinting for DNNs.", "\\newline This paper proposes DeepMarks, a novel end-to-end framework that enables coherent integration of robust digital fingerprinting in contemporary deep learning models.", "DeepMarks, for the first time, introduces a generic functional fingerprinting methodology for DNNs.", "The proposed methodology is simultaneously user and model dependent .", "DeepMarks works by assigning a unique binary code-vector (a.k.a., fingerprint ) to each user and embedding the fingerprint information in the probabilistic distribution of the weights while preserving the accuracy.", "We demonstrate the robustness of our proposed framework against collusion and transformation attacks including model compression/pruning, and model fine-tuning.", "The explicit technical contributions of this paper are as follows: \\newline <list> \\ Proposing DeepMarks, the first end-to-end framework for systematic deep learning IP protection and digital right management.", "A novel fingerprinting methodology is introduced to encode the pdf of the DL models and effectively trace the IP ownership as well as the usage of each distributed model.", "\\newline \\ \\ Introducing a comprehensive set of qualitative and quantitative metrics to assess the performance of a fingerprinting methodology for (deep) neural networks.", "Such metrics provide new perspectives for model designers and enable coherent comparison of current and pending DL IP protection techniques.", "\\newline \\ \\ Performing extensive proof-of-concept evaluation on various benchmarks including commonly used MNIST, CIFAR10 datasets.", "Our evaluations corroborate the effectiveness of DeepMarks to detect IP ownership and track the individual culprits/colluders who use the model for unintended purposes.", "\\newline \\ </list> \\newline  </section>"], ["<section> <title> II Problem Formulation </title>  Fingerprinting is defined as the task of embedding a $ v $ -bit binary code-vector $ \\mathbf{c_{j}}\\in\\{0,1\\}^{v} $ in the weights of a host neural network.", "Here, $ j=1,...,n $ denotes the index for each distributed user where $ n $ is the number of total users.", "The fingerprint information can be either embedded in one or multiple layers of the DNN model.", "The objective of fingerprinting is two-fold: (i) claiming the ownership of a specific neural network, and (ii) tracing the unintended usage of the model by distributed users.", "In the following sections, we formulate the requirements for digital fingerprinting in the context of DL and discuss possible attacks that might render the embedded fingerprints ineffective.", "\\newline <subsection> <title> II-A Requirements </title> Table [@ref:LABEL:tab:required] summarizes the requirement for an effective fingerprints in the deep neural network domain.", "In addition to fidelity, efficiency, security, capacity, reliability, integrity, and robustness requirements that are shared between fingerprinting and watermarking, a successful fingerprinting methodology should also satisfy the uniqueness, scalability, and collusion resilience criteria.", "\\newline On the one hand, uniqueness is the intrinsic property of fingerprints.", "Since the model owner aims to track the usage of the model distributed to each specific user, the uniqueness of fingerprints is essential to ensure correct identification of the target user.", "On the other hand, as the number of participants involved in the distribution of neural networks increases, scalability is another key factor to perform IP protection and digital right management in large-scale settings.", "Particularly, the fingerprinting methodology should be able to accommodate a large number of distributed users.", "\\newline Collusion attacks can result in the attenuation of the fingerprint from each colluder and have been identified as cost-effective attacks in the multi-media domain.", "In a traditional collusion attack, multiple users work together to produce an unmarked content using differently marked versions of the same content [@bib:wu2004collusion] .", "In the domain of DL, a group of users who have the same host neural network but different fingerprints may work collaboratively to construct a model where no fingerprints can be detected by the owner.", "Considering the practicality of such attacks, We include collusion resilience in the robustness requirement for DNN fingerprinting.", "\\newline </subsection> <subsection> <title> II-B Attack Models </title> Corresponding to the robustness requirements listed in Table [@ref:LABEL:tab:required] , we discuss three types of DL domain-specific attacks that the fingerprinting methodology should be resistant to: model fine-tuning, model compression, and collusion attacks.", "\\newline Model Fine-tuning.", "Fine-tuning the pre-trained neural networks for transfer learning is a common practice since training a DL model from scratch is computationally expensive [@bib:shin2016deep] .", "For this reason, model fine-tuning can be an unintentional model transformation conducted by honest users or an intentional attack performed by malicious users.", "The parameters of the model are changed during fine-tuning, therefore the embedded fingerprints should be robust against this modification.", "\\newline Model Compression.", "Compressing the DNN models by parameter pruning is a typical technique to reduce the computational overhead of executing a neural network [@bib:han2015learning] .", "Genuine users may leverage parameter pruning to make their models compressed while adversaries may apply pruning to remove the fingerprints embedded by the owner.", "Since pruning alters the model parameters that carry the fingerprints information, an effective fingerprinting methodology shall be resistant to parameter pruning.", "\\newline Collusion Attack.", "Multiple attackers who have the same host neural network with different embedded fingerprints may perform collusion attacks to produce an unmarked model.", "We consider fingerprints averaging attack which is a common collusion attack and demonstrate how DeepMarks is robust against such attacks.", "\\newline </subsection>  </section>"], ["<section> <title> III Fingerprint Embedding </title>  The global flow of DeepMarks is illustrated in Figure [@ref:LABEL:fig:global] .", "In order to trace the models that are distributed to individual users, the owner first assigns a specific code-vector to each user.", "Given the code-vector and an orthonormal basis matrix, a unique fingerprint is constructed to identify each user.", "The designed fingerprint is then embedded in the weights distribution for each user by fine-tuning the model with an additive embedding loss .", "To identify a specific user, the owner assesses the weights of the marked layers in her model and extracts the corresponding code-vector.", "The decoded code-vector thus uniquely identifies the inquired user.", "In addition, DeepMarks enables the owner to detect colluders who work collaboratively and try to generate a model where no fingerprints can be detected by the owner.", "\\newline There are two types of fingerprint modulation mechanisms in the multi-media domain: (i) orthogonal modulation , and (ii) coded modulation [@bib:wu2004collusion] .", "In the rest of this section, we discuss how DeepMarks framework adopts these two fingerprinting methods to provide a generic solution for DNNs.", "\\newline <subsection> <title> III-A Orthogonal Fingerprinting </title> As discussed in Section [@ref:LABEL:reqiurements] , uniqueness is an essential requirement for fingerprinting to track individual users.", "Orthogonal modulation is a technique that uses orthogonal signals to represent different information [@bib:wu2003data] .", "By using mutually orthogonal watermarks as fingerprints, the separability between users can be maximized.", "Given an orthogonal matrix $ \\mathbf{U}_{v\\times v}=[\\mathbf{u_{1}},...,\\mathbf{u_{v}}] $ , the unique fingerprint for user $ j $ can be constructed by assigning each column to a user: \\newline <equation> $ \\mathbf{f_{j}}=\\mathbf{u_{j}}, $ </equation> where $ \\mathbf{u_{j}} $ is the $ j^{th} $ column of the matrix $ \\mathbf{U} $ , $ j=1,...v $ .", "Here, $ v $ orthogonal signals deliver $ B=log_{2}v $ bits information and can be recovered from $ v $ correlators.", "The orthogonal matrix can be generated from element-wise Gaussian distribution [@bib:wu2004collusion] .", "\\newline Regularizing neural networks for security purpose has been presented in previous works [@bib:CuRTAIL,DeepSigns] .", "However, none of these works focuses on the fingerprinting of the DL models.", "DeepMarks embeds the constructed fingerprint in the target layers of the host model by adding the following term to the loss function conventionally used for training/fine-tuning deep neural networks: \\newline <equation> $ \\mathcal{L}=\\mathcal{L}_{0}\\;+\\gammaMSE(\\mathbf{f_{j}}-\\mathbf{X}\\mathbf{w}).", "$ </equation> Here, $ \\mathcal{L}_{0} $ is the conventional loss function (e.g. cross-entropy loss), $ MSE $ is the mean square error function, $ \\gamma $ is the embedding strength that controls the trade-off between the two loss terms, $ \\mathbf{X} $ is the secret random projection matrix generated by the owner.", "$ \\mathbf{w} $ is the flattened averaged weights of the target layers for embedding the pertinent fingerprint.", "\\newline As a proof-of-concept analysis, we embed the fingerprint $ \\mathbf{f_{j}} $ in the convolutional layer of the host neural network, thus the weight $ \\mathbf{W} $ is a 4D tensor $ \\mathbf{W}\\in\\mathbb{R}^{D\\times D\\times F\\times H} $ where $ D $ is the input depth, $ F $ is the kernel size, and $ H $ is the number of channels in the convolutional layer.", "The ordering of filter channels does not change the output of the neural network if the parameters in the consecutive layers are rearranged correspondingly [@bib:uchida2017embedding] .", "As such, we take the average of $ \\mathbf{W} $ over all channels and stretch the resulting tensor into a vector $ \\mathbf{w}\\in\\mathbb{R}^{N} $ , where $ N=D\\times D\\times F $ .", "The rearranged weight vector $ \\mathbf{w} $ is then multiplied with a secret random matrix $ \\mathbf{X}\\in\\mathbb{R}^{v\\times N} $ and compared with the fingerprint $ \\mathbf{f_{j}} $ .", "The additional embedding loss term $ MSE(\\mathbf{f_{j}}-\\mathbf{Xw}) $ inserts the fingerprint $ \\mathbf{f_{j}} $ in the distribution of the target layer weights by enforcing the model to minimize the embedding loss together with the conventional loss during the training/fine-tuning of the DNN model.", "\\newline Since each user corresponds to a column vector in the orthogonal basis matrix, the maximum number of users is equal to the dimension of the fingerprint (which is also the number of orthogonal bases): $ n=v $ .", "Thus, the amount of customers that the same neural network can be distributed to is limited by the fingerprints dimension.", "Orthogonal fingerprints are developed based on spread spectrum watermarking [@bib:cox1997secure] .", "The straightforward concept and simplicity of implementation make orthogonal fingerprinting attractive to identification applications where only a small group of users are involved.", "Although orthogonality helps to distinguish individual users, the independent nature of orthogonal fingerprints makes it vulnerable to collusion attacks [@bib:wu2004collusion] .", "\\newline </subsection> <subsection> <title> III-B Coded Fingerprinting </title> To support a large group of users and improve the collision resilience of the fingerprints, coded modulation is leveraged to introduce correlation between fingerprints [@bib:trappe2003anti,trappe2002collusion] .", "Similar ideas have been discussed in Antipodal CDMA-type watermarking where the correlation contributions only decrease at the locations where the watermarks code-bits are different [@bib:liu2005multimedia] .", "Correlation not only allows the system to support a larger number of fingerprints than the dimensionality of the orthogonal basis vectors, but also alleviates the attenuation of fingerprints due to collusion attacks.", "The challenge for coded fingerprinting is to design code-vectors such that (i) the correlations are introduced in a strategical way, and (ii) the correct identification of the users involved in a collusion attack is facilitated.", "\\newline Anti-collusion codes (ACC) is proposed in [@bib:wu2004collusion] for coded fingerprinting and have the property that the composition of any subset of $ K $ or fewer code-vectors is unique.", "This property allows the owner to identify a group of $ K $ or fewer colluders accurately.", "A $ K $ -resilient AND-ACC is a codebook where the element-wise composition is logic-AND and allows for the accurate identification of $ K $ unique colluders from their composition.", "Previous works in the multi-media domain have shown that Balanced Incomplete Block Design (BIBD) can be used to generate ACCs of binary values [@bib:yu2010group] .", "A $ (v,k,\\lambda) $ -BIBD is a pair $ (\\mathcal{X},\\mathcal{A}) $ where $ \\mathcal{A} $ is the collection of $ k $ -element subsets (blocks) of a $ v $ -dimension set $ \\mathcal{X} $ such that each pair of elements of $ \\mathcal{X} $ appear together exactly $ \\lambda $ times in the subsets [@bib:trappe2003anti,dinitz1992contemporary] .", "The $ (v,k,\\lambda) $ -BIBD has $ b=\\sfrac{\\lambda(v^{2}-v)}{(k^{2}-k)} $ blocks ( $ k $ is the block size) and can be represented by its corresponding incidence matrix $ \\mathbf{C}_{v\\times b} $ .", "The elements in the incidence matrix have binary values where: \\newline <equation> $ c_{ij}=\\begin{cases}1,\\;\\text{if $i^{th}$ value occurs in $j^{th}$ block}\\\\ 0,\\;\\text{otherwise}.\\end{cases} $ </equation> \\newline By setting the number of concurrent occurrence to one ( $ \\lambda=1 $ ) and assigning the bit complement of columns of the incidence matrix $ \\mathbf{C}_{v\\times b} $ as the code-vectors, the resulting $ (v,k,1) $ -BIBD code is $ (k-1) $ -resilient and supports up to $ n=b $ users [@bib:trappe2003anti] .", "The theory of BIBD shows that the parameters satisfy the relationship $ b>v $ [@bib:dinitz1992contemporary] , which means the number of users (or fingerprints) is larger than the dimension of the orthogonal basis vectors.", "More specifically, the BIBD-ACC construction only requires $ \\mathcal{O}(\\sqrt{n}) $ basis vectors to accommodate $ n $ users instead of $ \\mathcal{O}(n) $ in orthogonal fingerprinting scheme.", "Systematic approaches for constructing infinite families of BIBDs have been developed [@bib:colbourn2006handbook] , which provides a vast supply of ACCs.", "\\newline Given the designed incidence matrix $ \\mathbf{C}_{v\\times b} $ , the coefficient matrix $ \\mathbf{B}_{v\\times b} $ for fingerprints embedding can be computed from the linear mapping $ b_{ij}=2c_{ij}-1 $ , thus $ b_{ij}\\in\\left\\{\\pm 1\\right\\} $ corresponds to the antipolar form [@bib:proakis1994communication] .", "The fingerprint for $ j^{th} $ user is then constructed from the orthogonal matrix $ \\mathbf{U}_{v\\times v} $ and the coefficient matrix $ \\mathbf{B}_{v\\times b} $ as follows: \\newline <equation> $ \\mathbf{f_{j}}=\\sum_{i=1}^{v}b_{ij}\\mathbf{u_{j}}, $ </equation> where $ \\mathbf{b_{j}}\\in\\left\\{\\pm 1\\right\\}^{v} $ is the coefficient vector associated with user $ j $ .", "Finally, The designed fingerprint $ \\mathbf{f_{j}} $ is embedded in the weights of the target model by adding the embedding loss to the conventional loss as shown in Equation [@ref:LABEL:eq:embed_loss] .", "\\newline Comparing the orthogonal fingerprinting in Equation [@ref:LABEL:eq:orthog_fp] with the coded fingerprinting in Equation [@ref:LABEL:eq:coded_fp] , one can see that orthogonal fingerprinting can be implemented by coded fingerprinting if an identity matrix is used as the ACC codebook $ \\mathbf{C}=\\mathbf{I} $ .", "This, in turn, means that the code-vector assigned to each user only has one element that equals to $ 1 $ and all the others are zeros.", "Therefore, orthogonal fingerprinting can be considered as a special case of coded fingerprinting.", "\\newline </subsection>  </section>"], ["<section> <title> IV Fingerprint Extraction </title>  For the purpose of fingerprints inquiry and colluder detection, the model owner assesses the weights of the marked layers, recovers the code-vector assigned to the user, and uses correlation statistics (orthogonal fingerprinting method) or BIBD ACC codebook (coded fingerprinting method) to identify colluders.", "Note that in the multi-media domain, there are two types of detection schemes for spread spectrum fingerprinting: blind or non-blind detection, depending on whether the original host signal is available in the detection stage or not.", "Non-blind detection has higher confidence in detection while blind detection is applicable in distributed detection settings [@bib:wu2004collusion,zhao2006fingerprint] .", "DeepMarks leverages blind detection scheme and does not require the knowledge of the original content; thus content registration and storage resources are not needed.", "We discuss the workflow of extracting the code-vector from the marked weights and detecting participants in fingerprints collusion attacks for both fingerprinting methods in the following sections.", "\\newline <subsection> <title> IV-A Orthogonal Fingerprinting </title> Code-vector extraction.", "As discussed in Section [@ref:LABEL:prob_form] , one objective of embedding fingerprints in the DNNs is to uniquely identify individual users.", "Since the fingerprint is determined by the corresponding code-vector, we formulate the problem of user identification as code-vector extraction from the marked weighs in each distributed model.", "\\newline The embedding methodology of orthogonal fingerprinting is described in Section [@ref:LABEL:orthog_embed] .", "In the inquiry stage, DeepMarks first acquires the weights tensor $ \\mathbf{\\widetilde{W_{j}}} $ of the pertinent marked layers for the target user $ j $ and computes the flattened averaged version $ \\mathbf{\\widetilde{w_{j}}} $ .", "The fingerprint is recovered from the multiplication $ \\mathbf{\\widetilde{f_{j}}}=\\mathbf{X\\widetilde{w_{j}}} $ where $ \\mathbf{X} $ is the random projection matrix specified by the owner.", "For simplicity, we use orthonormal columns to construct the basis matrix $ \\mathbf{U} $ , thus the correlation score vector (which is also the coefficient vector) can be computed as follows: \\newline <equation> $ \\mathbf{\\widetilde{b_{j}}}=\\mathbf{\\widetilde{f_{j}}}^{T}\\mathbf{U}=[\\mathbf{% \\widetilde{f_{j}}}^{T}\\mathbf{u_{1}},...,\\mathbf{\\widetilde{f_{j}}}^{T}\\mathbf% {u_{v}}].", "$ </equation> Since the fingerprints are orthogonal, only $ j^{th} $ component in the correlation scores $ \\mathbf{\\widetilde{b_{j}}} $ will have large magnitude while all the other elements will be nearly zeros.", "Finally, the code-vector $ \\mathbf{\\widetilde{c_{j}}}\\in\\left\\{0,1\\right\\}^{v} $ assigned to $ j^{th} $ user is extracted by element-wise hard-thresholding of the correlation vector $ \\mathbf{\\widetilde{b_{j}}} $ .", "\\newline Colluder detection.", "Recall that the second objective of the owner for leveraging fingerprinting is to trace illegal redistribution or unintended usages of the models.", "Here we consider a typical linear collusion attack where $ K $ colluders average their fingerprints and collaboratively generate a new model where the fingerprint is not detectable.", "To detect participants in the collusion attack, the owner first computes the correlation scores between the colluded fingerprint and each basis vector as shown in Equation [@ref:LABEL:eq:orthog_decode] .", "Element-wise hard-thresholding is then performed on the correlation vector where the positions of \u201c1\u201ds correspond to the indices of the colluders.", "According to Equation [@ref:LABEL:eq:orthog_decode] , the magnitude of averaged fingerprints is attenuated by $ \\frac{1}{K} $ assuming there are $ K $ colluders participating in the attack.", "As shown in [@bib:wu2004collusion] , $ \\mathcal{O}(\\sqrt{\\sfrac{v}{logv}}) $ colluders are sufficient to defeat the fingerprinting system, where $ v $ is the dimension of the fingerprint.", "\\newline </subsection> <subsection> <title> IV-B Coded Fingerprinting </title> Code-vector extraction.", "Similar to the extraction of orthogonal fingerprints, the owner acquires the weights in the marked layers $ \\mathbf{\\widetilde{W_{j}}} $ and computes its averaged flattened version $ \\mathbf{\\widetilde{w_{j}}} $ , then extracts the colluders\u2019 fingerprint $ \\mathbf{\\widetilde{f_{j}}=X\\widetilde{w_{j}}} $ .", "The extracted fingerprint is then multiplied with the basis matrix to compute the correlation score vector $ \\mathbf{\\widetilde{b_{j}}}=\\mathbf{\\widetilde{f_{j}}}^{T}\\mathbf{U} $ .", "Finally, the ACC code-vector $ \\mathbf{\\widetilde{c_{j}}} $ assigned to the $ j^{th} $ user is decoded from $ \\mathbf{\\widetilde{b_{j}}} $ by hard-thresholding.", "\\newline To illustrate the workflow of code-vector extraction for coded fingerprinting, let us consider a $ (7,3,1) $ -BIBD codebook given in Equation [@ref:", "LABEL:eq:codebook_eg] .", "The coefficient vector of each fingerprint is constructed by mapping each column of the codebook $ \\mathbf{C} $ to the antipodal form $ \\left\\{\\pm 1\\right\\} $ .", "The fingerprints for all users are shown in Equation [@ref:LABEL:eq:code_fp_eg] : \\newline <equation> $ \\mathbf{C}=\\begin{pmatrix}0&0&0&1&1&1&1\\\\ 0&1&1&1&0&1&1\\\\ 1&0&1&0&1&0&1\\\\ 0&1&1&1&1&0&0\\\\ 1&1&0&0&1&1&0\\\\ 1&0&1&1&0&1&0\\\\ 1&1&0&1&0&0&1\\end{pmatrix}, $ </equation> <equation> $ \\begin{cases}\\mathbf{f_{1}}=-\\mathbf{u_{1}}-\\mathbf{u_{2}}+\\mathbf{u_{3}}-% \\mathbf{u_{4}}+\\mathbf{u_{5}}+\\mathbf{u_{6}}+\\mathbf{u_{7}},\\\\ \\cdots\\\\ \\mathbf{f_{6}}=+\\mathbf{u_{1}}+\\mathbf{u_{2}}-\\mathbf{u_{3}}-\\mathbf{u_{4}}+% \\mathbf{u_{5}}+\\mathbf{u_{6}}-\\mathbf{u_{7}},\\\\ \\mathbf{f_{7}}=+\\mathbf{u_{1}}+\\mathbf{u_{2}}+\\mathbf{u_{3}}-\\mathbf{u_{4}}-% \\mathbf{u_{5}}-\\mathbf{u_{6}}+\\mathbf{u_{7}},\\\\ \\end{cases} $ </equation> where $ \\mathbf{u_{i}}(i=1,...,7) $ are orthogonal columns of the matrix $ \\mathbf{U} $ .", "For user $ 1 $ , her coefficient vector can be recovered by computing the correlation scores: \\newline <equation> $ \\mathbf{\\widetilde{b_{1}}}=\\mathbf{f_{1}}^{T}[\\mathbf{u_{1}},...,\\mathbf{u_{7}% }]=[-1,-1,+1,-1,+1,+1,+1].", "$ </equation> The corresponding code-vector is then extracted by the inverse linear mapping $ c_{ij}=\\frac{1}{2}(b_{ij}+1) $ .", "The resulting code-vector is $ \\mathbf{\\widetilde{c_{1}}}=[0,0,1,0,1,1,1] $ , which is exactly the same as the first column of $ \\mathbf{C} $ .", "The consistency shows that BIBD AND-ACC codebooks can be leveraged to identify individual users.", "\\newline Colluder detection.", "Recall that in Section [@ref:LABEL:code_embed] , we discuss the property of BIBD and its application for constructing anti-collusion codes.", "Here, we describe how to use the intrinsic asset of AND-ACC for colluder detection in fingerprints averaging attack.", "Assuming the positions of the marked layer are known to the colluders, they can perform element-wise average on their weight tensors in the pertinent layers and generate $ \\mathbf{W^{avg}} $ as the response to the owner\u2019s inquiry.", "The owner then computes the correlation vector $ \\mathbf{b^{avg}} $ as follows: \\newline <equationgroup> <equation> $ \\mathbf{f^{avg}}=\\mathbf{Xw^{avg}}, $ $ \\mathbf{f^{avg}} $ $ =\\mathbf{Xw^{avg}}, $ </equation> <equation> $ \\mathbf{b^{avg}}=\\mathbf{(f^{avg})^{T}}\\mathbf{U}. $ $ \\mathbf{b^{avg}} $ $ =\\mathbf{(f^{avg})^{T}}\\mathbf{U}. $ </equation> </equationgroup> \\newline The problem of identifying colluders based on the correlation statistics has been well addressed in conventional fingerprinting that is based on spread spectrum watermarking [@bib:cox1997secure,jain2000digital] .", "There are three main schemes: hard-thresholding detector, adaptive sorting detector, and sequential detector [@bib:wu2004collusion] .", "Hard-thresholding detector works by comparing each element in the correlation score vector $ \\mathbf{b} $ with a threshold $ \\tau $ to decide the corresponding bit (\u201c0\u201d or \u201c1\u201d) in the ACC code-vector.", "Adaptive sorting detector sorts the correlation scores in a descending order and iteratively narrow down the set of suspected users until the corresponding likelihood estimation of the colluder set stops increasing.", "Sequential detector directly estimates the colluder set from the pdf of the correlation statistics without decoding the ACC code-vector.", "For details about each detection method, we refer readers to the paper [@bib:wu2004collusion] .", "\\newline DeepMarks deploys hard-thresholding detector for colluders identification.", "The ACC code-vector is decoded from the correlation vector $ \\mathbf{b^{avg}}=[b^{avg}_{1},...,b^{avg}_{v}] $ by comparing each component with the threshold $ \\tau $ : \\newline <equation> $ c^{avg}_{i}=\\begin{cases}1,\\text{if $b^{avg}_{i}>\\tau$},\\\\ 0,\\text{otherwise}.\\end{cases} $ </equation> Given the ACC code-vector of the colluders $ \\mathbf{c^{avg}} $ , the remaining problem is to find the subsets of columns from the codebook $ \\mathbf{C} $ such that their logic-AND composition is equal to $ \\mathbf{c^{avg}} $ .", "For a $ (v,k,1) $ -BIBD-ACC, at most $ (k-1) $ colluders can be uniquely identified.", "\\newline As an example, we demonstrate the colluder detection scheme of DeepMarks using the $ (7,3,1) $ -BIBD codebook given in Equation [@ref:LABEL:eq:codebook_eg] .", "Assuming user $ 6 $ and user $ 7 $ collectively generate the averaged fingerprint: \\newline <equationgroup> <equation> $ \\mathbf{f^{avg}}=\\frac{1}{2}(\\mathbf{f_{6}}+\\mathbf{f_{7}}), $ $ \\mathbf{f^{avg}} $ $ =\\frac{1}{2}(\\mathbf{f_{6}}+\\mathbf{f_{7}}), $ </equation> <equation> $ =\\frac{1}{2}(2\\mathbf{u_{1}}+2\\mathbf{u_{2}}-2\\mathbf{u_{4}}).", "$ $ =\\frac{1}{2}(2\\mathbf{u_{1}}+2\\mathbf{u_{2}}-2\\mathbf{u_{4}}).", "$ </equation> </equationgroup> The owner assesses the averaged fingerprint and computes the correlation scores as the following: \\newline <equationgroup> <equation> $ \\mathbf{b^{avg}}=\\mathbf{(f^{avg})^{T}}\\mathbf{U}=[1,1,0,-1,0,0,0].", "$ $ \\mathbf{b^{avg}} $ $ =\\mathbf{(f^{avg})^{T}}\\mathbf{U}=[1,1,0,-1,0,0,0].", "$ </equation> </equationgroup> The colluders\u2019 code-vector is then extracted according to decision rule in Equation [@ref:LABEL:eq:b_threshold] : \\newline <equation> $ \\mathbf{c^{avg}}=[1,1,0,0,0,0,0].", "$ </equation> It can be observed that the logic-AND of column 6 and column 7 in the codebook $ \\mathbf{C} $ is exactly equal to $ \\mathbf{c^{avg}} $ , while all the other compositions cannot produce the same result.", "This example shows that the two colluders can be uniquely identified using the designed BIBD AND-ACC codebook.", "\\newline </subsection>  </section>"], ["<section> <title> V Evaluation </title>  We evaluate the performance of DeepMarks on MNIST [@bib:lecun1998mnist] and CIFAR10 [@bib:krizhevsky2009learning] datasets and two different neural network architectures: convolutional neural networks and wide residual networks.", "The topologies of these two models are summarized in Table [@ref:LABEL:tab:bench] .", "The fingerprints are embedded in the first convolutional layer of the underlying neural network.", "Since orthogonal fingerprinting can be considered as a sub-category of coded fingerprinting, we focus on the comprehensive evaluation of latter one.", "Both MNIST-CNN and CIFAR10-WRN benchmarks are used to assess the performance of coded fingerprinting while only MNIST-CNN benchmark is used to demonstrate the workflow of orthogonal fingerprinting.", "\\newline <subsection> <title> V-A Coded Fingerprinting Evaluation </title> In the evaluations of coded fingerprinting, we use a $ (31,6,1) $ -BIBD AND-ACC codebook ( $ \\mathbf{C} $ ) and assign each column as a code-vector for individual users.", "The codebook can accommodate $ n=\\frac{v(v-1)}{k(k-1)}=31 $ users and is resilient to at most $ (k-1)=5 $ colluders, theoretically.", "The embedding strength in Equation [@ref:LABEL:eq:embed_loss] is set to $ \\gamma=0.1 $ and the pre-trained host neural network is fine-tuned with the additional embedding loss for $ 20 $ epochs in order to embed the fingerprints.", "The threshold for extracting the code-vector is set to $ \\tau=0.85 $ in all experiments.", "We perform a comprehensive examination of the DeepMarks\u2019 performance in the rest of this paper.", "\\newline Fidelity.", "To show that the insertion of fingerprints does not impair the original task, we compare the test accuracy of the baseline (host neural network without fine-tuning), the fine-tuned model without embedding fingerprints, and the fine-tuned model with fingerprints embedded."]], "target": "The comparison of results are summarized in Table . It can be observed from the table that embedding fingerprints in the (deep) neural network does not induce any accuracy drop and can even slightly improve the accuracy of the fine-tuned model."}, {"tabular": ["  Dataset-ID  &  BC-DC  &  Top-5%  &  Fraction of nodes ", "  &  Spearman Coefficient  &  Overlap  &  having DC=1 ", " CAIDA-1557  &  0.95  &  53%  &  54% ", " RocketFuel-1239  &  0.96  &  85%  &  82% ", " MrInfo, Tier1-1239  &  0.86  &  54%  &  43% ", " MrInfo, Transit-3292  &  0.94  &  40%  &  32%  "], "ref_sec": [["<section> <title> I Introduction </title>  Social Network Analysis (SNA) constitutes a highly interdisciplinary theoretical framework that seeks to process social information and analyze existing social structures [@bib:Faust] .", "SNA draws heavily on graph models that map individual actors within the social network to the graph vertices and their relationships to the graph (weighted) edges.", "It then leverages graph-theoretic concepts, metrics and results to answer various questions about the relative importance of the actors for the network or the way that information (or innovations) flow (resp.", "spread) across it.", "\\newline The centrality concept, to the best of our knowledge, dates back to the work of Bavelas [@bib:bavelas] .", "By that time significant sociological research was directed to the area of professional networks addressing how the position and power of individual actors relate to their social interconnections and the way they interact with the rest of the network.", "Such sociological studies motivated the introduction of various sociological indices, which sought to quantify the importance of nodes and their relationships.", "Bavela\u2019s work appears to be the first to have given a formal definition of node centrality in connected graphs as the sum of its own geodesics (shortest-path distances) to all other nodes.", "\\newline This work triggered a large research thread and a huge number of publications in the area of centrality indices.", "Many of them proposed new indices [@bib:Katz] or adaptations of existing ones that expanded their applicability in a broader range of scenarios [@bib:Beauchamp,Anthonisse] .", "The vast majority of work was heuristic and only a few of them attempted to come up with axiomatic definitions of centrality indices and the properties they should satisfy [@bib:sabidussi] .", "The highly-cited work of Freeman in [@bib:Freeman] appears to have served as a turning point for this first wave of work, by reviewing a number of centrality indices and promoting three of them, i.e. , the closeness, degree, and betweenness, as the most representative ones.", "About the same time Bonacich had established the eigenvector centrality as a fourth, distinctly different but equally popular, index [@bib:power] .", "\\newline The research interest in the centrality concept revives in late 90\u2019s and early 2000, primarily through the works of physicists such as D. Watts and M. Newman.", "They use centrality indices to explore the vulnerability and community structure, respectively, of general network instances.", "SNA techniques and centrality, in particular, find applicability to research work across a broader set of disciplines beyond sociology.", "In the case of computer scientists, insights from centrality indices are primarily exploited in the design of more effective protocols for communication networks [@bib:Daly09,cacheICN] .", "The trend is only catalyzed by the broader expectations about the evolution of a Network Science [@bib:NetScience] , which could serve as the theoretical foundation for a unified treatment of all network types.", "\\newline Motivation and objective : The relevance of centrality indices to the communication network ( i.e. , Internet topologies) robustness, in particular, is the motivation for this study.", "Our main objective is to quantify how much information is embedded in centrality indices about the relative importance of Internet nodes for different network operations .", "Given that the different formulations of centrality proposed in literature are heuristic, the questions that naturally arise are how do these formulations compare in their assessments/predictions about the relative importance of network nodes and which one(s) may be the \u201cright one(s)\u201d to consider as reference for more reliable predictions of network robustness.", "\\newline The paper seeks to systematically address these questions by undertaking a three-step study with various instances of methodological innovation.", "The first step involves a thorough survey and novel classification of the variety of centrality indices proposed in literature over the last sixty years.", "This classification is then used to select the seven most popular and representative indices for carrying out the two experimental steps of the study.", "Hence, as a second step, we derive the node rankings these indices induce over more than 40 router-level snapshots of network topologies and study their correlation.", "The correlation strength is assessed by the mainstream rank/linear correlation coefficients but also less widespread measures such as the percentage overlap in the lists of the $ k $ most central nodes.", "Finally, we compare the seven indices with respect to their capacity to reveal the network vulnerability to node removals; we let the indices dictate the most central nodes to-be-removed and assess how the network connectivity properties but also its traffic-carrying capacity are affected.", "\\newline Our results identify certain index pairs with consistently high full rank correlation across all datasets we experiment with.", "However, they also warn against the interpretation of its high values showing that significant part of this correlation is due to nodes at the bottom of the rankings.", "As a result, the percentage overlap of the $ k $ most central nodes for the same pairs assumes clearly smaller values.", "Among the noteworthy results is that when the nodes removals are driven by the single index that can be computed through local-only information ( i.e. , the Degree Centrality index), the impact on the network traffic serving capacity approximates closely the maximum over the seven indices.", "The hint for network vulnerability studies is that the added complexity of global indices may be circumvented when an estimate of what is the worst-case impact on the network is needed.", "\\newline The remainder of the article is structured as follows: In Section [@ref:LABEL:sec:survey] , we summarize a survey of a broad range of proposed centrality indices over the last sixty years and the classification scheme we adopted.", "Note that a detailed description of the various centrality formulations appears in [@bib:thesis] .", "We then turn to the question of how much information different centrality indices entail regarding the importance of network nodes and the resulting network vulnerability.", "First, we select a subset of seven popular indices and carry out a correlation study in Section [@ref:LABEL:sec:correlations] .", "Then, in Section [@ref:LABEL:sec:robustness] we let the seven indices drive targeted node attacks over the Internet graphs and experimentally assess their impact in both connectivity and traffic-carrying capacity terms.", "Related literature is summarized in Section [@ref:LABEL:sec:related] .", "Finally, we conclude the paper with a summary of the main messages out of our study in [@ref:LABEL:sec:conclusions] .", "\\newline  </section>"], ["<section> <title> II A novel Classification of centrality indices </title>  In this report, we attempt to summarize this classification, pointing the interested reader to [@bib:thesis] for a much more detailed description of the indices and the context within which they were originally proposed.", "At a first-level the reviewed indices are split between node (point) centrality and graph centrality indices.", "The former, which are addressed by the vast majority of the literature, characterize individual nodes, whereas the latter are derived for whole graphs as functions of the individual node centrality indices.", "Then, node centrality indices are further characterized in line with the attributes shown in Fig. [@ref:LABEL:fig:pointCentrality_tree] .", "These include the network properties that are reflected in the index formulation (topological vs. flow-aware), the type of underlying graph over which an index is computed, as well as computational aspects such as the amount of information (local vs. global) and complexity involved in the index computation.", "\\newline <subsection> <title> II-A Node centrality indices </title> The first broad category groups point centrality indices that have been, at least originally, proposed for connected, binary, non-directed graphs.", "\\newline <subsubsection> <title> II-A1 Context: Purely topological vs. flow-aware </title> <paragraph> <title> Pure topological indices </title> This set of centrality indices takes into account only the network topology, i.e. , the nodes and the links between them.", "Topological indices may reflect two different aspects of a node\u2019s position in a network.", "\\newline {Distance-based centrality:} The corresponding indices measure how distant a node is from all other network nodes.", "Indices that fall in this category are the Closeness Centrality [@bib:Freeman] and Eccentricity [@bib:eccentrcity] .", "\\newline {Path-based centrality:} Indices of this type assess to what extent a node lies on {paths} connecting other nodes in the network.", "Degree and Betweenness Centrality are some of the relevant indices [@bib:Freeman] .", "\\newline Both types of indices can be further differentiated as to whether the distance (resp. path) definition accounts only for geodesics ( i.e. , shortest paths) between node pairs or a broader set of paths connecting them.", "Therefore, indices such as the Katz index [@bib:Katz] and random walk betweenness [@bib:RW_BC] essentially relax the underlying assumption that information flows only through shortest path routes.", "\\newline A third category of topological indices, which has been shown to be closely related to path-based centrality, are spectral centrality indices.", "Common to these indices are their dependence on the eigenstructure of a matrix related to the network in question and their computation through linear-algebraic manipulations.", "The indices, sometimes also called \u201cprestige\u201d measures of centrality [@bib:Faust] , have the special feature that the centrality index of a node is a function of the centralities of the nodes it is (directly) connected to.", "The eigenvector centrality index [@bib:power] is the most popular one in this family.", "\\newline </paragraph> <paragraph> <title> Flow-aware indices </title> The so far considered centrality indices rank the graph nodes taking into account the network topology only.", "A separate thread of work has attempted to factor the traffic that a network is expected to serve in the computation of the centrality indices.", "The traffic-aware betweenness [@bib:trafficBC] and the weighted conditional betweenness centrality [@bib:ITC] are two relevant indices.", "\\newline </paragraph> </subsubsection> <subsubsection> <title> II-A2 Underlying graph types </title> Most, if not all, of the considered centrality indices are defined over connected, undirected, binary, static graphs.", "In what follows, we relax in turn each one of these four graph attributes and discuss how the centrality indices are adapted to the resulting types of graphs.", "\\newline <paragraph> <title> extensions of centrality indices for disconnected graphs </title> Most of the centrality metrics have been formulated and proposed with connected networks in mind, i.e. , there are finite paths between every pair of nodes in the network that together form a single giant connected component.", "Much less attention has been paid to centrality metric formulations for disconnected graphs featuring more than one connected component and/or isolated nodes.", "Notably, some metric definitions are such that they can directly generalize for disconnected graphs without any additional care.", "For instance, this is the case with the degree and betweenness centrality while the closeness centrality metric as defined by Beauchamp [@bib:Beauchamp] and Freeman [@bib:Freeman77] does not trivially generalize into disconnected graphs.", "\\newline </paragraph> <paragraph> <title> extensions of centrality indices for directed graphs </title> The main body of work that proposes centrality indices appropriate for directed graphs, evolves around the spectral ones.", "PageRank, one of the most discussed implementation on the Web, delineates the basic model to effectively manage graph-based structures composed by directed (either inbound or outbound) links [@bib:pagerank] .", "\\newline </paragraph> <paragraph> <title> extensions of centrality indices for weighted graphs </title> Adaptations of centrality metrics for weighted graphs have been mainly proposed for the three most common centrality indices, the Degree, Betweenness and Closeness Centrality; in the last two instances, only geodesics are considered.", "The intuitive way to expand the node degree centrality definition is by replacing the sum of the node\u2019s neighboring links with the sum of their weights [@bib:weightedNets] .", "Likewise, the notion of link distance (or cost) underlying both the betweenness and closeness centrality indices is captured by its (inverse) weight and geodesics are estimated accordingly [@bib:Brandes_variants] .", "\\newline Regarding spectral indices, to derive the Eigenvector centrality variant for weighted graphs it suffices to substitute the binary elements of the adjacency matrix involved in the eigenvector computations with the edge weights [@bib:weightedNewman] .", "The extension of PageRank is somewhat more involved; the index originally designed to rank Web pages exploits the binary graph based nature of the Web.", "However, treating equally all inbound and outbound links remains restrictive when measuring the importance of each page.", "Therefore, proposed extensions of PageRank over weighted networks assign to each outlink page a value proportional to its popularity [@bib:wPageRank_alg] or use factors to modulate how rank scores are distributed to neighbors [@bib:AuthorRank,journal_status] .", "With hyperlink weights, the surfer can now express preferences among pages instead of uniformly jumping to arbitrary ones.", "\\newline </paragraph> <paragraph> <title> extensions of centrality indices for dynamic graphs </title> The extension of standard complex network indices, including centrality ones, to networks that vary over time is a more recent thread.", "There are more than one graph representations for dynamic networks and many more terms that are used to denote them such as temporal graphs [@bib:kostakos] , evolving graphs [@bib:evolving_graphs] , space-time graphs [@bib:spacetime_graphs] or time-varying graphs [@bib:time-varying] .", "To the best of our knowledge, there have been two main studies that have proposed adaptations of centrality indices for temporal graphs.", "The first one draws on the notion of temporal path [@bib:temporal_paths] over a sequence of graph instances, whereas the second relies on a time-expanded graph representation to define temporal Betweenness and Closeness indices [@bib:time_ordered] .", "\\newline </paragraph> </subsubsection> <subsubsection> <title> II-A3 Computational Aspects </title> <paragraph> <title> Index scope (local vs. global) </title> Centrality indices can be separated into local and global ones, depending on the extent of topological information that is required to compute them.", "For instance, since Degree Centrality is a function of the number of direct (one-hop) neighbors, it is a local index.", "On the other hand, Betweenness and Closeness Centrality are global indices in that they rely on geodesic paths computed all over the network.", "\\newline One typical way to control the scope of (path-based) centrality computations is through the sociological notion of the ego-network.", "The ego network of a node $ v $ is the subgraph involving $ v $ , called the \u201cego\u201d node, its 1-hop neighbors, and their inter-connections.", "The ego network (centered-graph [@bib:centered] in graph theoretic terms) is used sometimes to derive a local approximation of an otherwise global centrality index.", "Betweenness Centrality is a typical index that lends to ego-centric approximations [@bib:ppantaz] .", "Another way to control the scope of centrality indices, this time purely path-based indices, is by controlling the length $ k $ of paths that are taken into account in their computation.", "Indices such as $ k $ -path [@bib:k_path] and and vertex-disjoint k-path centrality [@bib:k-BC] are examples of this category.", "\\newline </paragraph> <paragraph> <title> Computational cost of the index </title> Of particular interest for embedding centrality indices in communication network protocols is their computational complexity.", "The centrality interpretation by Freeman [@bib:Freeman77] does not seem to require special computing power to be applied on large network structures.", "On the contrary, the solution proposed by Bonacich [@bib:Bonacich91] to correlate the point centralities with graph centralities, could be considered computationally heavy as the network size increases.", "Consequently, he suggested a way to control this limitation using a new kind of matrix known as \u201coverlapping\u201d instead of adjacency matrix before the eigenvector calculation.", "Also, Moxleys\u2019 solution [@bib:Moxley] for (un)connected graphs seems to encounter the same serious problem with their AIC (Adjusted Index of Centrality) metric when analyzing rich datasets.", "As a result, they managed to represent the connections of each element in a vector based structure to efficiently compute the adjacency matrix and measuring the centrality for every reached or unreached point.", "\\newline </paragraph> </subsubsection> </subsection> <subsection> <title> II-B Graph centrality indices </title> Centrality indices have also been proposed as single numbers for the whole graph ( i.e. , graph centrality indices).", "If point centrality indices essentially generate rankings of nodes within a given graph, graph centrality indices seek to rank different graphs.", "Note that the first studies on point centrality indices by Bavelas [@bib:bavelas] and Beauchamp [@bib:Beauchamp] address graph centrality indices as well.", "Graph centrality was initially defined as the sum of point centralities over each network node.", "Later on, more complex axiomatic definitions appeared in literature ( e.g. , [@bib:sabidussi] ), therefore assigning different notions to the graph centrality indices.", "A more insightful categorization attempt is given by H\u00f8ivik [@bib:Hoivik] and recognizes three graph centrality concepts: \\newline <subsubsection> <title> II-B1 Integration </title> This is a measure of how centrally located are the nodes of a graph as a whole.", "It is measured by the sum of individual node centrality indices.", "This is what Freeman calls {compactness} in his definitions of graph centrality indices out of the Degree, Betweenness and Closeness Centrality indices [@bib:Freeman] .", "\\newline </subsubsection> <subsubsection> <title> II-B2 Unipolarity </title> Reflects whether there is a very central node and is taken equal to the maximum node centrality.", "\\newline </subsubsection> <subsubsection> <title> II-B3 Centralization </title> Captures the dispersion of the node centrality values and is taken equal to the sum of differences of point centralities from the minimum point centrality value.", "\\newline As a final note, the interpretations of centrality indices are multiple.", "To refer to some of those, Freeman noted that central parties may generally affect the communication, facilitating or even distorting whatever flows in the network.", "Particularly, from the perspective of degree centrality, he argued that a point with relative high degree serves to control the communication activity inside the topology having the advantage of binding together flow processes [@bib:thesis] .", "Bonacich agreed saying that a central firm has the possibility to acquire satisfying information rapidly and therefore with high probability.", "Borgatti on the other hand, tried to shed more light on the question of which centrality index is appropriate for which occasion [@bib:Borgatti_05] .", "He introduced general flow typologies over networks using two criteria i.e. , the way the flow is realized in the network ( i.e. , point-to-point transfer, serial and parallel duplication) and the kind of graph-theoretic path ( i.e. , walk, trail, and path) that is relevant.", "\\newline </subsubsection> </subsection> <subsection> <title> II-C Selecting centrality indices for experimentation </title> In summary, the survey work in this Section has shown that there is a plethora of centrality index formulations, many of them capturing different properties of network nodes.", "For the experimentation that follows, we select seven indices that include the most popular ones, i.e. , those that are repeatedly considered in the literature, and, at the same time, are highly representative of the attributes discussed in the survey: the Degree (DC) [@bib:Freeman] , Betweenness (BC) [@bib:Freeman] , Closeness (CC) [@bib:Freeman] , Eigenvector (EC) [@bib:power] , Harmonic Centrality (HC) [@bib:harmonic] , Pagerank (PG, with the damping factor $ d $ set to $ 0.85 $ as typically used in literature) [@bib:pagerank] and Eccentricity (ECC) [@bib:eccentrcity] .", "\\newline In Table [@ref:LABEL:tab:seven_indices] we characterize them according to the aforementioned classification attributes.", "Also the formal normalized definitions are recalled for each index along with the running time of the algorithms utilized for their computation, as function of the node $ V $ and edge $ E $ sets of a graph $ G=(V,E) $ .", "\\newline </subsection>  </section>"], ["<section> <title> III Correlation study of centrality indices </title>  In almost all instances, where centrality indices inform communication network protocols, what matters is the {ranking} of nodes that is induced by the indices rather than the absolute centrality values.", "These rankings are subsequently used in the decisions made by the respective protocols.", "For example, in [@bib:Daly09,BubbleRap] , the rankings determine whether a Delay Tolerant Network (DTN) node will forward a message to another DTN node it encounters; in [@bib:cacheICN] , whether a content item will be cached at a Information-Centric Networking (ICN) node or not; and in [@bib:adamic] whether to search for a file in a given unstructured Peer-to-Peer(P2P) network node or not.", "Likewise, in vulnerability analysis of the service migration protocol in [@bib:ITC] , it is the {set} of the $ k,k<|V| $ most highly-ranked nodes that matters, again irrespective of their actual centrality values.", "The question that plausibly arises in every case is how similar are the rankings generated by each centrality index.", "\\newline In this section, we carry out a thorough correlation study of these rankings, as computed over a broad set of ISP router-level topologies.", "The study proceeds in two steps.", "First, ( Step 1 ) we calculate for each network topology and each node in it the seven centrality index (see subsection [@ref:LABEL:employed_indices] ) values, thus generating seven different node rankings per topology.", "Then, ( Step 2 ) we compute pairwise correlation measures over these rankings.", "Two different measures are considered, one accounting for the full node rankings and the other only for the highly-ranked nodes.", "\\newline <subsection> <title> III-A Index correlation measures and router-level topologies </title> <subsubsection> <title> III-A1 Index correlation measures </title> The first correlation measure is the nonparametric Spearman\u2019s rank-correlation coefficient, $ \\rho $ , and is computed over the full node rankings.", "The coefficient assesses how well a monotonic function can describe the rankings induced by the two centrality indices on the network nodes.", "For a given network topology node set $ V $ , it is given by: \\newline <equation> $ \\rho_{V}(C_{1},C_{2})=1-\\frac{6\\sum\\limits_{u\\in V}(r_{C_{1}}(u)-r_{C_{2}}(u))% ^{2}}{|V|(|V|^{2}-1)} $ </equation> \\newline where $ r_{C_{1}}(u) $ and $ r_{C_{2}}(u) $ are the ranks of node $ u $ in line with centrality indices $ C_{1} $ and $ C_{2} $ , respectively.", "The coefficient values lie in $ [-1,1] $ , with high positive (negative) values denoting strong positive (resp.", "negative) correlation .", "\\newline The second correlation measure is the percentage overlap between the sets of the $ k $ most highly ranked (top- $ k $ ) nodes that are generated by two centrality indices.", "\\newline <equation> $ ov_{V}(C_{1},C_{2};k)=\\frac{|\\{v\\in V:r_{C_{1}}(v)\\leq k\\}\\bigcap\\{v\\in V:r_{C% _{2}}(v)\\leq k\\}|}{k}\\cdot 100\\% $ </equation> \\newline Contrary to the Spearman\u2019s coefficient, the percentage overlap is computed over a subset of the full node rankings and takes values in $ [0,100] $ .", "\\newline The relevance of the two measures depends on the usage context of centrality-based ranks.", "The decisions that relate to the DTN forwarding, CCN caching and P2P node search examples rely on full node rankings; whereas, vulnerability analysis is usually concerned with the subset of nodes that are important (\u201ccentral\u201d) for the network.", "High correlation between the rankings of two indices implies that a computationally complex or intractable index can be approximated by a simpler one without significant penalties for the intended protocol operation or the conclusions of the vulnerability analysis.", "\\newline </subsubsection> <subsubsection> <title> III-A2 Router-level ISP topologies </title> All experiments in this paper are carried out over datasets collected in the context of four projects.", "Four of them relate to measurement projects and are referred to as Rocketfuel [@bib:rocketFL] , CAIDA [@bib:caida] , and mrinfo (Tier-1 and Transit) [@bib:PAM10] datasets, respectively.", "They report {binary} router-level graphs for different Internet ASes.", "On the contrary, the last dataset, called the Topology Zoo dataset, contains {capacitated} topologies at the router- and Point-of-Presence (PoP) level [@bib:zoo] , as collected directly by network operators of primarily academic and research networks.", "The basic properties of the all datasets are summarized in Tables [@ref:LABEL:tab:nets] and [@ref:LABEL:tab:ZOOnets] in the Appendix.", "\\newline <paragraph> <title> Rocketfuel dataset </title> The Rocketfuel dataset [@bib:rocketFL] is the chronologically oldest dataset, drawn with the help of the traceroute active measurement tool.", "The Rocketfuel engine collected raw traceroute data from public BGP tables, processed them and extracted router-level networks by mapping diverse ISP routers to ASes.", "Ten diverse ISPs across the world were mapped utilizing approximately 800 traceroute sources hosted by nearly 300 servers.", "\\newline </paragraph> <paragraph> <title> CAIDA dataset </title> CAIDA topologies (IDTK 2011-10) [@bib:caida] , the most recent release out of our datasets, were obtained by means of an active measurement infrastructure known as Archipelago; it performed traceroute probes to randomly-chosen destinations, located in 29 countries worldwide within the interval of Oct 24 to Nov 3, 2011.", "At first, publicly available BGP dumps were used to map IP addresses to ASes relying on several tools for alias resolution.", "Then, heuristic rules [@bib:caida] properly assigned each router to the AS it belongs.", "\\newline </paragraph> <paragraph> <title> Mrinfo datasets </title> The Mrinfo [@bib:PAM10] , dataset was collected during the period 2005-2008 and contains 264 Tier-1, 244 Transit, and 342 Stub ISP network topology files.", "To cope with traceroute inaccuracies, the dataset collection was extracted by the new mrinfo tool which silently crawls IPv4 addresses only, based on the Internet Group Management Protocol (IGMP).", "The advantage of this tool is twofold; it can efficiently discriminate interconnections between ASes without suffering from IP alias resolution problems and, besides layer-3 devices, detect the presence of level-2 hardware (switches) between interconnections of routers for each AS.", "In our study we considered only the largest available snapshots corresponding to two datasets, Tier-1 and Transit, leaving aside the small-sized Stub topologies.", "\\newline </paragraph> <paragraph> <title> Topology Zoo dataset </title> Whereas previous studies employ a number of route discovery tools to reveal the Internet connectivity, the Topology Zoo gathers the maps of more than 140 real-world topologies directly from the network operators, including layout views of the optical fibers used for both commercial (COM) and Research & Education (REN) networks.", "As the resulting maps (topologies and associated attributes) come from the owner and/or manager of the network, they are claimed to reflect an accurate network view circumventing any errors due to biases of measurement techniques.", "Out of the 232 network graphs included in the Zoo, we have carefully singled-out the largest capacitated router-level snapshots (see Table [@ref:LABEL:tab:ZOOnets] in the Appendix) representing the topologies of 11 different European, one Asian and one cross-European research networks as traced during the period 2008-2011.", "We will use these topologies to evaluate the traffic-serving capacity of networks (see Section [@ref:LABEL:subsec:flow] ).", "\\newline </paragraph> </subsubsection> </subsection> <subsection> <title> III-B Results </title> <subsubsection> <title> III-B1 Full-ranking correlation over binary graphs </title> The results follow a similar trend over the four datasets so that the rank correlation between the studied indices can be summarized in the graphs of Fig. [@ref:LABEL:fig:graphs] .", "This graph-based illustration represents all AS topologies since they exhibit similar coefficient values for every distinct centrality pair.", "Notably, none of the possible centrality pairs have been found to be negatively correlated over any of the studied topologies.", "With this in mind, we empirically characterize the correlation strength as high and low when the corresponding coefficient exhibits a value in the interval [0.7,1] and [0.3,0.7), respectively; the two indices are actually uncorrelated when coefficients lie in [0-0.3).", "Accordingly, bold edge-lines (solid or dashed) denote high correlation values between two centralities, whereas plain edge-lines denote low values.", "We have omitted the connections for those index pairs that do not exhibit any kind of correlation.", "\\newline In what follows, index pairs of interest are discussed in more detail.", "Where appropriate we draw links to studies reporting similar or different results on different kinds of networks.", "In Table [@ref:LABEL:rank_correl_results] each row ( i.e. , top to bottom) in every box reports averages measured over the CAIDA, Rocketfuel, MrInfo -Tier1 and -Transit datasets, respectively.", "The interested reader is referred to [@bib:thesis] for the full set of results while in the Appendix ( i.e. , Table [@ref:LABEL:kendal_correl_results] ) she can find the respective table when the Kendall $ \\tau $ is used as correlation measure.", "\\newline Betweenness vs. Degree centrality Degree centrality (DC) captures, at least phenomenally, a completely different notion of centrality than Betweenness (BC).", "DC takes into account only the node\u2019s local neighbors, whereas BC considers the position of the node within the whole network.", "Therefore, in some cases DC can evaluate nodes\u2019 position very differently than BC; it may overestimate the importance of nodes belonging to isolated subgraphs (high DC-low BC) or underestimate the role of nodes acting as bridges between groups of nodes (low DC-high BC).", "On the other hand, high-degree nodes have better chances to be parts of the shortest paths linking node pairs.", "In our datasets, the two indices are found consistently highly correlated, in agreement with earlier studies [@bib:ppantaz,correl_complex,AS_properties] that report positive {Pearson} correlation between DC and BC over a wide range of networks such as random graphs and real-world complex networks.", "\\newline Pagerank vs. Degree centrality.", "Another interesting result, that is immediately apparent from Figure [@ref:LABEL:fig:graphs] , is the strong correlation between Pagerank and Degree centrality.", "Pagerank is principally defined for digraphs discriminating between incoming and outgoing connections at each node.", "For undirected general graphs, Grolmusz [@bib:PG_undirect] shows that Pagerank is statistically close to the degree distribution but not identical.", "Furthermore, taking into account the aforementioned strong BC-DC correlation, a triangle-like schema emerges and may be of practical importance as it relates the only local index ( i.e. , Degree) with globally-determined ones ( i.e. , Pagerank and Betweenness centrality).", "Interestingly, significant positive correlation between these three indices (PG-DC-BC), with $ \\rho $ values in [0.66, 0.95] for all three index pairs, is also reported by Yan and Ding [@bib:coauthorship] over coauthorship real-world data (directed graphs).", "\\newline Figure [@ref:LABEL:fig:PG_DC] .a describes the monotonic increase of the PG-DC correlation with the damping factor $ d $ of PG.", "Pagerank [@bib:pagerank] is often approached as the steady-state distribution of the frequency of visits to the network nodes by a random walker who each time either jumps towards another arbitrary network node with probability (1-d)/N, where N the cardinality of the network node set, or randomly follows an outbound link towards a neighboring node.", "As $ d $ increases the walker\u2019s long jumps get rarer and only 1-hop steps are feasible.", "Figure [@ref:LABEL:fig:PG_DC] .a (dashed line) also shows similar association between the damping factor and the PG-BC $ \\rho $ values.", "\\newline Pagerank vs. Eigenvector centrality.", "PG, and EC centrality are the two spectral indices we experiment with.", "Both express the stationary probability of a random surfer to reside on some page while moving on the Web graph.", "Hence, one would expect some positive correlation between these indices.", "However, our results indicate the absence of such a relationship.", "A possible cause is that their actual interpretation differs as, contrary to EC, the PG Centrality utilizes the damping factor $ d $ to determine the \u201cjump\u201d probability.", "However, as a couple of indicative experiments suggest (Fig. [@ref:LABEL:fig:PG_DC] .b), the rank correlation between the two metrics increases yet does not reach very high values as $ d $ moves to unity i.e. , the surfer moves only to neighboring pages.", "It seems then that $ d $ can only partially justify the poor PG-EC correlation strength; as the PG formula suggests (Table [@ref:LABEL:tab:seven_indices] ) a node\u2019s ( i.e. , Web page) PG rank value is evenly divided ( $ L_{u} $ term) over its neighbors, which for the case of undirected graphs corresponds to its DC value.", "The fact that DC index is found to be weekly correlated with EC (Table [@ref:LABEL:rank_correl_results] ) can further distort any anticipated PG-EC correlation.", "\\newline Eccentricity vs. Closeness centrality.", "Another strong correlation that we observe in our correlation study involves the Eccentricity and Closeness centrality indices.", "Recalling the definitions of the two indices (ref.", "Table [@ref:LABEL:tab:seven_indices] ), there is absolute positive ECC-CC correlation if it holds: \\newline <equation> $ ECC(n_{1})>ECC(n_{2}) $ </equation> whenever \\newline <equation> $ CC(n_{1})>CC(n_{2}) $ </equation> We can rewrite eq. [@ref:LABEL:eq:ecc] as \\newline <equation> $ max_{j\\in V}d_{n_{2},j}>max_{j\\in V}d_{n_{1},j} $ </equation> and eq. [@ref:LABEL:eq:cc] as \\newline <equation> $ \\sum_{j\\in V}d_{n_{2},j}>\\sum_{j\\in V}d_{n_{1},j} $ </equation> Hence, the question becomes when the order in maximum index values (eq. [@ref:LABEL:eq:max] ) is also preserved for their averages (eq. [@ref:LABEL:eq:avr] ) over a certain graph.", "This holds in several trivial graphs ( e.g. , line graph, rectangular grid) but not in all graphs.", "One simple counterexample is the 4-node star network with a 2-node line graph attached to one of its leaf nodes (compare the two indices for the hub node and the leaf node, where the line graph is attached).", "\\newline Additional remarks.", "There exist further centrality pairs yielding positive correlations, which are less straightforward to reason about.", "For instance, in our results, high rank correlation has been observed for pairs such as Eigenvector-Harmonic and Eigenvector-Closeness centrality.", "These findings seem consistent with previous results.", "Iyer et al. [@bib:attack_robustness] have noticed that synthetic scale-free networks (whose degree distribution follows a power law, at least asymptotically) present moderate positive Pearson CC-EC correlation.", "Higher values ( $ r $ =0.61) are reported for the case of networks with exponential degree distribution.", "\\newline Elaborating more on this thread, we have tried to identify how the degree distribution relates to the EC-CC correlation.", "In Figure [@ref:LABEL:fig:DDs] left, we plot in log-log scale the degree distribution of a 411-node large AS out of the RocketFuel datasets, as a representative sample, with positive Pearson correlation between EC and CC ( $ r $ =0.65).", "The straight-line points to power-law degree distribution suggesting that this may be beneficial for the positive correlation, as in [@bib:attack_robustness] .", "\\newline On the other hand, the scale-free property is not a necessary condition for high EC-CC correlation.", "In Figure [@ref:LABEL:fig:DDs] right, the degree distribution of a 645-node large mrinfo Transit AS clearly deviates from a power-law pattern, yet it features a considerably higher Pearson coefficient ( $ r $ =0.78).", "Similar remarks hold for the EC-CC rank correlation over these snapshots (where we measure the corresponding Spearman $ \\rho_{V} $ = $ 0.88 $ for the former and $ \\rho_{V} $ = $ 0.96 $ for the latter one).", "\\newline </subsubsection> <subsubsection> <title> III-B2 Top- k percentage overlap over binary graphs </title> So far, our correlation analysis has taken into account the full rankings produced by the seven centrality indices.", "We now focus our attention on the top-5% most central nodes identified by each index and investigate how large are the overlaps between different rankings.", "Our motivation for this set of experiments is the existence of network protocol instances that typically seek to exploit a small set of the top-central nodes [@bib:ITC] .", "Likewise, vulnerability studies of Internet graphs, as the one we carry out in Section [@ref:LABEL:sec:robustness] , are concerned with the subset of most central nodes.", "\\newline In Figure [@ref:LABEL:fig:graphs] .c we show a summarizing graph-based illustration of the overlap scores among the seven centrality indices.", "The bold solid lines ( e.g. , between CC-HC) denote what we consider as high top-5% overlap between two centralities i.e. , beyond 70%.", "The dashed solid lines ( e.g. , between EC-HC) reflect overlap values between 40-70%, whereas the dashed plain lines represent looser relations for the corresponding pairs.", "Additionally, figure [@ref:LABEL:fig:top5_overlp] presents the average overlap of nodes over all ASes of each dataset for the most significant centrality pairs.", "On the one hand the overlap of some indices (such as BC-CC or HC-BC) appear to be highly sensitive to the considered topology, with differences that reach 40% across different datasets.", "On the other, all pairs that are strongly correlated in terms of full rankings in [@ref:LABEL:subsec:full_correl] appear to be more weakly associated in terms of overlap values .", "Exceptions to that rule are the HC-BC and CC-BC pairs that represent a slight increase of the relation strength when passing from the rank correlation to the overlap measure.", "Overall, only two of the centrality index pairs combine high overlap values with strong full rank-correlation (see Figure [@ref:LABEL:fig:graphs] .a): PG-DC and HC-CC, both exhibiting larger than 80% overlap in the top-5% node rankings they induce across all datasets, whereas all the other pairs hardly exceed the 60% value.", "This result should come as no surprise since rank correlation is determined over all network nodes rather than a subset of cardinality $ k $ .", "\\newline Let us look closer into the BC-DC pair.", "For these two indices, there is an apparent association between the nodes that are ranked in the last positions by the two indices; namely, nodes with the lowest DC value ( i.e. , DC=1) exhibit as well the lowest BC value ( i.e. , BC=0).", "Figure [@ref:LABEL:fig:scatter] illustrates how the number of nodes with DC=1 affects the rank correlation coefficients.", "It seems that (especially for the datasets of Caida and RocketFuel) the Spearman values between the considered indices increase with the number of DC=1 nodes.", "These nodes are expected to positively contribute to the DC-BC correlation as they also exhibit the lowest-ranked betweenness value ( i.e. , BC=0)."]], "target": "At the same time, the ones with the top BC and DC values may not necessarily coincide as indicated in Table . The above results suggest that the high DC-BC correlation is mainly due to nodes of lowest ranks. This observation warns against the actual value of high Spearman rank correlation coefficients between two indices. On the other hand, the overlap measure does not suffer from similar biases."}, {"tabular": ["  Name  &  Year  &  Presumed Target  &  TS  &  Purp.  &  Affected ICS  &  Exploited CVE ", " Slammer  &  2003  &  untargeted  &  1  &  Sabot.  &  Nuclear Power Station  &  CVE-2002-0649 ", " Conficker  &  2009  &  untargeted  &  1  &  Sabot.  &  French  &  German Air Force  &  CVE-2008-4250 ", " Stuxnet  &  2010  &  Iranian Nuclear Enrichment Facilites  &  4  &  Sabot.  &  Siemens S7-300  &  CVE-2010-2568 ", "  &    &    &    &    &    &  CVE-2008-4250 ", "  &    &    &    &    &    &  CVE-2010-2729 ", "  &    &    &    &    &    &  CVE-2010-2772 ", " Duqu / Duqu 2.0  &  2011/2015  &  Industrial Project Documents  &  3  &  Esp.  &  -  &  - ", " Shamoon / Shamoon 2.0  &  2012/2017  &  Saudi-Arabian Oil Industry  &  2  &  Sabot.  &  -  &  - ", " Regin  &  2012  &  GSM Base Stations  &  4  &  Esp.  &  -  &  - ", " Stuxnet 0.5  &  2013  &  Iranian Nuclear Enrichment Facilites  &  4  &  Sabot.  &  Siemens S7-300  &  CVE-2012-3015 ", " Havex  &  2013  &  European Energy Industry  &  3  &  Esp.  &  -  &  - ", " BlackEnergy  &  2016  &  Ukrainian Power Plant  &  3  &  Sabot.  &  -  &  CVE-2014-4114 ", "  &    &    &    &    &    &  CVE-2014-0751 ", " Industroyer  &  2017  &  Ukrainian Power Plant  &  4  &  Sabot.  &  Siemens SIPROTEC  &  CVE-2015-5374  "], "ref_sec": [["<section> <title> I Introduction </title>  In the 1970\u2019s, the third industrial revolution took place [@bib:Thomson.2015] .", "During this phase, computers were introduced into industry in order to automate tasks that, until then, had to be done by hand or by application-tailored solutions.", "Since then, the computer technology has taken huge steps.", "Reconfigurable Programmable Logic Controllers ( PLCs ) took the place of hard-wired relay logic circuits [@bib:Galloway.2013] .", "Domain-specific, proprietary fieldbuses, like CAN [@bib:RobertBoschGmbH.1991] and Modbus [@bib:MODICONInc..1996,ModbusIDA.2006] , have been replaced by TCP/IP -based solutions, such as ModbusTCP [@bib:ModbusIDA.2006,Modbus.2012] , ProfiNET [@bib:PROFIBUS.2017] and OPC UA [@bib:OPCFoundation.2017] , that make use of the vastly available internet infrastructure and its network hardware.", "Opening networks to the outside enables easier management of production capabilities.", "Remote maintenance, simpler adjustment of machines and a constant flow of information are but a few of the advantages.", "There are, however, some downsides.", "Two of the main reasons why security is inherently absent in virtually every technology and protocol used, are as follows: Industrial networks were physically separated from the internet, when the technology arose [@bib:Igure.2006] and each set up of an industrial company is unique and very hard to get around in [@bib:Igure.2006] .", "As recent events, many of which are explained in section [@ref:LABEL:sec:attack_campaigns] , show, both assertions do not hold true anymore, if they ever did.", "Many recent examples show that industrial networks can and will be breached.", "It needs to be highlighted, that, as in consumer electronics, the user plays a crucial role in securing a system.", "Many of the newer botnets, such as Hajime or Mirai, try to gain access by using default credentials, with a tremendous success.", "This behaviour has been analysed, among others, in our previous works [@bib:Fraunholz.2017,Fraunholz.2017_2] .", "Many industrial systems use credentials for means of configuration.", "For reasons of ease of use, however, the passwords are often weak and shared among many users.", "Attackers that try standard configurations to gain access will succeed if the system credentials have not been altered.", "This kind of threat is also common in the exploits examined in section [@ref:LABEL:sec:in-depth_anal] .", "It is very hard for intrusion detection systems to discover abuse that is performed with valid credentials.", "Changing default credentials is therefore a vital step in order to enable security in a system.", "The remainder of this work is structured as follows.", "In section [@ref:LABEL:sec:related_work] , surveys and analyses of attacks are listed.", "After that, a statistical analysis of the Common Vulnerabilities and Exposures ( CVE ) list is performed in section [@ref:LABEL:sec:stat_anal] .", "This is followed by an in-depth analysis of available Supervisory Control And Data Acquisition ( SCADA )-system based exploits in section [@ref:LABEL:sec:in-depth_anal] , as well as a breakdown of attack campaigns against industry in section [@ref:LABEL:sec:attack_campaigns] .", "The lessons learned are listed in section [@ref:LABEL:sec:lessons_learned] .", "This work will be concluded in section [@ref:LABEL:sec:conclusion] .", "\\newline  </section>"], ["<section> <title> II Related Work </title>  Even though there are a lot of survey papers, as well as taxonomies that present an overview of different kinds of attacks, there has not yet been a systematic analysis of all publicly available SCADA exploits to the best of our knowledge.", "A very broad and extensive overview over current SCADA -based attack-vectors can be found in the works of Zhu, Joseph and Sastry [@bib:Zhu.2011] .", "In addition to that, there are other works that give an overview over existing SCADA-attacks and survey current exploits [@bib:Igure.2006,MottaPires.2006,Caswell.2011,Meixell.", "July2013] .", "Not only attacks on SCADA -systems are well documented, but also countermeasures, as well as means for hardening systems, are processed in literature [@bib:Chandia.2007,HildickSmith.2005] .", "There are also works presenting taxonomies of attacks, also in order to help operators assess risks and threats to their systems and implement the according countermeasures [@bib:InternationalOrganizationforStandardization.2013,Langfinger.2016] , as well as works for the collection of data that allows for insight about the condition of a system [@bib:DuqueAnton.2017,DuqueAnton_2.2017] .", "The German Federal Office for Information Security ( BSI ) periodically releases security advices for industry [@bib:BundesamtfurSicherheitinderInformationstechnik.2016] .", "Furthermore, there are surveys analysing specific domains, such as automotive and fieldbus-security [@bib:Checkoway.2011] (some of the relevant works are in German [@bib:Wolf.2014,TSystems.2016] ) and wireless-security [@bib:Wright.2007] .", "Many of the exploits we examine in this paper have already been investigated in literature.", "The amount of works analysing singular attacks is vast, therefore, we only reference such works in the according sections.", "\\newline  </section>"], ["<section> <title> III Statistical Analysis </title>  An exhaustive list of all CVEs can be found online [@bib:MITRE.2016] .", "Since it contains over 100 000 entries, manual analysis was infeasible.", "We developed a text-processing script in order to gain statistical information about the distribution of exploits.", "A major drawback was that the most specific information was written in natural language, without any form.", "We searched the document for keywords while using stemming in order to find any variant of the keyword.", "Stemming is a technique employed to process natural languages [@bib:Lovins.1968] .", "The word stems of keywords are derived, then similar word stems are searched in the target file.", "We used the python stemming-library [@bib:Chaput.2010] .", "The results of the statistical analysis are summarised in table [@ref:LABEL:tab:stat_cve_anal] .", "\\newline The entry \u201dOverall categorized entries\u201d, as well as the \u201dPercentage covered by keywords\u201d, display the number of different attacks that have been classified, after accounting for entries with multiple keywords.", "That means 65 919 entries (or 61.87%) in the CVE list can be attributed to at least one of the categories.", "The largest group is Remote Code Execution with 28 000 occurrences, closely followed by Denial of Service ( DoS ) and Injection attacks.", "SCADA exploits are relatively small, with only 373 entries.", "This shows that, even though it is not as present as office IT -based attacks, SCADA -based exploits are becoming more of an issue for manufacturers.", "\\newline  </section>"], ["<section> <title> IV In-depth Analysis </title>  In this section, four different types of attacks that are relevant for industrial applications are analysed.", "First, attacks on PLC systems are considered in subsection [@ref:LABEL:ssec:plc] .", "After that, fieldbus-based exploits are discussed in subsection [@ref:LABEL:ssec:fieldbus] , followed by wireless- and hardware-attacks in subsections [@ref:LABEL:ssec:wireless] and [@ref:LABEL:ssec:hw] .", "These types of attacks were chosen to be discussed as they are the industrial-specific attack vectors and have not be discussed at large in the context of office- IT -security.", "PLCs can mostly be found in industrial environments as they are used to control production machines.", "The same goes for fieldbus systems, that, aside from some appliances in home automation, are comonly employed in industrial automation.", "Wireless networks are also commonly used in office and home environments.", "There are, however, industry specific protocols that are only applied in this context.", "These protocols are discussed here.", "Hardware attacks can have a great impact due to the distributed nature of production environment and the fact that machines have hardware interfaces.", "\\newline <subsection> <title> IV-A Attacks on PLCs </title> PLCs are resource for industrial applications controlling Cyber-Physical (Production) Systems.", "Hence, they interact with and operate devices in the physical world.", "In contrast to office IT systems which only handle data, they interact with the real world.", "Attacks on PLCs therefore have an impact on physical entites, be it human workers or production resources.", "This leads to grave consequences of the successful abuse of PLCs .", "As common computation resources, PLCs usually require an underlying operating system.", "In most cases, this is a version of Windows, adapted to the specific needs for industrial applications.", "As there is an abundance of exploits and vulnerabilites based on flaws in the operating system, we only consider vulnerabilities that specifically derive from the industrial application of the given system.", "Furthermore, only threats that occur in this context are analysed.", "In total, we found about 100 exploits as metasploit [@bib:Rapid7.2010] modules and Proofs of Concepts ( PoC ).", "All metasploit-modules are listed in the Rapid7 -database [@bib:Rapid7.2000] .", "The databases we searched additionally were exploit-db [@bib:OffensiveSecurity.2009] , 0day-today [@bib:Inj3ct0rTeam.2008] and packetstorm-security [@bib:PacketStormSecurity.1998] .", "This number is smaller than the entries found in the CVE list in section [@ref:LABEL:sec:stat_anal] as there is executable code to be found.", "As a result, anybody can exploit these vulnerabilities without much difficulties, rendering them very dangerous for operators.", "The number of CVE discoveries and exploit developments per year is shown in figure [@ref:LABEL:fig:exp_per_year] .", "Unfortunately, some exploits could not be attributed to a year; this has been accounted for by a question mark.", "The list amounts to a mean value of 8.8 and a median of 7 exploit developments per year.", "A peak of 31 developments per year can be found in 2011.", "One possible explanation is that it was the year after Stuxnet [@bib:Falliere2011-stux] was discovered (see table [@ref:LABEL:tab:campaigns_table] ) and there was a special interest in PLC -exploitation.", "The trend of CVE -development is also rising, meaning that the amount of CVEs discovered per year has been rising, starting in 2011.", "\\newline We distinguished between four different categories of exploits: \\newline <list> \\ Code Execution is the unauthorised execution of malicious code \\newline \\ \\ Data Extraction is the unauthorised disclosure of information \\newline \\ \\ DoS describes the partial or full degradation of the availability of a service or resource \\newline \\ \\ Privilege Escalation is the process of maliciously obtaining higher privileges on a system than intended \\newline \\ </list> \\newline The distribution of these categories on windows-based systems is depicted in figure [@ref:LABEL:fig:windows_cat_per_plat] .", "Of 66 windows-based exploits, almost three quarters allow the execution of arbitrary code.", "This is a tremendous threat since it allows an attacker to alter, add and delete resources on the affected system.", "\\newline Furthermore, we grouped all exploits into remote and local .", "Local exploits allow an attacker to execute an exploit on a system he already has unprivileged access to, usually in the form of a user account with limited rights.", "Remote exploits can be executed without any prior access to the system, despite some form of network connection.", "In figure [@ref:LABEL:fig:local_cat_per_acc] , the distribution of the categories for local access is shown.", "The overall number of local exploits is relatively small, comprising only 12 exploits.", "In this scenario, the execution of code is most common.", "The distribution of the categories for remote access is shown in figure [@ref:LABEL:fig:remote_cat_per_acc] .", "It comprises of 84 exploits, most of which are code execution as well.", "The most prevalent threat for PLC -based exploitation is the execution of remote code.", "This is a very severe threat because of the priorities of industry.", "While in classic office- IT , the CIA (Confidentiality, Integrity, Availability) security targets are common, each with about the same importance, the most important security target by far for industry is availability.", "Unavailable production facilities cost a huge amount of money, making this the top priority of machine operators.", "Code Execution has the potential to disable facilities, rendering them unavailable and costing revenue.", "\\newline </subsection> <subsection> <title> IV-B Attacks on Fieldbus-Level </title> Due to the proprietary nature of industrial networks, a vast landscape of fieldbus protocols has emerged.", "Protocols such as Modbus [@bib:MODICONInc..1996] , Profinet [@bib:PROFIBUS.2017] , CAN [@bib:RobertBoschGmbH.1991] , Local Interconnect Network (LIN) [@bib:LINConsortium.2010] , Media Oriented System Transport (MOST) [@bib:MOSTCooperation.2010] and FlexRay [@bib:FlexRayConsortium.2010] .", "These protocols have inherent security flaws.", "Since there are no means of authentication, identities are not assigned to the participating entities [@bib:Zhu.2011] .", "That means an attacker with access to the bus can appear as a valid communication partner and thus extract and inject messages.", "This results in a break of confidentiality and integrity.", "Due to these security flaws and the lack of encryption [@bib:Porros.2010] , an attacker can monitor the systems and even deploy attacks.", "Examples for such attacks are Man in the Middle ( MitM ) and DoS .", "In systems using Modbus , malicious adversaries can read all messages to discover active controllers and used function codes as well as inject commands themselves.", "Additionally, they can send incorrect messages or error flags to eliminate single controllers or even the entire system.", "Many industrial systems have a remote maintenance interface that can be accessed via internet [@bib:Caswell.2011] .", "Often, this interface is secured poorly, or not at all [@bib:Caswell.2011] .", "This means that an attacker with access to the same network as the interface can change system settings and read system conditions.", "Gateways are used in order to connect several fieldbus networks.", "Oftentimes, these gateways are not configured securely, allowing an attacker that has access to one fieldbus network, to traverse to different networks [@bib:Wolf.2014] .", "As a counter example, OPC-UA [@bib:OPCFoundation.2017] needs to be mentioned.", "It is a very modern fieldbus-protocol that allows definition of entities, including authentication and encryption.", "The shell model allows for encapsulation of functional units and the definition of interfaces.", "\\newline </subsection> <subsection> <title> IV-C Attacks on Wireless Systems </title> Driven by the fourth industrial revolution, wireless communication finds its way into industrial systems.", "There are some protocols that are commonly used in industrial applications, such as Bluetooth Low Energy [@bib:BluetoothSIG.2010] , ZigBee [@bib:ZigBeeAlliance.2004] and Z-Wave [@bib:ABR.2016] , Radio Frequency IDentifier (RFID) [@bib:etsi.2017] and the Long Range Wide Area Network (LoRa) [@bib:Sornin.2015] .", "Wireless Local Area Network (WLAN) [@bib:IEEEComputerSociety.2016] is also often used in industry, but since it was originally developed for classical office- IT , it is not considered in this work.", "RFID is commonly used by industry to tag entities and materials and account for them in storage or production.", "The other protocols are commonly used for data transmission and communication.", "There are several flaws and fixes for WLAN , but they are out of scope for this work for the reasons named above.", "As there is no physical access control to the wireless channel, an adversary can listen to the communication, given he is within the range of the wireless signal.", "Therefore, most wireless communication protocols are encrypted.", "Still, some encryption schemes can be broken, rendering the content unprotected.", "If there is no, or weak, encryption, an attacker can listen to the communication and extract information to perform a MitM [@bib:Conti.2016] attack.", "Furthermore, he can inject messages into the network with the purpose of launching DoS attacks.", "A famous example is Wireless Equivalent Privacy (WEP) [@bib:IEEE802.11.1994] , that is broken [@bib:Fluhrer.2001] but still in use.", "Another example is ZigBee whose encryption key, in its default configuration, can easily be recovered by an attacker.", "Due to poor manufacturer implementations, the secret key is often transmitted in plain text if a new device advertises to the network, for example after restarting [@bib:Zillner.2015] .", "An attacker can obtain this key and gains full access to the network.", "Another problem in wireless networks are relay attacks.", "Using those, an attacker can capture a communication packet, transport it over a different protocol, and inject it into the network on a different place.", "This is commonly done with Bluetooth or RFID .", "An attacker can use this method to get a response to a challenge, even though the key is not near a key reader.", "This method has already successfully been applied to break the Passive Keyless Entry and Start (PKES) of different car manufacturers [@bib:Francillion.2010] .", "Spoofing and impersonation are other common attack concepts on wireless protocols.", "Spoofing means the disguise of an attacker as a valid entity to participate in a communication, impersonation describes an attacker that claims to be an entity she is not.", "Bluetooth is vulnerable to attacks with Rogue Access Points (APs) [@bib:Wright.2007] , among others.", "Those are APs that are set up by an attacker and imitate valid APs.", "Because of the ad-hoc nature and the frequency hopping properties of Bluetooth , rogue APs are hard to detect [@bib:Wright.2007] .", "The same concept can be applied to RFID , where fake tags or readers can read or manipulate entries [@bib:Garfinkel.2005] .", "Furthermore, wireless channels are inherently prone to jamming attacks.", "Since there is no access control, an attacker can flood the channel with packets, or simply jam it with noise [@bib:Xu.2005] .", "This prevents the valid users from communicating with each other.", "There are also more sophisticated approaches that exploit protocol flaws to prevent communication or that do not jam constantly to make discovery harder [@bib:Xu.2005] .", "\\newline </subsection> <subsection> <title> IV-D Physical-Layer Attacks </title> Physical, or hardware attacks, are among the most difficult ones.", "An adversary with physical access to a device or system has more possibilities of inflicting damage and abusing services than one on a remote location.", "Industrial companies, therefore, put a strong emphasis on obstruction of physical access by perimeters such as, walls, gates and guards.", "Given access, an adversary can, with enough force, always destroy a system rendering it unusable and creating a DoS .", "There are, however, more sophisticated and subtle approaches in tampering with devices.", "There are attacks on embedded devices, particularly PLCs , that falsify sensor values.", "This, in turn, creates, inapt reactions from the devices, leading to undesired behaviour.", "In literature, there is the \u201dGhost in the PLC\u201d-attack, that alters the input-pins of a PLC , as described by Abbasi and Hashemi [@bib:Abbasi.2016] .", "Another work on falsifying input values and creating improper responses from the system is shown by Urbina, Giraldo, Tippenhauer and Cardenas [@bib:Urbina.2016] .", "In addition to tampering with sensor-values, an attacker can read or update the code on a PLC .", "Such an attack is described by Basnight, Butts, Lopez and Dube [@bib:Basnight.2013] .", "In order to stealthily deploy malware on a PLC , Garcia, Brasser, Cintuglu, Sadeghi, Mohammed and Zonouz propose a method to read system information and create a fitting rootkit [@bib:Garcia.2017] .", "Even though it is not the most relevant attack vector in practice, securing physical access is a vital task for industry, since adversaries with direct access have many opportunities with a potentially high impact.", "\\newline </subsection>  </section>"], ["<section> <title> V Attack Campaigns </title>  The exploits that have been introduced in section [@ref:LABEL:sec:in-depth_anal] have been used for attack campaigns against industrial players.", "We found that there were two noteworthy kinds of attacks: \\newline <list> \\ Spearphishing campaigns against employees \\newline \\ \\ Attacks on the industrial infrastructure \\newline \\ </list> \\newline Phishing and spearphishing are common practices for malicious adversaries intending to gain insight on company secrets by gaining access to the office IT infrastructure and stealing data.", "A timeline of known spearphishing campaigns with an industrial background is shown in figure [@ref:LABEL:fig:timeline] .", "In phishing, unsuspecting victims are sent emails with malicious content, oftentimes a link to a website that is infected with malware [@bib:Wood2016-threats] .", "Attachments with malicious content are another common form of phishing [@bib:Wood2016-threats] .", "The chances of an attacker to get a victim to follow the link can be increased by personalizing the email.", "This is called \u201csocial engineering\u201d [@bib:Wood2016-threats] , the application of phishing to selected targets with highly adapted content is called \u201cspearphishing\u201d.", "\\newline Operation Aurora [@bib:McClure2010-aurora] aimed at the software industry, particularly Google .", "The Night Dragon , Greek Oil and New Year\u2019s campaigns aimed at various branches of the energy industry, namely research and petroleum processing [@bib:Wueest2014-energy] .", "Furthermore, the Nitro campaign [@bib:Chien2011-nitro] aimed at the chemical industry and was intended to obtain sensitive documents, designs and schemas for manufacturing.", "Black Vine [@bib:DiMaggio2015-blackvine] campaign was used for several targets.", "First, aerospace companies were in the focus.", "After that, it was aimed against healthcare institutions in the U.S. The Dragonfly [@bib:secresp2014-dragon] and Black Energy [@bib:Lee2016analysis] campaigns aimed at the energy industry as well, this time against Industrial Control System (ICS) manufacturing and power generation.", "In a report, an attack campaign, that is called Unnamed [@bib:klab2017-threats] in our timeline in figure [@ref:LABEL:fig:timeline] , was described also aimed for the extraction of confidential information about ICS manufacturing in the energy industry.", "Attacks on the industrial infrastructure often aim at sabotaging production.", "Highly sophisticated malware is employed in these campaigns [@bib:Wood2016-threats] ."]], "target": "A selected list of all known industrial malware campaigns can be found in table . In this table, the name of the malware is shown, as well as the year of discovery. Furthermore, the presumed target is listed, followed by a Target Score (TS) describing the kind of attack that was employed. The TS is assigned a value according to the following scheme:"}, {"tabular": ["  Search Term  &  TR  &  POSR  &  TH  &  Score ", " {element}  &  0.98  &  0.98  &  0  &  1.96 ", " {IResource}  &  0.93  &  1.00  &  0  &  1.93 ", " {Provider}  &  0.68  &  0.95  &  0  &  1.63 ", " {Level}  &  0.83  &  0.80  &  0  &  1.63 ", " {Tree}  &  0.78  &  0.75  &  0  &  1.53  "], "ref_sec": [["<section> <title> I Introduction </title>  During maintenance, software developers deal with numerous change requests as a part of software change implementation.", "Identification of exact source location (i.e., also called {concept location} ) during software code change (e.g., new feature addition, bug fixation) is a major challenge, even for a medium sized system [@bib:infer] .", "Change requests are often made by the users of a software system, and these requests are generally written using unstructured natural language texts [@bib:kevicdict] .", "While the software users might be familiar with the application domain of a software system, they generally lack the idea of how a particular software feature is implemented in the source code.", "Hence, a change request from them generally involves one or more {\u201chigh level\u201d} concepts (i.e., functional requirement) related to the application domain.", "A developer needs to map these concepts to the relevant source locations within the project for implementing the change [@bib:kevicdict,textret] .", "Such mapping is possibly trivial for the developer who has substantial knowledge on the target project.", "However, developers involved in the maintenance might not be aware of the low-level architecture of the software project, and the design documents might not be available either [@bib:ossdoc,measure] .", "Thus, they often experience difficulties in identifying the exact source locations (e.g., methods) to be changed.", "The mapping task generally starts with a search within the project which requires one or more suitable search terms.", "Previous studies [@bib:kevic,vocaprob,sitir] suggest that on average, developers perform poorly in coming up with good search terms for a change task regardless of their experience.", "For example, [@bib:kevic] report from a user study that only 12.20% of the search terms from the developers were able to retrieve relevant results.", "According to [@bib:vocaprob] , there is a small chance (10%\u201315%) that developers guess the exact words used in the source code.", "One way to help them overcome this challenge is to automatically suggest suitable search terms for the change task at hand, and our work addresses this research problem.", "\\newline Existing studies from relevant literature apply various lightweight heuristics [@bib:kevic] and query reformulation strategies [@bib:gayg,refoqus,shepherd,infer] .", "They also perform different query quality analyses [@bib:qquality,qeffect,specificity,refoqus] and data mining activities [@bib:kevicdict,ccmapping,infer] .", "However, most of these approaches expect a developer to provide the initial search query which they can improve upon.", "Unfortunately, preparing such a query is often a non-trivial task for the developers as well [@bib:kevic,vocaprob] .", "One can think of the whole change request as the initial query.", "However, this might lead the developers to major query reformulation tasks [@bib:gayg] or suboptimal solutions.", "[@bib:kevic] propose the only heuristic model for automatically identifying initial search terms for a change task where they consider different heuristics associated with {frequency, location, parts of speech} and {notation} of the terms from the change request.", "Although their model is found promising according to the preliminary evaluation, it suffers from two major limitations.", "First, their model is neither trained using a large dataset (i.e., uses only 20 change requests) nor cross-validated using the change requests from multiple software projects (i.e., uses only one project).", "Thus, the model is yet to be matured and reliable.", "Second, {tf\u2013idf} is the most dominating feature of their model which is subject to the size of the change request dataset for {inverse document frequency (idf)} calculation.", "Hence, their model is likely to be affected significantly by the size of the dataset.", "That is, it might require frequent re-training to keep itself useful for search term identification.", "Thus, an approach that overcomes such limitations and yet can identify appropriate search terms from a given change request is warranted.", "\\newline In this paper, we propose a novel query recommendation technique\u2013STRICT\u2013that automatically identifies and recommends good quality search terms from a change request for concept location.", "We determine importance of each term by employing two graph-based term weighting algorithms (from information retrieval domain)\u2013 {TextRank} and {POSRank} \u2013on the content of a change request, and then suggest the most important terms as the search query.", "Both TextRank and POSRank are adaptations of {PageRank} algorithm [@bib:pagerank] for natural language texts, and they extract the most important terms from a change request by analyzing co-occurrences [@bib:rada] and syntactic dependencies [@bib:rada,blanco] among the terms respectively.", "Unlike [@bib:kevic] , they are not subject to the size of subject systems under study, and also do not require any training.", "In fact, our technique is highly suited for the target research problem from several perspectives.", "First, our technique considers the content of a change request as a text graph (e.g., Fig. [@ref:LABEL:fig:tgraph] ) based on either term co-occurrences or syntactic dependencies rather than plain text.", "Thus, it has a higher potential for revealing important semantic relationships among the terms which might lead one to choosing appropriate search terms.", "Second, both TextRank and POSRank determine importance of a term in the graph (i.e., change request) not only based on its connectivity but also by considering the weights (i.e., importance) of the connected terms.", "That is, a term would be considered important only if it connected to other important terms [@bib:rada,sameer] .", "Thus, our technique has a better chance of locating the chunk of important terms from the change request which can be suggested as the search terms.", "\\newline Table [@ref:LABEL:table:ctask] shows an example change request from eclipse.jdt.ui system that reports a concern with custom search result display in Eclipse IDE.", "Our technique\u2013STRICT\u2013first converts the textual content of the request into two text graphs by capturing (a) co-occurrences of the terms in the request (i.e., Fig. [@ref:LABEL:fig:tgraph] -(a)) and (b) dependencies among the terms due to their parts of speech (POS) (i.e., Fig. [@ref:LABEL:fig:tgraph] -(b)) respectively.", "Then, it identifies the most important terms by recursively analyzing the topological characteristics (i.e., term connectivity) of both graphs.", "STRICT returns the following Top-5 search terms (i.e., highlighted, Fig. [@ref:LABEL:fig:tgraph] )\u2013 {\u2018element\u2019, \u2018IResource\u2019, \u2018Provider\u2019, \u2018Level\u2019} and {\u2018Tree\u2019} \u2013which return the first correct result at the Top-1 position.", "On the contrary, the baseline queries\u2013 {Title} , {Description} and {Title} + {Description} \u2013 return such result at 559 $ ^{th} $ , 71 $ ^{st} $ and 211 $ ^{th} $ positions.", "Thus, our suggested search terms (1) can provide a meaningful starting point for code search during code change, and (2) can potentially reduce the query reformulation efforts spent by the developers.", "It should be noted that this paper is a significantly extended version of our preliminary work on search term identification [@bib:saner2015masud] .", "While the earlier work explores the potential of {TextRank} using a limited dataset, this work (1) extends that idea by applying another appropriate term-weighting technique\u2013 {POSRank} , (2) proposes a novel search term ranking algorithm, and (3) then evaluates and validates the technique extensively using a larger dataset [@bib:strict] .", "\\newline Experiments using 1,939 change requests from eight subject systems (i.e., three {Apache} systems and five {Eclipse} systems) report that our technique\u2013STRICT\u2013can provide better quality search terms than 52%\u201362% of the baseline queries which is highly promising according to relevant literature [@bib:refoqus,trconfig] .", "Our suggested queries can retrieve relevant source code files for 30%\u201357% of the change tasks with about 30% mean average precision@10 where the first relevant file is mostly found within the Top-4 positions, which are also promising [@bib:antoniol,bavota] .", "Comparison with two state-of-the-art techniques\u2013 [@bib:kevic] and [@bib:rocchio] \u2013 not only validates our empirical findings but also demonstrates the superiority of our technique.", "We thus make the following contributions: \\newline <list> \\ A novel and promising search term identification technique\u2013STRICT\u2013that identifies good quality search terms for a change task from its change request.", "\\newline \\ \\ Comprehensive evaluation of the technique using 1,939 change requests from eight subject systems and four state-of-the-art performance metrics.", "\\newline \\ \\ Comprehensive validation of the technique using comparisons with two state-of-the-art techniques.", "\\newline \\ </list> \\newline  </section>"], ["<section> <title> II Graph Based Term-Weighting </title>  In information retrieval (IR), natural language text is often transformed into a graph where unique words are denoted as vertices, and meaningful relations among those words are represented as the edges [@bib:rada] .", "Such relation can be statistical, syntactic or semantic in nature [@bib:blanco] .", "In our research, we represent a software change request as a text graph where we consider both statistical and syntactic relations among words as the edges in the graph.", "To capture statistical relation, we consider co-occurrence of the words within a fixed window (e.g., {window size = 2} ) across all sentences from the request.", "For example, Fig. [@ref:LABEL:fig:tgraph] -(a) shows the text graph for the showcase change request (i.e., Table [@ref:LABEL:table:ctask] ) based on co-occurrence relationships among the words within a window of two.", "In order to capture syntactic relation, we consider grammatical modification of words from the request using Jespersen\u2019s Rank Theory [@bib:jespersen] .", "According to [@bib:jespersen] , words belonging to different parts of speech from a sentence can be provided with three major ranks\u2013 primary (i.e., nouns), secondary (i.e., verbs, adjectives) and tertiary (i.e., adverbs)\u2013 where a word from a higher rank modifies another word from the same or lower ranks.", "We thus encode such modification relations into edges in the text graph.", "Fig. [@ref:LABEL:fig:tgraph] -(b) shows the text graph of the example change request (i.e., Listing 1) based on grammatical dependencies among the words.", "Once text graphs are developed, we apply two adapted versions of the popular algorithm by [@bib:pagerank] (for web link analysis)\u2013 {PageRank} [@bib:pagerank] \u2013for term weighting.", "In particular, we identify the most important words from the text graphs by exploiting their topological properties (e.g., connectivity) in the graphs.", "\\newline  </section>"], ["<section> <title> III STRICT: Proposed Technique for Search Term Identification from a Change Request </title>  Given that appropriate search term identification is a major challenge for the developers and existing studies are limited in certain contexts, we introduce a novel IR-based technique.", "Fig. [@ref:LABEL:fig:sysdiag] shows the schematic diagram of our proposed technique\u2013STRICT\u2013for search term identification and suggestion from a change request.", "We first turn a software change request into two text graphs (e.g., Fig. [@ref:LABEL:fig:tgraph] ) based on word co-occurrence and grammatical modification of words.", "Then, we employ two graph-based term-weighting algorithms\u2013 {TextRank} and {POSRank} \u2013on those graphs, estimate term weights, and identify the suitable search terms for the change task.", "In this section, we discuss different steps of our technique as follows: \\newline <subsection> <title> III-A Data Collection </title> Our technique accepts user-provided texts of a change request as the input (i.e., Step 1, Fig. [@ref:LABEL:fig:sysdiag] ), and returns a ranked list of search terms as the output (i.e., Step 8, Fig. [@ref:LABEL:fig:sysdiag] ).", "We collect change requests from two popular bug tracking systems\u2013 {BugZilla} and {JIRA} .", "Each change request is submitted as a semi-structured report written using natural language texts, and it contains several fields such as {Issue ID} (e.g., 303705), {Product} (e.g., JDT), {Component} (e.g., UI), {Title} and {Description} .", "We extract the last two fields from each report for analysis, as was also done by literature [@bib:kevic] . {Title} summarizes a requested change task whereas {Description} contains the user\u2019s detailed explanation of the task in natural language texts.", "\\newline </subsection> <subsection> <title> III-B Text Preprocessing </title> We analyze {Title} and {Description} of a software change request, and perform several preprocessing steps on them (i.e., Step 2, Fig. [@ref:LABEL:fig:sysdiag] ).", "We consider {sentence} as a logical unit for the change request texts, and collect each of the sentences from both fields.", "Then we perform standard natural language preprocessing (i.e., stop word removal and splitting of dotted terms) on each of the sentences, and extract the candidate search terms.", "A dotted term (e.g., org.eclipse.ui.part ) often contains multiple technical artifacts, and splitting helps one to analyze each of them in isolation [@bib:splitting] .", "We also split each camel case (e.g., createPartControl ) term into simpler terms (i.e., create , Part and Control ) and keep both term types for our analysis [@bib:splitting,refoqus] .", "It should be noted that we avoid term stemming (i.e., extracting root form of a given term) since it degrades the performance of our technique, as was also reported by [@bib:kevic] .", "\\newline </subsection> <subsection> <title> III-C Text Graph Development </title> Using Word Co-occurrence: After preprocessing steps, we get a list of sentences from each change request where each of the sentences contains an ordered list of candidate search terms.", "We then use those sentences to develop a {text graph} (e.g., Fig. [@ref:LABEL:fig:tgraph] -(a)) for the change request (Step 3, Fig. [@ref:LABEL:fig:sysdiag] ).", "In the text graph, each unique term is represented as a vertex and the {co-occurrence} of terms in the sentence is denoted as the edges among the vertices.", "The underlying idea is that all the terms that co-occur in the text within a fixed window have some relationships or dependencies [@bib:rada,blanco] .", "For example, if we consider the sentence\u2013 {\u201cCustom search results not shown hierarchically in the java search results view\u201d} \u2013from the example request texts (i.e., Table [@ref:LABEL:table:ctask] ), the preprocessed version forms an ordered list of terms\u2013 {\u201cCustom search hierarchically java search view.", "\u201d} Please note that the transformed sentence contains several phrases such as {\u201ccustom search\u201d} and {\u201csearch view\u201d} , and the terms in those phrases are semantically dependent on each other for comprehensive meaning.", "Use of term co-occurrence captures such dependencies in a statistical sense.", "We thus consider a {sliding window} of {window size=2} (as recommended by [@bib:rada] ) as a semantic unit of words, and derive the following relationships: {Custom} $ \\longleftrightarrow $ {search} , {search} $ \\longleftrightarrow $ {hierarchically} , {hierarchically} $ \\longleftrightarrow $ {java} , {java} $ \\longleftrightarrow $ {search} and {search} $ \\longleftrightarrow $ {view} .", "Then such relationships are encoded into the connecting edges between the corresponding vertices in the text graph (i.e., Fig. [@ref:LABEL:fig:tgraph] -(a)).", "\\newline Using POS Dependence: Term co-occurrence models relationship between terms statistically which might not be always effective for determining term-weight (i.e., term\u2019s importance).", "We thus apply another type of relationship\u2013 syntactic dependencies\u2013 among the terms based on grammatical modification.", "According to Jespersen\u2019s Rank Theory [@bib:jespersen] , words from a sentence can be provided with three major ranks\u2013 primary (i.e., nouns), secondary (i.e., verbs, adjectives), and tertiary (i.e., adverbs).", "[@bib:jespersen] suggests that a word from a higher rank generally defines (i.e., modifies) another word from the same or lower ranks in a sentence.", "Thus, a noun can modify only another noun whereas a verb can modify another noun, verb or adjective but not an adverb.", "We consider this principle of grammatical modification of words, and represent such dependencies as directed edges in the text graph (i.e., Step 4, Fig. [@ref:LABEL:fig:sysdiag] ).", "We first annotate each of the sentences from a change request using Stanford POS tagger [@bib:postagger] , and organize the annotated words into various ranks.", "For instance, the example statement\u2014 {\u201celement reported plain flat element hierarchical java search view\u201d} \u2013can be organized into two ranks\u2013 {primary} ( {\u201csearch\u201d, \u201cview\u201d, \u201cjava\u201d, \u201celement\u201d} ), and {secondary} ( {\u201cplain\u201d, \u201cflat\u201d, \u201chierarchical\u201d} , and {\u201creported\u201d} ).", "We derive the following relationships based on their grammatical modifications\u2013 {search} $ \\longleftrightarrow $ {view} , {view} $ \\longleftrightarrow $ {java} , {java} $ \\longleftrightarrow $ {element} , {reported} $ \\longrightarrow $ {search} , {reported} $ \\longrightarrow $ {view} , {reported} $ \\longrightarrow $ {java} , {reported} $ \\longrightarrow $ {element} , {reported} $ \\longrightarrow $ {plain} , {reported} $ \\longrightarrow $ {flat} , {reported} $ \\longrightarrow $ {hierarchical} , and, then encode them into connecting edges in the text graph (i.e., Fig. [@ref:LABEL:fig:tgraph] -(b)).", "\\newline </subsection> <subsection> <title> III-D TextRank (TR) Calculation </title> Once text graph (i.e., using co-occurrence) for a change request is developed, we consider it as a regular connected network, and apply a popular graph-based algorithm\u2013PageRank [@bib:pagerank] \u2013for ranking its nodes (i.e., terms) (Step 5, Fig. [@ref:LABEL:fig:sysdiag] ).", "PageRank was originally proposed by [@bib:pagerank] for web link analysis, and the algorithm exploits topological properties of a graph to estimate the weight (i.e., importance) of each of the vertices.", "TextRank is an adaptation of PageRank for text graph.", "It analyzes the connectivity (i.e., connected neighbours and their weights) of each term $ v_{i} $ in the graph recursively, and then calculates the term\u2019s weight, $ TR(v_{i}) $ , as follows: \\newline <equation> $ TR(v_{i})=(1-\\phi)+\\phi\\sum_{j\\epsilon V(v_{i})}\\frac{TR(v_{j})}{|V(v_{j})|}{% }(0\\leq\\phi\\leq 1) $ </equation> Here, $ V(v_{j}) $ and $ \\phi $ denote node list connected to $ v_{i} $ and {dumping factor} respectively.", "In the text graph (e.g., Fig. [@ref:LABEL:fig:tgraph] -(a)), co-occurrences among terms are represented as bi-directional connecting edges between the nodes.", "In the context of web surfing, dumping factor, $ \\phi $ , is considered as the probability of randomly choosing a web page by the surfer, and $ 1-\\phi $ is the probability of jumping off that page.", "[@bib:rada] use a heuristic value of $ \\phi=0.85 $ for natural language texts in the context of keyword extraction, and we also use the same value for our TextRank calculation.", "We initialize each of the terms in the graph with a default value of 0.25, and run an iterative version of the algorithm [@bib:pagerank] .", "It should be noted that the initial value of a term does not affect its final score [@bib:rada] .", "The computation iterates until the scores of all the terms converge below a certain threshold or it reaches the maximum iteration limit (i.e., 100 as suggested by [@bib:blanco] ).", "As [@bib:rada] suggest, we use a heuristic threshold of 0.0001 for the convergence checking.", "\\newline TextRank applies the underlying mechanism of a recommendation (i.e., voting) system, where a term (e.g., {\u201cCustom\u201d} ) recommends (i.e., votes) another term (e.g., {\u201csearch\u201d} ) if the second term complements the semantics of the first term in any way (e.g., {\u201cCustom search\u201d} ) [@bib:rada] .", "The algorithm captures recommendation for a term by analyzing its connected edges (i.e., both incoming and outgoing) in the text graph (e.g., Fig. [@ref:LABEL:fig:tgraph] -(a)) with other terms both in local (i.e., same sentence) and global (i.e., entire task description) contexts, and thus determines importance of that term.", "Once computation is over, each of the terms in the graph is found with a final score which is considered to be the weight or importance of that term within the user provided texts from the change request.", "\\newline </subsection> <subsection> <title> III-E POSRank (POSR) Calculation </title> While TextRank operates on a text graph based on word co-occurrence (e.g., Fig. [@ref:LABEL:fig:tgraph] -(a)), POSRank determines term-weight by operating on the text graph (e.g., Fig. [@ref:LABEL:fig:tgraph] -(b)) that represents the grammatical dependencies among words as the connecting edges (Step 6, Fig. [@ref:LABEL:fig:sysdiag] ).", "POSRank is another adaptation of PageRank algorithm [@bib:pagerank] for natural language texts.", "Similar to TextRank, it also analyzes connectivity of each term in the graph but considers the links according to their directions.", "Incoming links and outgoing links of the term are treated differently.", "Incoming links represent votes cast for the term by other terms and vice versa.", "Thus, POSRank $ POSR(v_{i}) $ of each term $ v_{i} $ is calculated as follows: \\newline <equation> $ POSR(v_{i})=(1-\\phi)+\\phi\\sum_{j\\epsilon In(v_{i})}\\frac{POSR(v_{j})}{|Out(v_{% j})|}(0\\leq\\phi\\leq 1) $ </equation> Here $ In(v_{i}) $ and $ Out(v_{i}) $ denote the node lists that are connected to node $ v_{i} $ through incoming and outgoing links respectively.", "Since the underlying mechanism of PageRank-based algorithms is recommendation (i.e., votes) from other nodes of the graph, POSRank also determines the weight (i.e., importance) of a term by capturing and analyzing the weights of the incoming links recursively.", "It should be noted that not only frequent votes but also the votes from other high scored nodes from the graph are essential for a node (i.e., term) to be highly scored (i.e., important).", "Given the similar topological properties of the text graph using grammatical modifications (i.e., Fig. [@ref:LABEL:fig:tgraph] -(b)), we apply the same settings\u2013 damping factor ( $ \\phi $ ), iteration count, initial score, and convergence threshold\u2013of TextRank (Section [@ref:LABEL:sec:textrank] ) for POSRank calculation as well.", "\\newline <float> Search Term Identification using IR Methods \\ procedure STRICT ( $ CR $ ) $ \\triangleright $ $ CR $ : change request \\ \\ $ L\\leftarrow $  $ \\triangleright $ list of search terms \\ \\ $ \\triangleright $ collecting task details from the change request \\ \\ $ T\\leftarrow $ collectTitle( $ CR $ ) \\ \\ $ D\\leftarrow $ collectDescription( $ CR $ ) \\ \\ $ TD\\leftarrow $ preprocess(combine( $ T,D $ )) \\ \\ $ \\triangleright $ developing text graphs from the task details \\ \\ $ G_{coc}\\leftarrow $ developTGUsingCo-occurrence( $ TD $ ) \\ \\ $ G_{pos}\\leftarrow $ developTGUsingPOS-dependence( $ TD $ ) \\ \\ $ \\triangleright $ calculating TextRank and POSRank \\ \\ $ TR\\leftarrow $ calculateTR( $ G_{coc} $ ) \\ \\ $ TR_{norm}\\leftarrow $ normalize(sortByValue( $ TR $ )) \\ \\ $ POSR\\leftarrow $ calculatePOSR( $ G_{pos} $ ) \\ \\ $ POSR_{norm}\\leftarrow $ normalize(sortByValue( $ POSR $ )) \\ \\ $ \\triangleright $ calculating additional weights for title terms \\ \\ $ TT\\leftarrow $ assignUniformWeight( $ T $ ) \\ \\ $ \\triangleright $ determining term importance \\ \\ $ CST\\leftarrow $ getUniqueTerms( $ TD $ ) \\ \\ for CandidateSearchTerm $ CST_{i} $ $ \\in $ $ CST $ do \\ \\ $ S_{TR}\\leftarrow TR_{norm}[CST_{i}] $ \\ \\ $ S_{POSR}\\leftarrow POSR_{norm}[CST_{i}] $ \\ \\ $ S_{TT}\\leftarrow TT[CST_{i}] $ \\ \\ $ \\triangleright $ calculating final term-weight \\ \\ $ S[{CST_{i}}]\\leftarrow S_{TR}+S_{POSR}+S_{TT} $ \\ \\ end for \\ \\ $ \\triangleright $ ranking and then returning Top-K search terms \\ \\ $ SST\\leftarrow $ sortByFinalTermWeight( $ S $ ) \\ \\ $ L\\leftarrow $ getTopKSearchTerms( $ SST $ ) \\ \\ return $ L $ \\ \\ end procedure \\ </float> \\newline </subsection> <subsection> <title> III-F Search Term Ranking and Selection </title> Fig.", "[@ref:LABEL:fig:sysdiag] shows the schematic diagram and Algorithms [@ref:LABEL:algo] , [@ref:LABEL:algo2] show the pseudo code of our proposed technique\u2013STRICT\u2013for search term identification from a change request.", "We first collect {Title} and {Description} of the request submitted by the user, combine them to prepare a complete request text, and then perform standard natural language preprocessing (Lines 3\u20136, Algorithm [@ref:LABEL:algo] ).", "Then we develop two text graphs based on co-occurrences and grammatical dependencies among the terms from the preprocessed text (Lines 7\u20139, Algorithm [@ref:LABEL:algo] ).", "The goal is to identify the most important terms that could be used as a search query for concept location.", "We then analyze the topological properties of both graphs, and determine TextRank and POSRank for each of the terms from the request (Lines 10\u201314, Algorithm [@ref:LABEL:algo] , Steps 5, 6, Fig. [@ref:LABEL:fig:sysdiag] ).", "\\newline <float> Candidate Score Normalization Algorithm \\ procedure NORMALIZE ( $ R $ ) \\ \\ $ \\triangleright $ $ R $ : candidates search terms sorted by scores \\ \\ for CandidateSearchTerm $ t $ $ \\in $ $ R.keys $ do \\ \\ $ R[t]\\leftarrow 1-\\frac{position(t)}{size(R)} $ \\ \\ end for \\ \\ return $ R $ \\ \\ end procedure \\ </float> \\newline Since TextRank and POSRank estimate term importance from different perspectives, we normalize both scores for each of the candidate terms using Algorithm [@ref:LABEL:algo2] .", "Normalization step can reduce the potential bias of any specific score component.", "In particular, we sort the candidate terms based on TextRank or POSRank, and derive a score between 0 and 1 for each term by using its position in the sorted list.", "Such normalization technique is common in the relevant literature [@bib:context,surfclipse] , and often called as {degree of interest} [@bib:context] .", "Given that title of the request often contains good quality search terms, we assign the highest degree of interest to the candidate terms found in the {Title} field (Lines 15\u201316).", "Thus, each of the candidate terms gets three normalized scores from three types of ranking\u2013 TextRank, POSRank and title-based heuristic.", "Please note that such scores for the candidates are calculated by recursively analyzing the votes (i.e., connections) from their surrounding terms in the text graphs.", "Now, we iterate through the unique candidate search terms, and add up those three scores for each of the candidate terms (Lines 17\u201325, Algorithm [@ref:LABEL:algo] ).", "Then we rank the candidates based on their final accumulated scores, and select the Top-K ( $ K=10 $ ) candidates as the search terms for the change request (Lines 26\u201330, Algorithm [@ref:LABEL:algo] , Step 7, 8, Fig. [@ref:LABEL:fig:sysdiag] ).", "We also expand the camel case search terms into simpler forms, and keep both forms in the search query [@bib:splitting] .", "\\newline Example: Table [@ref:LABEL:table:example] shows a working example of our technique\u2013STRICT\u2013for the showcase change request in Table [@ref:LABEL:table:ctask] .", "Our technique suggests the following Top-5 terms\u2013 {\u2018element\u2019, \u2018IResource\u2019, \u2018Provider\u2019, \u2018Level\u2019} and {\u2018Tree\u2019} \u2013that returns the first correct result at the Top-1 position.", "We first calculate TextRank and POSRank for each of the candidate terms from the text graphs\u2013Fig. [@ref:LABEL:fig:tgraph] -(a) and Fig. [@ref:LABEL:fig:tgraph] -(b)\u2013respectively by carefully analyzing their topological properties (Sections [@ref:LABEL:sec:textrank] , [@ref:LABEL:sec:posrank] )."]], "target": "Table shows the normalized scores for the top terms. We see that these terms are highly connected in the text graphs, i.e., frequently voted by other important terms across the request text. Our algorithms translate such connectivity into meaningful equivalent scores, and identify the top-scored terms carefully. Please note that none of these terms comes from the title of the request which is often copied and pasted by the developers as the initial query. Besides, the title returns the first correct result at the 559 $ ^{th} $ position. Thus, our suggested terms can significantly reduce the query reformulation efforts spent by the developers, and can provide them with a meaningful starting point for concept location."}, {"tabular": ["    &  $ m=100 $  &  $ m=200 $  &  $ m=400 $ ", " $ N=10000 $  &  7.71 (0.02)  &  24.34 (0.04)  &  50.67 (0.16) ", " $ N=20000 $  &  47.06 (0.01)  &  96.56 (1.25)  &  198.07 (1.27)  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Knowing the distribution of data is a fundamental task of data science.", "Prior distributions such as Laplacian, Gaussian and Gaussian mixture distributions are often utilized to model the data.", "However, their ability of representation is limited.", "With the rise of deep learning, we can use more parameters to model the distribution accurately.", "The basic assumption of such methods is that complex high-dimensional data such as images concentrate near a low-dimensional manifold.", "Generative adversarial network (GAN) [@bib:goodfellow2014generative] and Wasserstein auto-encoder with generative adversarial network (WAE-GAN) (also known as adversarial auto-encoder (AAE)) [@bib:makhzani2015adversarial] [@bib:tolstikhin2017wasserstein] are the representatives and have many variants.", "GAN trains a generator to generate new samples and a discriminator to teach the generator to improve its quality.", "From a probabilistic view, the generator maps points from a simple low-dimensional distribution such as a uniform distribution or a Gaussian distribution to the target high-dimensional distribution (e.g., face or handwriting images), while the discriminator computes the discrepancy between the generated distribution and the target one.", "WAE-GAN trains an invertible mapping between two distributions with the Wasserstein distance as the reconstruction loss, i.e., an encoder from the data space to the latent space and a decoder from the latent space to the data space.", "WAE-GAN employs GAN to minimize the discrepancy between the output of the encoder and the samplable prior distribution in the latent space.", "Both methods utilize adversarial training, i.e., a two player game between generator (encoder) and discriminator.", "\\newline As we know that GAN is hard to train.", "Arjovsky et al. [@bib:arjovsky2017wasserstein] [@bib:arjovsky2017towards] ascribed this to the choice of discrepancy.", "Classifical GAN utilizes KL-divergence and performs good under some tricks [@bib:salimans2016improved] . But in theory, when the supports of two distributions are disjoint, KL-divergence fails and causes unstability of the model.", "A more stable variant Wasserstein-GAN (WGAN) introduced from the optimal transportation view utilizes a discriminator with clipped parameters to compute the Wasserstein distance.", "However, clipping limits the discriminator to find the subtle difference between two distributions.", "Another strategy imposes the one-Lipschitz constraint by regularization methods.", "Since the Wasserstein distance is a real distance, the optimization appears more stable and converges faster than GAN.", "Apart from the optimal transportation, several other studies have also been proposed to explain and improve this [@bib:salimans2016improved] [@bib:goodfellow2016nips] [@bib:miyato2018spectral] [@bib:isola2017image] .", "\\newline The complexity of high-dimensional data and the instability of adversarial models lead to mode collapse, which is the main obstacle for GANs in many applications.", "The mode collapse in GANs refers to the problem of overfitting to a part of the training modes and forget the rest.", "Lucic et al. [@bib:lucic2018gans] showed that even the best GAN dropped $ 72\\% $ of the modes.", "In theory, Arora et al. [@bib:arora2017generalization] proved that the trained distribution will not converge to the target one with several standard metrics.", "This can be blamed on the adversarial mechanism.", "In game theory, based on gradient descent optimization algorithm, the discriminator and generator find a local Nash equilibrium rather than a global one.", "From a statistical view, the discriminator has cumulative preference of mode when it classifies real and fake data in the training process, since the discriminator is trained based on the former step.", "So the discriminator is sensitive to some modes and insensitive to others.", "More formally, the estimation of discrepancy is biased, which makes the generated distribution not converge to the target one.", "\\newline To solve this problem, a potential approach is to find alternatives of the adversarial mechanism by computing the discrepancy without neural network for discrimination.", "For example, a kernel-based method maximum mean discrepancy (MMD) shows a good property on approximating the independent and identically distributed (i.i.d.) Gaussian distribution and finds its usage on WAE-MMD [@bib:tolstikhin2017wasserstein] and MMD-GAN [@bib:li2017mmd] .", "However, MMD only matches principle features of two distributions and lose other ones which cannot be captured by the kernel.", "As to the discrepancy of arbitrary distributions, researchers have introduced a new metric called the sliced-Wasserstein (SW) distance [@bib:bonnotte2013unidimensional] , which has similar qualitative properties with the Wasserstein distance. But it is much easier to compute.", "Inspired by the one-dimensional case of the Wasserstein distance, the data is projected onto an one-dimensional subspace for analytical solution, then the SW distance is obtained by integrating over all the subspaces.", "Thus, the number of samples needed to estimate the integration increases as the dimension of data goes up.", "\\newline Compared to adversarial training, non-adversarial approaches have no cumulative preference since they do not utilize historical information and are easy to train due to the unemployment of the discriminator.", "However, since the distribution of high-dimensional data concentrates near a low-dimensional manifold, where the Euclidean distance is no longer effective, non-adversarial approaches are not over-parameterized to learn the distance on the manifold.", "So they may be cursed by high dimensionality.", "This means, when the dimension is high and the shape of the manifold is complicated, the error of the estimation to the discrepancy may be beyond tolerance.", "As a consequence, the performance of non-adversarial algorithms such as VAE, WAE-MMD, SWAE are not as good as that of WAE-GAN or variants of GAN under similar architectures of neural network.", "\\newline In this paper, we develop a novel non-adversarial framework\u2013Tessellated Wasserstein Auto-encoders (TWAE) to tessellate the support of the target distribution in the latent space into a given number of regions and design batches of data according to the tessellation instead of random shuffling.", "In more detail, the cost function of classical generative auto-encoders consists of the reconstruction error in the data space and the discrepancy error in the latent space.", "To compute the latter, TWAE separates the computation of the global discrepancy into some local ones.", "To do this, we need to obtain a tessellation of the support of both the generated and target distributions (Fig. [@ref:LABEL:fig:1] ).", "We implement this task in two steps: first we tessellate the support of the prior distribution; second we cluster the encoded data corresponding to the tessellation in the first step.", "For the first step, we provide two ways to achieve the tessellation: centroidal Voronoi tessellation (CVT) and sphere packing.", "CVT can generate points which are the centroids of the corresponding Voronoi regions.", "Asymptotically speaking, all regions of the optimal CVT are congruent to a basic region.", "CVT can be applied to a connected set in $ R^{n} $ with arbitrary shapes.", "The sphere packing approach can tessellate the space into exactly congruent regions with $ E_{8} $ -lattice in $ R^{8} $ and Leech lattice in $ R^{24} $ .", "For the second step, we adopt an assignment algorithm to keep the correspondence of the real data and the generated one.", "Thereby the discrepancy on the whole support is separated into a sum of local discrepancies on each region.", "Compared with traditional ways of sampling on the whole support, TWAE can sample more points in each region.", "Thus, we can force the generated distribution to approximate the target one better.", "Since the tessellation is independent of the choice of discrepancy metrics, TWAE is compatible to different metrics and enhance their performance.", "\\newline The rest of this paper is organized as follows.", "In section 2, we start from the optimal transportation and briefly review the optimal transportation-based generative methods such as WGAN [@bib:arjovsky2017wasserstein] , SWGAN [@bib:deshpande2018generative] and WAE [@bib:tolstikhin2017wasserstein] .", "To the end, we introduce CVT and sphere packing as basic tools to achieve the tessellation.", "In section 3, we describe TWAE in details.", "In section 4, we derive the sample and measurement error of TWAE theoretically.", "In section 5, we conduct extensive experiments to demonstrate the effectiveness of TWAE.", "In section 6, we provide discussion and conclusion.", "\\newline  </section>"], ["<section> <title> 2 Related Work </title>  <subsection> <title> 2.1 Optimal transportation </title> The optimal transportation problem stems from a problem on transporting commodities.", "Suppose there are $ m $ sources $ x_{1},\\cdots,x_{m} $ for a commodity, with $ a_{i} $ units of supply at $ x_{i} $ and $ n $ sinks $ y_{1},\\cdots,y_{n} $ for it, with $ b_{i} $ units of demand at $ y_{i} $ , $ c_{ij} $ $ (i=1,\\cdots,m;j=1,\\cdots,n) $ is the cost of transporting one unit of this commodity from $ x_{i} $ to $ y_{j} $ .", "We wish to find a transportation plan $ \\{f_{ij}|i=1,\\cdots,m;j=1,\\cdots,n\\} $ to minimize the total cost.", "The problem can be formulated as \\newline <equationgroup> <equation> $ \\min\\sum\\limits_{i,j}c_{ij}f_{ij} $ $ \\min $ $ \\sum\\limits_{i,j}c_{ij}f_{ij} $ </equation> <equation> $ \\mbox{s.t.}\\sum\\limits_{j=1}^{n}f_{ij}=a_{i},\\quad i=1,\\cdots,m $ $ \\sum\\limits_{j=1}^{n}f_{ij}=a_{i},\\quad i=1,\\cdots,m $ </equation> <equation> $ \\sum\\limits_{i=1}^{m}f_{ij}=b_{j},\\quad i=1,\\cdots,n $ $ \\sum\\limits_{i=1}^{m}f_{ij}=b_{j},\\quad i=1,\\cdots,n $ </equation> <equation> $ \\qquad f_{ij}\\geq 0 $ $ \\qquad f_{ij}\\geq 0 $ </equation> </equationgroup> which can be solved by linear programming.", "\\newline With the development of measure theory, the transportation problem can be stated as follows [@bib:bonnotte2013knothe] \\newline <equation> $ W_{c}(P_{x},P_{y})=\\inf_{\\mathcal{T}}\\mathbb{E}_{x\\sim P_{x}}[c(x,\\mathcal{T}(% x))] $ </equation> where $ \\mathcal{T}:X\\to Y $ is a measure preserving transformation.", "There can be no admissible $ \\mathcal{T} $ , for instance if $ P_{x} $ is a Dirac delta and $ P_{y} $ is not.", "To overcome this difficulty, Kantorovich [@bib:kantorovich2006problem] proposed the following way to relax this problem \\newline <equation> $ W_{c}\\left(P_{x},P_{y}\\right)=\\inf_{\\Gamma\\in{\\Pi}\\left(P_{x},P_{y}\\right)}% \\mathbb{E}_{(x,y)\\sim\\Gamma}[c(x,y)] $ </equation> where $ \\Pi(P_{x},P_{y}) $ denotes the set of all joint distributions $ \\Gamma(x,y) $ whose marginals are respectively $ P_{x} $ and $ P_{y} $ .", "$ c:X\\times Y\\to[0,\\infty] $ is the cost function of transporting.", "Intuitively, $ \\Gamma(x,y) $ indicates how much \u201cmass\u201d must be transported from $ x $ to $ y $ in order to transform the distribution $ P_{x} $ into the distribution $ P_{y} $ .", "The infimum of the transportation cost is called the Wasserstein distance of two distributions $ P_{x} $ and $ P_{y} $ .", "The Wasserstein distance is a true distance and has a finer topology to guarantee convergence when minimize the distance. But the Wasserstein distance is hard to compute because the feasible region of $ \\Pi(P_{x},P_{y}) $ is too large to search.", "If the two distributions are assumed to be Gaussian, i.e., $ x\\sim\\mathcal{N}(m_{1},\\Sigma_{1}) $ , $ y\\sim\\mathcal{N}(m_{2},\\Sigma_{2}) $ with the means $ m_{1} $ , $ m_{2}\\in\\mathbb{R}^{p} $ and the covariance $ \\Sigma_{1} $ , $ \\Sigma_{2}\\in\\mathbb{R}^{p\\times p} $ , their squared Wasserstein distance has a closed form [@bib:olkin1982distance] \\newline <equationgroup> <equation> $  GW^{2}=W_{2}^{2}\\left(P_{x},P_{y}\\right)=\\left\\|m_{1}-m_{2}% \\right\\|_{2}^{2} $ $  GW^{2}=W_{2}^{2}\\left(P_{x},P_{y}\\right) $ $ =\\left\\|m_{1}-m_{2}\\right\\|_{2}^{2} $ </equation> <equation> $ +\\operatorname{tr}\\left(\\Sigma_{1}+\\Sigma_{2}-2\\left(\\Sigma_{2}^{% 1/2}\\Sigma_{1}\\Sigma_{2}^{1/2}\\right)^{1/2}\\right) $ $ +\\operatorname{tr}\\left(\\Sigma_{1}+\\Sigma_{2}-2\\left(\\Sigma_{2}^{% 1/2}\\Sigma_{1}\\Sigma_{2}^{1/2}\\right)^{1/2}\\right) $ </equation> </equationgroup> This is denoted as the GW distance.", "\\newline </subsection> <subsection> <title> 2.2 Optimal transportation-based generative models </title> Arjovsky et al. [@bib:arjovsky2017wasserstein] first approached the problem of generative modeling from the optimal transportation view.", "The infimum in ( [@ref:LABEL:eq:wasserstein] ) is highly intractable.", "On the other hand, the Kantorovich-Rubinstein duality [@bib:villani2008optimal] tells us that \\newline <equation> $ W_{1}(P_{x},P_{y})=\\sup_{\\|f\\|_{L}\\leq 1}\\left(\\mathbb{E}_{x\\sim P_{x}}[f(x)]-% \\mathbb{E}_{y\\sim P_{y}}[f(y)]\\right) $ </equation> where the supremum is over all the one-Lipschitz functions $ \\{f:\\mathcal{X}\\to\\mathbb{R}\\} $ .", "The function $ f $ is approximated by a parameterized family of functions $ \\{f_{w}\\}_{w\\in\\mathcal{W}} $ .", "Arjovsky et al. [@bib:arjovsky2017wasserstein] suggested to impose the one-Lipschitz constraint to force parameters $ w $ lie in a compact space by clipping the weights to a fixed box.", "Gulrajani et al. [@bib:gulrajani2017improved] introduced a soft version of the constraint with a penalty on the gradient norm for random samples by optimizing \\newline <equation> $ L=\\mathbb{E}_{x\\sim P_{x}}[f(x)]-\\mathbb{E}_{y\\sim P_{y}}[f(y)]+\\lambda\\mathbb% {E}_{\\widehat{x}\\sim P_{\\widehat{x}}}[(\\|\\nabla_{\\widehat{x}}f(\\widehat{x})\\|_% {2}-1)^{2}] $ </equation> \\newline To improve the stability of WGAN, Deshpande et al. [@bib:deshpande2018generative] developed a mechanism based on random projections as an alternative to the black-box discriminator.", "Notice that the squared Wasserstein distance of two one-dimensional distributions $ P_{x} $ and $ P_{y} $ can be estimated accurately by sorting their samples according to their values.", "Suppose $ x_{i} $ , $ y_{i} $ $ (i=1,\\cdots,N) $ are independently sampled from $ P_{x} $ and $ P_{y} $ , and $ x_{i}\\leq x_{i+1} $ , $ y_{i}\\leq y_{i+1} $ for all $ i\\in\\{1,\\cdots,N-1\\} $ , then \\newline <equation> $ W_{2}^{2}(P_{x},P_{y})\\approx\\frac{1}{N}\\sum_{i=1}^{N}(x_{i}-y_{i})^{2} $ </equation> Generally, if $ P_{x} $ and $ P_{y} $ are $ d $ -dimensional distributions, we project the sampled $ d $ -dimensional points onto one-dimensional spaces spanned by directions $ w $ and integrate over all possible directions $ w $ on the unit sphere $ S^{d-1} $ .", "Then we obtain the SW distance \\newline <equation> $ SW_{2}^{2}(P_{x},P_{y})=\\int_{w\\in S^{d-1}}W_{2}^{2}(P_{x|w},P_{y|w})dw $ </equation> Hereby $ P_{x|w} $ and $ P_{y|w} $ denote the projected distribution on the subspace spanned by $ w $ .", "The SW distance is a real distance and is equivalent to the Wasserstein distance as the following property holds [@bib:bonnotte2013unidimensional] \\newline <equation> $ SW_{2}^{2}(P_{x},P_{y})\\leq C_{d}W_{2}^{2}(P_{x},P_{y})\\leq C_{d}R^{\\frac{1}{(% d+1)}}SW_{2}^{\\frac{1}{(d+1)}}(P_{x},P_{y}) $ </equation> where $ C_{d}>0 $ is a constant correlated with the dimension $ d $ , and $ P_{x} $ , $ P_{y}\\in\\mathcal{P}(B(0,R)) $ , where $ B(0,R) $ is the ball with radius $ R $ and the origin as the center point, $ \\mathcal{P}(\\cdot) $ is the space of probability measure.", "The SW distance can be regarded as a good alternative to the Wasserstein distance because it can be easily acquired by random projections.", "However, since the area of a sphere with a radius of $ r $ in $ \\mathbb{R}^{d} $ is proportional to $ r^{d-1} $ , the number of projections goes up exponentially with the dimension of data.", "Hence, the huge computation caused by the curse of dimensionality becomes a main obstacle to put it into practice.", "The SW-based methods sacrifice accuracy to the discrepancy for the privilege of stability without the discriminator.", "\\newline Another main stream of generative models is based on auto-encoders.", "Different from GAN, generative auto-encoders approximate a prior distribution in the latent space.", "Their generalized formulation is as follows \\newline <equation> $ \\min_{\\phi,\\psi}\\mathbb{E}_{x\\sim P_{x}}[c(x,\\psi(\\phi(x)))]+\\lambda D(P_{z}||% Q_{z}) $ </equation> where $ \\phi $ is the encoder, $ \\psi $ is the decoder, $ P_{x} $ is the data distribution, $ P_{z} $ is a prior samplable distribution, $ Q_{z} $ is the empirical distribution of the encoded data $ z=\\phi(x) $ , and $ \\lambda $ indicates the relative importance of the discrepancy.", "In WAE [@bib:tolstikhin2017wasserstein] , GAN and MMD have been proposed (denoted as WAE-GAN and WAE-MMD respectively).", "In SWAE [@bib:kolouri2018sliced]", ", the choice of $ D $ in ( [@ref:LABEL:eq:autoencoder] )", "is the SW distance.", "\\newline </subsection> <subsection> <title> 2.3 Centroidal Voronoi Tessellation </title> Given an open set $ \\Omega\\subseteq\\mathbb{R}^{d} $ , the set $ \\{V_{i}\\}_{i=1}^{k} $ is called a tessellation of $ \\Omega $ if $ V_{i}\\cap V_{j}=\\varnothing $ for $ i\\neq j $ and $ \\cup_{i=1}^{k}\\overline{V}_{i}=\\overline{\\Omega} $ ( $ \\overline{\\Omega} $ means the closed hull of set $ \\Omega $ ).", "Given a set of points $ \\{\\widehat{z}_{i}\\}_{i=1}^{k} $ belonging to $ \\overline{\\Omega} $ , the set $ \\{\\widehat{V}_{i}\\}_{i=1}^{k} $ is called a Voronoi tessellation if the Voronoi region $ \\widehat{V}_{i} $ corresponding to the point $ \\widehat{z}_{i} $ is defined by \\newline <equation> $ \\widehat{V}_{i}=\\{x\\in\\Omega|\\|x-\\widehat{z}_{i}\\|<\\|x-\\widehat{z}_{j}\\|\\ % \\text{for }j=1,\\cdots,k,j\\neq i\\} $ </equation> The points $ \\{\\widehat{z}_{i}\\}_{i=1}^{k} $ are called generators.", "In the rest of this paper, without special mention, a generator denotes the generator of tessellation rather than that of GAN.", "Given a region $ V\\subseteq\\mathbb{R}^{d} $ and a density function $ \\rho $ , the mass centroid $ z^{*} $ of $ V $ is defined by \\newline <equation> $ z^{*}=\\frac{\\int_{V}y\\rho(y)dy}{\\int_{V}\\rho(y)dy} $ </equation> If $ \\widehat{z}_{i}=z_{i}^{*} $ , $ i=1,\\cdots,k $ , i.e., the mass centroid of the region is exactly the generator, we call such a tessellation a CVT [@bib:du1999centroidal] .", "\\newline Next, we introduce the classical Lloyd\u2019s method to construct an approximate CVT in the following steps: Step 0 : Select an initial set of $ k $ points $ \\{z_{i}\\}_{i=1}^{k} $ using a sampling strategy (e.g., Monte Carlo sampling); Step 1 : Construct the Voronoi tessellation $ \\{V_{i}\\}_{i=1}^{k} $ of $ \\Omega $ associated with the points $ \\{z_{i}\\}_{i=1}^{k} $ ; Step 2 : Compute the mass centroids of the Voronoi regions $ \\{V_{i}\\}_{i=1}^{k} $ found in Step 1 ; these centroids are the new set of points $ \\{z_{i}\\}_{i=1}^{k} $ ; Step 3 : If this new set of points meets some convergence criteria, then terminate; otherwise, return to Step 1 .", "The Lloyd\u2019s method can be viewed as an alternative iteration between the Voronoi tessellation construction and centroid computation.", "Clearly, a CVT is a fixed point of the iteration.", "\\newline </subsection> <subsection> <title> 2.4 Sphere Packing </title> The CVT technique is an approximate method.", "In mathematics, there is an exact method based on sphere packing to tessellate the space.", "The standard packing problem is how to arrange spheres of equal radius to fill space as densely as possible in $ R^{n} $ .", "It is very hard to construct a packing scheme for an arbitrary $ n $ .", "Luckily, for the special cases, it has been proved that $ E_{8} $ -lattice ( $ n=8 $ ) and Leech lattice ( $ n=24 $ ) give the densest lattice packing [@bib:griess1001e8] .", "For $ E_{8} $ -lattice, each lattice point has 240 nearest neighbors, and for Leech lattice the number is 196560 which is too large for our tessellation considering the sizes of common data.", "In more detail, for $ E_{8} $ -lattice, the nearest neighbors of the origin have the shape $ (\\pm 1^{2},0^{6}) $ ( $ 2^{2}C^{2}_{8}=112 $ of these) and $ (\\pm\\frac{1}{2}^{8}) $ with even number of negative signs ( $ 2^{7}=128 $ of these).", "The set of neighbors $ \\Delta $ is actually the root lattice of $ E_{8} $ -lattice since $ E_{8}=\\mathbb{Z}\\Delta $ .", "\\newline Though $ E_{8} $ gives the densest packing in $ \\mathbb{R}^{8} $ , it may not be optimal restricted to a region with a fixed shape.", "Nevertheless, for a ball $ B $ in $ \\mathbb{R}^{8} $ , a possible tessellation scheme utilizing $ E_{8} $ -lattice is that one point locates at the center of $ B $ , surrounded by 240 points in the way of $ E_{8} $ within $ B $ .", "By adjusting the radius of packed spheres, we obtain a tessellation for $ B $ , which is symmetrical and has regions with exactly the same volume.", "Then if we tessellate the space with the tangent plane of each two spheres, we separate the space into regions with exactly the same volume rather than roughly equal one in a CVT.", "\\newline </subsection>  </section>"], ["<section> <title> 3 TWAE </title>  <subsection> <title> 3.1 Model Construction </title> We follow the generalized formulation of generative auto-encoder with a reconstruction error in the data space and a discrepancy error in the latent space, \\newline <equation> $ \\min_{\\phi,\\psi}\\mathbb{E}_{x\\sim P_{x}}[c(x,\\psi(\\phi(x)))]+\\lambda D(P_{z}||% Q_{z}) $ </equation> In this paper, we propose $ P_{z} $ to be a uniform distribution in a unit ball, then the probability of a region is proportional to its volume.", "We adopt the Wasserstein distance as the divergence $ D $ for its good property though our tessellation framework is also flexible to other discrepancy metrics.", "\\newline Let\u2019s go back to the discrete Wasserstein distance ( [@ref:LABEL:eq:monge] ).", "Suppose there are $ N $ points of $ \\tilde{z}_{i} $ sampled from the prior distribution $ P_{z} $ and the same number of $ z_{i} $ encoded by the encoder $ \\phi $ .", "$ P_{N} $ and $ Q_{N} $ are the empirical distribution of $ \\{\\tilde{z}_{i}\\}_{i=1}^{N} $ and $ \\{z_{i}\\}_{i=1}^{N} $ , respectively.", "We can compute the Wasserstein distance by assigning each $ z_{i} $ to a $ \\tilde{z}_{\\sigma_{i}} $ as follows \\newline <equation> $ W(P_{N},Q_{N})=\\frac{1}{N}\\min_{\\sigma}\\sum_{i=1}^{N}\\|z_{i}-\\tilde{z}_{\\sigma% _{i}}\\| $ </equation> where $ \\sigma $ is a permutation of an index set $ \\{1,\\cdots,N\\} $ .", "It can be formulated as an assignment problem and solved by mature linear programming algorithms with a computational complexity of $ O(N^{2.5}\\mbox{log}(N)) $ .", "This complexity is prohibitive for usage in the inner loop of a learning algorithm.", "As mentioned before, instead of linear programming, inaccurate approaches such as clipped networks [@bib:arjovsky2017wasserstein] and random projection [@bib:deshpande2018generative] have been proposed to address it.", "For large $ N $ , the traditional way is to divide the dataset into batches and to optimize the objective function batch by batch in a gradient descent manner, which is the well-known stochastic gradient descent.", "However, batches with small size lose some information to model the distribution delicately.", "To address this issue, we combine the assignment method and the batch optimization to a two-step algorithm.", "That is we first design the batches according to their similarity and then minimize the discrepancy based on the optimization per batch.", "\\newline For the first step, we find $ m $ points $ \\{\\widehat{z}_{j}\\}_{j=1}^{m} $ on the support of $ P_{z} $ .", "$ \\{\\widehat{z}_{j}\\}_{j=1}^{m} $ can be treated as generators of a tessellation $ \\{V_{j}\\}_{j=1}^{m} $ on the support $ \\Omega $ that $ V_{i}\\cap V_{j}=\\varnothing $ for $ i\\neq j $ and $ \\cup_{i=1}^{k}\\overline{V}_{i}=\\overline{\\Omega} $ .", "We assume that the volume of each $ V_{j} $ is equal so that we can sample a batch with the same number $ n $ of points in each $ V_{j} $ to model the distribution of $ P_{z} $ restricted on $ V_{j} $ .", "Assigning each encoded data point $ z_{i} $ to one of the generators $ \\{\\widehat{z}_{j}\\}_{j=1}^{m} $ is an easier task than ( [@ref:LABEL:eq:discrete_W] ) because $ m $ is much smaller than $ N $ .", "Each of $ \\{\\widehat{z}_{j}\\}_{j=1}^{m} $ is assigned by $ n=\\frac{N}{m} $ points.", "The problem can be formulated as \\newline <equationgroup> <equation> $ \\min\\sum\\limits_{i,j}\\|z_{i}-\\widehat{z}_{j}\\|_{2}^{2}f_{ij} $ $ \\min $ $ \\sum\\limits_{i,j}\\|z_{i}-\\widehat{z}_{j}\\|_{2}^{2}f_{ij} $ </equation> <equation> $ \\mbox{s.t.}\\sum\\limits_{j=1}^{m}f_{ij}=1,\\ i=1,\\cdots,N $ $ \\sum\\limits_{j=1}^{m}f_{ij}=1,\\ i=1,\\cdots,N $ </equation> <equation> $ \\sum\\limits_{i=1}^{N}f_{ij}=n,\\ j=1,\\cdots,m $ $ \\sum\\limits_{i=1}^{N}f_{ij}=n,\\ j=1,\\cdots,m $ </equation> <equation> $ \\quad f_{ij}\\in\\{0,1\\} $ $ \\quad f_{ij}\\in\\{0,1\\} $ </equation> </equationgroup> It is a special case of the Hitchcock problem as both the demands and supplies are equal.", "By doing this, the dataset $ \\{z_{i}\\}_{i=1}^{N} $ is clustered into $ m $ sets $ \\{S_{j}\\}_{j=1}^{m} $ according to their distance to the generators $ \\{\\widehat{z}_{j}\\}_{j=1}^{m} $ .", "Then for each cluster $ S_{j} $ corresponding to the generator $ \\widehat{z}_{j} $ , we can estimate the Wasserstein distance of $ Q_{z} $ and $ P_{z} $ restricted on the region $ V_{j} $ .", "\\newline The overall discrepancy is obtained by computing the local ones upon all the sets $ \\{S_{j}\\}_{j=1}^{m} $ .", "Thus, we have \\newline <equationgroup> <equation> $ \\mathbb{E}\\left[W_{2}^{2}(P_{N},Q_{N})\\right]=\\frac{1}{N}\\mathbb{% E}\\left[\\min_{\\sigma}\\sum_{i=1}^{N}\\|z_{i}-\\tilde{z}_{\\sigma_{i}}\\|_{2}^{2}\\right] $ $ \\mathbb{E}\\left[W_{2}^{2}(P_{N},Q_{N})\\right] $ $ =\\frac{1}{N}\\mathbb{E}\\left[\\min_{\\sigma}\\sum_{i=1}^{N}\\|z_{i}-% \\tilde{z}_{\\sigma_{i}}\\|_{2}^{2}\\right] $ </equation> <equation> $ =\\frac{1}{N}\\mathbb{E}\\left[\\min_{\\sigma}\\sum_{j=1}^{m}\\sum_{z_{i% }\\in S_{j}}\\|z_{i}-\\tilde{z}_{\\sigma_{i}}\\|_{2}^{2}\\right] $ $ =\\frac{1}{N}\\mathbb{E}\\left[\\min_{\\sigma}\\sum_{j=1}^{m}\\sum_{z_{i% }\\in S_{j}}\\|z_{i}-\\tilde{z}_{\\sigma_{i}}\\|_{2}^{2}\\right] $ </equation> <equation> $ \\leq\\frac{1}{N}\\mathbb{E}\\left[\\sum_{j=1}^{m}\\min_{\\sigma^{j}}% \\sum_{\\scriptsize\\begin{array}[]{l}z_{i}\\in S_{j}\\\\ \\tilde{z}_{\\sigma_{i}^{j}}\\in V_{j}\\end{array}}\\|z_{i}-\\tilde{z}_{\\sigma_{i}^{% j}}\\|_{2}^{2}\\right] $ $ \\leq\\frac{1}{N}\\mathbb{E}\\left[\\sum_{j=1}^{m}\\min_{\\sigma^{j}}% \\sum_{\\scriptsize\\begin{array}[]{l}z_{i}\\in S_{j}\\\\ \\tilde{z}_{\\sigma_{i}^{j}}\\in V_{j}\\end{array}}\\|z_{i}-\\tilde{z}_{\\sigma_{i}^{% j}}\\|_{2}^{2}\\right] $ </equation> <equation> $ =\\frac{1}{m}\\mathbb{E}\\left[\\sum_{j=1}^{m}W(P_{n|V_{j}},Q_{n|S_{j% }})\\right] $ $ =\\frac{1}{m}\\mathbb{E}\\left[\\sum_{j=1}^{m}W(P_{n|V_{j}},Q_{n|S_{j% }})\\right] $ </equation> </equationgroup> where $ P_{n|V_{j}} $ denotes the empirical distribution of $ n $ samples of $ P_{z} $ restricted on $ V_{j} $ , $ Q_{n|S_{j}} $ denotes the empirical distribution of $ S_{j} $ , $ \\sigma^{j} $ denotes a permutation of an index set $ \\{1,\\cdots,n\\} $ corresponding to the region $ V_{j} $ .", "The inequation in ( [@ref:LABEL:eq:ineq] ) is because the solution of linear programming problem ( [@ref:LABEL:eq:hitchcock] ) may not agree with the true optimal transportation plan in ( [@ref:LABEL:eq:oplan] ).", "However, when $ P_{z}=Q_{z} $ , since $ S_{j} $ is a set of points which are the closest to $ \\widehat{z}_{j} $ , then for a fixed $ z_{i}\\in V_{j} $ , its optimal match $ \\tilde{z}_{\\sigma_{i}} $ in ( [@ref:LABEL:eq:oplan] ) belongs to $ S_{j} $ with high probability.", "If we fix $ m $ and let $ N $ approach infinity, the equation holds in ( [@ref:LABEL:eq:ineq] ).", "We assume that in the training procedure, $ N\\gg m $ and after a few iterations, $ Q_{z} $ and $ P_{z} $ are approximately equal so that we can optimize the subproblems on the right side of ( [@ref:LABEL:eq:tessellate] ) instead.", "\\newline We expect the sum of errors of estimates to the local discrepancies is smaller than the error on the whole support with the same estimator.", "We assume the total error can be divided into measurement error $ e_{m} $ and sample error $ e_{s} $ .", "First, the measurement error denotes the error of the estimated Wasserstein distance.", "In general, the measurement error is a high-level minim of the true discrete Wasserstein distance.", "As the sum of estimations on the regions is almost equal to that on the whole support, the sum of measurement errors ( $ e_{m} $ ) on regions should be smaller.", "Second, traditionally, we sample a batch of points from the whole distribution, so fewer points locate in a region of the support.", "Now we sample a batch in a local region to find the more subtle discrepancy and approximate the prior distribution better.", "Thus, the sample error in local regions ( $ e_{s} $ ) is smaller.", "Our main results are that $ e_{m} $ and $ e_{s} $ decrease with rates of $ \\mathcal{O}(\\frac{1}{\\sqrt{m}}) $ and $ \\mathcal{O}(\\frac{1}{\\sqrt{n}}) $ , respectively.", "We leave it to Section 4 for detailed theoretical exploration.", "\\newline The whole scheme of the algorithm is summarized in Algorithm 1 .", "Here we adopt the CVT technique to generate a proper tessellation.", "The volumes of regions are approximately equal.", "The Hitchcock problem needs to be solved in each iteration, and it still costs too much to find the optimal solution.", "We adopt the least cost method (LCM) instead, which is a heuristic algorithm.", "We find the smallest admissible item $ d_{ij}^{*} $ of the distance matrix between $ \\{z_{i}\\}_{i=1}^{N} $ and $ \\{\\widehat{z}_{j}\\}_{j=1}^{m} $ , and assign $ z_{i} $ to $ \\widehat{z}_{i} $ if $ \\widehat{z}_{i} $ is not saturated.", "The scheme of LCM is summarized in Algorithm 2 .", "As to the discrepancy, we propose two non-adversarial methods based on the GW distance ( [@ref:LABEL:eq:Wofgaussian] ) and the SW distance ( [@ref:LABEL:eq:slicedwasserstein] ).", "Both discrepancy metrics can be computed efficiently.", "\\newline </subsection> <subsection> <title> 3.2 Optimization with Non-identical Batches </title> Mini-batch gradient descent is the most common implementation of the gradient descent in the deep learning field.", "It splits the training data into small batches, which are used to calculate model error and update model coefficients.", "An underlying assumption of mini-batch gradient descent is that data in each batch are sampled from an identical distribution.", "Though the variance of empirical distribution increases with batch size becoming small, some techniques such as batch normalization and dropout enhance the robustness of the model.", "However, in our case, batches are designed with data from disjoint supports.", "The variance of designed batches is too large that it is beyond the tolerance of such techniques.", "So we adopt a new optimization method to make the algorithm converge to better solutions.", "Our main idea is to sample a batch randomly from the whole support to balance the variance induced by the designed batches.", "\\newline The loss function $ f $ can be separated by batches \\newline <equation> $ f(\\theta)=\\sum_{i=1}^{m}f_{i}(\\theta) $ </equation> where $ m $ is the number of batches, $ \\theta $ is the parameter of this model.", "The first-order Taylor expansion of $ f_{i}(\\theta) $ is \\newline <equation> $ f_{i}(\\theta)=f_{i}^{(1)}(\\theta)+R_{i}(\\theta) $ </equation> where $ f^{(1)}_{i}(\\theta)=f_{i}(\\bar{\\theta})+\\triangledown f_{i}(\\bar{\\theta})(% \\theta-\\bar{\\theta}) $ , $ R_{i}(\\theta)=f_{i}(\\theta)-f_{i}^{(1)}(\\theta) $ .", "To assure the convergence while retaining the differences among batches, we let $ f_{i}^{(1)}(\\theta) $ stay the same and change $ R_{i}(\\theta) $ to $ R(\\theta) $ , i.e., $ f(\\theta)-f^{(1)}(\\theta) $ .", "A hyper parameter $ \\alpha $ is added to keep the balance.", "Then when we optimize with the $ i $ th batch of data, we are actually optimizing \\newline <equation> $ \\min_{\\theta}f_{i}^{(1)}(\\theta)+\\alpha R(\\theta) $ </equation> where $ R(\\theta) $ can be viewed as a regularizer.", "Since the popular optimization algorithms for deep learning are first-order gradient descent methods, we only need to concern about the gradient.", "For the $ k $ th iteration, the gradient we obtained from the objective function in ( [@ref:LABEL:eq:optimized_formula] ) is \\newline <equation> $ g=\\triangledown f_{i}(\\theta_{k})+\\alpha(\\triangledown f(\\theta_{k})-% \\triangledown f(\\theta_{k-1})) $ </equation> It is unrealistic to compute $ \\triangledown f(\\theta) $ as the number of data is huge.", "Actually, the only thing that matters is the variation $ \\triangledown f(\\theta_{k})-\\triangledown f(\\theta_{k-1}) $ , so we estimate $ f(\\theta_{k}) $ and $ f(\\theta_{k-1}) $ with the same sampled data and compute the variation.", "This optimization strategy is inspired by CEASE [@bib:fan2019communication] and CSL [@bib:jordan2019communication] algorithms in distributed computing, where $ f_{i}(\\theta) $ is changed into $ f(\\theta) $ in each node machine under the assumption that data in different node machines are identically distributed.", "On the contrary, we assume the supports of distributions in different batches are disjoint, so we keep the first-order Taylor expansion unchanged to retain the differences.", "The algorithm of TWAE with regularization is summarized in Algorithm [@ref:LABEL:algo:twae-r] .", "\\newline </subsection>  </section>"], ["<section> <title> 4 Theoretical Analysis </title>  From a statistical view, the estimation of discrepancy by the discriminator in GAN is biased and of high variance.", "Since the discriminator has cumulative preferences of features when classify real and fake data, the estimates of discrepancy are somehow biased.", "Moreover, as of two-player setting, noise impedes drastically more the training compared to single objective one [@bib:chavdarova2019reducing] .", "Thus, the variance is high.", "On the contrary, non-adversarial methods treat each data equally and have low variance on estimating the discrepancy.", "However, since non-adversarial methods are not accurate enough and not over-parameterized to memorize data, they suffer from errors, which are analysable.", "Suppose $ P_{N} $ and $ Q_{N} $ are empirical distributions of the sampled data $ \\{\\tilde{z}_{i}\\}_{i=1}^{N} $ and encoded data $ \\{z_{i}\\}_{i=1}^{N} $ , while $ P_{n} $ and $ Q_{n} $ denote the empirical distributions of batches with $ n $ points sampled from $ \\{\\tilde{z}_{i}\\}_{i=1}^{N} $ and $ \\{z_{i}\\}_{i=1}^{N} $ , respectively.", "We use $ \\widehat{W}(\\cdot,\\cdot) $ to denote the estimator of the true Wasserstein distance $ W(\\cdot,\\cdot) $ , then the error of estimation can be divided into sample error $ e_{s} $ and measurement error $ e_{m} $ based on \\newline <equationgroup> <equation> $ \\left|\\widehat{W}(P_{n},Q_{n})-W(P_{N},Q_{N})\\right|\\leq\\Big{|}W(% P_{n},Q_{n})-W(P_{N},Q_{N})\\Big{|} $ $ \\left|\\widehat{W}(P_{n},Q_{n})-W(P_{N},Q_{N})\\right| $ $ \\leq\\Big{|}W(P_{n},Q_{n})-W(P_{N},Q_{N})\\Big{|} $ </equation> <equation> $ +\\left|\\widehat{W}(P_{n},Q_{n})-W(P_{n},Q_{n})\\right| $ $ +\\left|\\widehat{W}(P_{n},Q_{n})-W(P_{n},Q_{n})\\right| $ </equation> <equation> $ =e_{s}+e_{m} $ $ =e_{s}+e_{m} $ </equation> </equationgroup> In the following, we will elaborate the superiority of the tessellation to reduce $ e_{s} $ and $ e_{m} $ respectively.", "\\newline <subsection> <title> 4.1 Sample Error </title> In practice, the size of data is too large to optimize, and we sample batches for better computation.", "Thus, the speed of convergence of the Wasserstein distance $ P_{n} $ to $ P_{N} $ is of importance.", "Sommerfeld and Munk [@bib:sommerfeld2018inference] showed that the convergence rate is $ n^{-\\frac{1}{2}} $ , i.e., \\newline <theorem> Theorem 1 .", "Suppose $ P $ is an empirical distribution.", "Let $ P_{n} $ be generated by i.i.d.", "samples $ \\tilde{z}_{1},\\cdots,\\tilde{z}_{n}\\sim P $ .", "Then with $ n $ approaching infinity \\newline <equation> $ \\sqrt{n}W_{2}^{2}(P_{n},P)\\to\\gamma_{1} $ </equation> where $ \\gamma_{1} $ is a random variable correlated with $ P $ .", "\\newline </theorem> The theorem indicates that the convergence rate of empirical distribution is independent of the dimension.", "So we need not worry about the curse of dimensionality.", "However, if $ P $ is absolutely continuous on $ R^{d} $ , then $ \\mathbb{E}\\left[W_{2}(P_{n},P)\\right]>Cn^{-\\frac{1}{d}} $ [@bib:weed2019sharp] .", "Since computation of the SW distance is based on empirical distribution and is equivalent to the Wasserstein distance.", "This asymptotic property can be generalized to the SW distance.", "\\newline <theorem> Theorem 2 .", "Suppose $ P $ and $ Q $ are empirical distributions.", "Let $ P_{n} $ and $ Q_{n} $ be generated by i.i.d.", "samples $ z_{1},\\cdots,z_{n}\\sim Q $ and $ \\tilde{z}_{1},\\cdots,\\tilde{z}_{n}\\sim P $ respectively.", "$ P_{n}^{^{\\prime}} $ is an independent copy of $ P_{n} $ .", "Then with $ n $ approaching infinity \\newline <equation> $ \\sqrt{n}\\left(SW_{2}^{2}\\left(P_{n},Q_{n}\\right)-SW_{2}^{2}\\left(P,Q\\right)% \\right)\\to N(0,\\sigma^{2}) $ </equation> <equation> $ nSW_{2}^{2}\\left(P_{n},P_{n}^{^{\\prime}}\\right)\\to\\gamma_{2} $ </equation> where $ \\sigma^{2} $ is the variance correlated with $ P $ and $ Q $ , and $ \\gamma_{2} $ is a random variable correlated with $ P $ .", "\\newline </theorem> <proof> Proof.", "For fixed $ w\\in S^{d-1} $ , we first see the asymptotic property of Wasserstein distance in the one-dimensional space.", "Let $ P_{n|w} $ , $ P_{n|w}^{^{\\prime}} $ , $ Q_{n|w} $ , $ P_{w} $ , $ Q_{w} $ be the projected empirical distributions of $ P_{n} $ , $ P_{n}^{^{\\prime}} $ , $ Q_{n} $ , $ P $ and $ Q $ respectively.", "The results in [@bib:del2000contributions] [@bib:munk1998nonparametric] showed that, with $ n $ approaching infinity, \\newline <equation> $ \\sqrt{n}\\left(W_{2}^{2}\\left(P_{n|w},Q_{n|w}\\right)-W_{2}^{2}\\left(P_{w},Q_{w}% \\right)\\right)\\to N(0,\\sigma_{1}^{2}) $ </equation> <equation> $ nW_{2}^{2}\\left(P_{n|w},P_{n|w}^{^{\\prime}}\\right)\\to\\gamma^{^{\\prime}} $ </equation> where $ \\sigma=\\sigma(P,Q,w) $ , $ \\gamma^{^{\\prime}}=\\gamma^{^{\\prime}}(P,w) $ .", "Since $ S^{d-1} $ is compact and by the definition of the SW distance, we obtain that, with $ n $ approaching infinity, \\newline <equation> $ \\sqrt{n}\\left(SW_{2}^{2}\\left(P_{n},Q_{n}\\right)-SW_{2}^{2}\\left(P,Q\\right)% \\right)\\to\\int_{w\\in S^{d-1}}N(0,\\sigma_{1}(w)^{2})dw $ </equation> <equation> $ nSW_{2}^{2}\\left(P_{n},P_{n}^{^{\\prime}}\\right)\\to\\int_{w\\in S^{d-1}}\\gamma^% {^{\\prime}}(w)dw $ </equation> where $ \\int_{w\\in S^{d-1}}N(0,\\sigma_{1}(w)^{2})dw $ is also gaussian, denoted by $ N(0,\\sigma^{2}) $ , and $ \\int_{w\\in S^{d-1}}\\gamma^{^{\\prime}}(w)dw $ is the random variable denoted by $ \\gamma_{2} $ .", "\u220e \\newline </proof> Numerical test simulates the asymptotic property of the SW distance (Fig. [@ref:LABEL:fig:asymptotic] ) and we observe that $ |SW_{2}^{2}(P_{n},Q_{n})-SW_{2}^{2}(P,Q)| $ and $ SW_{2}^{2}(P_{n},P_{n}^{^{\\prime}}) $ decrease roughly via $ \\mathcal{O}(n^{-\\frac{1}{2}}) $ and $ \\mathcal{O}(n^{-1}) $ , respectively.", "Then we can obtain upper bounds correlated with $ n $ , which are tighter than Claim 1 in [@bib:deshpande2018generative] , \\newline <equation> $ \\mathbb{E}\\left[\\left|SW_{2}^{2}\\left(P_{n},Q_{n}\\right)-SW_{2}^{2}\\left(P,Q% \\right)\\right|\\right]\\leq\\frac{C_{1}}{\\sqrt{n}} $ </equation> <equation> $ \\mathbb{E}\\left[SW_{2}^{2}\\left(P_{n},P_{n}^{^{\\prime}}\\right)\\right]\\leq% \\frac{C_{2}}{n} $ </equation> where $ C_{1} $ and $ C_{2} $ are two constants.", "For the GW distance, Rippl et al. proved a similar asymptotic property (Theorem 2.2 in [@bib:rippl2016limit] ) \\newline <theorem> Theorem 3 . Let $ P\\neq Q $ be Gaussian, $ P\\sim N(m_{1},\\Sigma_{1}) $ , $ Q\\sim N(m_{2},\\Sigma_{2}) $ with $ \\Sigma_{1} $ and $ \\Sigma_{2} $ having full rank.", "Let $ P_{n} $ and $ Q_{n} $ be generated by i.i.d.", "samples $ z_{1},\\cdots,z_{n}\\sim Q $ and $ \\tilde{z}_{1},\\cdots,\\tilde{z}_{n}\\sim P $ , respectively.", "$ P_{n}^{^{\\prime}} $ is an independent copy of $ P_{n} $ .", "Then with $ n $ approaching infinity \\newline <equation> $ \\sqrt{n}\\left(GW^{2}\\left(P_{n},Q_{n}\\right)-GW^{2}(P,Q)\\right)\\rightarrow N(0% ,w) $ </equation> <equation> $ nGW^{2}(P_{n},P_{n}^{^{\\prime}})\\to\\gamma_{3} $ </equation> where $ w $ is correlated with $ P $ and $ Q $ , and $ \\gamma_{3} $ is correlated with $ P $ .", "\\newline </theorem> The target of generative models is to learn a continuous distribution.", "However, the road to continuity is discrete sampling.", "Points sampled randomly from the prior distribution are compared with the real data to make the encoder of auto-encoders or generator of GANs smooth in the latent space or the data space, respectively.", "Thus, while optimizing each batch, the task is to minimize the discrepancy of empirical distributions.", "Theorems [@ref:LABEL:thm:sommer] , [@ref:LABEL:thm:sw] and [@ref:LABEL:thm:Gaussian] give insights into why GANs perform better with larger batch sizes [@bib:brock2018large] .", "On the other hand, the size of batches in deep learning is limited by computational resources.", "TWAE solves this dilemma by sampling the same number of points from different Voronoi regions.", "\\newline Suppose the whole support $ \\Omega $ of the prior distribution $ P_{z} $ is tessellated into $ m $ regions, and we utilize the SW distance to measure the discrepancy.", "On the one hand, if we sample $ n $ points in each region, there will be $ mn $ points on $ \\Omega $ in total.", "Then the sample error will be $ \\mathcal{O}(\\frac{1}{\\sqrt{mn}}) $ .", "On the other hand, if we sample $ n $ points from $ \\Omega $ for $ m $ times, then the error will be added up to $ \\mathcal{O}(\\frac{m}{\\sqrt{n}}) $ .", "In other words, if we optimize with batches of size $ n $ on $ \\Omega $ , then after a few epochs, $ SW_{2}^{2}(P_{n},Q_{n}) $ is approximately equal to $ SW_{2}^{2}(P_{n},P_{n}^{^{\\prime}}) $ , where $ P_{n}^{^{\\prime}} $ is an independent copy of $ P_{n} $ .", "This means we can not identify $ Q_{z} $ from $ P_{z} $ with $ n $ sampled points.", "However, if we take a look at a region $ V_{i} $ with probability $ P(V_{i})=\\frac{1}{m} $ , we can still find differences between $ P_{n|V_{i}} $ and $ Q_{n|V_{i}} $ because in the past batches only a few points located in $ V_{i} $ and the sample error was high.", "So the local information is lost in this way.", "On the contrary, TWAE samples a batch from each region, so that with the same size of batches, we can approximate the continuous distribution better.", "Numerical experiments in Section 5 demonstrate the effectiveness of this idea.", "\\newline </subsection> <subsection> <title> 4.2 Measurement Error </title> The SW and GW discrepancy metrics may lead to inaccurate estimation of the discrepancy.", "For the SW distance, we replace the integration in ( [@ref:LABEL:eq:slicedwasserstein] ) over $ S^{d-1} $ with a summation over a randomly chosen set of unit vectors $ \\widehat{S}^{d-1} $ .", "For the GW distance, we approximate $ P_{n} $ and $ Q_{n} $ with Gaussian distributions.", "We expect that the sum of errors for measuring the discrepancies on the tessellated supports is smaller than that on the whole support.", "For instance, if we approximate $ P_{n|V_{j}} $ with a Gaussian distribution in each region of $ \\Omega $ , we are actually utilizing a Gaussian mixture model to approximate $ P_{N} $ .", "A standard result in Bayesian nonparametrics says that every probability density is closely approximable by an infinite mixture of Gaussians.", "However, since the distribution can be arbitrarily complex, it is hard to show the reduction of error with the increase of $ m $ .", "The measurement error induced by different approaches can be unified by utilizing a parameter $ \\epsilon $ to depict the estimator $ \\widehat{W} $ .", "We assume that the expectation of $ P_{n} $ and $ Q_{n} $ is equal.", "Then it can be easily verified using the triangle inequality, i.e., \\newline <equationgroup> <equation> $  W_{2}^{2}(P_{n},Q_{n})=\\min_{\\sigma}\\frac{1}{n}\\sum_{i=1}^{n}\\|z% _{i}-\\tilde{z}_{\\sigma(i)}\\|_{2}^{2} $ $  W_{2}^{2}(P_{n},Q_{n})=\\min_{\\sigma}\\frac{1}{n}\\sum_{i=1}^{n}\\|z% _{i}-\\tilde{z}_{\\sigma(i)}\\|_{2}^{2} $ </equation> <equation> $ \\leq\\frac{2}{n}\\sum_{i=1}^{n}\\|z_{i}-\\mathbb{E}_{z\\sim P_{n}}[z]% \\|_{2}^{2}+\\frac{2}{n}\\sum_{i=1}^{n}\\|\\tilde{z}_{i}-\\mathbb{E}_{z\\sim Q_{n}}[z% ]\\|_{2}^{2} $ $ \\leq\\frac{2}{n}\\sum_{i=1}^{n}\\|z_{i}-\\mathbb{E}_{z\\sim P_{n}}[z]% \\|_{2}^{2}+\\frac{2}{n}\\sum_{i=1}^{n}\\|\\tilde{z}_{i}-\\mathbb{E}_{z\\sim Q_{n}}[z% ]\\|_{2}^{2} $ </equation> <equation> $ =\\frac{2(n-1)}{n}\\left[\\operatorname{tr}\\left(\\Sigma(P_{n})\\right% )+\\operatorname{tr}\\left(\\Sigma(Q_{n})\\right)\\right] $ $ =\\frac{2(n-1)}{n}\\left[\\operatorname{tr}\\left(\\Sigma(P_{n})\\right% )+\\operatorname{tr}\\left(\\Sigma(Q_{n})\\right)\\right] $ </equation> </equationgroup> where $ \\Sigma(P_{n}) $ , $ \\Sigma(Q_{n}) $ are the unbiased empirical covariance matrices of $ P_{n} $ and $ Q_{n} $ respectively, and $ \\operatorname{tr}(\\cdot) $ is the trace operator.", "\\newline <theorem> Definition 1 .", "Suppose $ P $ and $ Q $ are empirical distributions.", "An estimator $ \\widehat{W} $ is $ \\epsilon $ -good for $ (P,Q) $ if it holds that $ |\\widehat{W}_{2}^{2}(P,Q)-W_{2}^{2}(P,Q)|\\leq\\epsilon(\\operatorname{tr}\\left(% \\Sigma(P)\\right)+\\operatorname{tr}\\left(\\Sigma(Q)\\right)) $ \\newline </theorem> For instance, while adopting the GW distance, we utilize multivariate Gaussians to approximate $ P $ and $ Q $ , and ignore the information in the moments higher than two.", "Intuitively, by doing Taylor expansion on $ |\\widehat{W}_{2}^{2}(P,Q)-W_{2}^{2}(P,Q)| $ , the loss of moments higher than two can be bounded by the variance of $ P $ and $ Q $ .", "Then we obtain an upper bound to the measurement error of the tessellated Wasserstein distance, and prove the optimality of the usage of CVT according to the bound.", "\\newline <theorem> Theorem 4 . Let $ P $ be a uniform distribution on $ \\Omega $ , $ \\{V_{j}\\}_{j=1}^{m} $ be a tessellation on $ \\Omega $ .", "$ Q $ is the target distribution and $ \\mathcal{T} $ is the optimal transportation map from $ P $ to $ Q $ .", "Assume $ \\mathcal{T} $ is $ L $ -Lipschitz on $ \\Omega $ .", "$ P_{n|V_{j}} $ and $ Q_{n|\\mathcal{T}(V_{j})} $ are the empirical distributions of $ n $ points i.i.d. sampled from $ P $ restricted to $ V_{j} $ and $ Q $ restricted to $ \\mathcal{T}(V_{j}) $ , respectively.", "The estimator $ \\widehat{W} $ is $ \\epsilon $ -good for $ \\{(P_{n|V_{j}},Q_{n|\\mathcal{T}\\left(V_{j}\\right)})\\}_{j=1}^{m} $ .", "The estimate error of the tessellated Wasserstein distance is \\newline <equationgroup> <equation> $  error=\\sum_{i=1}^{m}P\\left(V_{i}\\right)|W_{2}^{2}\\left(Q_{n|% \\mathcal{T}\\left(V_{i}\\right)},P_{n|V_{i}}\\right) $ $  error $ $ =\\sum_{i=1}^{m}P\\left(V_{i}\\right)|W_{2}^{2}\\left(Q_{n|\\mathcal{T% }\\left(V_{i}\\right)},P_{n|V_{i}}\\right) $ </equation> <equation> $ -\\widehat{W}_{2}^{2}\\left(Q_{n|\\mathcal{T}\\left(V_{i}\\right)},P_{% n|V_{i}}\\right)| $ $ -\\widehat{W}_{2}^{2}\\left(Q_{n|\\mathcal{T}\\left(V_{i}\\right)},P_{% n|V_{i}}\\right)| $ </equation> </equationgroup> Then we have \\newline <equation> $ \\mathbb{E}\\left[error\\right]\\leq\\frac{\\epsilon\\left(1+L^{2}\\right)}{|\\Omega|}% \\sum_{i=1}^{m}\\int_{V_{i}}\\|z-\\widehat{z}_{i}\\|_{2}^{2}dz $ </equation> where $ \\widehat{z}_{i} $ is the mass centroid of $ V_{i} $ .", "The right side of the inequation ( [@ref:LABEL:ineq:fvz] ) can be viewed as a function of $ \\mathcal{F}\\left(V,\\widehat{z}\\right) $ .", "Furthermore, a necessary condition for the right side to be minimized is that $ V $ is the CVT and $ \\widehat{z} $ is the generator set.", "\\newline </theorem> <proof> Proof.", "For the $ \\epsilon $ -good estimator $ \\widehat{W} $ , the error bound of the tessellated Wasserstein distance is \\newline <equationgroup> <equation> $ \\sum_{i=1}^{m}P\\left(V_{i}\\right)\\left|W_{2}^{2}\\left(Q_{n|% \\mathcal{T}\\left(V_{i}\\right)},P_{n|V_{i}}\\right)-\\widehat{W}_{2}^{2}\\left(Q_{% n|\\mathcal{T}\\left(V_{i}\\right)},P_{n|V_{i}}\\right)\\right| $ $ \\sum_{i=1}^{m}P\\left(V_{i}\\right)\\left|W_{2}^{2}\\left(Q_{n|% \\mathcal{T}\\left(V_{i}\\right)},P_{n|V_{i}}\\right)-\\widehat{W}_{2}^{2}\\left(Q_{% n|\\mathcal{T}\\left(V_{i}\\right)},P_{n|V_{i}}\\right)\\right| $ </equation> <equation> $ \\leqslant\\epsilon\\sum_{i=1}^{m}P\\left(V_{i}\\right)\\left(% \\operatorname{tr}\\left(\\Sigma\\left(Q_{n|\\mathcal{T}\\left(V_{i}\\right)}\\right)% \\right)+\\operatorname{tr}\\left(\\Sigma\\left(P_{n|V_{i}}\\right)\\right)\\right) $ $ \\leqslant\\epsilon\\sum_{i=1}^{m}P\\left(V_{i}\\right)\\left(% \\operatorname{tr}\\left(\\Sigma\\left(Q_{n|\\mathcal{T}\\left(V_{i}\\right)}\\right)% \\right)+\\operatorname{tr}\\left(\\Sigma\\left(P_{n|V_{i}}\\right)\\right)\\right) $ </equation> <equation> $ =\\frac{\\epsilon n}{n-1}\\sum_{i=1}^{m}P\\left(V_{i}\\right)\\mathbb{E% }_{z\\sim P_{n|V_{i}}}\\left[\\|\\mathcal{T}(z)-\\bar{\\mathcal{T}}_{i}\\|_{2}^{2}+\\|% z-\\bar{z}\\|_{2}^{2}\\right] $ $ =\\frac{\\epsilon n}{n-1}\\sum_{i=1}^{m}P\\left(V_{i}\\right)\\mathbb{E% }_{z\\sim P_{n|V_{i}}}\\left[\\|\\mathcal{T}(z)-\\bar{\\mathcal{T}}_{i}\\|_{2}^{2}+\\|% z-\\bar{z}\\|_{2}^{2}\\right] $ </equation> <equation> $ \\leqslant\\frac{\\epsilon n}{n-1}\\sum_{i=1}^{m}P\\left(V_{i}\\right)% \\left(1+L^{2}\\right)\\mathbb{E}_{z\\sim P_{n|V_{i}}}\\left[\\|z-\\bar{z}\\|_{2}^{2}\\right] $ $ \\leqslant\\frac{\\epsilon n}{n-1}\\sum_{i=1}^{m}P\\left(V_{i}\\right)% \\left(1+L^{2}\\right)\\mathbb{E}_{z\\sim P_{n|V_{i}}}\\left[\\|z-\\bar{z}\\|_{2}^{2}\\right] $ </equation> <equation> $ =\\frac{\\epsilon n\\left(1+L^{2}\\right)}{(n-1)|\\Omega|}\\sum_{i=1}^{% m}|V_{i}|\\mathbb{E}_{z\\sim P_{n|V_{i}}}\\left[\\|z-\\bar{z}\\|_{2}^{2}\\right] $ $ =\\frac{\\epsilon n\\left(1+L^{2}\\right)}{(n-1)|\\Omega|}\\sum_{i=1}^{% m}|V_{i}|\\mathbb{E}_{z\\sim P_{n|V_{i}}}\\left[\\|z-\\bar{z}\\|_{2}^{2}\\right] $ </equation> </equationgroup> where $ \\bar{z}=\\mathbb{E}_{z\\sim P_{n|V_{i}}}\\left[z\\right] $ , $ \\bar{\\mathcal{T}}_{i}=\\mathbb{E}_{z\\sim P_{n|V_{i}}}\\left[\\mathcal{T}(z)\\right] $ .", "The last equation is because $ P(V_{i})=\\frac{|V_{i}|}{|\\Omega|} $ . Let $ \\tilde{z}_{1}^{(i)},\\cdots,\\tilde{z}_{n}^{(i)} $ be the support points of $ P_{n|V_{i}} $ , since they are randomly sampled from the uniform distribution on $ V_{i} $ , then \\newline <equationgroup> <equation> $ \\mathbb{E}_{P_{n|V_{i}}}\\left[\\mathbb{E}_{z\\sim P_{n|V_{i}}}\\left% [\\|z-\\bar{z}\\|_{2}^{2}\\right]\\right]=\\mathbb{E}_{P_{n|V_{i}}}\\left[\\frac{1}{n}% \\sum_{k=1}^{n}\\|\\tilde{z}_{k}^{(i)}-\\bar{z}^{(i)}\\|_{2}^{2}\\right] $ $ \\mathbb{E}_{P_{n|V_{i}}}\\left[\\mathbb{E}_{z\\sim P_{n|V_{i}}}\\left% [\\|z-\\bar{z}\\|_{2}^{2}\\right]\\right] $ $ =\\mathbb{E}_{P_{n|V_{i}}}\\left[\\frac{1}{n}\\sum_{k=1}^{n}\\|\\tilde{% z}_{k}^{(i)}-\\bar{z}^{(i)}\\|_{2}^{2}\\right] $ </equation> <equation> $ =\\frac{n-1}{n|V_{i}|}\\int_{V_{i}}\\|z-\\widehat{z}_{i}\\|_{2}^{2}dz $ $ =\\frac{n-1}{n|V_{i}|}\\int_{V_{i}}\\|z-\\widehat{z}_{i}\\|_{2}^{2}dz $ </equation> </equationgroup> where $ \\widehat{z}_{i}=\\frac{1}{|V_{i}|}\\int_{V_{i}}zdz $ .", "Taking it to ( [@ref:LABEL:eq:proof] ), we obtain the upper bound in ( [@ref:LABEL:ineq:fvz] ).", "Next, we will prove CVT is the necessary condition to minimize the upper bound.", "\\newline First, fix the tessellation $ V $ , $ \\forall j\\in\\{1,\\cdots,m\\} $ \\newline <equationgroup> <equation> $ \\int_{V_{j}}\\|z-{z}_{j}^{*}\\|_{2}^{2}dz=\\int_{V_{j}}\\left(\\|z\\|_{% 2}^{2}-2z^{T}{z}_{j}^{*}+\\|z_{j}^{*}\\|_{2}^{2}\\right)dz $ $ \\int_{V_{j}}\\|z-{z}_{j}^{*}\\|_{2}^{2}dz=\\int_{V_{j}}\\left(\\|z\\|_{% 2}^{2}-2z^{T}{z}_{j}^{*}+\\|z_{j}^{*}\\|_{2}^{2}\\right)dz $ </equation> </equationgroup> The integration is minimized when $ z_{j}^{*}=\\widehat{z}_{j} $ .", "Second, fix $ \\widehat{z} $ and see what happens if $ V $ is not a Voronoi tessellation generated by $ \\widehat{z} $ .", "Suppose that $ \\widehat{V} $ is the Voronoi tessellation generated by $ \\widehat{z} $ .", "Since $ V $ is not a Voronoi tessellation, there exists a particular value of $ z\\in V_{i} $ , $ \\exists j\\in\\{1,\\cdots,m\\} $ that \\newline <equation> $ \\|z-\\widehat{z}_{j}\\|_{2}^{2}<\\|z-\\widehat{z}_{i}\\|_{2}^{2} $ </equation> Thus, \\newline <equation> $ \\sum_{i=1}^{m}\\int_{V_{i}}\\|z-\\widehat{z}_{i}\\|_{2}^{2}dz>\\sum_{i=1}^{m}\\int_{% \\widehat{V}_{i}}\\|z-\\widehat{z}_{i}\\|_{2}^{2}dz $ </equation> So that the upper bound is minimized when $ V $ is chosen to be the CVT and $ \\widehat{z} $ is the set of generators.", "\u220e \\newline </proof> <theorem> Theorem 5 .", "In the setting of Theorem [@ref:LABEL:thm:twd] .", "Assume \\newline <equation> $ (V^{*},\\widehat{z}^{*})\\in\\arg\\min_{V,\\widehat{z}}\\mathcal{F}\\left(V,\\widehat{% z}\\right) $ </equation> then \\newline <equation> $ \\mathcal{F}\\left(V^{*},\\widehat{z}^{*}\\right)\\leq\\frac{\\epsilon(1+L^{2})% \\mathbb{E}\\left[C(P_{n|V^{*}_{i}},i=1,\\cdots,m)\\right]}{\\sqrt{m}} $ </equation> which means, utilizing $ V^{*} $ as tessellation, the estimate error of tessellated Wasserstein distance is upper bounded, \\newline <equation> $ \\mathbb{E}\\left[error\\right]\\leq\\frac{\\epsilon(1+L^{2})\\mathbb{E}\\left[C(P_{n|% V^{*}_{i}},i=1,\\cdots,m)\\right]}{\\sqrt{m}} $ </equation> \\newline </theorem> <proof> Proof.", "Following the result in Theorem [@ref:LABEL:thm:twd] , we have \\newline <equationgroup> <equation> $ \\mathcal{F}\\left(V^{*},\\widehat{z}^{*}\\right)=\\frac{\\epsilon\\left% (1+L^{2}\\right)}{|\\Omega|}\\sum_{i=1}^{m}\\int_{V^{*}_{i}}\\|z-\\widehat{z}^{*}_{i% }\\|_{2}^{2}dz $ $ \\mathcal{F}\\left(V^{*},\\widehat{z}^{*}\\right)= $ $ \\frac{\\epsilon\\left(1+L^{2}\\right)}{|\\Omega|}\\sum_{i=1}^{m}\\int_{% V^{*}_{i}}\\|z-\\widehat{z}^{*}_{i}\\|_{2}^{2}dz $ </equation> <equation> $ =\\frac{\\epsilon\\left(1+L^{2}\\right)}{|\\Omega|}\\sum_{i=1}^{m}|V^{*% }_{i}|\\mathbb{E}_{P_{n|V^{*}_{i}}}\\left[\\mathbb{E}_{z\\sim P_{n|V^{*}_{i}}}% \\left[\\|z-\\widehat{z}^{*}_{i}\\|_{2}^{2}\\right]\\right] $ $ = $ $ \\frac{\\epsilon\\left(1+L^{2}\\right)}{|\\Omega|}\\sum_{i=1}^{m}|V^{*}% _{i}|\\mathbb{E}_{P_{n|V^{*}_{i}}}\\left[\\mathbb{E}_{z\\sim P_{n|V^{*}_{i}}}\\left% [\\|z-\\widehat{z}^{*}_{i}\\|_{2}^{2}\\right]\\right] $ </equation> </equationgroup> Since $ (V^{*},\\widehat{z}^{*})\\in\\arg\\min_{V,\\widehat{z}}\\mathcal{F}\\left(V,\\widehat{% z}\\right) $ , following the result in Theorem [@ref:LABEL:thm:twd] , $ V^{*} $ is a CVT and $ \\widehat{z}^{*} $ is its generator.", "Let $ P^{*}=\\sum_{i=1}^{m} $ $ \\frac{|V^{*}_{i}|}{|\\Omega|}P_{n|V^{*}_{i}} $ , $ Q^{*}=\\sum_{i=1}^{m}\\frac{|V^{*}_{i}|}{|\\Omega|}\\delta_{\\widehat{z}^{*}_{i}} $ .", "Suppose $ \\mathcal{T}_{1} $ is the optimal transportation map from $ P^{*} $ to $ Q^{*} $ , then $ \\forall z\\in\\operatorname{supp}P_{n|V^{*}_{i}} $ , $ \\mathcal{T}_{1}(z)=\\widehat{z}_{i}^{*} $ , which is held for $ i=1,\\cdots,m $ .", "Thus, we have \\newline <equation> $ \\sum_{i=1}^{m}\\frac{|V^{*}_{i}|}{|\\Omega|}\\mathbb{E}_{P_{n|V^{*}_{i}}}\\left[% \\mathbb{E}_{z\\sim P_{n|V^{*}_{i}}}\\left[\\|z-\\widehat{z}^{*}_{i}\\|_{2}^{2}% \\right]\\right]=\\mathbb{E}_{P^{*}}\\left[W_{2}^{2}(P^{*},Q^{*})\\right] $ </equation> Since $ P^{*} $ is an empirical distribution, let $ P^{*}_{m} $ be an empirical distribution of $ m $ points i.i.d. sampled from $ P^{*} $ .", "Thus, following the results in Theorem [@ref:LABEL:thm:sommer] and combining this with ( [@ref:LABEL:eq:thm4] ) and ( [@ref:LABEL:eq:m] ), we have \\newline <equationgroup> <equation> $ \\mathcal{F}\\left(V^{*},\\widehat{z}^{*}\\right)=\\epsilon\\left(1+L^{% 2}\\right)\\mathbb{E}_{P^{*}}\\left[W_{2}^{2}(P^{*},Q^{*})\\right] $ $ \\mathcal{F}\\left(V^{*},\\widehat{z}^{*}\\right) $ $ =\\epsilon\\left(1+L^{2}\\right)\\mathbb{E}_{P^{*}}\\left[W_{2}^{2}(P^% {*},Q^{*})\\right] $ </equation> <equation> $ \\leq\\epsilon\\left(1+L^{2}\\right)\\mathbb{E}_{P^{*}}\\left[\\mathbb{E% }_{P^{*}_{m}}\\left[W_{2}^{2}(P^{*},P_{m}^{*})\\right]\\right] $ $ \\leq\\epsilon\\left(1+L^{2}\\right)\\mathbb{E}_{P^{*}}\\left[\\mathbb{E% }_{P^{*}_{m}}\\left[W_{2}^{2}(P^{*},P_{m}^{*})\\right]\\right] $ </equation> <equation> $ \\leq\\epsilon\\left(1+L^{2}\\right)\\mathbb{E}_{P^{*}}\\left[\\frac{C}{% \\sqrt{m}}\\right] $ $ \\leq\\epsilon\\left(1+L^{2}\\right)\\mathbb{E}_{P^{*}}\\left[\\frac{C}{% \\sqrt{m}}\\right] $ </equation> </equationgroup> where $ C=C(P^{*}) $ .", "\u220e \\newline </proof> Since in the training procedure we need to define the tessellation $ V $ before $ Q $ is known, the upper bound of error corresponding to $ V $ is of importance.", "Theorem [@ref:LABEL:thm:twd] gives the reason for utilizing the CVT technique and Theorem [@ref:LABEL:thm:decrease] shows that the error decrease with a rate of $ m^{-\\frac{1}{2}} $ .", "Note that after a few iterations, $ Q $ is approximately equal to $ P $ , then the optimal transportation map $ \\mathcal{T} $ is almost identical.", "Thus, $ \\mathcal{T}(V_{i})\\approx V_{i} $ is a set of points that are closest to $ \\widehat{z}_{i} $ other than $ \\widehat{z}_{j}(j\\neq i) $ .", "So the empirical distribution of $ S_{i} $ obtained by ( [@ref:LABEL:eq:hitchcock] ) is close to $ Q_{n|\\mathcal{T}(V_{i})} $ .", "Thus, in the algorithm, we compute $ W(P_{n|V_{i}},Q_{n|S_{i}}) $ instead of $ W(P_{n|V_{i}},Q_{n|\\mathcal{T}(V_{i})}) $ .", "If $ \\{V_{i}\\}_{i=1}^{m} $ is not a CVT, $ Q_{n|\\mathcal{T}(V_{i})} $ and $ Q_{n|S_{i}} $ will not coincide.", "The error induced by the approximation of $ Q_{n|S_{i}} $ to $ Q_{n|\\mathcal{T}(V_{i})} $ is hard to model.", "Nevertheless, it makes little effect on the results in the experiment.", "\\newline </subsection>  </section>"], ["<section> <title> 5 Experimental Results </title>  In this section, we numerically evaluate TWAE from five aspects.", "In section 5.3, we compare TWAE with related studies.", "In section 5.4, we test the optimization method introduced in section 3.", "In section 5.5, we compare the performance of the CVT technique and sphere packing.", "Finally, in section 5.6, we compare the models with and without tessellation.", "We trained TWAE with the GW distance (TWAE-GW) and the SW distance (TWAE-SW) respectively on two real-world datasets including MNIST [@bib:lecun1998gradient] consisting of 70k images and CelebA [@bib:liu2015deep] consisting of about 203k images.", "We use the Fr\u00e9chet inception distance (FID) introduced by [@bib:heusel2017gans] to measure the quality of the generated images.", "Smaller FID indicates better quality.", "\\newline <subsection> <title> 5.1 Architectures for different datasets </title> For the MNIST dataset, we use a simple auto-encoder consisting of a mirrored deep convolutional neural network with ReLu as the activation function to compare the performance of the CVT technique and sphere packing (Section 5.5).", "\\newline Encoder architecture: \\newline <equationgroup> <equation> $  x\\in\\mathcal{R}^{28\\times 28}\\rightarrow\\text{Conv}_{128}% \\rightarrow\\mathrm{BN}\\rightarrow\\mathrm{ReLU} $ $  x\\in\\mathcal{R}^{28\\times 28} $ $ \\rightarrow\\text{Conv}_{128}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ </equation> <equation> $ \\rightarrow\\mathrm{Conv}_{256}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ $ \\rightarrow\\mathrm{Conv}_{256}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ </equation> <equation> $ \\rightarrow\\mathrm{Conv}_{512}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ $ \\rightarrow\\mathrm{Conv}_{512}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ </equation> <equation> $ \\rightarrow\\mathrm{Conv}_{1024}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU}\\rightarrow\\mathrm{FC}_{8} $ $ \\rightarrow\\mathrm{Conv}_{1024}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU}\\rightarrow\\mathrm{FC}_{8} $ </equation> </equationgroup> \\newline Decoder architecture: \\newline <equationgroup> <equation> $  z\\in\\mathcal{R}^{8}\\rightarrow\\mathrm{FC}_{7\\times 7\\times 1024} $ $  z\\in\\mathcal{R}^{8} $ $ \\rightarrow\\mathrm{FC}_{7\\times 7\\times 1024} $ </equation> <equation> $ \\rightarrow\\mathrm{FSConv}_{512}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ $ \\rightarrow\\mathrm{FSConv}_{512}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ </equation> <equation> $ \\rightarrow\\mathrm{FSConv}_{256}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU}\\rightarrow\\mathrm{FSConv}_{1} $ $ \\rightarrow\\mathrm{FSConv}_{256}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU}\\rightarrow\\mathrm{FSConv}_{1} $ </equation> </equationgroup> \\newline For the CelebA dataset, we use two architectures A and B with different sizes of parameters to test if TWAE shows consistent results under different architectures (Fig. [@ref:LABEL:fig:two_acrchi] ).", "Numerical experiments show that our tessellation technique is effective on both architectures.", "The FID score decreases rapidly when the number of regions $ m $ is lower than 100.", "However, there is no more decline when $ m $ is larger.", "Architecture A is similar to that of Tolstikhin et al. (2017) [@bib:tolstikhin2017wasserstein] and is used to compare the performance of TWAE with other generative auto-encoders fairly (Section 5.3).", "\\newline Encoder of architecture A: \\newline <equationgroup> <equation> $  x\\in\\mathcal{R}^{64\\times 64\\times 3}\\rightarrow\\operatorname{% Conv}_{128}\\rightarrow\\mathrm{BN}\\rightarrow\\operatorname{ReLU} $ $  x\\in\\mathcal{R}^{64\\times 64\\times 3} $ $ \\rightarrow\\operatorname{Conv}_{128}\\rightarrow\\mathrm{BN}% \\rightarrow\\operatorname{ReLU} $ </equation> <equation> $ \\rightarrow\\mathrm{Conv}_{256}\\rightarrow\\mathrm{BN}\\rightarrow% \\operatorname{ReLU} $ $ \\rightarrow\\mathrm{Conv}_{256}\\rightarrow\\mathrm{BN}\\rightarrow% \\operatorname{ReLU} $ </equation> <equation> $ \\rightarrow\\mathrm{Conv}_{512}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ $ \\rightarrow\\mathrm{Conv}_{512}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ </equation> <equation> $ \\rightarrow\\mathrm{Conv}_{1024}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU}\\rightarrow\\mathrm{FC}_{64} $ $ \\rightarrow\\mathrm{Conv}_{1024}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU}\\rightarrow\\mathrm{FC}_{64} $ </equation> </equationgroup> \\newline Decoder of architecture A: \\newline <equationgroup> <equation> $  z\\in\\mathcal{R}^{64}\\rightarrow\\mathrm{FC}_{8\\times 8\\times 1024} $ $  z\\in\\mathcal{R}^{64} $ $ \\rightarrow\\mathrm{FC}_{8\\times 8\\times 1024} $ </equation> <equation> $ \\rightarrow\\mathrm{FSConv}_{512}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ $ \\rightarrow\\mathrm{FSConv}_{512}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ </equation> <equation> $ \\rightarrow\\mathrm{FSConv}_{256}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ $ \\rightarrow\\mathrm{FSConv}_{256}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ </equation> <equation> $ \\rightarrow\\mathrm{FSConv}_{128}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU}\\rightarrow\\mathrm{FSConv}_{3} $ $ \\rightarrow\\mathrm{FSConv}_{128}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU}\\rightarrow\\mathrm{FSConv}_{3} $ </equation> </equationgroup> \\newline Architecture B has the same number of layers and half the number of nodes.", "For less computational cost, we use architecture B to investigate the properties of TWAE extensively (Sections 5.4 and 5.6).", "\\newline Encoder of architecture B: \\newline <equationgroup> <equation> $  x\\in\\mathcal{R}^{64\\times 64\\times 3}\\rightarrow\\operatorname{% Conv}_{64}\\rightarrow\\mathrm{BN}\\rightarrow\\operatorname{ReLU} $ $  x\\in\\mathcal{R}^{64\\times 64\\times 3} $ $ \\rightarrow\\operatorname{Conv}_{64}\\rightarrow\\mathrm{BN}% \\rightarrow\\operatorname{ReLU} $ </equation> <equation> $ \\rightarrow\\mathrm{Conv}_{128}\\rightarrow\\mathrm{BN}\\rightarrow% \\operatorname{ReLU} $ $ \\rightarrow\\mathrm{Conv}_{128}\\rightarrow\\mathrm{BN}\\rightarrow% \\operatorname{ReLU} $ </equation> <equation> $ \\rightarrow\\mathrm{Conv}_{256}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ $ \\rightarrow\\mathrm{Conv}_{256}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ </equation> <equation> $ \\rightarrow\\mathrm{Conv}_{512}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU}\\rightarrow\\mathrm{Conv}_{64} $ $ \\rightarrow\\mathrm{Conv}_{512}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU}\\rightarrow\\mathrm{Conv}_{64} $ </equation> </equationgroup> \\newline Decoder of architecture B: \\newline <equationgroup> <equation> $  z\\in\\mathcal{R}^{64}\\rightarrow\\mathrm{FSConv}_{512}\\rightarrow% \\mathrm{BN}\\rightarrow\\mathrm{ReLU} $ $  z\\in\\mathcal{R}^{64} $ $ \\rightarrow\\mathrm{FSConv}_{512}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ </equation> <equation> $ \\rightarrow\\mathrm{FSConv}_{256}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ $ \\rightarrow\\mathrm{FSConv}_{256}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ </equation> <equation> $ \\rightarrow\\mathrm{FSConv}_{128}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ $ \\rightarrow\\mathrm{FSConv}_{128}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU} $ </equation> <equation> $ \\rightarrow\\mathrm{FSConv}_{64}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU}\\rightarrow\\mathrm{FSConv}_{3} $ $ \\rightarrow\\mathrm{FSConv}_{64}\\rightarrow\\mathrm{BN}\\rightarrow% \\mathrm{ReLU}\\rightarrow\\mathrm{FSConv}_{3} $ </equation> </equationgroup> \\newline </subsection> <subsection> <title> 5.2 Experimental setup </title> The hyperparameter $ \\lambda $ of the auto-encoder in ( [@ref:LABEL:eq:autoencoder] ) is set to 1 for TWAE-SW and 0.01 for TWAE-GW.", "The dimensionalities of the latent space are set to 8 for MNIST and 64 for CelebA, respectively.", "The number 241 of root lattices of $ E_{8} $ -lattice is chosen for sphere packing test.", "How many data points ( $ N $ ) in the training dataset are used for one single tessellation is a question.", "In the traditional setting, the data is shuffled in each epoch to prevent overfitting.", "If we take $ N $ as large as the size of the training dataset, the designed batches in each epoch will be approximately the same, which leads to bad generalization.", "Thus, larger $ N $ may not perform better.", "We tried various values of $ N $ and noticed that $ N=10000 $ or $ 20000 $ work well for both MNIST and CelebA. Compared with traditional algorithms, the only extra computation is using LCM to solve the Hitchcock problem to design batches for each data."]], "target": "The time cost of LCM is only at most a few minutes for these settings before the model is optimized with $ N $ data points (Table ). We implement our algorithms on Pytorch with the Adam optimizer."}, {"tabular": ["    &  $ D=0.80 $  &  $ D=0.88 $ ", " Config  &  Corr.\u2009/  &  Tot.  &  xspk  &  Corr.\u2009/  &  Tot.  &  xspk ", " 20, VAD  &  66\u2009/  &  206 \u2009(.32)  &  5  &  52\u2009/  &  90 \u2009(.58)  &  1 ", " 50, VAD  &  182\u2009/  &  1330 \u2009(.14)  &  35  &  138\u2009/  &  490 \u2009(.28)  &  11 ", " 20, FA  &  1064\u2009/  &  7541 \u2009(.14)  &  114  &  728\u2009/  &  2339 \u2009(.31)  &  18 ", " 50, FA  &  3119\u2009/  &  43762 \u2009(.07)  &  963  &  1918\u2009/  &  11114 \u2009(.17)  &  287  "], "ref_sec": [["<section> <title> 1 Introduction </title>  High-quality automatic speech recognition (ASR) systems require hundreds of hours of transcribed training data.", "As a result, they are currently available for only a tiny fraction of the world\u2019s several thousand languages [@bib:besacier2014] .", "To broaden accessibility, research on zero-resource speech technology aims to develop useful systems, such as unsupervised term discovery [@bib:park2008unsupervised,zhang+glass_icassp10,jansen2011efficient] or query-by-example [@bib:zhang+etal_icassp12,metze+etal_icassp13,levin2015segmental] , without the need for transcribed audio data.", "While considerable progress has been made in this area recently [@bib:versteegh+etal_interspeech15,rasanen+etal_interspeech15,kamper2015fully,kamper+etal_taslp16] , learning from audio alone is very challenging.", "Here, we ask whether using side information could improve performance.", "\\newline In particular, we address the task of unsupervised term discovery (UTD), which aims to identify and cluster repeated word-like units from audio.", "We show that UTD can be improved using side information from text translations of the audio into another language.", "Such translations can often be obtained rapidly through crowd-sourcing, for example in disaster relief scenarios such as the 2010 Haiti earthquake [@bib:munro2010] . And when the low-resource language has no written form, text translations (ideally into a related language, as in [@bib:AlanBlackStuff] ) may be considerably easier to obtain than a phonetic transcription.", "\\newline In addition to improving UTD, our work may feed into the development of cross-lingual tools for low-resource languages, in particular systems for translating speech from a low-resource language to a higher-resource language.", "A traditional pipeline would use ASR to transcribe the audio, followed by machine translation of the transcriptions.", "However, training such a system requires both transcribed audio in the low-resource language and parallel text.", "Recent work [@bib:duong2015attentional] has begun to explore how to translate key words and phrases based on the kind of training data we use here.", "Our work could inform future approaches to this task.", "\\newline Although our ultimate goal is to work with truly low-resource languages, ours is the first attempt we know of to address this task setting, so as a proof of concept we present results using a dataset of Spanish speech paired with English text translations [@bib:post2013improved] .", "We use an open-source UTD system to discover potential word-like units from the audio, then use a simple rescoring method to improve the UTD output based on the translation information.", "Our results show large improvements in average precision across a wide range of hyperparameter settings, and also across cross-speaker matches.", "\\newline  </section>"], ["<section> <title> 2 Unsupervised Term Discovery </title>  Zero-resource speech technology addresses a number of different problems, ranging from automatic discovery of subword units [@bib:lee+glass_acl12,siu+etal_csl14] and improved feature representations [@bib:badino+etal_interspeech15,thiolliere+etal_interspeech15] to full segmentation and clustering of the audio into word-like units [@bib:walter+etal_asru13,lee+etal_tacl15,rasanen+etal_interspeech15,kamper+etal_taslp16] .", "Unsupervised term discovery is one of the most well-developed areas.", "Essentially, UTD systems search for pairs of audio segments that are similar, as measured by their dynamic time warping (DTW) [@bib:sakoe1978dynamic] distance.", "This task is inherently quadratic in the input size, and early systems [@bib:park2008unsupervised,zhang2009unsupervised] were prohibitively slow.", "Here, we use the open-source implementation in the Zero Resource Toolkit (ZRTools) [@bib:jansen2011efficient] , a state-of-the-art system which uses a more efficient two-pass approach.", "It is also the only freely available UTD system we know of.", "\\newline <subsection> <title> 2.1 Overview of the ZRTools UTD system </title> In its first pass, ZRTools uses an approximate randomized algorithm and image processing techniques to extract potential matching segments.", "Image processing is used based on the intuition that if we plot the cosine similarity between every frame of the input feature vector representation (e.g. MFCCs), any repeated segments in the pair of utterances will show up as diagonal line patterns.", "Figure [@ref:LABEL:fig:dtws] (a) illustrates this, showing a clear diagonal pattern corresponding to similar words in two utterances.", "\\newline In its second pass, ZRTools computes a normalized DTW score over potential matches to extract the final output.", "It returns segment pairs longer than a minimum duration (we used the recommended value of 500ms) along with their DTW score (between 0 and 1, with higher scores indicating greater similarity).", "These word-like or phrase-like segments can then be used for downstream tasks like keyword search and topic modeling [@bib:dredze2010nlp,zhang2009unsupervised,park2008unsupervised] .", "\\newline Full details of the system can be found in [@bib:jansen2011efficient] .", "\\newline </subsection> <subsection> <title> 2.2 Limitations of UTD </title> Like all UTD systems, ZRTools identifies patterns using acoustic information only.", "This can lead to various types of errors which we hope to reduce using cross-lingual side information.", "\\newline <subsubsection> <title> 2.2.1 Mismatch between acoustic and semantic information </title> Some phonetically similar pairs identified by UTD are nevertheless different semantically, as illustrated in Figure [@ref:LABEL:fig:dtws] (b).", "The words in the utterances are different, but UTD identifies similar phoneme sequences a n o p w e and e n o p w e .", "Acoustic information alone cannot overcome these errors, yet they will cause semantic errors in downstream applications such as machine translation or spoken document retrieval.", "\\newline On the other hand, due to noise and variability (both within and across speakers), not all semantically correct matches will be assigned a high DTW score.", "The ZRTools documentation recommends using a DTW score threshold of 0.88 to filter good matches, yet there are many correct pairs with scores lower than 0.88.", "One example is illustrated in Figure [@ref:LABEL:fig:dtws] (c), where a correct match has a score just below the cut-off threshold.", "Of course, we can lower the DTW threshold to return more pairs (raise recall), but this will also increase the number of incorrect pairs returned (lower precision).", "\\newline </subsubsection> <subsubsection> <title> 2.2.2 Silence and filler words as valid matches </title> UTD is sensitive to silence regions, background noises, and filler words, all three of which commonly occur in conversational speech.", "We observed that these phenomena generate a large number of discovered pairs, since they are frequent and are often good acoustic matches with each other.", "\\newline The number of non-word pairs found by UTD due to these phenomena depends on the preprocessing of the data.", "To show that our method improves UTD output regardless of preprocessing, we experiment with two different preprocessing methods.", "\\newline First, we use the automatic voice activity detection (VAD) script that comes with ZRTools, which uses Root Mean Squared (RMS) Energy detection to label VAD regions.", "Only these regions are then used when searching for patterns.", "This method aggressively filters out silence but removes a considerable amount of valid speech.", "It also retains many filler words, which often have high energy and long duration.", "\\newline Alternatively, we can use a forced alignment (FA) of the speech data with the transcripts to filter out non-speech regions.", "This method would not be available in a true zero-resource situation, but might better reflect the output of a more sophisticated automatic VAD system, and has the advantage of retaining more of the training data.", "However, we observed that it removes fewer silent regions than the VAD system.", "\\newline Regardless of which preprocessing method is used, UTD will tend to find a large number of matches based on non-word regions.", "However, the translations for such non-word pairs will rarely contain any content words in common, so rescoring them based on their translations should reduce these spurious matches.", "\\newline </subsubsection> </subsection>  </section>"], ["<section> <title> 3 Improving UTD using translations </title>  Given pair of speech utterances, we hypothesize that the similarity in their translations provides a (noisy) signal of the semantic similarity between the discovered acoustic units, and that this signal can improve UTD.", "\\newline Consider the examples in Table [@ref:LABEL:tab:comparison] , which shows the English translations of the utterances containing the segments depicted in Figure [@ref:LABEL:fig:dtws] .", "(The utterances are cropped, so not all Spanish words are shown.) Stop words are shown in parentheses; we filter these out using the NLTK toolkit before computing translation similarity.", "Notice that the two pairs (a and c) that have matching Spanish words also have matching English content words, even though one of them falls below the recommended 0.88 threshold for a UTD (acoustic) match.", "On the other hand, pair (b) has a high UTD score due to phonetic similarity, but there is no match between the English words.", "\\newline To exploit these observations, we rescore the pairs returned by ZRTools using their translation similarity.", "If $ dtw_{i} $ is the acoustic similarity score for pair $ i $ computed by ZRTools, and $ J_{i} $ is the translation similarity score (described below), then the new score of pair $ i $ is computed as the $ \\alpha $ -weighted mean between the two: \\newline <equationgroup> <equation> $  score_{i}=(1-\\alpha)\\timesdtw_{i}+\\alpha\\times% J_{i} $ $  score_{i} $ $ =(1-\\alpha)\\timesdtw_{i}+\\alpha\\timesJ_{i} $ </equation> </equationgroup> \\newline To compute the similarity $ J $ between a pair of English translations, we treat each translation as bag of words (after filtering for stop words), and use Jaccard similarity [@bib:jaccard1901distribution] : \\newline <equationgroup> <equation> $  J=\\frac{|E_{1}\\capE_{2}|}{|E_{1}\\cupE_{2}|} $ $  J $ $ =\\frac{|E_{1}\\capE_{2}|}{|E_{1}\\cupE_{2}|} $ </equation> </equationgroup> where $ E_{1} $ is the set of content words in translation 1 and $ E_{2} $ is the set of content words in translation 2.", "\\newline Note that even seemingly low translation similarity scores (such as 0.125 for pair (a) in Table [@ref:LABEL:tab:comparison] ) are still a strong signal of semantic similarity between acoustic matches, because any non-zero score indicates some content words in common.", "Empirically we have observed $ J\\geq0.1 $ to be a good indicator of a correct match (although in practice we do not impose any threshold on $ J $ ).", "\\newline  </section>"], ["<section> <title> 4 Experimental setup and evaluation </title>  In all experiments, the input consists of speech from the CALLHOME Spanish corpus and the crowdsourced English translations of [@bib:post2013improved] .", "The corpus consists of speech from telephone conversations between native speakers.", "We use the default feature representation as used by ZRtools: 39-dimensional Relative Spectral Transform - Perceptual Linear Prediction (PLP) feature vectors.", "\\newline We carry out four sets of experiments as summarized in Table [@ref:LABEL:tab:expconfigs] .", "Note that the energy-based VAD filters out far more of the data than forced alignment.", "For each phone call, we have two channels of audio, each with at least one speaker, but sometimes more.", "The same speaker may be on multiple calls.", "However, for the purposes of our cross-speaker evaluation, we assume that each channel corresponds to a unique speaker.", "\\newline To evaluate the results of the raw UTD system and our rescoring method, we use the original Spanish CALLHOME transcripts to check if a pair of discovered speech segments is actually a true match.", "Note that the transcripts are not otherwise used as input to our system, except to filter non-speech in the forced alignment setting, where it serves as a kind of oracle for speech detection.", "For each pair of segments, we retrieve the corresponding words (as per the time stamps) from the transcripts.", "We retrieve any words which either partially or completely overlap with ZRTools output.", "The retrieved words are then filtered for stop words using NLTK.", "A discovered pair is marked as correct if the two segments have at least one content word in common; otherwise, it is marked as incorrect.", "\\newline To implement our rescoring method, we begin by running UTD with an acoustic matching threshold of $ D=0.8 $ , which is considerably lower than the ZRTools recommended level of $ D=0.88 $ .", "An empirical check suggested that very few correct pairs had scores below 0.8, and this value of $ D $ gives us enough potential pairs to perform rescoring.", "\\newline For evaluation, we treat the set of correct pairs returned with $ D=0.8 $ as the total number of possible correct pairs\u2014that is, recall values are computed with respect to this number.", "Therefore, a recall value of 1 does not mean that all correct pairs in the entire dataset have been identified, only those whose DTW score is above 0.8.", "\\newline Using our recomputed scores (as defined in Equation [@ref:LABEL:eq:scoreupdate] ) we can choose a new threshold value $ S $ , and return pairs that score above $ S $ .", "For each value of $ S $ , we can compute precision and recall: \\newline <equationgroup> <equation> $ \\mbox{Precision@$S$}=\\frac{\\sum_{i=1}^{N}(correct_{i}\\land score_% {i}\\geqS)}{\\sum_{i=1}^{N}(score_{i}\\geq S)} $ $ S $ $ S $ $ =\\frac{\\sum_{i=1}^{N}(correct_{i}\\land score_{i}\\geqS)}{% \\sum_{i=1}^{N}(score_{i}\\geq S)} $ </equation> </equationgroup> <equationgroup> <equation> $ \\mbox{Recall@$S$}=\\frac{\\sum_{i=1}^{N}(correct_{i}\\land score_{i}% \\geqS)}{\\sum_{i=1}^{N}(correct_{i}\\land dtw_{i}\\geq0.80)} $ $ S $ $ S $ $ =\\frac{\\sum_{i=1}^{N}(correct_{i}\\land score_{i}\\geqS)}{% \\sum_{i=1}^{N}(correct_{i}\\land dtw_{i}\\geq0.80)} $ </equation> </equationgroup> where $ correct_{i} $ indicates if a UTD output pair is correct or not, and $ N $ is the total number of pairs discovered with DTW threshold $ D=0.80 $ .", "We find the Precision/Recall curve by considering all possible values of $ S $ , and then compute the average precision (AP) as the area under this curve.", "\\newline  </section>"], ["<section> <title> 5 Results and discussion </title>  <subsection> <title> 5.1 Baseline UTD system </title> Table [@ref:LABEL:tab:utdout] lists the number of pairs discovered by running the baseline UTD system in each configuration.", "The number of pairs discovered using energy-based VAD is low, as expected, due to large parts of speech data being filtered out.", "Using forced alignments gives us a higher number of discovered pairs, but at a cost of precision.", "The low number of cross-speaker pairs listed in Table [@ref:LABEL:tab:utdout] highlights the difficulty of discovering these, though they are important for downstream tasks [@bib:kamper2015unsupervised,renshaw+etal_interspeech15] ."]], "target": "Translation information may be particularly helpful for identifying cross-speaker pairs, but our method is limited by the small number of pairs that are discovered in the first place, as shown in the xspk columns in Table . In future work we plan to investigate whether translation information could be fed into the UTD system at an earlier stage to help discover more cross-speaker pairs."}, {"tabular": ["  Case ID  &  Event ID  &  Timestamp  &  Activity  &  Indet. event ", " ID327  &  $ e_{1} $  &  11:00  &  {HighFever}  &  ? ", " ID327  &  $ e_{2} $  &  11:10  &  { {Apyr2} , {Apyr4} }  &  ! ", " ID327  &  $ e_{3} $  &  [10:00, 12:00]  &  {Rash}  &  ! ", " ID327  &  $ e_{4} $  &  13:00  &  {Adm}  &  !  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Over the last decades, the concept of {process} has become more and more central in formally describing the activities of businesses, companies and other similar entities, structured in specific steps and phases.", "A process is thus defined as a well-structured set of activities, potentially performed by multiple actors ( {resources} ), which contribute to the completion of a specific task or to the achievement of a specific goal.", "In this context, a very important notion is the concept of {case} , that is, a single instance of a process.", "For example, in a healthcare process a case may be a single hospitalization of a patient, or the patient themself; if the process belongs to a credit institution, a case may be a loan application from a customer, and so on.", "The case notion allows us to define a process as a procedure that precisely defines the steps needed to handle a case from inception to completion.", "This procedure is referred to as {process model} , and can be expressed in a number of different formalisms (transition systems, Petri nets, BPMN and UML diagrams, and many more).", "Consequently, the study and adoption of analysis techniques specifically customized to deal with process data and process models has enable the bridging of business administration and data science and the development of dedicated disciplines like {business intelligence} and {business process management} (BPM).", "\\newline The processes that govern the innards of business companies are increasingly supported by software tools.", "Performing specific activities is both aided and recorded by {process-aware information systems} (PAISs), which support the definition and management of processes.", "The information regarding the execution of processes can then be extracted from PAISs in the form of an {event log} , a database or file containing the digital footprint of the operations carried out in the context of the execution of a process and recorded as {events} .", "Event logs can vary in form, and contain differently structured information depending on the information system that enacted data collection in the organization.", "There are however some basic information regarding events that are very often recorded: these are the time in which the event occurred, the activity that has been performed, and the case identifier to which the event belong.", "This last attribute allows to group events in clusters belonging to the same case, and these resulting clusters (usually organized in sequences sorted by timestamp) are called {process traces} .", "The discipline of {process mining} concerns the automatic analysis of event logs, with the goal of extracting knowledge regarding e.g. the structure of the process, the conformity of events to a specific normative process model, the performances in executing the process, the relationships between groups of actors in the process.", "\\newline In this paper, we will consider the analysis of a specific class of event logs: the logs that contain {uncertain event data} .", "Uncertain events are recordings of executions of specific activities in a process which are enclosed with an indication of uncertainty in the event attributes.", "Specifically, we consider the case where the attributes of an event are not recorded as a precise value but as a range or a set of alternatives.", "\\newline The recording of uncertain event data is a common occurrence in process management.", "The {Process Mining Manifesto} [@bib:van2011process] describes a fundamental property of event data as {trustworthiness} , the assumption that the recorded data can be considered correct and accurate.", "In a general sense, uncertainty as defined here is an explicit absence of trustworthiness, with an indication of uncertainty recorded together with the event data.", "In the taxonomy of event data proposed in the Manifesto the logs at the two lower levels of quality frequently lack trustworthiness, and thus can be uncertain.", "This encompasses a wide range of processes, such as event logs of document and product management systems, error logs of embedded systems, worksheets of service engineers, and any process recorded totally or partially on paper.", "There are many possible causes behind the recording of uncertain event data, such as: \\newline <list> \\ {Incorrectness} .", "In some instances, the uncertainty is simply given by errors occurred while recording the data itself.", "Faults of the information system, or human mistakes in a data entry phase can all lead to missing or altered event data that can be subsequently modeled as uncertain event data.", "\\newline \\ \\ {Coarseness} .", "Some information systems have limitations in their way of recording data - often tied to factors like the precision of the data format - such that the event data can be considered uncertain.", "A typical example is an information system that only records the date, but not the time, of the occurrence of an event: if two events are recorded in the same day, the order of occurrence is lost.", "This is an especially common circumstance in the processes that are, partially or completely, recorded on paper and then digitalized.", "Another factor that can lead to uncertainty in the time of recording is the information system being overloaded and, thus, delaying memorization of data.", "This type of uncertainty can also be generated by the limited sensibility of a sensor.", "\\newline \\ \\ {Ambiguity} .", "In some cases, the data recorded is not an identifier of a certain event attribute; in these instances, the data needs to be interpreted, either automatically or manually, in order to obtain a value for the event attribute.", "Uncertainty can arise if the meaning of the data is ambiguous and cannot be interpreted with precision.", "Example are data in the form of images, text, or video.", "\\newline \\ </list> Aside from the causes, we can individuate other types of uncertain event logs based on the frequency of uncertain data.", "Uncertainty can be {infrequent} , when a specific attribute is only seldomly recorded together with explicit uncertainty; the uncertainty is rare enough that uncertain events can be considered outliers.", "Conversely, {frequent} uncertain behavior of the attribute is systematic, pervasive in a high number of traces, and thus not to be considered an outlier.", "The uncertainty can be considered part of the process itself.", "These concepts are not meant to be formal, and are laid out to distinguish between logs that are still processable regardless of the uncertainty, and logs where the uncertainty is too invasive to analyze them with existing process mining techniques.", "\\newline In this paper, we propose a taxonomy of the different types of explicit uncertainty in process mining, together with a formal, mathematical formulation.", "As an example of practical application, we will consider the case of conformance checking [@bib:carmona2018conformance] , and we will apply it to uncertain data by assessing what are the upper and lower bounds on the conformance score for possible values of the attributes in an uncertain trace.", "\\newline The main driving reasons behind this work is to provide the means to treat uncertainty as a relevant part of a process; thus, we aim not to filter it out but model it.", "In conclusion, there are two novel aspects regarding uncertain data that we intend to address in this work.", "The first is the {explicitness of uncertainty} : we work with the underlying assumption that the actual value of the uncertain attribute, while not directly provided, is described formally.", "This is the case when meta-information about the uncertainty in the attribute is available, either deduced from the features of the information system(s) that record the logs or included in the event log itself.", "Note that, as opposed to all previous work on the topic, the fact that uncertainty is explicit in the data means that the concept of uncertain behavior is completely separated from the concept of infrequent behavior.", "The second is the goal of {modeling uncertainty} : we consider uncertainty part of the process.", "Instead of filtering or cleaning the log we introduce the uncertainty perspective in process mining by extending the currently available techniques to incorporate it.", "\\newline The rest of this paper is organized as follows.", "Section [@ref:LABEL:sec:taxonomy] proposes a taxonomy of the different possible types of uncertain process data.", "Section [@ref:LABEL:sec:definitions] contains the formal definitions needed to manage uncertainty.", "Section [@ref:LABEL:sec:conformance] describes a practical application of process mining over uncertain event data, the case of conformance checking through alignments.", "Section [@ref:LABEL:sec:experiments] shows experimental results on computing conformance checking scores for synthetic uncertain data, as well as a case of application on real-life data.", "Section [@ref:LABEL:sec:related] discusses previous and related work on the management of uncertain data and on the topic of conformance checking.", "Finally, Section [@ref:LABEL:sec:conclusion] concludes the paper and discusses about future work.", "\\newline  </section>"], ["<section> <title> 2 A Taxonomy of Uncertain Event Data </title>  The goal of this section of the paper is to propose a categorization of the different types of uncertainty that can appear in process mining.", "In process management, a central concept is the distinction between the data perspective (the event log) and the behavioral perspective (the process model).", "The first one is a static representation of process instances, the second summarizes the behavior of a process.", "Both can be extended with a concept of explicit uncertainty: this concept also implies an extension of the process mining techniques that have currently been implemented.", "\\newline In this paper we will focus on uncertainty in event data, while the concept of uncertainty applied to models will be examined in a future work.", "Specifically, as an example application we will consider computing the conformance score of uncertain process data on classical models.", "\\newline We can individuate two different notions of uncertainty: \\newline <list> \\ {Strong uncertainty} : the possible values for the attributes are known, but the probability that the attribute will assume a certain instantiation is unknown or unobservable.", "\\newline \\ \\ {Weak uncertainty} : both the possible values of an attribute and their respective probabilities are known.", "\\newline \\ </list> \\newline In the case of a discrete attribute, the strong notion of uncertainty consists on a set of possible values assumed by the attribute.", "In this case, the probability for each possible value is unknown.", "Vice-versa, in the weak uncertainty scenario we also have a discrete probability distribution defined on that set of values.", "In the case of a continuous attribute, the strong notion of uncertainty can be represented with an interval for the variable.", "Notice that an interval do not indicate a uniform distribution; there is no information on the likelihood of values in it.", "Vice-versa, in the weak uncertainty scenario we also have a probability density function defined on a certain interval.", "Figure [@ref:LABEL:fig:unctypes] summarizes this concepts.", "This leads to very simple representations of explicit uncertainty.", "\\newline In this paper we consider only the control flow and time perspective of a process \u2013 namely, the attributes of the events that allow to discover a process model.", "These are the unique identifier of a process instance (case ID), the timestamp (often represented by the distance from a fixed origin point, e.g. the {Unix Epoch} ), and the activity identifier of an event.", "Case IDs and activities are values chosen from a finite set of possible values; they are discrete variables.", "Timestamps, instead, are represented by numbers and thus are continuous variables.", "\\newline We will also describe an additional type of uncertainty, which lays on the event level rather that the attribute level: \\newline <list> \\ {Indeterminate event} : the event may have not taken place even though it was recorded in the event log.", "Indeterminate events are indicated with a ? symbol, while determinate (regular) events are marked with a ! symbol.", "\\newline \\ </list> \\newline Examples of strongly and weakly uncertain traces are shown in Tables [@ref:LABEL:table:uncertaintracestrong] and [@ref:LABEL:table:uncertaintraceweak] respectively.", "\\newline  </section>"], ["<section> <title> 3 Preliminaries </title>  <theorem> Definition 1 (Power Set) The {power set} of a set $ A $ is the set of all possible subsets of $ A $ , and is denoted with $ \\mathcal{P}(A) $ .", "$ \\mathcal{P}_{NE}(A) $ denotes the set of all the non-empty subsets of $ A $ : $ \\mathcal{P}_{NE}(A)=\\mathcal{P}(A)\\setminus\\{\\emptyset\\} $ .", "\\newline </theorem> <theorem> Definition 2 (Multiset) A {multiset} is an extension of the concept of set that keeps track of the cardinality of each element.", "$ {\\cal B}(A) $ is the set of all multisets over some set $ A $ .", "Multisets are denoted with square brackets, e.g. $ b=[x,x,y] $ .", "\\newline </theorem> <theorem> Definition 3 (Sequence, Subsequence and Permutation) Given a set $ X $ , a finite {sequence} over $ X $ of length $ n $ is a function $ s\\in X^{*}:\\{1,\\dots,n\\}\\rightarrow X $ , and it is written as $ s=\\langle s_{1},s_{2},\\dots,s_{n}\\rangle $ .", "We denote with $ \\langle\\leavevmode\\nobreak\\ \\rangle $ the empty sequence, the sequence with no elements and of length 0.", "Over the sequence $ s $ we define $ |s|=n $ , $ s[i]=s_{i} $ and $ x\\in s\\Leftrightarrow\\exists_{1\\leq i\\leq n}s=s_{i} $ .", "The concatenation between two sequences is denoted with $ \\langle s_{1},s_{2},\\dots,s_{n}\\rangle\\cdot\\langle s^{\\prime}_{1},s^{\\prime}_{% 2},\\dots,s^{\\prime}_{m}\\rangle=\\langle s_{1},s_{2},\\dots,s_{n},s^{\\prime}_{1},% s^{\\prime}_{2},\\dots,s^{\\prime}_{m}\\rangle $ .", "Given two sequences $ s=\\langle s_{1},s_{2},\\dots,s_{n}\\rangle $ and $ s^{\\prime}=\\langle s^{\\prime}_{1},s^{\\prime}_{2},\\dots,s^{\\prime}_{m}\\rangle $ , $ s^{\\prime} $ is a {subsequence} of $ s $ if and only if there exists a sequence of strictly increasing natural numbers $ \\langle i_{1},i_{2},\\dots,i_{m}\\rangle $ such that $ \\forall_{1\\leq j\\leq m}s_{i_{j}}=s^{\\prime}_{j} $ .", "We indicate this with $ s^{\\prime}\\subseteq s $ .", "A {permutation} of the set $ X $ is a sequence $ x_{\\mathcal{S}} $ that contains all elements of $ X $ without duplicates: $ x_{\\mathcal{S}}\\in X $ , $ X\\in x_{\\mathcal{S}} $ , and for all $ 1\\leq i\\leq|x_{\\mathcal{S}}| $ and for all $ 1\\leq j\\leq|x_{\\mathcal{S}}| $ , $ x_{\\mathcal{S}}[i]=x_{\\mathcal{S}}[j]\\rightarrow i=j $ .", "We denote with $ \\mathcal{S}_{X} $ all such permutations of set $ X $ .", "\\newline </theorem> <theorem> Definition 4 (Sequence Projection) Let $ X $ be a set and $ Q\\subseteq X $ one of its subsets.", "$ \\!\\!\\upharpoonright_{Q}\\in X^{*}\\rightarrow Q^{*} $ is the sequence projection function and is defined recursively: $ \\langle\\leavevmode\\nobreak\\ \\rangle\\!\\!\\upharpoonright_{Q}=\\langle\\leavevmode% \\nobreak\\ \\rangle $ and for $ \\sigma\\in X^{*} $ and $ x\\in X $ : \\newline <equation> $ (\\langle x\\rangle\\cdot\\sigma)\\!\\!\\upharpoonright_{Q}=\\begin{cases}\\sigma\\!\\!% \\upharpoonright_{Q}&\\mbox{if}\\ x\\not\\in Q\\\\ \\langle x\\rangle\\cdot\\sigma\\!\\!\\upharpoonright_{Q}&\\mbox{if}\\ x\\in Q\\end{cases} $ </equation> \\newline </theorem> For example, $ \\langle y,z,y\\rangle\\!\\!\\upharpoonright_{\\{x,y\\}}=\\langle y,y\\rangle $ .", "\\newline <theorem> Definition 5 (Applying Functions to Sequences) Let $ f\\in X\\not\\rightarrow Y $ be a partial function.", "$ f $ can be applied to sequences of $ X $ using the following recursive definition: $ f(\\langle\\leavevmode\\nobreak\\ \\rangle)=\\langle\\leavevmode\\nobreak\\ \\rangle $ and for $ \\sigma\\in X^{*} $ and $ x\\in X $ : \\newline <equation> $ f(\\langle x\\rangle\\cdot\\sigma)=\\begin{cases}f(\\sigma)&\\mbox{if}\\ x\\not\\in dom(% f)\\\\ \\langle f(x)\\rangle\\cdot f(\\sigma)&\\mbox{if}\\ x\\in dom(f)\\end{cases} $ </equation> \\newline </theorem> <theorem> Definition 6 (Transitive Relation and Correct Evaluation Order) Let $ X $ be a set of objects and $ R $ be a binary relation $ R\\subseteq X\\times X $ .", "$ R $ is {transitive} if and only if for all $ x,x^{\\prime},x^{\\prime\\prime}\\in X $ we have that $ (x,x^{\\prime})\\in R\\wedge(x^{\\prime},x^{\\prime\\prime})\\in R\\rightarrow(x,x^{% \\prime\\prime})\\in R $ .", "A {correct evaluation order} is a permutation $ s\\in\\mathcal{S}_{X} $ of the elements of the set $ X $ such that for all $ 1\\leq i<j\\leq|s| $ we have that $ (s[i],s[j])\\in R $ .", "\\newline </theorem> <theorem> Definition 7 (Strict Partial Order) Let $ S $ be a set of objects.", "Let $ s,s^{\\prime}\\in S $ .", "A {strict partial order} $ (\\prec,S) $ is a binary relation that have the following properties: \\newline <list> \\ Irreflexivity: $ s\\prec s $ is false.", "\\newline \\ \\ Transitivity: see Definition [@ref:LABEL:def:tr_rel] .", "\\newline \\ \\ Antisymmetry: $ s\\prec s^{\\prime} $ implies that $ s^{\\prime}\\prec s $ is false.", "Implied by irreflexivity and transitivity {[@bib:flavska2007transitive]} .", "\\newline \\ </list> \\newline </theorem> <theorem> Definition 8 (Directed Graph) A {directed graph} $ G\\in\\mathcal{U}_{G} $ is a tuple $ (V,E) $ where $ V $ is the set of vertices and $ E\\subseteq V\\times V $ is the set of directed edges.", "The set $ \\mathcal{U}_{G} $ is the {graph universe} .", "A {path} in a directed graph $ G=(V,E) $ is a sequence of vertices $ p $ such that for all $ 1<i<|p|-1 $ we have that $ (p_{i},p_{i+1})\\in E $ .", "We denote with $ P_{G} $ the set of all such possible paths over the graph G. Given two vertices $ v,v^{\\prime}\\in V $ , we denote with $ p_{G}(v,v^{\\prime}) $ the set of all paths beginning in $ v $ and ending in $ v^{\\prime} $ : $ p_{G}(v,v^{\\prime})=\\{p\\in P_{G}\\mid p[0]=v\\wedge p[|p|]=v^{\\prime}\\} $ .", "$ v $ and $ v^{\\prime} $ are {connected} (and $ v^{\\prime} $ is {reachable} from $ v $ ), denoted by $ v\\overset{G}{\\mapsto}v^{\\prime} $ , if and only if there exists a path between them in $ G $ : $ p_{G}(v,v^{\\prime})\\neq\\emptyset $ .", "Conversely, $ v\\overset{G}{\\not\\mapsto}v^{\\prime}\\Leftrightarrow p_{G}(v,v^{\\prime})=\\emptyset $ .", "We opmit the superscript $ G $ if it is clear from the context.", "A directed graph $ G $ is {acyclic} if there exists no path $ p\\in P_{G} $ satisfying $ p[1]=p[|p|] $ .", "\\newline </theorem> <theorem> Definition 9 (Topological Sorting) Let $ G=(V,E) $ be an acyclic directed graph.", "A {topological sorting [@bib:kalvin1983generation]} $ o_{G}\\in\\mathcal{S}_{V} $ is a permutation of the vertices of $ G $ such that for all $ 1\\leq i<j\\leq|o_{G}| $ we have that $ o_{G}[j]\\not\\mapsto o_{G}[i] $ .", "We denote with $ \\mathcal{O}_{G}\\subseteq\\mathcal{S}_{V} $ all such possible topological sortings over $ G $ .", "\\newline </theorem> <theorem> Definition 10 (Transitive Reduction) A {transitive reduction [@bib:aho1972transitive]} $ tr\\colon\\mathcal{G}\\to\\mathcal{G} $ of a graph $ G=(V,E) $ is a graph $ tr(G)=(V,E_{r}) $ with $ E_{r}\\subseteq E $ where every pair of vertices connected in $ tr(G) $ is not connected by any other path: for all $ (v,v^{\\prime})\\in E_{r} $ , $ p_{G}(v,v^{\\prime})=\\{\\langle v,v^{\\prime}\\rangle\\} $ .", "$ tr(G) $ is the graph with the minimal number of edges that maintain the reachability between edges of $ G $ .", "The transitive reduction of a directed acyclic graph always exists and is unique {[@bib:aho1972transitive]} .", "\\newline </theorem> <theorem> Definition 11 (Dependency Graph) Let $ X $ be a set of objects and $ R $ be a transitive relation $ R\\subseteq X\\times X $ .", "A {dependency graph [@bib:liu1998simple]} $ \\mathcal{D}(X,R)\\in\\mathcal{U}_{G} $ is the directed graph $ tr((X,R)) $ .", "Since $ R $ is transitive, for all $ x,x^{\\prime}\\in X $ we have that $ x\\mapsto x^{\\prime}\\Leftrightarrow(x,x^{\\prime})\\in R $ , thus all the topological sortings $ \\mathcal{O}_{\\mathcal{D}(X,R)} $ are also all possible correct evaluation orders of the objects in $ X $ for the relation $ R $ .", "\\newline </theorem> In general, and on a more abstract level, a dependency graph is a structure that explicitly expresses the property of adjuction between directed graphs and transitive relations, meaning that directed graphs define transitive relations and vice versa [@bib:spivak2014category] .", "\\newline Let us now define the basic artifacts needed to perform process mining.", "\\newline <theorem> Definition 12 (Universes) Let $ \\mathcal{U}_{E} $ be the set of all the {event identifiers} .", "Let $ \\mathcal{U}_{C} $ be the set of all the {case id identifiers} .", "Let $ \\mathcal{U}_{A} $ be the set of all the {activity identifiers} .", "Let $ \\mathcal{U}_{T} $ be the totally ordered set of all the {timestamp identifiers} .", "\\newline </theorem> <theorem> Definition 13 (Events and event logs) Let us denote with $ \\mathcal{E}_{C}=\\mathcal{U}_{E}\\times\\mathcal{U}_{C}\\times\\mathcal{U}_{A}% \\times\\mathcal{U}_{T} $ the universe of {certain events} .", "A {certain event log} is a set of events $ L_{C}\\subseteq\\mathcal{E}_{C} $ such that every event identifier in $ L_{C} $ is unique.", "\\newline </theorem> <theorem> Definition 14 (Simple certain traces and logs) Let $ \\{(e_{1},c_{1},a_{1},t_{1}),(e_{2},c_{2},a_{2},t_{2}),\\dots,(e_{n},c_{n},a_{n}% ,t_{n})\\}\\subseteq\\mathcal{E}_{C} $ be a set of certain events and let $ c_{1}=c_{2}=\\dots=c_{n} $ and $ t_{1}<t_{2}<\\dots<t_{n} $ .", "A {simple certain trace} is the sequence of activities $ \\langle a_{1},a_{2},\\dots,a_{n}\\rangle\\in{\\mathcal{U}_{A}}^{*} $ induced by such a set of events.", "$ \\mathcal{T} $ denotes the universe of certain traces.", "$ L\\in{\\cal B}(\\mathcal{T}) $ is a {simple certain log} .", "We will drop the qualifier \u201csimple\u201d if it is clear from the context.", "\\newline </theorem> As a preliminary application of process mining over uncertain event data we will consider conformance checking.", "Starting from an event log and a process model, conformance checking verifies if the event data in the log conforms to the model, providing a diagnostic of the deviations.", "Conformance checking serves many purposes, such as checking if process instances follow a specific normative model, assessing if a certain execution log has been generated from a specific model, or verifying the quality of a process discovery technique.", "\\newline The conformance checking algorithm that we are applying in this paper is based on {alignments} .", "Introduced by Adriansyah [@bib:adriansyah2014aligning] , conformance checking through alignments finds deviations between a trace and a Petri net model of a process by creating a correspondence between the sequence of activities executed in the trace and the firing of the transitions in the Petri net.", "The following definitions are partially from [@bib:van2013decomposing] .", "\\newline <theorem> Definition 15 (Petri Net) A Petri net is a tuple $ N=(P,T,F) $ with $ P $ the set of places, $ T $ the set of transitions, $ P\\cap T=\\emptyset $ , and $ F\\subseteq(P\\times T)\\cup(T\\times P) $ the flow relation.", "A Petri net $ N=(P,T,F) $ defines a directed graph $ (V,E) $ with vertices $ V=P\\cup T $ and edges $ E=F $ .", "A marking $ M\\in{\\cal B}(P) $ is a multiset of places.", "\\newline </theorem> A marking defines the state of a Petri net, and indicates how many {tokens} each place contains.", "For any $ x\\in P\\cup T $ , $ \\,\\stackrel{{\\scriptstyle N}}{{\\bullet}}\\!{x}=\\{x^{\\prime}\\mid(x^{\\prime},x)% \\in F\\} $ denotes the set of input nodes and $ {x}\\!\\kern-0.215pt\\stackrel{{\\scriptstyle N}}{{\\bullet}}\\,=\\{x^{\\prime}\\mid(x,% x^{\\prime})\\in F\\} $ denotes the set of output nodes.", "We opmit the superscript $ N $ if it is clear from the context.", "\\newline A transition $ t\\in T $ is {enabled} in marking $ M $ of net $ N $ , denoted as $ (N,M)[t\\rangle $ , if each of its input places $ \\bullet{t} $ contains at least one token.", "An enabled transition $ t $ may {fire} , i.e., one token is removed from each of the input places $ \\bullet{t} $ and one token is produced for each of the output places $ {t}\\kern-0.215pt\\bullet $ .", "Formally: $ M^{\\prime}=(M\\setminus\\bullet{t})\\uplus{t}\\kern-0.215pt\\bullet $ is the marking resulting from firing enabled transition $ t $ in marking $ M $ of Petri net $ N $ .", "$ (N,M)[t\\rangle(N,M^{\\prime}) $ denotes that $ t $ is enabled in $ M $ and firing $ t $ results in marking $ M^{\\prime} $ .", "\\newline Let $ \\sigma_{T}=\\langle t_{1},t_{2},\\ldots,t_{n}\\rangle\\in T^{*} $ be a sequence of transitions.", "$ (N,M)[\\sigma_{T}\\rangle(N,M^{\\prime}) $ denotes that there is a set of markings $ M_{0},M_{1},\\ldots,M_{n} $ such that $ M_{0}=M $ , $ M_{n}=M^{\\prime} $ , and $ (N,M_{i})[t_{i+1}\\rangle(N,M_{i+1}) $ for $ 0\\leq i<n $ .", "A marking $ M^{\\prime} $ is {reachable} from $ M $ if there exists a $ \\sigma_{T} $ such that $ (N,M)[\\sigma_{T}\\rangle(N,M^{\\prime}) $ .", "\\newline <theorem> Definition 16 (Labeled Petri Net) A labeled Petri net $ N=(P,T,F,l) $ is a Petri net $ (P,T,F) $ with labeling function $ l\\in T\\not\\rightarrow{\\cal U}_{A} $ where $ {\\cal U}_{A} $ is some universe of activity labels.", "Let $ \\sigma=\\langle a_{1},a_{2},\\ldots,a_{n}\\rangle\\in{{\\cal U}_{A}}^{*} $ be a sequence of activities.", "$ (N,M)[{\\sigma}\\rhd(N,M^{\\prime}) $ if and only if there is a sequence $ \\sigma_{T}\\in T^{*} $ such that $ (N,M)[\\sigma_{T}\\rangle(N,M^{\\prime}) $ and $ l(\\sigma_{T})=\\sigma $ .", "\\newline </theorem> If $ t\\notin\\mathit{dom}(l) $ , it is called {invisible} .", "To indicate invisible transitions we use the placeholder symbol $ \\tau $ ; by definition $ \\tau\\notin\\mathit{dom}(l) $ .", "An occurrence of visible transition $ t\\in\\mathit{dom}(l) $ corresponds to observable activity $ l(t) $ .", "\\newline <theorem> Definition 17 (System Net) A system net is a triplet $ \\mathit{SN}=(N,M_{\\mathit{init}},M_{\\mathit{final}}) $ where $ N=(P,T,F,l) $ is a labeled Petri net, $ M_{\\mathit{init}}\\in{\\cal B}(P) $ is the initial marking, and $ M_{\\mathit{final}}\\in{\\cal B}(P) $ is the final marking.", "$ {\\cal U}_{\\mathit{SN}} $ is the {universe of system nets} .", "Over a system net we define the following: \\newline <list> \\ $ T_{v}(\\mathit{SN})=\\mathit{dom}(l) $ is the set of {visible transitions} in $ \\mathit{SN} $ , \\newline \\ \\ $ A_{v}(\\mathit{SN})=\\mathit{rng}(l) $ is the set of corresponding {observable activities} in $ \\mathit{SN} $ , \\newline \\ \\ $ T_{v}^{u}(\\mathit{SN})=\\{t\\in T_{v}(\\mathit{SN})\\mid\\forall_{t^{\\prime}\\in T_{% v}(\\mathit{SN})}\\ l(t)=l(t^{\\prime})\\ \\Rightarrow\\ t=t^{\\prime}\\} $ is the set of {unique} visible transitions in $ \\mathit{SN} $ (i.e., there are no other transitions having the same visible label), \\newline \\ \\ $ A_{v}^{u}(\\mathit{SN})=\\{l(t)\\mid t\\in T_{v}^{u}(\\mathit{SN})\\} $ is the set of corresponding {unique} observable activities in $ \\mathit{SN} $ , \\newline \\ \\ $ \\phi(\\mathit{SN})=\\{\\sigma\\mid(N,M_{\\mathit{init}})[{\\sigma}\\rhd(N,M_{\\mathit{% final}})\\} $ is the set of {visible} traces starting in $ M_{\\mathit{init}} $ and ending in $ M_{\\mathit{final}} $ , and \\newline \\ \\ $ \\phi_{f}(\\mathit{SN})=\\{\\sigma_{T}\\mid(N,M_{\\mathit{init}})[{\\sigma_{T}}% \\rangle(N,M_{\\mathit{final}})\\} $ is the corresponding set of complete firing sequences.", "\\newline \\ </list> \\newline </theorem> Figure [@ref:LABEL:fig:esconformance] shows a system net with initial and final markings $ M_{\\mathit{init}}=\\{start\\} $ and $ M_{\\mathit{final}}=\\{end\\} $ .", "Given a system net, $ \\phi(\\mathit{SN}) $ is the set of all possible {visible} activity sequences, i.e. the labels of complete firing sequences starting in $ M_{\\mathit{init}} $ and ending in $ M_{\\mathit{final}} $ projected onto the set of observable activities.", "Given the set of activity sequences $ \\phi(\\mathit{SN}) $ obtainable via complete firing sequences on a certain system net, we can define a perfectly fitting event log as a set of traces which activity projection is contained in $ \\phi(\\mathit{SN}) $ .", "\\newline <theorem> Definition 18 (Perfectly Fitting Log) Let $ L\\in{\\cal B}(\\mathcal{T}) $ be a certain event log and let $ \\mathit{SN}=(N,M_{\\mathit{init}},M_{\\mathit{final}})\\in{\\cal U}_{\\mathit{SN}} $ be a system net.", "$ L $ is perfectly fitting $ \\mathit{SN} $ if and only if $ \\{\\sigma\\in L\\}\\subseteq\\phi(\\mathit{SN}) $ .", "\\newline </theorem> These definitions allow us to build {alignments} in order to compute the fitness of trace on a certain model.", "An alignment is a correspondence between a sequence of activities (extracted from the trace) and a sequence of transitions with the relative labels (fired in the model while replaying the trace).", "The first sequence indicates the \u201cmoves in the log\u201d and the second indicates the \u201cmoves in the model\u201d.", "If a move in the model cannot be mimicked by a move in the log, then a \u201c $ \\gg $ \u201d (\u201cno move\u201d)", "appears in the top row; conversely, if a move in the log cannot be mimicked by a move in the model, then a \u201c $ \\gg $ \u201d (\u201cno move\u201d) appears in the bottom row.\u201cno moves\u201d not corresponding to invisible transitions point to deviations between the model and the log.", "A {move} is a pair $ (x,(y,t)) $ where the first element refers to the log and the second element to the model.", "A \u201c $ \\gg $ \u201d in the first element of the pair indicates a move on the model, in the second element it indicates a move on the log.", "\\newline <theorem> Definition 19 (Legal Moves) Let $ L\\in{\\cal B}(\\mathcal{T}) $ be a certain event log, let $ A\\subseteq\\mathcal{U}_{A} $ be the set of activity labels appearing in the event log, and let $ \\mathit{SN}=(N,M_{\\mathit{init}},M_{\\mathit{final}})\\in{\\cal U}_{\\mathit{SN}} $ be a system net with $ N=(P,T,F,l) $ .", "$ A_{LM}=\\{(x,(x,t))\\mid x\\in A\\ \\wedge\\ t\\in T\\ \\wedge\\ l(t)=x\\}\\cup\\{(\\gg,(x,t% ))\\mid t\\in T\\ \\wedge\\ l(t)=x\\}\\cup\\{(x,\\gg)\\mid x\\in A\\} $ is the set of {legal moves} .", "\\newline </theorem> An alignment is a sequence of legal moves such that after removing all \u201c $ \\gg $ \u201d symbols, the top row corresponds to a trace in the log and the bottom row corresponds to a firing sequence starting in $ M_{\\mathit{init}} $ and ending $ M_{\\mathit{final}} $ .", "Notice that if $ t\\notin\\mathit{dom}(l) $ is an invisible transition, the activation of $ t $ is indicated by a \u201c $ \\gg $ \u201d on the log in correspondence of $ t $ and the placeholder label $ \\tau $ .", "Hence, the middle row corresponds to a visible path when ignoring the $ \\tau $ steps.", "Figure [@ref:LABEL:fig:esconformance] shows a system net with two examples of alignments, $ \\sigma_{1} $ of a fitting trace and $ \\sigma_{2} $ of a non-fitting trace.", "\\newline <theorem> Definition 20 (Alignment) Let $ \\sigma\\in L $ be a certain trace and $ \\sigma_{T}\\in\\phi_{f}(\\mathit{SN}) $ a complete firing sequence of system net $ \\mathit{SN} $ .", "An {alignment} of $ \\sigma $ and $ \\sigma_{T} $ is a sequence $ \\gamma\\in{A_{LM}}^{*} $ such that the projection on the first element (ignoring \u201c $ \\gg $ \u201d) yields $ \\sigma $ and the projection on the last element (ignoring \u201c $ \\gg $ \u201d and transition labels) yields $ \\sigma_{T} $ .", "\\newline </theorem> A trace and a model can have several possible alignments.", "In order to select the most appropriate one, we introduce a function that associate a {cost} to undesired moves - the ones associated with deviations.", "\\newline <theorem> Definition 21 (Cost of Alignment) Cost function $ \\delta\\in{A_{LM}}\\rightarrow\\mathrm{I\\kern-1.5ptN} $ assigns costs to legal moves.", "The {cost} of an alignment $ \\gamma\\in{A_{LM}}^{*} $ is the sum of all costs: $ \\delta(\\gamma)=\\sum_{(x,y)\\in\\gamma}\\delta(x,y) $ .", "\\newline </theorem> Moves where log and model agree have no costs, i.e., $ \\delta(x,(x,t))=0 $ for all $ x\\in A $ .", "Moves on model only have no costs if the transition is invisible, i.e., $ \\delta(\\gg,(\\tau,t))=0 $ if $ l(t)=\\tau $ .", "$ \\delta(\\gg,(x,t))>0 $ is the cost when the model makes an \u201c $ x $ move\u201d without a corresponding move of the log (assuming $ l(t)=x\\neq\\tau $ ).", "$ \\delta(x,\\gg)>0 $ is the cost for an \u201c $ x $ move\u201d only on the log.", "In this paper we often use a standard cost function $ \\delta_{S} $ that assigns unit costs: $ \\delta_{S}(x,(x,t))=0 $ , $ \\delta_{S}(\\gg,(\\tau,t))=0 $ , and $ \\delta_{S}(\\gg,(x,t))=\\delta_{S}(x,\\gg)=1 $ for all $ x\\in A $ .", "\\newline <theorem> Definition 22 (Optimal Alignment) Let $ L\\in{\\cal B}(\\mathcal{T}) $ be a certain event log and let $ \\mathit{SN}\\in{\\cal U}_{\\mathit{SN}} $ be a system net with $ \\phi(\\mathit{SN})\\neq\\emptyset $ .", "\\newline <list> \\ For $ \\sigma\\in L $ , we define: $ \\Gamma_{\\sigma,SN}=\\{\\gamma\\in{A_{LM}}^{*}\\mid\\exists_{\\sigma_{T}\\in\\phi_{f}(% \\mathit{SN})}\\ \\gamma\\ \\mathit{is}\\ \\mathit{an}\\ \\allowbreak\\mathit{alignment}% \\ \\mathit{of}\\ \\sigma\\ \\mathit{and}\\ \\sigma_{T}\\} $ .", "\\newline \\ \\ An alignment $ \\gamma\\in\\Gamma_{\\sigma,SN} $ is {optimal} for trace $ \\sigma\\in L $ and system net $ \\mathit{SN} $ if for any $ \\gamma^{\\prime}\\in\\Gamma_{\\sigma,SN} $ : $ \\delta(\\gamma^{\\prime})\\geq\\delta(\\gamma) $ .", "\\newline \\ \\ $ \\lambda_{SN}\\in\\mathcal{T}\\rightarrow{A_{LM}}^{*} $ is a deterministic mapping that assigns any trace $ \\sigma $ to an optimal alignment, i.e., $ \\lambda_{SN}(\\sigma)\\in\\Gamma_{\\sigma,SN} $ and $ \\lambda_{SN}(\\sigma) $ is optimal.", "\\newline \\ \\ $ \\mathit{costs}(L,\\mathit{SN},\\delta)=\\sum_{\\sigma\\in L}\\delta(\\lambda_{SN}(% \\sigma)) $ are the {misalignment costs} of the whole event log.", "\\newline \\ </list> $ \\sigma\\in L $ is a (perfectly) fitting trace for the system net $ \\mathit{SN} $ if and only if $ \\delta(\\lambda_{SN}(\\sigma))=0 $ .", "$ L $ is a (perfectly) fitting event log for the system net $ \\mathit{SN} $ if and only if $ \\mathit{costs}(L,\\mathit{SN},\\delta)=0 $ .", "\\newline </theorem> The technique to compute the optimal alignment [@bib:adriansyah2014aligning] is as follows.", "Firstly, it creates an {event net} , a sequence-structured system net able to replay only the trace to align.", "The transitions in the event net have labels corresponding to the activities in the trace.", "Then, a {product net} should be computed; it is the union of the event net and the model together with synchronous transitions added.", "These additional transitions are paired with transitions in the event net and in the process model that have the same label; they are then connected with arcs from the input places and to the output places of those transitions.", "The product net is able to represent moves on log, moves on model and synchronous moves by means of firing transitions: the transitions of the event net correspond to moves on log, the transitions of the process model correspond to moves on model, the added synchronous transitions correspond to synchronous moves.", "The union of the initial and final markings of the event net and the process model constitute respectively the initial and final marking of the product net: every complete firing sequence on the product net corresponds to a possible alignment.", "Lastly, the product net is translated to a state space, and a state space exploration via the $ \\mathbb{A}^{*} $ algorithm is performed in order to find the complete firing sequence that yields the lowest cost.", "\\newline Let us define formally the construction of the event net and the product net: \\newline <theorem> Definition 23 (Event Net) Let $ \\sigma\\in\\mathcal{T} $ be a certain trace.", "The {event net} $ \\mathit{en}:\\mathcal{T}\\to\\mathcal{U}_{SN} $ of $ \\sigma $ is a system net $ \\text{en}(\\sigma)=(P,T,F,l,M_{init},M_{final}) $ such that: \\newline <list> \\ $ P=\\{p_{i}\\mid 1\\leq i\\leq|\\sigma|+1\\} $ , \\newline \\ \\ $ T=\\{t_{i}\\mid 1\\leq i\\leq|\\sigma|\\} $ , \\newline \\ \\ $ F=\\bigcup_{1\\leq i\\leq}\\{(p_{i},t_{i}),(t_{i},p_{i+1})\\} $ \\newline \\ \\ $ l\\colon T\\to\\mathcal{U}_{A} $ such that for all $ 1\\leq i\\leq|\\sigma| $ , $ l(t_{i})=\\sigma[i] $ , \\newline \\ \\ $ M_{init}=\\{p_{1}\\} $ , \\newline \\ \\ $ M_{final}=\\{p_{|P|}\\} $ .", "\\newline \\ </list> \\newline </theorem> <theorem> Definition 24 (Product of two Petri Nets ) Let $ S_{1}=(P_{1},T_{1},F_{1},l_{1},M_{init_{1}},\\\\ M_{final_{1}}) $ and $ S_{2}=(P_{2},T_{2},F_{2},l_{2},M_{init_{2}},M_{final_{2}}) $ be two system nets.", "The {product net} of $ S_{1} $ and $ S_{2} $ is the system net $ S=S_{1}\\otimes S_{2}=(P,T,F,l,M_{init},M_{final}) $ such that: \\newline <list> \\ $ P=P_{1}\\cup P_{2} $ , \\newline \\ \\ $ T\\subseteq(T_{1}\\cup\\{\\gg\\}\\times T_{2}\\cup\\{\\gg\\}) $ such that $ T=\\{(t_{1},\\gg)\\mid t_{1}\\in T_{1}\\}\\cup\\{(\\gg,t_{2})\\mid t_{2}\\in T_{2}\\}\\cup% \\{(t_{1},t_{2})\\in(T_{1}\\times T_{2})\\mid l_{1}(t_{1})=l_{2}(t_{2})\\neq\\tau\\} $ , \\newline \\ \\ $ F\\subseteq(P\\times T)\\cup(T\\times P) $ such that $ F=\\{(p,(t,\\gg))\\mid p\\in P_{1}\\wedge t\\in T_{1}\\wedge(p,t)\\in F_{1}\\}\\cup\\\\ \\{((t,\\gg),p)\\mid t\\in T_{1}\\wedge p\\in P_{1}\\wedge(t,p)\\in F_{1}\\}\\cup\\\\ \\{(p,(t,\\gg))\\mid p\\in P_{2}\\wedge t\\in T_{2}\\wedge(p,t)\\in F_{2}\\}\\cup\\\\ \\{((t,\\gg),p)\\mid t\\in T_{2}\\wedge p\\in P_{2}\\wedge(t,p)\\in F_{2}\\}\\cup\\\\ \\{(p,(t_{1},t_{2}))\\mid p\\in P_{1}\\cup P_{2}\\wedge(t_{1},t_{2})\\in T\\cap(T_{1}% \\times T_{2})\\}\\cup\\\\ \\{((t_{1},t_{2}),p)\\mid p\\in P_{1}\\cup P_{2}\\wedge(t_{1},t_{2})\\in T\\cap(T_{1}% \\times T_{2})\\} $ \\newline \\ \\ $ l\\colon T\\to\\mathcal{U}_{A} $ such that for all $ (t_{1},t_{2})\\in T $ , $ l((t_{1},t_{2}))=l_{1}(t_{1}) $ if $ t_{2}=\\gg $ , $ l((t1,t2))=l_{2}(t_{2}) $ if $ t_{1}=\\gg $ , and $ l((t_{1},t_{2}))=l_{1}(t_{1}) $ otherwise, \\newline \\ \\ $ M_{init}=M_{init_{1}}\\uplus M_{init_{2}} $ , \\newline \\ \\ $ M_{final}=M_{final_{1}}\\uplus M_{final_{2}} $ .", "\\newline \\ </list> \\newline </theorem>  </section>"], ["<section> <title> 4 Uncertainty in Process Mining </title>  <theorem> Definition 25 (Determinate and indeterminate event qualifiers) Let $ \\mathcal{U}_{O}=\\{!,?\\} $ , where the \u201c!\u201d symbol denotes {determinate events} , and the \u201c?\u201d symbol denotes {indeterminate events} .", "\\newline </theorem> <theorem> Definition 26 (Uncertain events) Let us denote $ \\mathcal{E}_{S}=\\mathcal{U}_{E}\\times\\mathcal{P}_{NE}(\\mathcal{U}_{C})\\times% \\mathcal{P}_{NE}(\\mathcal{U}_{A})\\times\\mathcal{P}_{NE}(\\mathcal{U}_{T})\\times% \\mathcal{U}_{O} $ the universe of {strongly uncertain events} .", "$ \\mathcal{E}_{W}=\\{(e,f)\\in\\mathcal{U}_{E}\\times(\\mathcal{U}_{C}\\times\\mathcal{% U}_{A}\\times\\mathcal{U}_{T}\\not\\to[0,1])\\mid\\sum_{(a,c,t)\\in dom(f)}f(c,a,t)% \\leq 1\\} $ is the universe of {weakly uncertain events} .", "Over a strongly uncertain event $ (e,c_{s},a_{s},t_{s},o)\\in\\mathcal{E}_{S} $ we define the following projection functions: $ \\pi^{\\mathcal{E}_{S}}_{c}(e)=c_{s} $ , $ \\pi^{\\mathcal{E}_{S}}_{a}(e)=a_{s} $ , $ \\pi^{\\mathcal{E}_{S}}_{t}(e)=t_{s} $ and $ \\pi^{\\mathcal{E}_{S}}_{o}(e)=o $ .", "We opmit the superscript $ \\mathcal{E}_{S} $ from the projection functions if it is clear from the context.", "\\newline </theorem> Now that the definitions of strongly and weakly uncertain events are structured, let us aggregate them in uncertain event logs.", "\\newline <theorem> Definition 27 (Event logs) A {strongly uncertain event log} is a set of events $ L_{S}\\subseteq\\mathcal{E}_{S} $ such that every event identifier in $ L_{S} $ is unique.", "A {weakly uncertain event log} is a set of events $ L_{W}\\subseteq\\mathcal{E}_{W} $ such that every event identifier in $ L_{W} $ is unique.", "\\newline </theorem> A weakly uncertain event log $ L_{W}\\subseteq\\mathcal{E}_{W} $ has a corresponding strongly uncertain event log $ \\overline{L_{W}}=L_{S}\\subseteq\\mathcal{E}_{S} $ such that $ L_{S}=\\{(e,c_{s},a_{s},t_{s},o)\\in\\mathcal{E}_{S}\\mid\\exists_{(e^{\\prime},f)% \\in L_{W}}e=e^{\\prime}\\wedge\\\\ c_{s}=\\{c\\in\\mathcal{U}_{C}\\mid\\exists_{a,t}((c,a,t)\\in dom(f)\\wedge f(c,a,t)>% 0)\\}\\wedge\\\\ a_{s}=\\{a\\in\\mathcal{U}_{A}\\mid\\exists_{c,t}((c,a,t)\\in dom(f)\\wedge f(c,a,t)>% 0)\\}\\wedge\\\\ t_{s}=\\{t\\in\\mathcal{U}_{T}\\mid\\exists_{c,a}((c,a,t)\\in dom(f)\\wedge f(c,a,t)>% 0)\\}\\wedge\\\\ (o=\\>!\\Leftrightarrow\\sum_{(c,a,t)\\in dom(f)}f(c,a,t)=1\\wedge\\\\ (o=\\>?\\Leftrightarrow\\sum_{(c,a,t)\\in dom(f)}f(c,a,t)<1\\} $ .", "\\newline <theorem> Definition 28 (Realization of an event log) $ L_{C}\\subseteq\\mathcal{E}_{C} $ is a {realization} of $ L_{S}\\subseteq\\mathcal{E}_{S} $ if and only if: \\newline <list> \\ For all $ (e,c,a,t)\\in L_{C} $ there is a distinct $ (e^{\\prime},c_{s},a_{s},t_{s},o)\\in L_{S} $ such that $ e^{\\prime}=e $ , $ a\\in a_{s} $ , $ c\\in c_{s} $ and $ t\\in t_{s} $ ; \\newline \\ \\ For all $ (e,c_{s},a_{s},t_{s},o)\\in L_{S} $ with $ o=\\>!", "$ there is a distinct $ (e^{\\prime},c,a,t)\\in L_{C} $ such that $ e^{\\prime}=e $ , $ a\\in a_{s} $ , $ c\\in c_{s} $ and $ t\\in t_{s} $ .", "\\newline \\ </list> $ \\mathcal{R}_{L}(L_{S}) $ is the set of all such realizations of the log $ L_{S} $ .", "\\newline </theorem> Note that these definitions allow us to transform a weakly uncertain log into a strongly uncertain one, and a strongly uncertain one in a set of certain logs.", "\\newline The types of uncertainty in the specific scenario we consider in this paper includes: \\newline <list> \\ Strong uncertainty on the activity; \\newline \\ \\ Strong uncertainty on the timestamp; \\newline \\ \\ Strong uncertainty on indeterminate events.", "\\newline \\ </list> All three can happen concurrently."]], "target": "Table shows such a trace, which we will use as running example. It is worth noticing that the specific case of uncertainty on the case ID causes a problem; since an event can have many possible case IDs, it can belong to different traces. In data format where the events are already aggregated into traces, such as the very common XES standard, this means that the information related to a trace can be {non-local} to the trace itself, but can be stored in some other points of the log. We will focus on the problem of uncertainty on the case ID attribute in a future work."}, {"tabular": ["  Function  &  Details  &  Kernel  &  Channels <ln> (Input, Output) ", " $ \\mathcal{F}_{head} $  &  Convolution  &  $ 3\\times 3 $  &  (3, 32) ", " $ \\mathcal{F}_{skip} $  &  Convolution  &  $ 3\\times 3 $  &  (3, $ p*p*3 $ ) ", " PixelShuffle  &  -  &  - ", " $ \\mathcal{F}^{i}_{proj} $  &  Convolution  &  $ 1\\times 1 $  &  ( $ i*32 $ , 32) ", " $ \\mathcal{F}^{i}_{att} $  &  Adaptive AvgPool  &  -  &  - ", " Convolution  &  $ 1\\times 1 $  &  (32, 32) ", " ReLU  &  -  &  - ", " Convolution  &  $ 1\\times 1 $  &  (32, 32) ", " Sigmoid  &  -  &  - ", " $ \\mathcal{F}^{i}_{res} $  &  Convolution  &  $ 3\\times 3 $  &  (32, 128) ", " ReLU  &  -  &  - ", " Convolution  &  $ 3\\times 3 $  &  (128, 32) ", " $ \\mathcal{F}_{tail} $  &  Convolution  &  $ 3\\times 3 $  &  (32, $ p*p*3 $ ) ", " PixelShuffle  &  -  &  -  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Convolutional neural network (CNN) has been widely used for single image super-resolution (SISR) since the debut of SRCNN [@bib:SRCNN] .", "Most of the CNN-based SISR models [@bib:VDSR,EDSR,SRDensenet,WDSR,WangmenZuo,RCAN] are deep and large.", "However, in the real world, the models often need to be run efficiently in embedded system like mobile phone with limited computational resources [@bib:chen,videoenhancement1,medical1,medical2,tracking2,monitoring] .", "Thus, those methods are not proper for many practical SISR applications, and lightweight networks have been becoming an important way for practical SISR.", "Also, the model compression techniques can be used in lightweight architecture to further reduce the parameters and computation.", "However, before using model compression techniques (e.g. model pruning), it is time-consuming to train a large model and it also occupies more memory.", "This is unrealistic for some low budget devices, so CNN-based lightweight SISR methods become increasingly popular because it can be regarded as an image preprocessing or postprocessing instrument for other tasks [@bib:CSL,surrounding,shen2019deep,scrdet,learning] .", "\\newline One typical strategy is to reduce the parameters [@bib:FSRCNN,DRCN,ESPCN,DRRN] .", "Moreover, the network architecture is essential for lightweight SISR models.", "Generally, methods of designing architectures can be categorized into two groups.", "One is based on neural architecture search.", "MoreMNA-S and FALSR [@bib:FALSR,MoreMNAS] adopt the evolutionary algorithm to search efficient model architectures for lightweight SISR.", "The other is to design the models manually [@bib:AWSRN,FC2N] .", "These methods all utilize features of previous layers to better learn the features of the current layer, which reflect that auxiliary features can boost the performance of lightweight models.", "However, these methods do not fully use all the features of previous layers, which possibly limits the performance.", "\\newline Directly combining the auxiliary features with current features is conceptually problematic as features of different layers are often embedded in different space.", "Thus, we use the projection unit to project the auxiliary features to a common space that is suitable for fusing features.", "After projected to a common space, these projected features may not be all useful for learning features of the current layer.", "So we adopt the channel attention to make the model automatically assign the importance to different channels.", "The projection unit and channel attention constitute the proposed attentive auxiliary feature block.", "We term our model that consists of A ttentive A uxiliary F eature blocks as A $ ^{2} $ F since it utilizes the auxilary features and the attention mechanism.", "Figure [@ref:LABEL:effComp] gives the comparison between different models on Manga109 [@bib:Manga109] dataset with a upscale factor of 2.", "As shown in Figure [@ref:LABEL:effComp] , models of our A $ ^{2} $ F family can achieve better efficiency than current SOTA methods [@bib:AWSRN,FC2N] .", "Figure [@ref:LABEL:netArch] describes the architecture of A $ ^{2} $ F with four attentive auxiliary feature blocks.", "Our main contributions are given below: \\newline <list> \\ We handle the super resolution task from a new direction, which means we discuss the benefit brought by auxiliary features in the view of how to recover multi-frequency through different layers.", "Thus, we propose the attentive auxiliary feature block to utilize auxiliary features of previous layers for facilitating features learning of the current layer.", "The mainstay we use the channel attention is the dense auxiliary features rather than the backbone features or the sparse skip connections, which is different from other works.", "\\newline \\ \\ Compared with other lightweight methods especially when the parameters are less than 1000K, we outperform all of them both in PSNR and SSIM but have fewer parameters, which is an enormous trade-off between performance and parameters.", "In general, A $ ^{2} $ F is able to achieve better efficiency than current state-of-the-art methods [@bib:FC2N,AWSRN,SRFBN] .", "\\newline \\ \\ Finally, we conduct a thorough ablation study to show the effectiveness of each component in the proposed attentive auxiliary feature block.", "We release our PyTorch implementation of the proposed method and its pretrained models together with the publication of the paper.", "\\newline \\ </list> \\newline  </section>"], ["<section> <title> 2 Related Work </title>  Instead of powerful computers with GPU, embedded devices usually need to run a super resolution model.", "As a result, lightweight SR architectures are needed and have been recently proposed.", "\\newline One pioneering work is SRCNN [@bib:SRCNN] which contains three convolution layers to directly map the low-resolution (LR) images to high-resolution (HR) images.", "Subsequently, a high-efficiency SR model named ESPCNN [@bib:ESPCN] was introduced, which extracts feature maps in LR space and contains a sub-pixel convolution layer that replaces the handcrafted bicubic filter to upscale the final LR map into the HR images.", "DRRN [@bib:DRRN] also had been proposed to alleviate parameters by adopting recursive learning while increasing the depth.", "Then CARN [@bib:CARN] was proposed to obtain an accurate but lightweight result.", "It addresses the issue about heavy computation by utilizing the cascading mechanism for residual networks.", "More recently, AWSRN [@bib:AWSRN] was designed to decrease the heavy computation.", "It applies the local fusion block for residual learning.", "For lightweight network, it can remove redundancy scale branches according to the adaptive weights.", "\\newline Feature fusion has undergone its tremendous progress since the ResNet [@bib:Resnet] was proposed, which implies the auxiliary feature is becoming the crucial aspect for learning.", "The full utilization of the auxiliary feature was adopted in DenseNet [@bib:densenet] .", "The authors take the feature map of each former layer into a layer, and this alleviates the vanishing gradient problem.", "SR methods also make use of auxiliary features to improve performance, such as [@bib:VDSR,DRRN,MemNet,RCAN,RDN] .", "The local fusion block of AWSRN [@bib:AWSRN] consists of concatenated AWRUs and a LRFU.", "Each output of AWRUs is combined one by one, which means a dense connection for a block.", "A novel SR method called FC $ ^{2} $ N was presented in [@bib:FC2N] .", "A module named GFF was devised through implementing all skip connections by weighted channel concatenation, and it also can be considered as the auxiliary feature.", "\\newline As an important technique for vision tasks, attention mechanism [@bib:attention] can automatically determine which component is important for learning.", "Channel attention is a type of attention mechanism, which concentrates on the impact of each feature channel.", "SENet [@bib:SENet] is a channel attention based model in the image classification task.", "In the domain of SR, RCAN [@bib:RCAN] had been introduced to elevate SR results by taking advantage of interdependencies among channels.", "It can adaptively rescale features according to the training target.", "\\newline In our paper, auxiliaty features are not fully-dense connections, which indicates it is not dense in one block.", "We expect that each block can only learn to recover specific frequency information and provide auxiliary information to the next block.", "There are two main differences compred with FC $ ^{2} $ N and AWSRN.", "One is that for a block of A $ ^{2} $ F, we use the features of ALL previous blocks as auxiliary features of the current block, while FC $ ^{2} $ N and AWSRN use the features of a FIXED number of previous blocks.", "The second is that we adopt channel attention to decide how to transmit different informations to the next block, but the other two works do not adopt this mechanism.", "\\newline  </section>"], ["<section> <title> 3 Proposed Model </title>  <subsection> <title> 3.1 Motivation and Overview </title> Our method is motivated by an interesting fact that many CNN based methods [@bib:CARN,EDSR,FC2N] can reconstruct the high frequency details from the low resolution images hierachically, which indicates that different layers learn the capacity of recovering multi-frequency information.", "However, stacking more layers increases the computation burden and higher frequency information is difficult to regain.", "So we aim to provide a fast, low-parameters and accurate method that can restore more high frequency details on the basis of ensuring the accuracy of low frequency information reconstruction.", "According to this goal, we have the following observations: \\newline <list> \\ To build a lightweight network, how to diminish parameters and the multiply operation is essential.", "Generally, we consider reducing the depth or the width of the network, performing upsampling operation at the end of the network and adopting small kernel to reach this target.", "It also brings a new issue that a shallow network (i.e. fewer layers and fewer channels in each layer) can not have an excellent training result due to the lower complexity of the model, which also can be considered as an under-fitting problem.", "\\newline \\ \\ For the limited depth and width of the network, feature reusing is the best way to solve the issue.", "By this way, the low-frequency information can be transmitted to the next layer easily and it is more useful to combine multi-level low-frequency features to obtain accurate high-frequency features.", "Thus, more features benefitting to recover high-frequency signal will circulate across the entire network.", "It will promote the capacity of learning the mapping function if the network is shallow.", "\\newline \\ \\ We also consider another problem that the impact of multi-frequency information should be different when used for the learning of high frequency features.", "As the depth of the layer becomes deeper, effective information of the last layer provided for current layer is becoming rarer, because the learning of high frequency features is more and more difficult.", "So how to combine the information of all the previous layers to bring an efficient result is important and it should be dicided by the network.", "\\newline \\ </list> \\newline Based on these observations, we design the model by reusing all features of the preceding layers and then concating them directly along channels like [@bib:densenet] in a block.", "Meanwhile, to reduce the disturbance brought by the redundant information when concating all of channels and adaptively obtain the multi-frequency reconstruction capability of different layers, we adopt the same-space attention mechanism in our model, which can avoid the situation that features from different space would cause extraodinary imbalance when computing the attention weight.", "\\newline </subsection> <subsection> <title> 3.2 Overall Architecture </title> As shown in Figure [@ref:LABEL:netArch] , the whole model architecture is divided into four components: head module, nonlinear mapping, skip module and tail module."]], "target": "Detailed configuration of each component can be seen in Table . We denote the low resolution and the predicted image as $ I_{LR} $ and $ I_{SR} $ , respectively. The input is first processed by the head module $ \\mathcal{F}_{head} $ to get the features $ x_{0} $ :"}, {"tabular": ["    &    &  Features ", "  &    &  $ f_{1} $  &  $ f_{2} $  &  $ f_{3} $  &  $ f_{4} $ ", " Products  &  $ P_{1} $  &  $ \\times $  &  $ \\times $  &  $ \\times $  &  ", " $ P_{2} $  &  $ \\times $  &  $ \\times $  &    &  $ \\times $ ", " $ P_{3} $  &  $ \\times $  &    &  $ \\times $  &    "], "ref_sec": [["<section> <title> I Introduction </title>  A {Software Product Line} (SPL) \u201cis a set of software-intensive systems that share a common, managed set of features satisfying the specific needs of a particular market segment or mission and that are developed from a common set of core assets in a prescribed way\u201d [@bib:clements-pl] .", "Features are thus the key to the discrimination of SPL members by showing their commonalities and differences.", "Features are often organized in a {Feature Model} (FM) [@bib:BenavidesSC10,Kang:1990:FODA] which represents all the possible products of the SPL by expressing relationships and constraints between features.", "Henceforth, we consider a {product} to be a combination of features conforming to the constraints of the FM.", "\\newline Testing an SPL is an inherently difficult activity [@bib:springerlink:10.1007/978-3-642-14335-9_4] .", "Although testing all the products would be ideal, it is rarely feasible in practice.", "Indeed, the number of possible configurations (i.e. the products) induced by a given FM usually grows exponentially with the number of features, quickly leading to millions of possible products to test.", "As a result, test engineers are seeking for solutions to reduce the size of their test suites so that they can meet release deadlines and cost constraints.", "\\newline Previous work [@bib:Cohen97theaetg,Kuhn04] has identified Combinatorial Interaction Testing (CIT) as a relevant approach to reduce the number of products for testing.", "CIT is a systematic approach for sampling large domains of test data.", "It is based on the observation that most of the faults are triggered by the interactions between a small number of variables.", "For example, Kuhn et al. [@bib:Kuhn04] have shown that 2-wise or pairwise interactions are able to disclose 80% of the bugs.", "In some cases, higher interaction strengths ( $ t $ -wise in general) may be needed [@bib:10.1109/MITP.2008.54] .", "Recently, such approaches have been adapted to SPL testing [@bib:Oster:2010:AIP:1885639.1885658,Perrouin2011,Johansen:2011:PRF:2050655.2050721] , generating products from the FM covering all the valid (with respect to the FM constraints) pairwise combinations of features.", "Some of them, like [@bib:Johansen:2011:PRF:2050655.2050721] , also cover $ t $ -wise .", "\\newline However, computing all $ t $ -wise interactions in the presence of constraints, as it is the case for FMs, is known to be NP-complete in the general case [@bib:Johansen:2011:PRF:2050655.2050721,Perrouin:2010:AST:1828417.1828490] .", "As a result, although $ t $ -wise generation techniques from FMs have greatly improved, now relying on efficient satisfiability (SAT) solvers [@bib:johansen12] , higher interaction strengths ( $ t>2 $ ) may remain inaccessible for large FMs.", "This is particularly problematic since 3-wise interactions were shown to commonly appear in SPL testing practice [@bib:DBLP:conf/vamos/SteffensOLF12] .", "Since such an exact computation may remain out of reach, one may ask if it is possible to cope with these difficult situations: \\newline [RQ1] Can we mimic $ t $ -wise test generation, partially but efficiently while achieving decent coverage? \\newline While $ t $ -wise testing drastically reduces the number of products to consider, this number may still be too high to fit the budget allocated for SPL testing.", "For example, 2-wise coverage for the Linux FM (over 6,000 features) already requires 480 products to be tested [@bib:johansen12] .", "Therefore, being able to prioritize the test suite with the most relevant products is critical.", "In this paper, the most relevant products are those that exhibit the highest number of $ t $ feature interactions.", "The process of identifying these products is referred to as test prioritization.", "This forms our second research question: \\newline [RQ2] What are the most relevant products and how to prioritize them? \\newline To answer RQ1, we introduce a similarity heuristic [@bib:hemmati10] given in the form of a fitness function.", "We assess the suitability of the function to characterize $ t $ -wise coverage of a given test suite.", "The intuitive idea underlying this approach is: the more different the products (in terms of selected or unselected features), the more likely their ability to cover different $ t $ -wise interactions.", "We provide a search-based strategy to generate valid sets of products (i.e. respecting the constraints of the FM) for $ t $ -wise testing.", "\\newline To answer RQ2, we first consider that the most important products are those covering the most $ t $ -wise interactions.", "Indeed, they can potentially reveal more bugs as they test more feature interactions.", "We then introduce two prioritization algorithms, named {Greedy} and {Near Optimal} .", "\\newline Our approach introduces significant flexibility in the testing process: the number of products that can be tested (i.e. fitting the budget) can be specified as well as the time allowed for generating them.", "The use of similarity has the following two advantages.", "First, it is very fast to compute.", "Second, it is independent of the $ t $ value.", "This implies that there is no need to compute and enumerate the huge number of combinations involved in the $ t $ feature interactions.", "The applicability of the proposed strategies is evaluated on both real and generated FMs.", "This holds even for the largest FM, which contains over 6,000 features.", "The experimental data and the implementation are publicly available at http://research.henard.net/SPL/ .", "\\newline The remainder of this paper is organized as follows: Sections [@ref:LABEL:sBg] and [@ref:", "LABEL:sSim] introduce the context and the concepts underlying the proposed approaches.", "Sections [@ref:LABEL:sPrio] and [@ref:LABEL:sSb] respectively detail the product prioritization and generation techniques.", "Section [@ref:LABEL:sStudy] reports on the empirical study.", "Finally, Section [@ref:LABEL:sRw] discuss related work before Section [@ref:LABEL:sConcl] concludes the paper.", "\\newline  </section>"], ["<section> <title> II Background </title>  <subsection> <title> II-A SPL Products as Test Cases </title> In this work, we focus on a model-based testing of SPLs where the variability model is an FM.", "In this context, one product (an abstract test case) is represented as a set of $ n $ features of an FM as $ P=\\{\\pm f_{1},...,\\pm f_{n}\\} $ , where $ +f_{i} $ indicates a feature which is selected by this product, and $ -f_{i} $ an unselected one.", "Table [@ref:LABEL:products_example] illustrates an example of three products and four features.", "For instance, product $ P_{1}=\\{+f_{1},+f_{2},+f_{3},-f_{4}\\} $ supports all the features except $ f_{4} $ .", "\\newline </subsection> <subsection> <title> II-B T-wise Testing and Coverage </title> T-wise testing focuses on the interactions between any $ t\\geq 2 $ features of an SPL [@bib:Perrouin:2010:AST:1828417.1828490] .", "Such an interaction is called a $ t $ -set.", "It is noted that unselected features are also involved in such interactions."]], "target": "For instance, with reference to Table , $ (+f_{1},-f_{2},-f_{4}) $ is a 3-set covered by $ P_{3} $ . The ability of a given test suite to find bugs (i.e. its fault detection power) can be estimated by the number of $ t $ -sets covered by the products of the test suite and is called $ t $ -wise coverage. In this context, $ V_{t} $ denotes the set of all the valid $ t $ -sets of a given FM, implying that all the $ t $ -sets containing incompatible features, the $ t $ -sets where a given feature is both selected and unselected or the $ t $ -sets violating the constraints are excluded. More formally, $ V_{t} $ can be expressed as:"}, {"tabular": ["  Testing View  &  Training View ", " (1,2,3)  &  (2,3)  &  $ 3\\choose 2 $ (1,2,3) ", " (1,2,3)  &  67.36  &  78.06  &  83.79 ", " (1,2)  &  62.88  &  62.0  &  80.44 ", " (2,3)  &  65.96  &  69.6  &  80.67 ", " (1,3)  &  62.01  &  63.1  &  80.09 ", " $ 3\\choose 2 $ (1,2,3)  &  63.13  &  64.93  &  79.67 ", " (1)  &  57.28  &  59.8  &  77.26 ", " (2)  &  56.16  &  59.7  &  74.17 ", " (3)  &  55.25  &  58.4  &  72.23  "], "ref_sec": [["<section> <title> 1 Introduction </title>  In recent years, we have seen some success in the research on video synthesis.", "The proposed methods are mainly focused on future frame prediction [@bib:mathieu2015deep,babaeizadeh2017stochastic,byeon2018contextvp] , future clip prediction [@bib:vondrick2016generating,xiong2017learning,kratzwald2017towards] , or conditioned video generation [@bib:tulyakov2017mocogan,baddar2017dynamics,spampinato2018vos,saito2017temporal] .", "The future frame/clip prediction methods can synthesize frames from near future in the video with some realism.", "The video generation works mainly leverage the Generative Adversarial Network [@bib:goodfellow2014generative] for realistic video synthesis based on some conditioning.", "All of these methods tackle the problem of video synthesis from a single viewpoint and focus on the time dimension of the video.", "However, wouldn\u2019t be interesting if we can bring in the notion of viewpoint into video synthesis as well? This is what we address in this paper.", "The diversity in a scene and objects dynamics, along with camera motion, makes video synthesis of real-world scenarios a very challenging problem.", "Adding the notion of viewpoint makes it even more difficult, as the observed video of the same scene and dynamics will vary from one viewpoint to another.", "Historically, view-point in-variance has been a very active research area in computer vision, and is currently also important from the perspective of representation learning.", "There have been some work in view-aware image synthesis [@bib:regmi2018cross,eslami2018neural] , where given images captured from different views one can synthesize an image from an unseen view.", "Most intriguing recent work in this area is by Eslami et.", "al [@bib:eslami2018neural] , who proposed a simple neural network approach for rendering images from unseen views for synthetic data.", "However, to the best of our knowledge, the problem of view-aware video synthesis has not been addressed yet.", "Inspired by Eslami et.", "al [@bib:eslami2018neural] , in this paper, we explore generalization of their idea to video and propose time-aware and view-aware video rendering for real-world videos instead of synthetic images.", "The proposed framework, shown in Figure [@ref:LABEL:fig1] , takes multiple video clips from varying view-points and times as input, and renders a video from a given an arbitrary viewpoint and time.", "The learned representation has an understanding of temporal and view-point significance of the input videos.", "The ability of the network to render a video from any given viewpoint and time, enables the network to learn a robust view and time aware representation, which can be employed for view-invariant activity classification.", "We make the following contributions in this paper.", "We introduce a novel view and time-aware video rendering problem and propose an unsupervised representation learning framework to solve this.", "The proposed framework bears an understanding of time and view-point and therefore the learned representation can be used to generate videos from arbitrary given viewpoint and time.", "We also demonstrate the effectiveness of the proposed framework for future video prediction.", "We further validate the robustness of the learned representation for view-invariant action classification, where we observe a significant improvement ( $ \\sim 26\\% $ ) in the performance, when compared with the state-of-the art methods on NTU-RGB+D dataset using RGB modality.", "\\newline  </section>"], ["<section> <title> 2 Related Work </title>  The research in image synthesis [@bib:mirza2014conditional,gregor2015draw,wang2017high] has recently seen a great progress, and it is mainly attributed to the success of Generative Adversarial Networks (GAN) [@bib:goodfellow2014generative] .", "This includes methods for generating high-resolution images [@bib:ledig2017photo,wang2017high] along with image-to-image translation [@bib:zhu2017unpaired,liu2017unsupervised,choi2017stargan] .", "However, video synthesis is still a landmark challenge and the research is in preliminary stage.", "Our work is closely related to the research in video synthesis, which explores future frame prediction [@bib:mathieu2015deep,babaeizadeh2017stochastic,byeon2018contextvp] , future clip prediction [@bib:xiong2017learning,kratzwald2017towards] , and conditioned video generation [@bib:vondrick2016generating,tulyakov2017mocogan,baddar2017dynamics,spampinato2018vos,saito2017temporal] .", "In one of the early attempts on video prediction, the authors in [@bib:mathieu2015deep] proposed a GAN based approach for next-frame prediction, where they explore different types of loss functions along with adversarial loss.", "Similarly, the authors in [@bib:vondrick2016generating,baddar2017dynamics,xiong2017learning,kratzwald2017towards,tulyakov2017mocogan,saito2017temporal,spampinato2018vos] explored the GAN framework for video synthesis, where they focus on future frame prediction and conditional video generation.", "The authors in [@bib:babaeizadeh2017stochastic] recently proposed a variational latent space learning framework for video synthesis, and similarly the authors in [@bib:byeon2018contextvp] also explored a recurrent approach for next frame prediction.", "Our work is distinctly different from these approaches as we have a notion of viewpoint, which has not been addressed earlier .", "Apart from this, our proposed method is time-aware, and therefore given a single-view video it can also be used for future frame prediction.", "In addition, our work is also related to unsupervised video representation learning [@bib:srivastava2015unsupervised,Wang_2015_ICCV,goyal2017nonparametric] .", "The research in unsupervised video representation learning mainly focuses on encoder-decoder [@bib:kingma2013auto] kind of networks, where the decoder is used for reconstruction of the input video.", "The authors in [@bib:srivastava2015unsupervised] proposed a recurrent network for both encoding and decoding which was based on LSTM.", "Similarly, the authors in [@bib:goyal2017nonparametric] proposed to learn a latent distribution instead of encoding for video representation.", "Our approach resembles to these methods as we also learn a representation.", "However, instead of learning a representation for a single video, we learn a representation for the whole scene and its dynamics captured from different viewpoints.", "Also, instead of trying to generate the input video, we aim to generate a video from a different viewpoint and time.", "Cross-view synthesis of data is an interesting problem, which can have multiple applications including view-invariant representation learning.", "There are some existing works focusing on this problem for image synthesis [@bib:regmi2018cross,eslami2018neural] .", "In [@bib:rahmani20163d] , the authors proposed a GAN based approach, where they perform a image-to-image translation from aerial to ground view images.", "In [@bib:eslami2018neural] , the authors proposed a scene representation learning framework where a representation is learned for a scene and a view of the same scene is generated from a different viewpoint.", "However, there has been no work in cross-view video synthesis.", "Our work is inspired from [@bib:eslami2018neural] , which was mainly focused on synthetic images and we generalize it to real-world videos .", "Apart from this, we also propose the notion of time awareness in the viewpoint which is intuitive from the perspective of videos.", "We demonstrate the effectiveness of the learned representation for view-invariant activity classification.", "It is an active research topic in computer vision community [@bib:shahroudy2018deep] and most of the existing works are focused on multiple modalities, such as depth [@bib:10.1007/978-3-319-46448-0_32] and pose [@bib:shahroudy2016ntu] , besides RGB data [@bib:luo2017unsupervised,li2018unsupervised] .", "We mainly focus on RGB modality and present a comparison with existing works.", "\\newline  </section>"], ["<section> <title> 3 Method </title>  Following pioneering work of Eslami et.", "al [@bib:eslami2018neural] , the proposed method consists of two components, a representation learning network, $ f $ (RL-NET), and a video rendering network, $ g $ (VR-NET).", "The RL-NET takes multiple video clips captured from varying viewpoints and time of an event termed as observations $ o_{i}=\\{(x_{i}^{k},v_{i}^{k},t_{i})\\}_{k=1,2,...,K} $ , where, $ x_{i}^{k} $ represents $ k^{th} $ video clip captured from viewpoint $ v_{i}^{k} $ and time $ t_{i} $ for any event $ i $ .", "The RL-NET take these observations and learns a comprehensive representation, $ r_{i} $ , of the event with the help of Blending Network (BL-NET), preserving the view and time notion.", "BL-NET is a recurrent network maintaining an internal representation, which is updated as more observations are seen by the network before providing a holistic representation $ r $ of the scene and its dynamics.", "The VR-NET, then, use this representation, $ r $ , along with stochastic latent variables, $ z $ , to render a video clip from an arbitrary viewpoint, $ v_{i}^{k} $ , and time, $ t_{i} $ .", "Formally, we can define the representation learning as, $ r_{i}=f_{\\theta}(o_{i}) $ , and the video rendering network as, \\newline <equation> $ g_{\\theta}(x|v^{q},t^{q},r)=\\int g_{\\theta}(x,z|v^{q},t^{q},r)dz, $ </equation> where, $ g_{\\theta}(x|v^{q},t^{q},r) $ represents a probability density of a video $ x $ observed from a viewpoint $ v^{q} $ at time $ t^{q} $ , for a scene with representation $ r $ and latent variable $ z $ .", "We train the two networks, RL-NET and VR-NET, jointly in an end-to-end fashion to maximize the likelihood of rendering the ground-truth video, observed from the query viewpoint and timestep.", "A detailed overview of the proposed framework is shown in Figure [@ref:LABEL:fig1bf] .", "\\newline <subsection> <title> 3.1 Representation Learning Network (RL-NET) </title> We use a convolution based neural network to learn the scene representation.", "RL-NET is shown in Figure [@ref:LABEL:fig1bf] C, the input consists of multiple video clips along with view-point and time conditioning.", "The view-point and time conditioning is applied on encodings generated after few convolutions on input clip.", "We use concatenation of viewpoint, and time with the convolution features from the video for conditioning.", "It is followed by some more convolution layers.", "The final encodings from each observation are then combined together to learn a unified scene and dynamics representation, $ r $ , using a blending network.", "The encoding network is shared among all the observations.", "We explore both 2D and 3D convolution based networks, with conditioning as additional input and generate an encoding for each observation.", "The learned encodings are, then, used to learn the scene representation, $ r $ , with size, $ (X,Y,Z) $ (Figure [@ref:LABEL:fig1bf] .E).", "The scene representation is learned using a convolutional recurrent network (BL-NET), which accumulates information from all the observations effectively (Figure [@ref:LABEL:fig1bf] .E).", "The work in [@bib:eslami2018neural] proposed a simple addition of encodings to learn the scene representation.", "We propose a recurrent network , instead, which we found more effective both in terms of performance and training efficiency.", "\\newline <paragraph> <title> Blending Network (BL-NET) </title> We want to learn a representation which holistically represents the scene, and its dynamics as viewed from varying viewpoints.", "We propose a recurrent network which updates its representation after looking at each observation (Figure [@ref:LABEL:fig1bf] E).", "More specifically, we utilize an LSTM architecture [@bib:gers1999learning] , where the memory cell, $ c $ , acts as an accumulator of state information and is updated by the input ( $ i $ ), output ( $ o $ ) and forget ( $ f $ ) gates, which are self-parameterized controlling gates.", "The order in which the observations are seen by the cell should not have any role in the learned representation, therefore we propose to use bi-directional layers [@bib:schuster1997bidirectional] in the network for a more effective learning.", "Also, to preserve the spatial information in the embeddings, we make use of convolutional LSTM [@bib:xingjian2015convolutional] .", "For a given video embedding, $ e_{i} $ , after seeing all other observations in a forward and a backward pass, we get an updated hidden representation $ h^{r}_{i} $ .", "\\newline <equation> $ h^{r}_{i}=(o_{i}^{f}\\circ\\tanh(c_{i}^{f}))^{\\frown}(o_{i}^{b}\\circ\\tanh(c_{i}^% {b})).", "$ </equation> Here, $ o_{i}^{f} $ and $ o_{i}^{b} $ are the output gates of the forward pass and backward pass respectively, $ c_{i}^{f} $ and $ c_{i}^{b} $ are the corresponding memory cell states, $ \\circ $ denotes the Hadamard product, and $ ^{\\frown} $ denotes a concatenation operation between learned representations from the forward and backward pass.", "The updated intermediate representation from each observation is then passed to a uni-directional LSTM layer, which accumulates these to get a holistic representation $ r $ .", "\\newline <equation> $ r=o_{n}\\circ\\tanh(c_{n}).", "$ </equation> Here, $ o_{n} $ is the output gate, $ c_{n} $ is the memory cell state of the network after seeing all the $ n $ observations.", "\\newline </paragraph> </subsection> <subsection> <title> 3.2 Video Rendering Network (VR-NET) </title> The representation, $ r $ , learned based on the given observations, $ o $ , is used to render a video with a video rendering network (VR-NET).", "The VR-NET, shown in Figure [@ref:LABEL:fig1bf] F, is also a convolution based network which takes as input the learned representation, $ r $ , along with query viewpoint, $ v^{q} $ , time $ t^{q} $ , and latent noise $ z $ .", "The viewpoint $ v^{q} $ , time $ t^{q} $ , and noise $ z $ are feed to the network as conditioning, for which we use concatenation operation with the representation features.", "The VR-NET consists of 2D convolutions followed by 3D convolutions to render the video clips.", "The convolution layers are used in combination with upsampling of features to generate video clips with resolution same as the input observations.", "The two networks, RL-NET and VR-NET, are trained jointly in an end-to-end fashion minimizing the reconstruction loss $ L^{r} $ as the objective function.", "The reconstruction loss $ L^{r} $ is computed as mean squared error between the predicted $ V^{p} $ and the ground truth video clip $ V^{g} $ .", "\\newline <equation> $ L^{r}=\\frac{1}{N}\\sum_{n}^{N}\\sum_{i}^{F}\\sum_{j}^{H}\\sum_{k}^{W}\\sum_{m}^{C}|% |V^{p}_{ijkm}-V^{g}_{ijkm}||^{2}. $ </equation> Here, $ N $ is the number of samples, $ F $ is the number of frames in the clip, $ H,W $ is height and width of the video frames, and $ C=3 $ for three RGB color channels (more details in supplementary file).", "\\newline </subsection>  </section>"], ["<section> <title> 4 Activity Recognition </title>  The learned representation can render view-aware as well as time-aware video clips.", "To further explore the effectiveness of the learned representation, we use it for the task of view-invariant action recognition.", "We modify the same RL-NET and VR-NET framework and add convolution layers followed by fully connected layers on top of the representation features.", "This branch of the network (CL-NET) predicts probabilities for each action classes (Figure [@ref:LABEL:fig9] b).", "We use categorical cross entropy to compute the loss $ L^{c} $ for the classification branch.", "\\newline <equation> $ L^{c}=-\\frac{1}{N}\\sum_{n}^{N}\\sum_{c}^{C}1_{y_{i}\\in C_{c}}\\log(\\hat{p}[y_{i}% \\in C_{c}]).", "$ </equation> Here, $ C $ is the number of action categories, and $ \\hat{p}[y_{i}\\in C_{c}] $ is the predicted probability for this sample corresponding to category $ c $ .", "The modified network is trained end-to-end with the two loss functions ( $ L^{r} $ and $ L^{c} $ ) in a multi-task setting and the overall loss of the network is defined as, \\newline <equation> $ L=\\lambda 1\\times L^{r}+\\lambda 2\\times L^{c}. $ </equation> In all our experiments, we use $ \\lambda 1=\\lambda 2=1 $ .", "The network is trained using observations captured from certain views and later tested on observations from unseen views.", "In another variant, we also explore the proposed framework for multi-view action recognition, where all the views are provided during the classification training.", "\\newline  </section>"], ["<section> <title> 5 Experiments </title>  We perform our experiments on two different real-world datasets: UCF-101 [@bib:soomro2012ucf101] , and NTU-RGB+D [@bib:shahroudy2016ntu] .", "UCF-101 does not have the notion of viewpoint, therefore, we use it for time-aware video rendering experiments.", "NTU-RGB+D is a large scale dataset with videos captured from multiple viewpoints.", "We use it for view-ware video rendering and view-invariant representation learning, which is further explored for view-invariant activity classification.", "\\newline <subsection> <title> 5.1 Datasets </title> UCF-101 :The UCF-101 dataset [@bib:soomro2012ucf101] covers a wide range of activities and has around 13K video samples with 101 action classes.", "There are three different splits in this dataset and we use split-1 for our experiments.", "NTU-RGB+D : This human activity recognition dataset contains more than 56K videos and 4 millions frames with 60 different actions, including individual activities, interactions between 2 people and health related events.", "There are a total of 40 different actors, who perform actions captured from 80 different viewpoints.", "The authors proposed two different splits in this dataset, cross-view and cross-subject.", "We perform our classification experiments on both the splits as suggested in [@bib:shahroudy2016ntu] .", "Apart from this, we use cross-view split for view-invariant rendering and cross-subject split for other rendering experiments.", "\\newline </subsection> <subsection> <title> 5.2 Training </title> We perform the pre-processing of video frames in UCF-101 as suggested in [@bib:tran2015learning] , and take a random crop of 112x112 on the resized frames.", "In the time-aware frame rendering experiments, the RL-NET takes 6 frames in a video randomly and the VR-NET generates a video frame from arbitrary time in the clip.", "In video rendering experiments, the input video clips have 6 frames and we feed in 3 randomly selected clips to the RL-NET for representation learning, and VR-NET generates a video clip with 6 frames from arbitrary time.", "In all our experiments on NTU-RGB+D dataset, we use subject split, except for the view-split based classification task.", "For view-based rendering, the subject training split is further divided to get the desired view.", "We resize the video frames to 240x135, preserving the aspect ratio, and then take a random 112x112 crop for training.", "The input clips with 6 frames are randomly selected from each view, with varying time, and are used for representation learning, and subsequently the VR-NET generates a video clip with 6 frames from arbitrary view and time.", "The additional view-point information is used along with time for representation learning as well as video rendering.", "In all our experiments we use Adam optimizer [@bib:kingma2014adam] with a learning rate of 1e-4 and a batch size of 6.", "We implemented our code in Keras with Tensorflow backend and use Titan-X GPU for training our network.", "\\newline </subsection> <subsection> <title> 5.3 Time-aware Rendering </title> Building upon view-invariant neural representation for image generation using synthetic data [@bib:eslami2018neural] , we learn a representation encompassing the temporal domain.", "The video representation $ r $ is learned conditioned on the time factor using a convolution network (RL-NET).", "The representation $ r $ , with an understanding of the temporal domain, is used to generate an image/clip at arbitrary time in the video with the help on VR-NET.", "In their work [@bib:eslami2018neural] , related to view-invariant image representation, the authors use an iterative LSTM generator.", "Drawing on similar lines, we explore a recurrent LSTM generator (VR-NET) for image generation.", "Apart from this, we also explore a CNN generator (VR-NET) with similar training conditions.", "The images generated by both the networks are shown in Figure [@ref:LABEL:fig3] for a comparison.", "In the absence of any marked difference between the quality of generated images, we choose a CNN generator (VR-NET) for further experiments, which is faster to train in comparison with an LSTM network.", "The representation learned by this network can also predict 3-4 frames in future or the whole video frame by frame.", "A comparison of the generated image quality with other methods is shown in Table [@ref:LABEL:table4] .", "We use the same testing setup as suggested in [@bib:byeon2018contextvp] .", "The method proposed by [@bib:byeon2018contextvp] performs better in terms of PSNR values, however, it is important to note that this method was specifically trained for future frame prediction, whereas our network was trained for predicting arbitrary frames in the video.", "Moreover, our network outperforms all the other methods in terms of SSIM score.", "\\newline Next, we explore the video generation capability of the proposed framework.", "We experimented with both 2D and 3D convolutions to learn a representation with 3D-CNN based RL-NET.", "The input to RL-NET is a set of frames from arbitrary time in case of 2D-CNN and a set of video clips in case of 3D-CNN.", "The frames from the generated videos for some of the UCF-101 action classes are shown in Figure [@ref:LABEL:fig4] .", "The videos generated using 3D-CNN based RL-NET are relatively better when compared with 2D-CNN.", "We compared our method with [@bib:mathieu2015deep] for future video prediction and observed an improvement in the predicted video quality based on PSNR and SSIM measures (Table [@ref:LABEL:table3] ).", "\\newline </subsection> <subsection> <title> 5.4 View Invariant Video Generation </title> We perform our view-invariant video rendering experiments on NTU-RGB+D dataset.", "We train the network with view-point conditioning along with time condition to render videos from arbitrary view-points.", "A viewpoint is defined using 6 different parameters: camera height, camera distance, view-point, horizontal-pan, vertical-pan, and actor position (refer to supplementary files for more details).", "\\newline We first explore the effectiveness of the proposed blending network (BL-NET) for representation learning.", "We use a 2D-CNN based RL-NET along with proposed BL-NET to learn a representation $ r $ for a given set of frames captured from different view-points and time.", "The learned representation $ r $ is used then used to render a frame from arbitrary viewpoint and time.", "We perform similar experiment with addition in place of BL-NET for representation learning.", "Some of the generated images with these experiments are shown in Figure [@ref:LABEL:fig6] .", "We can observe that the quality of generated images is much better with BL-NET representation.", "Apart from this, we also compare the variation in loss and learning curve for these two blending techniques (Figure [@ref:LABEL:fig_blending] ).", "We observe a faster learning and a better performance for BL-NET.", "\\newline We use a 3D-CNN based RL-NET along with BL-NET blending to learn $ r $ for a given set of video clips from different viewpoints and time, which is then passed to a 3D-CNN based VR-NET for video rendering from an arbitrary viewpoint and time.", "(Figure [@ref:LABEL:fig9] a).", "We experimented with three different variations in the training setup based on the input and rendered videos (Figure [@ref:LABEL:renderingNTU] ).", "We start with a challenging setup, where the input clips are from $ 3\\choose 2 $ (1,2,3), i.e. two randomly selected views from three views (1, 2, 3) and VR-NET renders the third unseen view (Figure [@ref:LABEL:renderingNTU] row 1 & 2).", "In the second variation, the input clips are from view 2 and 3 and VR-NET always generates view 1 (row 3 & 4).", "In the third variation, the input was given from all three views and VR-NET renders a video from a randomly selected view among the three views (row 5 & 6).", "We observe that all the three variations generate video-clips with correct view-point on the test-set.", "Although we observe some blur in the regions with motion, the quality of the videos generated is best with the third variation.", "Some more synthesized video frames for this variation are shown in Figure [@ref:LABEL:fig10] .", "We also perform a quantitative evaluation of the proposed view and time aware rendering approach.", "We compute PSNR and SSIM measures to evaluate the quality of generated videos.", "The evaluation scores are shown in row 3-5 of Table [@ref:LABEL:table3] .", "We observe that the quality of generated videos is better when all the views are seen by the network as compared with generating unseen views which was expected.", "\\newline </subsection> <subsection> <title> 5.5 Activity Classification </title> We further explore the effectiveness of the proposed representation learning approach for view-invariant activity classification.", "We modify the proposed framework for multi-tasking (Figure [@ref:LABEL:fig9] b) where the network is jointly trained for video rendering as well as activity classification.", "Although, multi-tasking with classification does not improve rendering quality, we obtain state-of-the-art activity classification results on NTU-RGB+D dataset using RGB modality.", "We experimented with different training variations based on the input to RL-NET (different combinations of views and number of clips) and query to VR-NET.", "The RL-NET performs representation learning based on a set of input observations.", "These observations can be from different viewpoints (varying views) and different time in a video (Figure [@ref:LABEL:fig11] ).", "The visual appearance of any activity changes with viewpoint as well as time.", "This analogy between time and viewpoint for variation in visual appearance of any activity allows us to use the two concepts interchangeably during representation learning.", "This idea makes the proposed architecture even more powerful as a network trained under some settings can be tested on different set of parameters in terms of number of views and number of clips.", "The proposed BL-NET supports this further due to its recurrent structure which allows it to learn a representation for different varying observations.", "\\newline We perform an ablation study on activity classification to explore this idea further."]], "target": "In Table , we show the classification accuracy on a cross subject-split using three different network variations. The classification accuracy is highest, when all three views are available which provides more activity information. Please note that the actors are either facing view 2 or view 3 in this dataset, which provides uniformity to the input (2, 3) thus accuracy is second highest when we use this input view."}, {"tabular": ["    &  Testing Range  &  Training Range  &  Units ", " $ \\mathbf{r} $  &  $ [-20,~{}0,~{}0]~{}\\pm~{}2 $  &  $ [-20,~{}0,~{}0]~{}\\pm~{}4 $  &  m ", " $ \\mathbf{v} $  &  $ [0,0,0]~{}\\pm~{}0.1 $  &  $ [0,0,0]~{}\\pm~{}0.2 $  &  m/s ", " $ [\\phi,~{}\\theta,~{}\\psi] $  &  $ [0,180,0]~{}\\pm~{}20 $  &  $ [0,180,0]~{}\\pm~{}40 $  &  deg ", " $ \\boldsymbol{\\omega} $  &  $ [0,~{}0,~{}0]~{}\\pm~{}5 $  &  $ [0,~{}0,~{}0]~{}\\pm~{}10 $  &  deg/s  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Emerging technologies such as satellite servicing and active orbital debris removal rely on autonomous docking capabilities.", "Current missions, including NASA\u2019s Restore-L [@bib:vavrina2019restoreL] and DARPA\u2019s Robotic Servicing of Geosynchronous Satellites (RSGS) [@bib:sullivan2015darparsgs] , are highly constrained and planned far in advance; it is expected that the number of such missions will increase and their scope expanded to a wide range of orbits, targets, and objectives.", "As such, guidance and control algorithms for proximity operations and docking will require higher levels of autonomy to deal with challenges such as varying constraints, target motion, fault-tolerance, and uncertain dynamic environments [@bib:nasa2015taroadmap,starek2016survey] .", "\\newline There have been numerous research efforts to address these challenges.", "Lee and Pernicka [@bib:lee2010optcontrol] presented an optimal control method for the Space Shuttle V-bar rendezvous trajectory with the International Space Station.", "Boyarko et al. [@bib:boyarko2011tumble] generated minimum-time and minimum-fuel trajectories for rendezvous with a tumbling target, but the method is not implementable in real-time.", "Weiss et al. [@bib:weiss2015mpc] demonstrated good performance for docking while abiding by path and control constraints using model predictive control; however the study was limited to three-degree-of-freedom (3-DOF) scenarios that excluded attitude dynamics and control.", "Jiang et al. [@bib:jiang2016fault] provided actuator fault-tolerance and disturbance robustness using an adaptive fixed-time controller, but again, only the 3-DOF position was considered in docking trajectories.", "Jewison [@bib:jewison2017uncertain] introduced a method of generating probabilistically optimal trajectories with uncertainty regarding the target spacecraft state and obstacles.", "Malyuta et al. [@bib:malyuta2019apollo] recently developed a six-degree-of-freedom (6-DOF) docking trajectory optimization method using successive convexification that is able to address state-triggered constraints.", "\\newline This research investigates reinforcement learning (RL) as an alternative solution to the aforementioned challenges.", "RL involves learning a policy that maps observations to actions in order to maximize a reward signal given by the environment.", "Since it is a general, model-free framework, RL is potentially advantageous over model-based methods for scenarios where model identification is infeasible or prohibitive, e.g., when environments, dynamics, or disturbances are time-varying.", "Moreover, once learned, implementation of the policy requires low amounts of computational effort and memory, making it practically realizable with current spacecraft computing resources.", "There have been numerous applications of RL within the robotics community for control tasks [@bib:ng2003helicopter,bojarski2016selfdrive] .", "\\newline However, its extension to spacecraft guidance, navigation, and control is still largely unexplored.", "Recent efforts include the application of the REINFORCE algorithm for asteroid mapping (Chan and Agha-mohammadi [@bib:chan2019imaging] ) and the use of an RL actor-critic framework to widen the capabilities of the zero-effort-miss/zero-effort-velocity guidance algorithm, generalizing it for path constraints in near-rectilinear orbits (Scorsoglio et al. [@bib:scorsoglio2019near] ).", "Broida and Linares [@bib:broida2019rendezvous] used proximal policy optimization (PPO) to accomplish 3-DOF rendezvous trajectories that exploit relative orbital dynamics.", "Likewise, Gaudet et al. [@bib:gaudet2019mars,gaudet2019asteroid] used PPO for producing 6-DOF planetary landings and asteroid hovering maneuvers.", "The latter work utilized meta-learning, where the RL agent can adapt to a novel environment from learning on a wide range of possible environments.", "Implementing meta-learning via recurrent neural networks, the trained agent was able to adapt to unique asteroid dynamic environments and actuator faults.", "Finally, Hovell and Ulrich [@bib:hovell2020rlguidance] recently presented a guidance policy for 3-DOF proximity operations using the \u201cdistributed distributional deep deterministic policy gradient\u201d (D4PG) algorithm, testing it successfully in granite surface hardware experiments.", "The hardware implementation distinguishes this work from most research efforts that are limited to simulation.", "\\newline The research presented in this paper extends the use of RL for close-proximity approach and docking maneuvers that require 6-DOF dynamic modeling.", "To the best of the authors\u2019 knowledge, RL has not been applied in a truly 6-DOF scenario representative of the final docking approach between two spacecraft.", "In this work, PPO is used to develop a precise docking policy that is valid for initial conditions within a subset of the state-space, while also preventing collisions and minimizing control and error costs.", "The policy is implemented as a feedback control law.", "Experimental results on the simulated Apollo transposition and docking maneuver [@bib:apollo1970constraints] demonstrate the policy\u2019s capabilities in a realistic 6-DOF docking scenario.", "This work also includes a comparison with standard optimal control methodology using the GPOPS-II software suite [@bib:patterson2014gpops] .", "The contributions of this work are two-fold: first, to present a novel RL-based framework for 6-DOF docking policies, and, second, to provide methods, results, and insight that will benefit future research in learning-based methods for spacecraft proximity operations.", "\\newline  </section>"], ["<section> <title> 2 Methods </title>  <subsection> <title> 2.1 Overview of Reinforcement Learning </title> RL is a subdivision of machine learning where an agent learns a policy that maps observations to actions in order to maximize a numerical reward across experienced trajectories [@bib:sutton2018rl] .", "The agent learns a policy by repeatedly interacting with the environment over numerous trajectories (termed \u201cepisodes\u201d), either real or simulated, and receiving rewards based on the action taken at each time step (Figure [@ref:LABEL:fig:rl_mdp] ).", "RL is modeled as a Markov decision process that includes a state space $ \\mathcal{S} $ , action space $ \\mathcal{A} $ , state transition distribution $ \\mathcal{P}(\\mathbf{x}_{t+1}|\\mathbf{x}_{t},\\mathbf{u}_{t}) $ , and reward function $ r(\\mathbf{x}_{t},\\mathbf{u}_{t}) $ , where state $ \\mathbf{x}\\in\\mathcal{S} $ , action (control input) $ \\mathbf{u}\\in\\mathcal{A} $ , and $ t $ is the discrete time-step index.", "During the learning process, the policy $ \\pi_{\\boldsymbol{\\theta}}=(\\mathbf{u}_{t}|\\mathbf{x}_{t}) $ is formalized as a conditional probability distribution, dependent upon the parameter vector $ \\boldsymbol{\\theta} $ , mapping states to actions.", "\\newline One episode results in a trajectory of state-action pairs, denoted as $ \\boldsymbol{\\tau}=[\\mathbf{x}_{0},\\mathbf{u}_{0},...,\\mathbf{x}_{T},\\mathbf% {u}_{T}]\\in\\mathbb{T} $ with $ T $ being the number of time steps in the trajectory and $ \\mathbb{T} $ being the set of all possible state-action pair trajectories.", "Rewards received at successive time-steps are discounted to accommodate infinite-horizon problems.", "The sum of discounted rewards over the trajectory is \\newline <equation> $ r(\\boldsymbol{\\tau})=\\sum_{t=0}^{T}\\gamma^{t}r(\\mathbf{x}_{t},\\mathbf{u}_{t}), $ </equation> where $ \\gamma\\in(0,1) $ is the discount factor.", "The goal of RL is to maximize the expectation of discounted rewards across all trajectories experienced by the agent: \\newline <equation> $ \\mathbb{E}_{p_{\\boldsymbol{\\theta}}(\\boldsymbol{\\tau})}\\left[r(\\boldsymbol{% \\tau})\\right]=\\int_{\\mathbb{T}}r(\\boldsymbol{\\tau})p_{\\boldsymbol{\\theta}}(% \\boldsymbol{\\tau})d\\boldsymbol{\\tau}. $ </equation>", "The probability of experiencing a particular trajectory based upon the policy\u2019s parameter vector $ \\boldsymbol{\\theta} $ is \\newline <equation> $ p_{\\boldsymbol{\\theta}}(\\boldsymbol{\\tau})=\\left[\\prod_{t=0}^{T-1}p(\\mathbf{x}% _{t+1}|\\mathbf{x}_{t},\\mathbf{u}_{t})\\right]p(\\mathbf{x}_{0}), $ </equation> where $ \\mathbf{u}_{t} $ is sampled from $ \\pi_{\\boldsymbol{\\theta}}(\\mathbf{u}_{t}|\\mathbf{x}_{t}) $ .", "Note that the state transition is stochastic in the general case: this can be replaced by a deterministic state transition in certain applications.", "For example, the Apollo docking scenario presented in this paper assumes nominal dynamics and thus a deterministic state transition is used.", "The variance of the policy\u2019s conditional distribution results in a stochastic action choice, enabling further exploration of the action space.", "As learning progresses, the variance is reduced to instead encourage more exploitation of the current policy.", "After the learning process is completed, the variance of the policy is set to zero, resulting in a deterministic action choice (the mean value of $ \\pi_{\\boldsymbol{\\theta}}(\\mathbf{u}_{t}|\\mathbf{x}_{t}) $ ), i.e., a deterministic feedback control law during implementation.", "\\newline </subsection> <subsection> <title> 2.2 Proximal Policy Optimization </title> The specific RL algorithm used in this research is PPO [@bib:schulman2017ppo] .", "PPO is a state-of-the-art policy learning algorithm with successful results in many control tasks with continuous or discrete state/action spaces.", "PPO is a model-free, actor-critic algorithm where the policy that selects actions (the actor) and an advantage function that evaluates the selected actions (the critic) are learned concurrently.", "The state-value function $ V_{\\mathbf{w}}^{\\pi}(\\mathbf{x}_{t}) $ (with the parameter vector $ \\mathbf{w} $ ) is used in PPO and estimates the sum of future discounted rewards over the trajectory starting at the current state $ \\mathbf{x}_{t} $ and following the current policy.", "However, this function is initially unknown and the parameter vector $ \\mathbf{w} $ must be learned concurrently with the policy parameter vector $ \\boldsymbol{\\theta} $ .", "The resulting advantage function $ A_{\\mathbf{w}}^{\\pi}(\\mathbf{x}_{t},\\mathbf{u}_{t}) $ is the difference between the empirical rewards received during the learning process and the state-value function\u2019s estimate.", "\\newline <equation> $ V_{\\mathbf{w}}^{\\pi}(\\mathbf{x}_{t})=\\mathbb{E}_{\\pi}\\left[\\sum_{k=t}^{T}% \\gamma^{k-t}r_{k}(\\mathbf{x}_{k},\\mathbf{u}_{k})\\middle|\\mathbf{x}_{t}\\right] $ </equation> <equation> $ A^{\\pi}_{\\mathbf{w}}(\\mathbf{x}_{t},\\mathbf{u}_{t})=\\left[\\sum_{k=t}^{T}\\gamma% ^{k-t}r_{k}(\\mathbf{x}_{k},\\mathbf{u}_{k})\\right]-V_{\\mathbf{w}}^{\\pi}(\\mathbf% {x}_{t}).", "$ </equation> \\newline PPO is a descendant of the trust region policy optimization algorithm [@bib:schulman2015TRPO] , retaining the ability to mitigate large policy updates (thus reducing the risk of learning divergence) while being simpler and more widely implementable.", "Central to PPO is the policy probability ratio \\newline <equation> $ p_{t}(\\boldsymbol{\\theta})=\\frac{\\pi_{\\boldsymbol{\\theta}}(\\mathbf{u}_{t}|% \\mathbf{x}_{t})}{\\hat{\\pi}_{\\boldsymbol{\\theta}}(\\mathbf{u}_{t}|\\mathbf{x}_{t}% )}, $ </equation> which compares the probability $ \\pi_{\\boldsymbol{\\theta}}(\\mathbf{u}_{t}|\\mathbf{x}_{t}) $ of selecting a particular action after a learning update to the probability $ \\hat{\\pi}_{\\boldsymbol{\\theta}}(\\mathbf{u}_{t}|\\mathbf{x}_{t}) $ of selecting the same action prior to the update.", "The probability ratio is then directly used in the PPO objective function we wish to maximize: \\newline <equation> $ J(\\boldsymbol{\\theta})=\\mathbb{E}_{p(\\boldsymbol{\\tau})}\\bigg{[}\\text{min}% \\Big{(}p_{t}(\\boldsymbol{\\theta})A^{\\pi}_{\\mathbf{w}}(\\mathbf{x}_{t},\\mathbf% {u}_{t}),\\text{clip}\\big{[}p_{t}(\\boldsymbol{\\theta}),\\epsilon\\big{]}A^{\\pi% }_{\\mathbf{w}}(\\mathbf{x}_{t},\\mathbf{u}_{t})\\Big{)}\\bigg{]} $ </equation> where the clip function, defined as \\newline <equation> $ \\mbox{clip}\\big{[}p_{t}(\\boldsymbol{\\theta}),\\epsilon\\big{]}=\\begin{cases}1-% \\epsilon&\\mbox{if}p_{t}(\\boldsymbol{\\theta})<1-\\epsilon\\\\ 1+\\epsilon&\\mbox{if}p_{t}(\\boldsymbol{\\theta})>1+\\epsilon\\\\ p_{t}(\\boldsymbol{\\theta})&\\mbox{otherwise}\\end{cases}, $ </equation> imposes bounds on the policy probability ratio using the clipping parameter $ \\epsilon\\in(0,1) $ .", "The clipping parameter controls how close the updated policy is to the old policy, effectively implementing a trust region and eliminating large, unwanted policy updates.", "Note that this objective function is measured relative to the policy prior to the update.", "Thus, the numerical value of the objective function over the course of many updates is uninformative.", "Instead, its immediate gradient is more critical in guiding the policy to maximize rewards over all trajectories.", "\\newline To learn the state-value function, we minimize the commonly used mean squared error cost function: \\newline <equation> $ L(\\mathbf{w})=\\frac{1}{2}\\mathbb{E}_{p(\\boldsymbol{\\tau})}\\left[\\left(V_{% \\mathbf{w}}^{\\pi}\\left(\\mathbf{x}_{t}\\right)-\\sum_{k=t}^{T}\\gamma^{k-t}r\\left(% \\mathbf{x}_{k},\\mathbf{u}_{k}\\right)\\right)^{2}\\right].", "$ </equation> Essentially, the mean squared difference between the state-value function estimate and the actual sum of resulting rewards is minimized.", "The multiplication by $ \\frac{1}{2} $ simplifies the loss gradient calculation.", "We now have an objective function to improve the policy in Equation ( [@ref:LABEL:eq:ppoobjective] ) and a cost function to correct errors in the state-value function in Equation ( [@ref:LABEL:eq:valueloss] ).", "Thus, we can use the gradients of these functions to perform gradient ascent on $ \\boldsymbol{\\theta} $ and gradient descent on $ \\mathbf{w} $ : \\newline <equationgroup> <equationgroup> <equation> $ \\boldsymbol{\\theta}^{+}=\\boldsymbol{\\theta}^{-}+\\beta_{% \\boldsymbol{\\theta}}\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})|_{% \\boldsymbol{\\theta}=\\boldsymbol{\\theta}^{-}} $ $ \\boldsymbol{\\theta}^{+} $ $ =\\boldsymbol{\\theta}^{-}+\\beta_{\\boldsymbol{\\theta}}\\nabla_{% \\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})|_{\\boldsymbol{\\theta}=\\boldsymbol{% \\theta}^{-}} $ </equation> <equation> $ \\mathbf{w}^{+}=\\mathbf{w}^{-}-\\beta_{\\mathbf{w}}\\nabla_{\\mathbf{w% }}L(\\mathbf{w})|_{\\mathbf{w}=\\mathbf{w^{-}}} $ $ \\mathbf{w}^{+} $ $ =\\mathbf{w}^{-}-\\beta_{\\mathbf{w}}\\nabla_{\\mathbf{w}}L(\\mathbf{w}% )|_{\\mathbf{w}=\\mathbf{w^{-}}} $ </equation> </equationgroup> </equationgroup> where the scalars $ \\beta_{\\boldsymbol{\\theta}} $ and $ \\beta_{\\mathbf{w}} $ are the policy learning rate and state-value function learning rate, respectively, which must be chosen by the designer.", "\\newline </subsection> <subsection> <title> 2.3 Implementation for 6-DOF Docking </title> For developing policies to perform 6-DOF docking maneuvers, we use the target-centered inertial frame $ \\mathcal{I} $ (assuming the target is stationary) and the chaser-centered body frame $ \\mathcal{B} $ .", "The state $ \\mathbf{x}={[{\\mathbf{r}}^{\\scriptscriptstyle\\top},{\\mathbf{v}}^{% \\scriptscriptstyle\\top},{\\mathbf{q}}^{\\scriptscriptstyle\\top},{% \\boldsymbol{\\omega}}^{\\scriptscriptstyle\\top}]}^{\\scriptscriptstyle\\top} $ is the state of the chaser\u2019s center of mass within the $ \\mathcal{I} $ frame, with $ \\mathbf{r}\\in\\mathbb{R}^{3} $ as the position, $ \\mathbf{v}\\in\\mathbb{R}^{3} $ as the velocity, $ \\mathbf{q}\\in\\mathbb{R}^{4} $ as the attitude quaternion, and $ \\boldsymbol{\\omega}\\in\\mathbb{R}^{3} $ as the angular velocity.", "The control action $ \\mathbf{u}={[{\\mathbf{F}}^{\\scriptscriptstyle\\top},{\\mathbf{L}}^{% \\scriptscriptstyle\\top}]}^{\\scriptscriptstyle\\top} $ consists of a thrust command $ \\mathbf{F}\\in\\mathbb{R}^{3} $ and a torque command $ \\mathbf{L}\\in\\mathbb{R}^{3} $ , both in the $ \\mathcal{I} $ frame.", "The thrust and torque commands are both bounded by minimum/maximum actuator constraints.", "Control actions are commanded by the policy at discrete time intervals.", "The dynamics are derived below in continuous-time, and are subsequently discretized using a sample-period of 1 second.", "\\newline The translational dynamics are modeled using the double-integrator equations: \\newline <equationgroup> <equationgroup> <equation> $ \\dot{\\mathbf{r}}=\\mathbf{v} $ $ \\dot{\\mathbf{r}} $ $ =\\mathbf{v} $ </equation> <equation> $ \\dot{\\mathbf{v}}=\\frac{\\mathbf{F}}{m} $ $ \\dot{\\mathbf{v}} $ $ =\\frac{\\mathbf{F}}{m} $ </equation> </equationgroup> </equationgroup> where $ m $ refers to the chaser mass.", "In practice, to compute individual thruster commands, the net force command must be determined in the chaser body frame.", "This is calculated using the chaser\u2019s current attitude, parameterized as a rotation matrix $ \\mathbf{R}(\\mathbf{q})\\in\\mathbb{R}^{3\\times 3} $ , that maps from the $ \\mathcal{B} $ frame to the $ \\mathcal{I} $ frame: \\newline <equation> $ \\mathbf{F}_{\\mathcal{B}}={\\mathbf{R}(\\mathbf{q})}^{\\scriptscriptstyle\\top}% \\mathbf{F}. $ </equation> \\newline The attitude dynamics are modeled using quaternion kinematics and Euler\u2019s equations for rigid bodies: \\newline <equationgroup> <equationgroup> <equation> $ \\dot{\\mathbf{q}}=\\frac{1}{2}\\boldsymbol{\\Omega}\\boldsymbol{\\omega} $ $ \\dot{\\mathbf{q}} $ $ =\\frac{1}{2}\\boldsymbol{\\Omega}\\boldsymbol{\\omega} $ </equation> <equation> $ \\dot{\\boldsymbol{\\omega}}=\\mathbf{J}^{-1}\\left(\\mathbf{L}-% \\boldsymbol{\\omega}\\times\\mathbf{J}\\boldsymbol{\\omega}\\right) $ $ \\dot{\\boldsymbol{\\omega}} $ $ =\\mathbf{J}^{-1}\\left(\\mathbf{L}-\\boldsymbol{\\omega}\\times\\mathbf% {J}\\boldsymbol{\\omega}\\right) $ </equation> </equationgroup> </equationgroup> where $ \\mathbf{J} $ is the chaser inertia tensor and $ \\boldsymbol{\\Omega} $ is defined as \\newline <equation> $ \\boldsymbol{\\Omega}=\\begin{bmatrix}-q_{x}&-q_{y}&-q_{z}\\\\ q_{w}&-q_{z}&q_{y}\\\\ q_{z}&q_{w}&-q_{x}\\\\ -q_{y}&q_{x}&q_{w}\\end{bmatrix}. $ </equation> \\newline Thus, Equations ( [@ref:LABEL:eq:doubleintegrate] ) and ( [@ref:LABEL:eq:eulers] ) govern the dynamics of the nonlinear, 6-DOF system.", "As docking requirements are often formulated on the relative state of the chaser and target docking ports, it is useful to define the relative position $ \\mathbf{r}_{p} $ and velocity $ \\mathbf{v}_{p} $ of the chaser docking port with respect to the target docking port as \\newline <equationgroup> <equationgroup> <equation> $ \\mathbf{r}_{p}=\\mathbf{r}+\\mathbf{R}(\\mathbf{q})\\mathbf{r}_{c}-% \\mathbf{r}_{t} $ $ \\mathbf{r}_{p} $ $ =\\mathbf{r}+\\mathbf{R}(\\mathbf{q})\\mathbf{r}_{c}-\\mathbf{r}_{t} $ </equation> <equation> $ \\mathbf{v}_{p}=\\mathbf{v}+\\left(\\boldsymbol{\\omega}\\times\\mathbf{% R}(\\mathbf{q})\\mathbf{r}_{c}\\right) $ $ \\mathbf{v}_{p} $ $ =\\mathbf{v}+\\left(\\boldsymbol{\\omega}\\times\\mathbf{R}(\\mathbf{q})% \\mathbf{r}_{c}\\right) $ </equation> </equationgroup> </equationgroup> where $ \\mathbf{r}_{c} $ and $ \\mathbf{r}_{t} $ refer to the chaser and target docking port positions in the $ \\mathcal{B} $ and $ \\mathcal{I} $ frames, respectively.", "Note that, if the target is stationary in the $ \\mathcal{I} $ frame, the relative attitude and angular velocity of the chaser docking port is equivalent to the chaser\u2019s attitude and angular velocity.", "\\newline The policy and state-value function are modeled through standard, feedforward neural networks.", "Thus, the parameters $ \\boldsymbol{\\theta} $ and $ \\mathbf{w} $ represent the weights and biases of each network\u2019s respective layers.", "The neural network backpropagation algorithm and Adam optimizer [@bib:adam2014] are used to perform gradient ascent/descent on the parameter vectors $ \\boldsymbol{\\theta} $ and $ \\mathbf{w} $ according to Equation ( [@ref:LABEL:eq:graddescent] ).", "The policy is specifically a multivariate, Gaussian distribution with a diagonal covariance matrix.", "The neural network output consists of the resulting mean action based on the given state.", "The variance for each action is also learned, but is independent of the state.", "This essentially controls the degree of action space exploration throughout the learning process.", "In general, the agent learns to set large variance values during the learning process to encourage more exploration, and then diminish them in the later stages of learning to induce more exploitation of the current policy.", "\\newline The inputs for both the policy and state-value function neural networks are scaled using a running mean and standard deviation of experienced state data while learning.", "This helps prevent the saturation of activation functions within each network layer.", "Similarly, neural network outputs are best defined when close to unity.", "As such, the policy network outputs are scaled accordingly so that an output of $ \\pm 1 $ corresponds to the maximum/minimum thrust or torque command.", "Table [@ref:LABEL:nnparams] shares the structure of network layers and their corresponding activation functions.", "\\newline In our implementation of PPO, we follow the example of Gaudet et al. [@bib:gaudet2019mars] in that we dynamically adjust learning parameters to target a desired Kullback-Leibler (KL) divergence value between successive policy updates [@bib:kullback1951KLDiv] .", "This helps to prevent large policy updates that could derail the learning process, while yielding smoother policy updates.", "Over the course of learning, both the PPO clipping parameter $ \\epsilon $ and the policy learning rate $ \\beta_{\\boldsymbol{\\theta}} $ are adjusted to keep the KL-divergence between updates as close as possible to the desired target value ( $ KL_{\\mathrm{des}} $ ).", "\\newline Employing a valid reward function is critical to the success of PPO as the policy will learn to explicitly maximize this function.", "For 6-DOF docking maneuvers, the reward function consists of several terms that together account for minimizing state tracking errors and control effort, preventing collisions, and reinforcing successful docks.", "All terms are weighted relative to one another through design coefficients.", "\\newline To account for translational state error, the term $ {(\\dot{\\mathbf{v}}_{t}-\\dot{\\bar{\\mathbf{v}}}_{t})}^{\\scriptscriptstyle\\top}% \\mathbf{M}(\\dot{\\mathbf{v}}_{t}-\\dot{\\bar{\\mathbf{v}}}_{t}) $ defines the quadratic weighted error between the acceleration produced by the RL agent via Equation ( [@ref:LABEL:eq:doubleintegrate] b) and a reference acceleration ( $ \\dot{\\bar{\\mathbf{v}}}_{t} $ ) provided by a linear quadratic regulator (LQR) feedback law: \\newline <equation> $ \\dot{\\bar{\\mathbf{v}}}_{t}=-\\mathbf{K}\\mathbf{x}^{\\prime}_{t} $ </equation> where $ \\mathbf{K} $ is the LQR gain matrix and $ \\mathbf{x}^{\\prime}_{t} $ is the translational part of the state vector (chaser position and velocity).", "The LQR design process is performed offline before the implementation of PPO.", "By adjusting the standard LQR performance and control cost matrices, the resulting gain matrix can be tuned to target a desired trajectory time length for nominal docking initial conditions.", "Additionally, the tuning process can account for a desired, non-zero final docking velocity by setting the LQR origin at an offset from the actual docking port location.", "The benefits of this reward term are two-fold: first, it provides a clear reward signal at all points in the translational state-space that guides the RL agent to achieve a successful docking trajectory, and, second, it encourages the RL agent to produce docking trajectories with a specific time length (an important design consideration for many docking maneuvers).", "Finally, $ \\mathbf{M}\\in\\mathbb{R}^{3\\times 3},\\mathbf{M}\\succ\\mathbf{0} $ where the weights in $ \\mathbf{M} $ are design parameters.", "\\newline To account for errors between the actual and desired attitude and angular velocity, we define the reward function term $ {\\widetilde{{\\boldsymbol{\\alpha}}}}^{\\scriptscriptstyle\\top}_{t}\\mathbf{Q}% \\widetilde{{\\boldsymbol{\\alpha}}}_{t} $ .", "This term is based on the error quaternion $ \\mathbf{\\widetilde{q}} $ between the current and desired final docking attitude ( $ \\mathbf{q}_{\\mathrm{des}} $ ): \\newline <equation> $ \\mathbf{\\widetilde{q}}=\\mathbf{q}_{\\mathrm{des}}\\otimes\\mathbf{q}^{-1}. $ </equation> From Markley [@bib:markley2003error] , we take twice the vector component of the error quaternion ( $ \\widetilde{\\mathbf{q}}_{v} $ ) as our measure of attitude error.", "We also penalize the angular velocity error $ \\widetilde{\\boldsymbol{\\omega}} $ between the current angular velocity and the desired angular velocity $ \\boldsymbol{\\omega}_{\\mathrm{des}} $ .", "This results in a vector $ \\widetilde{\\boldsymbol{\\alpha}}_{t}={[2{\\widetilde{\\mathbf{q}}}^{% \\scriptscriptstyle\\top}_{v},{\\widetilde{\\boldsymbol{\\omega}}}^{% \\scriptscriptstyle\\top}]}^{\\scriptscriptstyle\\top}\\in\\mathbb{R}^{6} $ that penalizes both attitude and angular velocity errors.", "This term also has a weighting design matrix $ \\mathbf{Q}\\in\\mathbb{R}^{6\\times 6},\\mathbf{Q}\\succ\\mathbf{0} $ .", "\\newline Finally, we include a quadratic control cost, collision penalty, and docking bonus.", "The quadratic control cost $ {\\mathbf{u}}^{\\scriptscriptstyle\\top}_{t}\\mathbf{P}\\mathbf{u}_{t} $ is applied to the force/torque command with a weighting design matrix $ \\mathbf{P}\\in\\mathbb{R}^{6\\times 6},\\mathbf{P}\\succ\\mathbf{0} $ .", "The collision penalty $ c\\sin\\left({\\frac{\\pi}{2}\\frac{||\\mathbf{r}_{p}||}{r_{\\mathrm{col}}}}\\right) $ is applied at each time step the chaser docking port is within the boundary of the target spacecraft (modeled as a rectangular region).", "The penalty is scaled based upon the relative docking distance at the time of collision and the maximum possible distance for a collision ( $ r_{\\mathrm{col}} $ ).", "Together with the sine function and a weighting coefficient $ c>0 $ , this permits a smooth function that penalizes collisions with significant state error more heavily.", "The docking bonus $ g(\\mathbf{x}_{t}) $ is a discrete term applied if the agent achieves the docking requirements: \\newline <equation> $ g(\\mathbf{x}_{t})=\\begin{cases}d&\\mbox{if $\\mathbf{x}_{t}$ satisfies docking % conditions}\\\\ 0&\\mbox{otherwise}\\end{cases} $ </equation> where $ d>0 $ is a weighting coefficient.", "\\newline We define two distinct reward functions based on the aforementioned reward contributions: \\newline <equationgroup> <equationgroup> <equation> $  r_{1}(\\mathbf{x}_{t},\\mathbf{u}_{t})=-{(\\dot{\\mathbf{v}}_{t}-% \\dot{\\bar{\\mathbf{v}}}_{t})}^{\\scriptscriptstyle\\top}\\mathbf{M}(\\dot{\\mathbf{v% }}_{t}-\\dot{\\bar{\\mathbf{v}}}_{t})-{\\widetilde{{\\boldsymbol{\\alpha}}}}^{% \\scriptscriptstyle\\top}_{t}\\mathbf{Q}\\widetilde{{\\boldsymbol{\\alpha}}}_{t}-{% \\mathbf{u}}^{\\scriptscriptstyle\\top}_{t}\\mathbf{P}\\mathbf{u}_{t}-c\\sin\\left({% \\frac{\\pi}{2}\\frac{||\\mathbf{r}_{p}||}{r_{\\mathrm{col}}}}\\right) $ $  r_{1}(\\mathbf{x}_{t},\\mathbf{u}_{t}) $ $ =-{(\\dot{\\mathbf{v}}_{t}-\\dot{\\bar{\\mathbf{v}}}_{t})}^{% \\scriptscriptstyle\\top}\\mathbf{M}(\\dot{\\mathbf{v}}_{t}-\\dot{\\bar{\\mathbf{v}}}_% {t})-{\\widetilde{{\\boldsymbol{\\alpha}}}}^{\\scriptscriptstyle\\top}_{t}\\mathbf{Q% }\\widetilde{{\\boldsymbol{\\alpha}}}_{t}-{\\mathbf{u}}^{\\scriptscriptstyle\\top}_{% t}\\mathbf{P}\\mathbf{u}_{t}-c\\sin\\left({\\frac{\\pi}{2}\\frac{||\\mathbf{r}_{p}||}{% r_{\\mathrm{col}}}}\\right) $ </equation> <equation> $  r_{2}(\\mathbf{x}_{t})=g(\\mathbf{x}_{t}) $ $  r_{2}(\\mathbf{x}_{t}) $ $ =g(\\mathbf{x}_{t}) $ </equation> </equationgroup> </equationgroup> where $ r_{1} $ represents the \u201cshaping\u201d penalties (LQR error, attitude/angular velocity error, control cost, and collision penalty) and $ r_{2} $ represents the terminal docking bonus.", "Following the example of Gaudet et al. [@bib:gaudet2019mars] , a slightly smaller discount factor is used for the shaping penalties ( $ \\gamma_{1} $ ) while a larger discount factor is used for the terminal docking bonus ( $ \\gamma_{2} $ ).", "This results in the docking bonus being weighted more heavily in the long-term than the shaping penalties.", "Thus, the advantage function (Equation ( [@ref:LABEL:eq:advantage] )) and the state-value loss function (Equation ( [@ref:LABEL:eq:valueloss] )) can be re-written as: \\newline <equation> $ A^{\\pi}_{\\mathbf{w}}(\\mathbf{x}_{t},\\mathbf{u}_{t})=\\sum_{k=t}^{T}\\left[\\gamma% _{1}^{k-t}r_{1}(\\mathbf{x}_{k},\\mathbf{u}_{k})+\\gamma_{2}^{k-t}r_{2}(\\mathbf{x% }_{k})\\right]-V_{\\mathbf{w}}^{\\pi}(\\mathbf{x}_{t}) $ </equation> <equation> $ L(\\mathbf{w})=\\frac{1}{2}\\mathbb{E}_{p(\\boldsymbol{\\tau})}\\left[\\left(V_{% \\mathbf{w}}^{\\pi}\\left(\\mathbf{x}_{t}\\right)-\\sum_{k=t}^{T}\\left[\\gamma_{1}^{k% -t}r_{1}\\left(\\mathbf{x}_{k},\\mathbf{u}_{k}\\right)+\\gamma_{2}^{k-t}r_{2}\\left(% \\mathbf{x}_{k},\\mathbf{u}_{k}\\right)\\right]\\right)^{2}\\right].", "$ </equation> The training episode either ends if the docking requirements are met or a trajectory time limit has been reached.", "\\newline </subsection>  </section>"], ["<section> <title> 3 Experimental Setup </title>  The above methodology was applied to the simulated Apollo transposition and docking maneuver.", "This maneuver involves the command service module (CSM) re-orienting itself and docking with the lunar module (LM) in order to extract it from the third stage of the Saturn V rocket [@bib:apollo1969massprop] .", "Figure [@ref:LABEL:figframes] depicts the relevant coordinate frames: the $ LM $ frame represents the target-centered inertial frame (situated at the LM\u2019s center of mass and coinciding with the LM\u2019s body frame), while the $ CSM $ frame represents the chaser\u2019s body frame (situated at the CSM\u2019s center of mass).", "Note that Figure [@ref:LABEL:figframes] shows the LM and CSM in their initial configuration for the maneuver: the $ CSM $ frame has a 180\u00b0 pitch rotation relative to the $ LM $ frame.", "\\newline We impose actuator constraints on the minimum/maximum force and torque commands (Table [@ref:LABEL:thrusttable] ).", "These are derived from approximating the maximum thrust and torque outputs achievable through the CSM\u2019s sixteen reaction control system thrusters [@bib:apollo1969rcs] .", "Note that the policy produces thrust and torque commands within a continuous range of values; in reality, the CSM thrusters produce discrete, on/off thrust.", "We also define a rectangular region around the LM\u2019s center of mass to model collisions (Figure [@ref:LABEL:figcollision] ).", "The region\u2019s $ y $ and $ z $ dimensions approximate the largest diameter of the LM and its surface intersects with the LM docking port.", "The collision geometry parameters, as well as the docking port positions of the CSM/LM in their respective spacecraft frames, are shown in Table [@ref:LABEL:tablegeometry] .", "To perform a successful dock, the CSM docking port must meet the conditions outlined in Table [@ref:LABEL:tabledockconditions] ( $ \\phi,\\theta,\\psi $ represent the Euler attitude angles in the $ x $ , $ y $ , and $ z $ axes, respectively) [@bib:apollo1970constraints] .", "Notice that the maneuver requires a strictly positive velocity and a $ -60 $ \u00b0 roll in the $ x $ -axis to activate the docking mechanism.", "\\newline For both training and testing episodes, the policy accepts the given state and produces a commanded force/torque at discrete, 1-second intervals.", "Episodes during training are limited to 150 seconds (a rough approximation of the time needed to dock) to gather suitable data while retaining efficiency in the overall learning process.", "However, for testing, the time limit is extended to 250 seconds (an arbitrary time limit greater than any time length needed for successful docking) to make sure valid docking trajectories are not prematurely terminated.", "\\newline An objective of this research is to synthesize a feedback control law that is robust to significant uncertainty in the initial condition of the docking maneuver.", "To this end, the RL goal is to generate a docking policy that can successfully be employed within a wide range of initial conditions.", "This range of initial conditions should wholly contain the range of uncertainty with respect to which robustness is required.", "For the Apollo transposition and docking maneuver, we specifically define the initial condition range shown in Table [@ref:LABEL:ictable] .", "Monte Carlo tests of the policy randomly sample an initial condition (in each state variable) for the trajectory according the \u201cTesting Range\u201d."]], "target": "However, to ensure the policy learns across a wide region of the state space, and thus gains more robust qualities, each training episode\u2019s initial conditions are sampled from the wider \u201cTraining Range\u201d (also shown in Table )."}, {"tabular": ["  1  &  L1.miss $ \\wedge $ $ \\neg $ L1.busy ", " 2  &  L1.miss $ \\wedge $ L1.busy $ \\wedge $ c2pRq_exist $ \\wedge $ $ \\neg $ c2pRq_rdy ", " 3  &  L1.miss $ \\wedge $ L1.busy $ \\wedge $ c2pRq_rdy $ \\wedge $ L2.state = M $ \\wedge $ $ \\neg $ L2.busy ", " 4  &  L1.miss $ \\wedge $ L1.busy $ \\wedge $ c2pRq_rdy $ \\wedge $ L2.state = M $ \\wedge $ L2.busy $ \\wedge $ p2cRq_exist $ \\wedge $ $ \\neg $ p2cRq_rdy ", " 5  &  L1.miss $ \\wedge $ L1.busy $ \\wedge $ c2pRq_rdy $ \\wedge $ L2.state = M $ \\wedge $ L2.busy $ \\wedge $ p2cRq_rdy $ \\wedge $ ownerL1.state = M ", " 6  &  L1.miss $ \\wedge $ L1.busy $ \\wedge $ c2pRq_rdy $ \\wedge $ L2.state = M $ \\wedge $ L2.busy $ \\wedge $ p2cRq_rdy $ \\wedge $ ownerL1.state $ < $ M ", " 7  &  L1.miss $ \\wedge $ L1.busy $ \\wedge $ c2pRq_rdy $ \\wedge $ L2.state = M $ \\wedge $ L2.busy $ \\wedge $ $ \\neg $ p2cRq_exist ", " 8  &  L1.miss $ \\wedge $ L1.busy $ \\wedge $ c2pRq_rdy $ \\wedge $ L2.state = S ", " 9  &  L1.miss $ \\wedge $ L1.busy $ \\wedge $ p2cRp_exist $ \\wedge $ $ \\neg $ p2cRp_rdy ", " 10  &  L1.miss $ \\wedge $ L1.busy $ \\wedge $ p2cRp_rdy ", " 11  &  $ \\neg $ L1.miss  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Tardis [@bib:yu2015] is a recently proposed cache coherence protocol that is able to scale to a large number of cores.", "Unlike full-map directory protocols [@bib:censier1978,tang1976] , Tardis does not keep the $ O(N) $ ( $ N $ is the core count) sharer information for each cacheline.", "In Tardis, only the owner ID of each cacheline ( $ O(\\log{N}) $ ) and logical timestamps ( $ O(1) $ ) for each cacheline are maintained.", "Unlike the snoopy bus coherence protocol [@bib:goodman1983] , or limited directory protocols such as ACKwise [@bib:ATAC] , Tardis does not broadcast messages to maintain coherence.", "\\newline In Tardis, each load or store is assigned a logical timestamp which may not agree with the physical time.", "The global memory order then simply becomes the timestamp order which is explicit in the protocol.", "This makes it much simpler to reason about the correctness of Tardis.", "Despite its simplicity, however, no proof of correctness has yet been published.", "We provide a simple and straightforward proof in Section [@ref:LABEL:sec:proof] ; our proof is simpler than existing proofs for snoopy and directory protocols such as [@bib:plakal1998,muralidaran2015] .", "\\newline In this paper, we formally prove the correctness of the Tardis protocol by showing that an execution of a program using Tardis strictly follows Sequential Consistency (SC).", "We also prove that the Tardis protocol can never deadlock or livelock.", "\\newline The original Tardis protocol [@bib:yu2015] was designed for a shared memory multicore processor.", "A number of optimization techniques were applied for performance improvement.", "These optimizations, however, may not be desirable in other kinds of shared memory systems.", "Therefore, in this paper we first extract the core algorithm of Tardis and prove its correctness.", "We then focus on correctness of generalizations of the base protocol.", "\\newline We prove the correctness of Tardis by developing simple and intuitive system invariants.", "Compared to the popular model checking [@bib:murphi,tlc2,gigamax] verification techniques, our proof technique is able to scale to high processor counts.", "More important, the invariants we developed are more intuitive to system designers and thus provide more guidance for system implementation.", "\\newline The rest of the paper is organized as follows.", "The Tardis protocol is formally defined in [@ref:LABEL:sec:tardis] .", "It is proven to obey sequential consistency in [@ref:LABEL:sec:proof] and to be deadlock-free and livelock-free in [@ref:LABEL:sec:freedom] .", "In [@ref:LABEL:sec:mem] , we generalize the proofs to systems with main memory.", "[@ref:LABEL:sec:related] describes related work and [@ref:LABEL:sec:conclusion] concludes the paper.", "\\newline  </section>"], ["<section> <title> 2 Tardis Coherence Protocol </title>  We first present the model of the shared memory system we use, along with our assumptions, in [@ref:LABEL:sec:system] .", "Then, we introduce system components of the Tardis protocol in [@ref:LABEL:sec:format] and formally specify the protocol in [@ref:LABEL:sec:protocol] .", "\\newline <subsection> <title> 2.1 System Description </title> [@ref:LABEL:fig:system] shows the architecture of a shared memory system based on which Tardis will be defined.", "The processors can execute instructions in-order or out-of-order but always commit instructions in order.", "A processor talks to the memory subsystem through a pair of local buffers (LB).", "Load and store requests are inserted into the memory request buffer ( mRq ) and responses from the memory subsystem are in the memory response buffer ( mRp ).", "\\newline We model a two-level memory subsystem with all the data fitting into the L2 caches.", "The network between L1 and L2 caches is modeled as buffers.", "c2pRq contains requests from L1 (child) to L2 (parent), c2pRp contains responses from L1 to L2, and p2c contains messages (both requests and responses) from L2 to L1.", "For simplicity, all the buffers are modeled as FIFOs and get_msg  returns the head message in the buffer.", "However, the protocol also works if the buffers only have the FIFO property for the same address.", "Each L1 cache has a unique id from $ 1 $ to $ N $ and each associated buffer has the same id .", "An L1 cacheline or a message in a buffer has the same id as the L1 cache or the buffer it is in.", "\\newline </subsection> <subsection> <title> 2.2 System Components in Tardis </title> The Tardis protocol is built around the concept of logical timestamps.", "Each memory operation in Tardis has a corresponding timestamp which indicates its global memory order.", "The memory dependency is expressed using timestamps and no sharer information is maintained.", "For simplicity, we assume the timestamps to be large enough that they never overflow (e.g., 64-bits).", "Timestamp compression algorithms are able to achieve much smaller timestamps (e.g., 16-bits) in practice [@bib:yu2015] .", "\\newline At a high level, if a load observes the value of a previous store, then the load should be ordered after the store in the logical time (and thus global memory order).", "Similarly, a store should be ordered after a load if the load does not observe the stored value.", "To keep track of the timestamps of each operation, every cacheline in Tardis has a read timestamp ( rts ) and a write timestamp ( wts ).", "The wts is the timestamp of the last store and rts is the timestamp of the last (potential) load to the cacheline ( wts $ \\leq $ rts ).", "Similar to a directory protocol, a cacheline can be cached in L1 in either M or S states.", "Only one L1 can obtain the M state at any time to modify the cacheline, and multiple L1s can share the line in the S state.", "Timestamps are also required for messages in the buffers.", "[@ref:LABEL:tab:format] summarizes the format of caches and buffers modeled in the system.", "The differences between Tardis and a directory protocol are highlighted in red.", "\\newline An L1 cacheline contains five fields: state , data , busy , wts and rts .", "The state can be M , S or I .", "For ease of discussion, we define a total ordering among the three states $ \\textit{I}<\\textit{S}<\\textit{M} $ .", "A cacheline has busy $ = $ True if a request to L2 is outstanding.", "This prevents duplicated requests.", "An L2 cacheline contains one more field owner , which is the id of the L1 that exclusively owns the cacheline in the M state.", "As in L1, busy in L2 is set when a write back request ( WBRq ) to an L1 is outstanding.", "\\newline Each entry in mRq contains four fields: type , addr , data and pts .", "The type can be S or M corresponding to a load or store request, respectively.", "The pts is a timestamp specified by the processor and the timestamp of the memory operation should be no less than pts .", "mRp has the same format as mRq , but pts here is the actual timestamp of the memory operation.", "\\newline The format of the messages in the network buffers ( c2pRq , c2pRp and p2c ) is shown in Table [@ref:LABEL:tab:format] , where the meaning of the fields are as in the cachelines or the messages in mRq .", "All network messages have a field id which is the id of the L1 cache that the message comes from or goes to.", "Messages in p2c have a field msg , which can be either Req or Resp ; p2c may contain both requests and responses from L2 to L1 and msg differentiates the two types.", "\\newline </subsection> <subsection> <title> 2.3 Protocol Specification </title> We now formally define the core algorithm of the Tardis protocol.", "The state transition rules for L1 and L2 caches are summarized in [@ref:LABEL:tab:l1-rules] and [@ref:LABEL:tab:l2-rules] respectively, with the differences between Tardis and a directory protocol highlighted in red.", "For all rules where a message is enqueued to a buffer, the rule can only fire if the buffer is not full.", "\\newline An important concept in Tardis is the lease.", "For a cacheline shared in an L1 cache, it also contains a lease which expires at the current rts .", "The data is only valid if the lease has not expired, i.e., pts from the request is less than or equal to rts .", "The rts in the L2 cache is the maximum of the rts of all the sharing L1 caches.", "When a shared cacheline in L2 cache gets a GetM request, it does not send invalidations as in a directory protocol, rather, it immediately returns exclusive ownership to the requesting processor, which will jump ahead in logical time and perform the store at $ \\textit{rts}+1 $ .", "If we consider logical time, the store happens after all the loads that do not observe its value, although in physical time, the store and the loads may happen simultaneously.", "\\newline Specifically, the following six transition rules may fire in an L1 cache.", "\\newline 1.", "LoadHit .", "LoadHit can fire if the requested cacheline is in the M state or is in the S state and the lease has not expired.", "If it is in the M state, then rts is updated to reflect the latest load timestamp.", "The pts returned to the processor is no less than the cacheline\u2019s wts , which orders the load after the previous store in logical time.", "\\newline 2.", "StoreHit .", "StoreHit can only fire if the requested cacheline is in the M state in the L1 cache.", "Both wts and rts are updated to the timestamp of the store operation which is at least $ \\textit{rts}+1 $ .", "The store is thus logically ordered after all concurrent loads on the same address in other L1s.", "\\newline 3.", "L1Miss .", "If neither LoadHit nor StoreHit can fire for a request and the cacheline is not busy, it is an L1 miss and the request ( GetS or GetM ) is forwarded to the L2 cache.", "The cacheline is then marked as busy to prevent sending duplicated requests.", "\\newline 4.", "L2Resp .", "A response from L2 sets all the fields in the L1 cacheline.", "The busy flag is reset to False and the cacheline can serve the next request in the mRq .", "\\newline 5.", "Downgrade .", "A cacheline in the M or S states may downgrade if the cacheline is not busy and LoadHit and StoreHit cannot fire.", "For M to S or I downgrade, the cacheline should be written back to the L2 in a WBRp message.", "S to I downgrade, however, is silent, i.e., no message is sent.", "\\newline 6.", "WriteBackReq .", "When a cacheline in M state receives a write back request, the cacheline is returned to L2 in a WBRp message and the L1 state becomes S .", "If the request is to a cacheline in S or I state, the request is simply ignored.", "This corresponds to the case where the line self downgrades after the write back request ( WBRq ) is sent from the L2.", "\\newline The following four rules may fire in the L2 cache.", "\\newline 7.", "ShReq_S .", "When a cacheline in the S state receives a shared request (i.e., GetS ), both the rts and the returned pts are set to pts $ ^{\\prime} $ which can be any timestamp greater than or equal to the current rts and pts .", "The pts $ ^{\\prime} $ indicates the end of the lease for the cacheline. And the cacheline may be loaded at any logical time between wts and pts $ ^{\\prime} $ .", "The returned message is a ToS message.", "\\newline 8.", "ExReq_S .", "When a cacheline in the S state receives an exclusive request (i.e., GetM ), the cacheline is instantly returned in a ToM message.", "Unlike in a directory protocol, no invalidations are sent to the sharers.", "The sharing processors may still load their local copies of the cacheline and such loads have smaller timestamps than the store from the new owner processor.", "\\newline 9.", "Req_M .", "When a cacheline in the M state receives a request and is not busy, a write back request (i.e., WBRq ) is sent to the current owner.", "busy is set to True to prevent sending duplicated WBRq requests.", "\\newline 10.", "WriteBackResp .", "Upon receiving a write back response (i.e., WBRp ), data and timestamps are written to the L2 cacheline.", "The state becomes S and busy is reset to False .", "\\newline </subsection>  </section>"], ["<section> <title> 3 Proof of Correctness </title>  We now prove the correctness of the Tardis protocol specified in [@ref:LABEL:sec:protocol] by proving that it strictly follows sequential consistency.", "We first give the definition of sequential consistency in [@ref:LABEL:sec:sc] and then introduce the basic lemma ( [@ref:LABEL:sec:basic-lemma] ) and timestamp lemmas ( [@ref:LABEL:sec:ts-lemma] ) that are used for the correctness proof.", "\\newline Most of the lemmas and theorems in the rest of the paper are proven through induction.", "For each lemma or theorem, we first prove that it is true for the initial system state (base case) and then prove that it is still true after any possible state transition assuming that it was true before the transition.", "\\newline In the initial system state, all the L1 cachelines are in the I state, all the L2 cachelines are in the S state and all the network buffers are empty.", "For all cachelines in L1 or L2, $ \\textit{wts}=\\textit{rts}=0 $ and $ \\textit{busy}=\\textit{False} $ .", "Requests from the processors may exist in the mRq buffers.", "For ease of discussion, we assume that each initial value in L2 was set before the system starts at timestamp $ 0 $ through a store operation.", "\\newline <subsection> <title> 3.1 Sequential Consistency </title> According to Lamport [@bib:lamport1979] , a parallel program is sequentially consistent if \u201c the result of any execution is the same as if the operations of all processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program \u201d.", "Using $ <_{m} $ and $ <_{p} $ to represent the global memory order and program order per processor respectively, sequential consistency (SC) is defined as follows [@bib:sorin2011] .", "\\newline <theorem> Definition 1 (Sequential Consistency) .", "An execution of a program is sequentially consistent iff \\newline Rule 1: $ \\forall X,Y\\in\\{Ld,St\\} $ from the same processor, $ X<_{p}Y\\Rightarrow X<_{m}Y $ .", "\\newline Rule 2: Value of $ L $ ( $ a $ ) = Value of Max $ _{<m}\\{S(a)|S(a)<_{m}L(a)\\} $ , where $ L(a) $ and $ S(a) $ are a load and a store to address $ a $ , respectively, and $ Max_{<m} $ selects the most recent operation in the global memory order.", "\\newline </theorem> In Tardis, the global memory order of sequential consistency is expressed using timestamps.", "Specifically, Theorem 1 states the invariants in Tardis that correspond to the two rules of sequential consistency.", "Here, we use $ <_{ts} $ and $ <_{pt} $ to represent (logical) timestamp order that is assigned by Tardis and physical time order that represents the order of events, respectively.", "\\newline <theorem> Theorem 1 (SC on Tardis) .", "An execution on Tardis has the following invariants.", "\\newline Invariant 1: Value of $ L $ ( $ a $ ) = Value of Max $ _{<ts}\\{S(a)|S(a)\\leq_{ts}L(a)\\} $ .", "\\newline Invariant 2: $ \\forall S_{1}(a),S_{2}(a) $ , $ S_{1}(a)\\neq_{ts}S_{2}(a) $ .", "\\newline Invariant 3: $ \\forall S(a),L(a),S(a)=_{ts}L(a)\\Rightarrow S(a)<_{pt}L(a) $ .", "\\newline </theorem> Theorem [@ref:LABEL:theorem:tardis-sc] itself is not enough to guarantee sequential consistency; we also need the processor model described in Definition [@ref:LABEL:def:inorder-commit] .", "The processor should commit instructions in the program order, which implies physical time order and monotonically increasing timestamp order.", "Both in-order and out-of-order processors fit this model.", "\\newline <theorem> Definition 2 (In-order Commit Processor) .", "$ \\forall X,Y\\in\\{Ld,St\\} $ from the same processor, $ X<_{p}Y\\Rightarrow X\\leq_{ts}Y\\wedge X<_{pt}Y $ .", "\\newline </theorem> Now we prove that given Theorem [@ref:LABEL:theorem:tardis-sc] and our processor model, an execution obeys sequential consistency per Definition 1.", "We first introduce the following definition of the global memory order in Tardis.", "\\newline <theorem> Definition 3 (Global Memory Order in Tardis) .", "<equation> $ X<_{m}Y\\triangleq X<_{ts}Y\\vee X=_{ts}Y\\wedge X<_{pt}Y. $ </equation> \\newline </theorem> <theorem> Theorem 2 .", "Tardis with in-order commit processors implements Sequential Consistency.", "\\newline <proof> Proof.", "According to Definitions 2 and 3, $ X<_{p}Y\\Rightarrow X\\leq_{ts}Y\\wedge X<_{pt}Y\\Rightarrow X<_{m}Y $ .", "So Rule 1 in Definition 1 is obeyed.", "\\newline $ S(a)\\leq_{ts}L(a)\\Rightarrow S(a)<_{ts}L(a)\\vee S(a)=_{ts}L(a) $ .", "By Invariant 3 in Theorem 1, this implies $ S(a)\\leq_{ts}L(a)\\Rightarrow S(a)<_{ts}L(a)\\vee S(a)=_{ts}L(a)\\wedge S(a)<_{pt% }L(a) $ .", "Thus, from Definition [@ref:LABEL:def:mem-order] , $ S(a)\\leq_{ts}L(a)\\Rightarrow S(a)<_{m}L(a) $ .", "We also have $ S(a)<_{m}L(a)\\Rightarrow S(a)\\leq_{ts}L(a) $ from Definition [@ref:LABEL:def:mem-order] .", "So $ \\{S(a)|S(a)\\leq_{ts}L(a)\\}=\\{S(a)|S(a)<_{m}L(a)\\} $ .", "According to Invariant 2 in Theorem 1, all the elements in $ \\{S(a)|S(a)<_{m}L(a)\\} $ have different timestamps, which means $ <_{m} $ and $ <_{ts} $ indicate the same ordering.", "Finally, Invariant 1 in Theorem 1 becomes Rule 2 in Definition 1.", "\u220e \\newline </proof> </theorem> In the following two sections, we focus on the proof of Theorem 1.", "\\newline </subsection> <subsection> <title> 3.2 Basic Lemma </title> We first give the definition of a clean block for ease of discussion.", "\\newline <theorem> Definition 4 (Clean Block) .", "A clean block can be an L2 cacheline in S state, or an L1 cacheline in M state, or a ToM or WBRp message in a network buffer.", "\\newline </theorem> <theorem> Lemma 1 .", "$ \\forall $ address $ a $ , at most one clean block exists.", "\\newline </theorem> The basic lemma is an invariant about the cacheline states and the messages in network buffers.", "No timestamps are involved.", "\\newline A visualization of Lemma [@ref:LABEL:lemma:basic] is shown in [@ref:LABEL:fig:clean] where a solid line represents a clean block.", "When the L2 state for an address is S , no L1 can have that address in M state, and no ToM and WBRp may exist.", "Otherwise if the L2 state is M , either a ToM response exists, or an L1 has the address in M state, or a WBRp exists.", "Intuitively, Lemma [@ref:LABEL:lemma:basic] says only one block in the system can represent the latest data value.", "\\newline <proof> Lemma For the base case, the lemma is trivially true since exactly one clean block exists for each address and the block is an L2 cacheline in S state.", "We now consider all the possible transition rules that may create a new clean block.", "\\newline Only the ExReq_S rule can create a ToM response.", "However, the rule changes the state of the L2 cacheline from S to M and thus removes a clean block.", "Only the L2Resp rule can change an L1 cacheline state to M .", "However, it removes a ToM response from the p2c buffer.", "Both Downgrade and WriteBackReq can enqueue WBRp messages and both will change the L1 cacheline state from M to S or I .", "Only WriteBackResp changes the L2 cacheline to S state but it also dequeues a WBRp from the buffer.", "\\newline In all of these transitions, a clean block is created and another one is removed.", "By the induction hypothesis, at most one clean block per address exists before the current transition, and still at most one clean block for the address exists after the transition.", "For other transitions not listed above, no clean block can be created so at most one clean block per address exists after any transition, proving the lemma.", "\u220e \\newline </proof> </subsection> <subsection> <title> 3.3 Timestamp Lemmas </title> <theorem> Lemma 2 .", "At the current physical time, a clean block has the following invariants.", "\\newline Invariant 1 Its rts is no less than the rts of all the other blocks (in caches and messages) with respect to the same address.", "\\newline Invariant 2 Till the current physical time, no store has happened to the address at timestamp ts such that ts $ > $ rts.", "\\newline </theorem> <proof> Proof.", "We prove the lemma by induction on the transition sequence.", "For the base case, only one block exists per address so Invariant 1 is true.", "All the stores so far happened at timestamp 0 which equals the rts of all the clean blocks, proving Invariant 2.", "\\newline According to Lemma 1, for an address, exactly one clean block exists.", "By the induction hypothesis, if no timestamp changes and no clean block is generated, Invariant 1 is still true after the transition.", "By the transition rules, wts or rts can only be increased if the block is an L2 cacheline in the S state or an L1 cacheline in the M state.", "In both cases the block is clean.", "After the transition, the rts of the clean block increases and is still no less than the rts of other cachelines with the same address.", "\\newline Similarly, by the induction hypothesis, Invariant 2 is true after the transition if no store happens and no clean block is generated.", "Only StoreHit can perform a store to a clean block, which changes both wts and rts to be $ \\max(\\textit{pts},\\textit{rts}+1) $ .", "For the stored cacheline, since no store has happened with timestamp $ ts $ such that $ {\\it ts}>{\\it old\\_}\\textit{rts} $ (induction hypothesis), after the transition, no store, including the current one, has happened with timestamp ts such that $ {\\it ts}>\\max(\\textit{pts},{\\it old\\_}\\textit{rts}+1)>{\\it old\\_}\\textit{rts} $ .", "\\newline Consider the last case where a clean block is generated at the current transition.", "Here, according to Lemma [@ref:LABEL:lemma:basic] , another clean block disappears.", "In all the transitions, the rts of the new clean block equals the rts of the old block.", "Thus, both invariants are still true after the transition.", "\u220e \\newline </proof> <theorem> Lemma 3 .", "For any block B in a cache or a message (WBRp, ToS and ToM), the data value associated with the block comes from a store St which has happened before the current physical time, and no other store $ St^{\\prime} $ has happened such that $ St.ts<St^{\\prime}.ts\\leq B.\\textit{rts} $ , where St.ts is the timestamp of the store St and B.rts is the rts of block B. \\newline </theorem> <proof> Proof.", "We prove the lemma by induction on the transition sequence.", "For the base case, each block has a corresponding store which happened before the system started and is thus before the current physical time.", "It is also the only store happened per address.", "Therefore the hypothesis is true.", "\\newline We first prove that after a transition, for each block, there exists a store $ St $ which creates the data of the block and $ St $ happened before the current physical time.", "Consider the case where the data of a block does not change or comes from another block.", "Then, by the induction hypothesis, $ St $ must exist for the block after the transition.", "The only transition that changes the data of a block is StoreHit .", "After the store, however, the data stored in the cacheline comes from the current store which has just happened in physical time.", "\\newline We now prove the second part of the lemma, that for any block $ B $ , no store $ St^{\\prime}\\neq St $ has happened such that $ St.ts<St^{\\prime}.ts\\leq B.\\textit{rts} $ .", "By the induction hypothesis, for the current transition, if no data or rts is changed in any block or if a block copies data and rts from an existing block, then the hypothesis is still true after the transition.", "The only cases in which the hypothesis may be violated are when the current transition changes rts or data for some block, which is only possible for LoadHit , StoreHit and ShReq_S .", "\\newline For LoadHit , if the cacheline is in the S state, then rts remains unchanged.", "Otherwise, the cacheline must be a clean block, in which case rts is increased.", "Similarly, ShReq_S increases the rts and the cacheline must be a clean block again.", "By Invariant 2 in Lemma [@ref:LABEL:lemma:clean-latest] , no store has happened to the address with timestamp greater than rts . And thus after the rts is increased, no store can have happened with timestamp between the old rts to the new rts .", "By the induction hypothesis, we also have that no store $ St^{\\prime} $ could have happened such that $ St.ts<St^{\\prime}.ts\\leq old\\_rts $ .", "These two inequalities together prove the hypothesis.", "\\newline For StoreHit , both rts and data are modified.", "For the stored cacheline, after the transition, $ St.ts $ = wts = rts = max(pts, old_rts + 1).", "Thus, no $ St^{\\prime} $ may exist in this situation.", "For all the other cachelines, by Invariant 1 in Lemma [@ref:LABEL:lemma:clean-latest] , their rts is no greater than the old rts of the stored cacheline and is thus smaller than the timestamp of the current store.", "By the induction hypothesis, no store $ St^{\\prime} $ exists for those blocks before the transition.", "Thus, in the overall system, no such store $ St^{\\prime} $ can exist, proving the lemma.", "\u220e \\newline </proof> Finally, we prove Theorem 1.", "\\newline <proof> Theorem 1 Proof.", "According to Lemma [@ref:LABEL:lemma:ts-store] , for each $ L(a) $ , the loaded data is provided by an $ S(a) $ and no other store $ S^{\\prime}(a) $ has happened between the timestamp of $ S(a) $ and the rts .", "And thus no $ S^{\\prime}(a) $ has happened between the timestamp of $ S(a) $ and the timestamp of the load which is no greater than rts by the transition rules.", "Therefore, Invariant 1 in Theorem [@ref:LABEL:theorem:tardis-sc] is true.", "\\newline By the transition rules, a new store can only happen to a clean block and the timestamp of the store is $ \\max(\\textit{pts},\\textit{rts}+1) $ .", "By Invariant 2 in Lemma [@ref:LABEL:lemma:clean-latest] , for a clean block at the current physical time, no store to the same address has happened with timestamp greater than the old rts of the cacheline.", "Therefore, for each new store, no store to the same address so far has the same timestamp as the new store, because the new store\u2019s timestamp is strictly greater than the old rts .", "And thus no two stores to the same address may have the same timestamp, proving Invariant 2.", "\\newline Finally, we prove Invariant 3.", "If $ S(a)=_{ts}L(a) $ , by Invariant 1 in Theorem [@ref:LABEL:theorem:tardis-sc] , $ L(a) $ returns the data stored by $ S(a) $ .", "Then by Lemma [@ref:LABEL:lemma:ts-store] , the store $ S(a) $ must have happened before $ L(a) $ in the physical time.", "\u220e \\newline </proof> </subsection>  </section>"], ["<section> <title> 4 Deadlock and Livelock Freedom </title>  In this section, we prove that the Tardis protocol specified in [@ref:LABEL:sec:tardis] is both deadlock-free ( [@ref:LABEL:sec:deadlock] ) and livelock-free ( [@ref:LABEL:sec:livelock] ).", "\\newline <subsection> <title> 4.1 Deadlock Freedom </title> <theorem> Theorem 3 (Deadlock Freedom) .", "After any sequence of transitions, if there is a pending request from any processor, then at least one transition rule (other than the Downgrade rule) can fire.", "\\newline </theorem> Before proving the theorem, we first introduce and prove several lemmas.", "\\newline <theorem> Lemma 4 .", "If an L1 cacheline is busy, either a GetS or GetM request exists in its c2pRq buffer or a ToS or ToM response exists in its p2c buffer.", "\\newline </theorem> <proof> Proof.", "This can be proven through induction on the transition sequence.", "In the base case, all the L1 cachelines are non-busy and the hypothesis is true.", "An L1 cacheline can only become busy through the L1Miss rule, which enqueues a request to its c2pRq buffer.", "A request can only be dequeued from c2pRq through the ShReq_S or ExReq_S rule, which enqueues a response into the same L1\u2019s p2c buffer.", "Finally, whenever a message is dequeued from the p2c buffer ( L2Resp rule), the L1 cacheline becomes non-busy, proving the lemma.", "\u220e \\newline </proof> <theorem> Lemma 5 .", "If an L2 cacheline is busy, the cacheline must be in state M. \\newline </theorem> <proof> Proof.", "This lemma can be proven by induction on the transition sequence.", "For the base case, no cachelines are busy and the hypothesis is true.", "Only Req_M makes an L2 cacheline busy but the cacheline must be in the M state.", "Only WriteBackResp downgrades an L2 cacheline from the M state but it also makes the cacheline non-busy.", "\u220e \\newline </proof> <theorem> Lemma 6 .", "For an L2 cacheline in the M state, the id of the clean block for the address equals the owner of the L2 cacheline.", "\\newline </theorem> <proof> Proof.", "According to Lemma [@ref:LABEL:lemma:basic] , exactly one clean block exists for the address.", "If the L2 state is M , the clean block can be a ToM response, an L1 cacheline in the M state or a WBRp .", "We prove the lemma by induction on the transition sequence.", "\\newline The base case is true since no L2 cachelines are in the M state.", "We only need to consider cases wherein a clean block is created.", "When ToM is created ( ExReq_S rule), its id equals the owner in the L2 cacheline.", "When an L1 cacheline in the M state is created ( L2Resp rule), its id equals the id of the ToM response.", "When a WBRp is created ( WriteBackReq or Downgrade rule), its id equals the id of the L1 cacheline.", "By the induction hypothesis, the id of a newly created clean block always equals the owner in the L2 cacheline which does not change as long as the L2 cacheline is in the M state.", "\u220e \\newline </proof> <theorem> Lemma 7 .", "For a busy cacheline in L2, either a WBRq or a WBRp exists for the address with id matching the owner of the L2 cacheline.", "\\newline </theorem> <proof> Proof.", "We prove the lemma by induction on the transition sequence.", "For the base case, no cacheline is busy and thus the hypothesis is true.", "We only need to consider the cases where an L2 cacheline is busy after the current transition, i.e., $ \\neg\\textit{busy}\\Rightarrow\\textit{busy} $ and $ \\textit{busy}\\Rightarrow\\textit{busy} $ .", "\\newline Only the Req_M rule can cause a $ \\neg\\textit{busy}\\Rightarrow\\textit{busy} $ transition and the rule enqueues a WBRq into p2c with id matching the owner and therefore the hypothesis is true.", "\\newline For $ \\textit{busy}\\Rightarrow\\textit{busy} $ , the lemma can only be violated if a WBRq or WBRp with matching id is dequeued.", "However, when a WBRp is dequeued, the cacheline becomes non-busy in L2 ( WriteBackResp rule).", "If a WBRq is dequeued and the L1 cacheline is in the M state, a WBRp is created with a matching id .", "So the only case to consider is when the WBRq with matching id is dequeued, and the L1 cacheline is in the S or I states, and no other WBRq exists in the same p2c buffer and no WBRp exists in the c2pRp buffer.", "\\newline The L2 cacheline can only become busy by sending a WBRq .", "The fact that the dequeued WBRq is the only WBRq in the c2pRq means that the L2 cacheline has been busy since the dequeued WBRq was sent (otherwise another WBRq will be sent when the L2 cacheline becomes busy again).", "Since p2c is a FIFO, when the WBRq is dequeued, the messages in the p2c must be sent after the WBRq was sent.", "By transition rules, the L2 cacheline cannot send ToM while being busy, so no ToM may exist in the p2c buffer when WBRq dequeues.", "As a result, no clean block exists with id = owner .", "Then, by Lemma [@ref:LABEL:lemma:l2-m] , no clean block exists for the address (L2 is in the M state because of Lemma [@ref:LABEL:lemma:l2-busy-m] ) which contradicts Lemma [@ref:LABEL:lemma:basic] .", "\u220e \\newline </proof> <proof> Theorem If any message exists in the c2pRp buffer, the WriteBackResp rule can fire.", "Consider the case where no message exists in c2pRp buffer.", "If any message exists in the p2c buffer\u2019s head, the L2Resp rule can fire, or the WriteBackReq , LoadHit or StoreHit rule can fire.", "For the theorem to be violated, no messages can exist in the c2pRp or p2c buffer.", "Then, according to Lemma [@ref:LABEL:lemma:l2-busy] , all cachelines in L2 are non-busy.", "\\newline Now consider the case when no message exists in c2pRp buffer or p2c buffer and a GetS or GetM request exists in c2pRq for an L1 cache.", "Since the L2 is not busy, one of ShReq_S , ExReq_S and Req_M can fire, which enqueues a message into the p2c buffer.", "\\newline Consider the last case where there is no message in any network buffer.", "By Lemma [@ref:LABEL:lemma:l1-busy] , all L1 cachelines are non-busy.", "By the hypothesis, there must be a request in mRq for some processor.", "Now if the request is a hit, the corresponding hit rule ( LoadHit or StoreHit ) can fire.", "Otherwise, the L1Miss rule can fire, sending a message to c2pRq .", "\u220e \\newline </proof> </subsection> <subsection> <title> 4.2 Livelock Freedom </title> Even though the Tardis protocol correctly follows sequential consistency and is deadlock-free, livelock may still occur if the protocol is not well designed.", "For example, for an L1 miss, the Downgrade rule may fire immediately after the L2Resp but before any LoadHit or StoreHit rule fires.", "As a result, the L1Miss needs to be fired again but the Downgrade always happens after the response comes back, leading to livelock.", "We avoid this possibility by only allowing Downgrade to fire when neither LoadHit nor StoreHit can fire.", "\\newline To rigorously prove livelock freedom, we need to guarantee that some transition rule should eventually make forward progress and no transition rule can make backward progress.", "We give the following definition of livelock freedom.", "\\newline <theorem> Theorem 4 .", "After any sequence of transitions, if there exists a pending request from any processor, then within a finite number of transitions, some request at some processor will dequeue.", "\\newline </theorem> In order to prove the theorem, we will show that for every transition rule, at least one request will make forward progress and move one step towards the end of the request and at the same time no other request makes backward progress; or if no request makes forward or backward progress for the transition, we show that such transitions can only be fired a finite number of times.", "Specifically, we define forward progress as a lattice of system states where each request in mRq (load or store) has its own lattice.", "[@ref:LABEL:tab:lattice] shows the lattice for a request where the lower parts in the lattice correspond to the states with more forward progress.", "We will prove livelock freedom by showing that for any state transition in any cache, any request either moves down the lattice (making forward progress) or stays at the current position but never moves up.", "Moreover, transitions which keep the state of every request staying at the same position in the lattice can only occur a finite number of times.", "Specifically, we will prove the following lemma.", "\\newline <theorem> Lemma 8 .", "For a state transition except Downgrade, WriteBackReq and WriteBackResp, either a request dequeues from the mRq or at least one request will move down its lattice.", "For all the state transitions, no request will move up its lattice.", "Further, the system can only fire Downgrade, WriteBackReq and WriteBackResp for a finite number of times without firing other transitions.", "\\newline </theorem> We need the following lemmas before proving Lemma [@ref:LABEL:lemma:lattice] .", "\\newline <theorem> Lemma 9 .", "If an L1 cacheline is busy, then exactly one request (GetS or GetM in c2pRq) or response (ToS or ToM in p2c) exists for the address and the L1 cache.", "If the L1 cacheline is non-busy, then no request or response can exist in its c2pRq and p2c.", "\\newline <proof> Proof.", "This lemma is a stronger lemma than Lemma [@ref:LABEL:lemma:l1-busy] .", "We prove this by the induction on the transition sequence.", "For the base case, all the L1 cachelines are non-busy and no message exists and thus the lemma is true.", "\\newline We only need to consider the cases where the busy flag changes or any request or response is enqueued or dequeued.", "Only the L1Miss , L2Resp , ShReq_S and ExReq_S rules need to be considered.", "\\newline For L1Miss , a request is enqueued to c2pRq and the L1 cacheline becomes busy.", "For L2Resp , a response is dequeued and the L1 cacheline becomes non-busy.", "For ShReq_S and ExReq_S , a request is dequeued but a response in enqueued.", "By the induction hypothesis, after the current transition, the hypothesis is still true for all the cases above, proving the lemma.", "\u220e \\newline </proof> </theorem> <theorem> Lemma 10 .", "If an L1 cacheline is busy, there must exist a request at the head of the mRq buffer for the address and the request misses in the L1.", "\\newline </theorem> <proof> Proof.", "For the base case, all L1 cachelines are non-busy and the lemma is true.", "\\newline We consider cases where the L1 cacheline is busy after the transition.", "Only L1Miss can make an L1 cacheline busy from non-busy and the rule requires a request to be waiting at the head of the mRq buffer.", "If the L1 cacheline stays busy, then no rule can remove the request from the mRq buffer.", "By the induction hypothesis, the lemma is true after any transition.", "\u220e \\newline </proof> <theorem> Lemma 11 .", "If an L2 cacheline is busy, there must exist a request with the same address at the head of the c2pRq buffer in L2.", "\\newline </theorem> <proof> Proof.", "The proof follows the same structure as the previous proof for Lemma [@ref:LABEL:lemma:l1-busy-mrq] .", "\u220e \\newline </proof> <theorem> Lemma 12 .", "For a memory request in a c2pRq buffer, its type and pts equal the type and pts of a pending processor request to the same address at the head of the mRq at the L1 cache.", "\\newline <proof> Proof.", "By Lemmas [@ref:LABEL:lemma:req-mutex] and [@ref:LABEL:lemma:l1-busy-mrq] , the L1 cacheline with the same address must be busy and a pending processor request exists at the head of the mRq buffer.", "Only the L1Miss rule sets the type and pts of a memory request in a c2pRq buffer and they equal the type and pts from the processor request.", "\u220e \\newline </proof> </theorem> <theorem> Lemma 13 .", "For a memory response in a p2c buffer, its type equals the type of a pending processor request to the same address at the L1 cache and if the type = S, its rts is no less than the pts of that processor request.", "\\newline <proof> Proof.", "Similar to the proof of Lemma [@ref:LABEL:lemma:getx] , the processor request must exist.", "Only the ShReq_S and ExReq_S rules set the type and rts of the response, and type equals the type of a memory request and if type = S , rts is no less than the memory request.", "Then the lemma is true by Lemma [@ref:LABEL:lemma:getx] .", "\u220e \\newline </proof> </theorem> <theorem> Lemma 14 .", "When the L2Resp rule fires, a request with the same address at the head of mRq will transition from an L1 miss to an L1 hit.", "\\newline <proof> Proof.", "Before the transition of L2Resp , the L1 cacheline is busy, and a response is at the head of the p2c buffer.", "By Lemma [@ref:LABEL:lemma:tox] , if the pending processor request has type = M , then the memory response also has type = M and thus it is an L1 hit.", "If the pending processor has type = S , also by Lemma [@ref:LABEL:lemma:tox] , the memory response has type = S and the rts of the response is no less than the pts of the pending request.", "Therefore, it is also an L1 hit.", "\u220e \\newline </proof> </theorem> <theorem> Lemma 15 (Coverage) .", "The union of all the entries in [@ref:LABEL:tab:lattice] is True.", "\\newline </theorem> <proof> Proof.", "By Lemma [@ref:LABEL:lemma:l1-busy] , if L1.busy we can prove that c2pRq_exist $ \\vee $ p2cRp_exist $ \\Rightarrow $ True .", "\\newline Then it becomes obvious that the union of all the entries is true.", "\u220e \\newline </proof> <theorem> Lemma 16 (Mutually Exclusive) .", "The intersection of any two entries in [@ref:LABEL:tab:lattice] is False.", "\\newline </theorem> <proof> Proof.", "For most pairs of entries, we can trivially check that the intersection is False .", "The only tricky cases are the intersection of entry 9 or 10 with an entry from 3 to 8.", "These cases can be proven False using Lemma [@ref:LABEL:lemma:req-mutex] , which implies that c2pRq_exist $ \\wedge $ p2cRp_exist $ \\Rightarrow $ False .", "\u220e \\newline </proof> <proof> Lemma We need to prove two goals.", "First, for each transition rule except Downgrade , WriteBackReq and WriteBackResp , at least one request will dequeue or move down the lattice.", "Second, for all transition rules no request will move up the lattice.", "\\newline We first prove that a transition with respect to address $ a_{1} $ never moves a request with address $ a_{2} $ ( $ \\neq a_{1} $ ) up its lattice.", "The only possible way that the transition affects the request with $ a_{2} $ is by dequeuing from a buffer which may make a request with $ a_{2} $ being the head of the buffer and thus becomes ready.", "However, this can only move the request with $ a_{2} $ down the lattice.", "\\newline Also note that each processor can only serve one request per address at a time, because the mRq is a FIFO.", "Therefore, for the second goal we only need to prove that requests with the same address in other processors do not move up the lattice.", "We prove both goals for each transition rule.", "\\newline For LoadHit and StoreHit , a request always dequeues from the mRq and the lemma is satisfied.", "\\newline For the L1Miss rule, a request must exist and be in entry $ 1 $ in a table before the transition. And since busy $ = $ True after the transition, it must move down the lattice to one of entries from $ 2 $ to $ 10 $ .", "Since the L1 cacheline state does not change, no other requests in other processors move in their lattice.", "\\newline For the L2Resp rule, according to Lemma [@ref:LABEL:lemma:hit-l2resp] , a request will move from L1 .", "miss to L1 .", "hit .", "In the lattice, this corresponds to moving from entry $ 10 $ to entry $ 11 $ , which is a forward movement.", "For another request to the same address, the only entries that might be affected are entry $ 4 $ , $ 5 $ and $ 6 $ .", "However, since p2c is a FIFO and the response is ready in the p2c buffer before the transition, no WBRq can be ready in this p2c buffer for other requests with the same address and thus they cannot be in entry $ 5 $ or $ 6 $ .", "If another request is in entry $ 4 $ , the transition removes the response from the p2c and this may make the WBRq ready in p2c and thus the request moves down the lattice.", "In all cases, no other requests move up the lattice.", "\\newline For the ShReq_S or ExReq_S rule to fire, there exists a request in the c2pRq buffer which means the address must be busy in the corresponding L1 (Lemma [@ref:LABEL:lemma:req-mutex] ) and thus a request exists in its mRq and misses the L1 (Lemma [@ref:LABEL:lemma:l1-busy-mrq] )."]], "target": "This request, therefore, must be in entry $ 8 $ in . The transition will dequeue the request and enqueue a response to p2c and thus moves the request down to entry $ 9 $ or $ 10 $ . For all the other requests with the same address, they cannot be ready in the c2pRq buffer since the current request blocks them, and thus they are not in entry $ 3 $ to $ 8 $ in the lattice. For the other entries, they can only possibly be affected by the transition if the current request is dequeued and one of them becomes ready. This, however, only moves the request down the lattice."}, {"tabular": ["    &  Artist attribution  &  Type prediction  &  Material prediction  &  Period estimation ", " Metric  &  Accuracy (%)  &  iMAP (%)  &  iMAP (%)  &  Mean Abs. Error (years) ", " Targets (#)  &  374+u  &  374  &  300  &  200  &  100  &  103  &  81  &  N/A ", " Data set usage (%)  &  100%  &  59.1%  &  55%  &  48%  &  36.8%  &  100%  &  100%  &  100% ", " Mensink et al.  &  52.8  &  66.5  &  68.7  &  72.1  &  76.3  &  91.4  &  94.7  &  72.4 ", " Deep CNN (single task)  &  50.3  &  63.9  &  69.5  &  72.5  &  76.7  &  91.7  &  97.2  &  71.2 ", " OmniArt (multi-task)  &  52.2  &  67.0  &  70.8  &  74.0  &  78.5  &  93.7  &  98.0  &  70.1  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Art applications like WikiArt , Europeana , ArtUk , WGA and Google Art Project have aggregated a diverse set of art collections together with basic meta-data and made them public using the web.", "Museums on the other hand expose a much larger part of the meta-data and structure based on a museum-centric point of view.", "Usually these collections contain far richer, expertly designed meta-data than the ones found in on-line art applications.", "Using the combination of accurate meta-data with quality photographic reproductions of the items in their collections, museum-centric data are ideal for analysis as they allow for deeper art exploration from multiple perspectives.", "\\newline In such museum-centric collections there is a gap between the available information and the data contained in the annotations.", "Often times, the semantic meta-data available for a specific piece of art is relayed differently in different use case scenarios.", "This poses a problem in searching and indexing these collections.", "Shreiber et al. made a significant step forward into bridging the gap in attributing meta-data to artworks in a standardized fashion [@bib:schreiber2008semantic] .", "They collected over 200,000 art samples from various collections on top of which they created a vocabulary for describing artworks.", "Using this vocabulary, they mapped the existing meta-data with RDF relations to other entities in the Linked Open Data cloud.", "Doing this effectively provided standardized annotations and vastly expanded the meta-data available with semantic context.", "\\newline However, even without the linked data expansion, cultural heritage is in general an outstandingly knowledge rich domain.", "In artistic paintings for example, most of the artworks have a known artist, style, year of creation, materials, geographical origins and even very detailed textual descriptions about their content.", "With specific methods from material science, chemical compositions of color can be extracted together with canvas thread patterns in paintings [@bib:yang2015quantitative] .", "Information is available on an even finer scale for these data sets.", "Using high resolution photography and x-rays [@bib:klockenkamper2000analysis,chung1999industrial] we are able to see the illusive details and generate more insight than ever before [@bib:pouyet20152d] .", "Each mentioned chunk of information presents a different challenge for scientists.", "With the growing amount of this museum-centric, context rich data , the need for efficient tools for exploring and analyzing art collections is ever more imminent.", "For this work we focus on a sub-domain of this data pool, which is the raw photographic reproductions of artworks in combination with the textual meta-data provided by the museums.", "\\newline Our focus area in meta-data contains attributes for which we hypothesize are semantically linked.", "Having multiple types of attributes, creates the possibility of having separate tasks for each type giving this research a multi-task nature.", "The most time efficient way to tackle multiple tasks is to do it simultaneously, which is why in this paper we propose a multi-task deep learning method with shared data representation between tasks depicted in Figure [@ref:LABEL:fig:figure_1] .", "Creating a shared representation allows us to exploit the semantic entanglement between the different tasks.", "With encouraging scientific progress in bridging the aforementioned information gap in mind, we propose a challenge to the tasks addressed in this paper.", "\\newline Challenges have been repeatedly proven as a good catalyst in stimulating a community to contribute to a cause.", "A shining example of a successful challenge in multimedia is The Multimedia Grand Challenge [@bib:snoek2011academia] that has been bringing commercial industrial needs to the attention of scientific researchers since 2009.", "In computer vision, the ImageNet Large Scale Visual Recognition Competition (ILSVRC) gave way for some of the largest breakthroughs.", "One such challenge for art, combining the information abundant artistic data, while providing a museum-centric perspective, was introduced in 2014 as The Rijksmuseum challenge by Mensink et al. [@bib:mensink2014rijksmuseum] .", "The Rijksmuseum challenge is composed of four separate tasks, namely: artist attribution, predicting the art-type , predicting the materials used and predicting the creation year of specific artworks in the collection.", "In 2014 this data set contained close to 120,000 entries of various photographic reproductions of the artworks in the Rijksmuseum\u2019s on-line collection.", "A single artwork in the challenge is described by a number of attributes like artist, period of creation, materials used, type of artwork and so on.", "The works of art in this data set date from ancient times to the late 19th century and are attributed to over 6000 individual artists.", "\\newline Even though artistic data provides multiple ways of analyzing it, most current methods for artistic data analysis [@bib:bar2014classification,karayev2013recognizing,elgammal2015quantifying,Roman-Rangel2016,gatys2016image,guccluturk2016convolutional] address each task individually.", "It would be more efficient to tackle this multi-task problem in a single end-to-end system, as this way the training time required for multiple models is reduced significantly.", "In some cases the multi-task learning environment can even improve classification performance if there is a correlation between the categories in each of the tasks.", "Work done by Kokkinos et al. [@bib:DBLP:journals/corr/Kokkinos16] successfully show the benefits of a deep model adapted for solving multiple tasks at once.", "Their architecture attempts to perform multiple computer vision tasks with one propagation of the input data through the model, which partly inspired our work.", "\\newline Using our proposed method, called OmniArt we report state-of-the-art results on The Rijksmuseum Challenge from 2014 and propose a new challenge with an expanded a better structured data set.", "Upon acceptance, we will make the challenge publicly available with the data set, trained models and evaluation engine to stimulate further development.", "\\newline In this work we elaborate on the following contributions: \\newline <list> \\ We propose an efficient and accurate multi-task end-to-end method for learning a shared representation of the input data with respect to all tasks.", "\\newline \\ \\ We offer a museum-centric data set with more than 430,000 samples with updated meta-data dubbed The OmniArt Challenge to stimulate engagement, encourage new research and maximize societal impact.", "\\newline \\ \\ We report state-of-the-art results on The Rijksmuseum Challenge from 2014 and The OmniArt Challenge with significantly shorter training duration.", "\\newline \\ </list> \\newline The rest of the paper is structured as follows: Section 2 contains the related work from a both a multi-task learning perspective and general artistic data analysis.", "Section 3 introduces the proposed method and the logic behind it.", "Section 4 is about the experimental setup, the datasets used for training and testing and experimental results.", "In the final section we give our concluding remarks with qualitative findings from the analysis we performed.", "\\newline  </section>"], ["<section> <title> 2 Related Work </title>  Related work in this area can be divided into two segments namely artistic data analysis and multi-task learning.", "\\newline <subsection> <title> 2.1 Artistic Data Analysis </title> As early as 1979, J. Rush [@bib:rush1979acquiring] concluded that experiences with individual instances of art from a particular artist can lead to the ability of identifying works from the same artist which have not been seen before.", "While a pure visual experience with samples from an artist efficiently taught the subjects to recognize such never before seen artworks, performance experienced a significant boost when other contextual information was presented in combination with the original image.", "With added context, possible sources of confusion were eliminated and recognition performance spiked.", "Jonson et al. [@bib:johnson2008image] performed a detailed analysis of brush-strokes in the work of Van Gogh using Gabor, Complex and D4 wavelets in combination with Support Vector Machines (SVM) and thresholding.", "This analysis has been done on a very small scale of just 101 images with full resolution reproductions as input.", "They conclude that brush-stroke analysis is helpful in artist attribution but it also depends on a lot of external factors like the canvas degradation and pigment loss.", "For a large scale accurate analysis, artworks need a scaled down representation with minimal information loss.", "Different from [@bib:rush1979acquiring,johnson2008image] we propose doing such categorization on a large scale.", "\\newline As one of the larger artistic datasets, the Rijks\u201914 data set was introduced by Mensink et al. [@bib:mensink2014rijksmuseum] in 2014 for The Rijksmuseum Challenge.", "At this point baseline scores for the data set were computed with the help of opponent and intensity SIFT features [@bib:van2010evaluating] represented in Fisher vectors.", "For classification they utilized the liblinear SVM library [@bib:fan2008liblinear] .", "On the same data set, Van Noord et al. [@bib:van2015toward] performed artist attribution using their own subsets with a convolutional neural network named PigeoNET.", "Their implementation features five convolutional and three stacked fully connected layers like Alexnet.", "Performance with artist attributions is reported on subsets with three sources of variation: 1) heterogeneity versus homogeneity, 2) number of artists in the set and 3) number of artworks per artist.", "Conclusions drawn from this research state that the performance of the model is proportional with the number of samples per class - more samples per class equals better attribution capabilities.", "Additionally, when the model is trained on a single type of artwork (for example only prints), performance increases since the model does not have to deal with big variations between artworks from the same artist.", "Although, similar artwork types improve the ability to learn better features, sometimes it can make classification confusing due to the sample similarity.", "Van Noord et al. [@bib:van2015toward] present an extensive analysis into artist attribution, but make no use of the other meta-data (period, materials, types\u2026) which we exploit and prove beneficial for determining the attributes of an artwork.", "\\newline Another large body of artistic data is the WikiArt data set.", "Multiple artistic data analysis approaches [@bib:bar2014classification,elgammal2015quantifying,karayev2013recognizing,saleh2015large] have been tested on WikiArt as it has quality annotations for artists, periods and art types.", "However, due to missing the material information about the artworks we only contain a subset of the WikiArt data in the OmniArt challenge.", "The Picasso data set used in [@bib:ginosar2014detecting,westlake2016detecting] for people detection features 218 Picasso paintings, and most of them are already included as a subset of the current version of the new data set.", "\\newline When it comes to art, tangible information like artists and periods is only one piece of the puzzle.", "Style also plays a significant role in identifying the origins of an artwork.", "In 2016 Gatys et al. [@bib:gatys2016image] proposed a style transfer method using an energy-minimization point of view.", "They use a pre-trained convolutional neural network [@bib:DBLP:journals/corr/SimonyanZ14a] as a feature extractor for both the style origin image and the image the style should be transfered to.", "Capturing such detail and transferring it in a meaningful fashion shows that quality information can be extracted from artistic data using convolutional neural networks.", "Another very recent generative approach to artistic data is presented in [@bib:CycleGAN2017] where Zhu et al. effectively transfer style, enhancements and transfigurations on images without pairing using Generative Adversarial Training.", "\\newline </subsection> <subsection> <title> 2.2 Multi-task Learning </title> Multi-task Learning is a paradigm of inductive transfer where the goal is to improve generalization performance by leveraging the domain-specific information of the training data in the related tasks [@bib:caruana1998multitask] .", "With the datasets becoming larger and larger, the idea of maximally exploiting each pass-through of data becomes rather attractive and approaches analyzing multiple aspects of the data in one go are becoming increasingly popular.", "Given the merits of multi-task learning, this paper addresses art data analysis from a multi-task point of view in a categorization setting.", "\\newline Kokkinos in [@bib:DBLP:journals/corr/Kokkinos16] introduces a convolutional neural network architecture that jointly handles visual features on different levels named UberNet.", "In his work he generates object boundaries, saliency maps, semantic segmentation, surface normals, and detection, in a single forward pass of an image through the model.", "Ubernet is part of the motivation behind our work as it uses a similar end-to-end paradigm for a multi-task problem.", "While it uses a clear separation between tasks, Ubernet does not allow for significant information sharing between tasks other than a joint loss affecting all layers below a specific output.", "Nevertheless, sharing information between different task representations proves to be beneficial for the model in training as Misra et al. conclude in [@bib:misra2016cross] .", "A stitching layer as they address it, provides a shared structure of units that combines the activations from multiple networks into one end-to-end trainable model.", "In natural language processing, the multi-task approach to deep learning has proven beneficial as well.", "Liu et al. [@bib:liu2015representation] perform multiple-domain classification on texts using multiple shared layer representations.", "Spanning different domains, multi-task learning can be done either with explicit [@bib:liu2015representation,misra2016cross] or implicit information sharing [@bib:DBLP:journals/corr/Kokkinos16] .", "\\newline Recent studies have shown that information sharing between tasks can be beneficial [@bib:yang2014unified] for action detection [@bib:DBLP:journals/corr/ZhuN16c] , zero-shot action recognition [@bib:DBLP:journals/corr/XuHG16] , human pose estimation [@bib:wang2016human] and adaptive visual feedback generation for facial expression improvement [@bib:Kaneko:2016:AVF:2964284.2967236] .", "Current methods use different layer depths to address tasks with varying complexity or use multiple inputs in their models so the different tasks have suitable features for training the classifier/regressor in the final block.", "While in our approach, we use the same features for each task and apply task specific scaling and weighting depending on the task\u2019s nature.", "An added benefit of our approach is that if there is even a slight correlation between the targets of the different tasks, it can improve the overall models performance.", "In our method we aim to learn a semantic link between tasks and use that insight to simultaneously predict multiple attributes about an artwork in an efficient and accurate fashion.", "\\newline </subsection>  </section>"], ["<section> <title> 3 Method </title>  Training separate models for each of the tasks in this data set is a computationally inefficient and time-consuming process.", "As is the case with multi-task datasets, the images propagating through the model, in the forward pass, are identical for each task.", "A difference can only be observed in the back-propagation from the final classification/regression block due to the different label spaces, dimensions and loss types.", "Moreover, it is common for these types of tasks that there is correlation between the different label types, influencing the outcome of a certain prediction.", "This means that a certain artwork with a known period of creation and artwork type significantly narrows down the list of possible artists for the artist attribution task.", "A mathematical interpretation of this example is shown with a simple conditional probability in equation 1 where $ T_{1} $ represents the artwork belonging to a particular artist, while $ T_{2} $ and $ T_{3} $ correspond to the the period of creation and the type of material used.", "\\newline <equation> $ P(T_{1}|T_{2},T_{3})=\\frac{P(T_{1}\\bigcap T_{2}|T_{3})}{P(T_{2}|T_{3})} $ </equation> \\newline A real world example of this type of correlation would be a painting which has a creation period of 1635 and a type of oil on canvas .", "The chances of this painting being a Van Gogh are close to none, because Van Gogh was not born until 1853.", "It would more likely be a Rembrandt since he was active in that time period.", "Therefore we hypothesize that there is a semantic entanglement between the different attributes in artistic data.", "\\newline <subsection> <title> 3.1 Method overview </title> In this paper we propose a multi-task learning method for learning a shared representation based on the semantic entanglement between multiple attributes of artistic data.", "As depicted in Figure [@ref:LABEL:fig:omniart_artchitecture] , our method consists of a base layer block for feature extraction, a shared representation block, a combined loss layer where the loss from all tasks is aggregated and separate evaluation blocks per task.", "We perform loss aggregation in a sum with weighing and scaling the separate losses depending on the type of task they originate from and the impact of that particular attribute to the overall performance.", "Using this method we improve discriminative performance on every task, reduce training and testing duration because of the one-time data set traversal.", "\\newline </subsection> <subsection> <title> 3.2 Combined loss layer </title> We propose a multi-task convolutional neural network which learns a shared representation of the artworks with respect to multiple types of accompanying meta-data.", "For each of the meta-data attributes we create separate tasks and assign a separate classification/regression block in the model, each with their own loss function.", "A natural way to efficiently propagate these gradients through our model and have them all influence the training properly is in a sum.", "In equation 2, $ L_{t} $ is the combined loss for all of the tasks, while $ L_{i} $ presents the loss per individual task.", "Parameters $ w_{i} $ and $ s_{i} $ are representing the task specific loss weight matrix assigning a different weight to each task and the task-specific scale factor respectively.", "\\newline <equation> $ L_{t}=\\sum_{i=1}^{n}w_{i}s_{i}L_{i} $ </equation> \\newline It is important to note that this way of combining loss functions only works if they share a layer with trainable parameters.", "Sharing such a layer would imply for them to get input from the same level.", "In terms of loss functions, for classification tasks like artist attribution we use a categorical cross-entropy loss with a softmax function.", "For regression we apply scaled mean absolute loss and an interval accuracy with a tolerance of $ \\pm 50 $ years.", "Since interval accuracy intrinsically implies classification, we utilize the mean absolute loss for training the regression block.", "Two of the tasks in this challenge are multi-label classification tasks, so we utilize a binary cross-entropy loss function over the sparse labels with sigmoid activation.", "\\newline While this type of loss aggregation comes to mind naturally in a scenario like this, the effect and scale of the loss value has to be taken into account [@bib:sculley2010combined] .", "In fact, the loss values generated by the regression tasks prove to be at least 10 times larger then the ones generated in the classification tasks or multi-label tasks.", "This influences the learning negatively as the adjustment to the shared representation is most influenced by the regression tasks, while the importance of the classification losses is diminished.", "In order to even the influence out and make the assigned task weights reliable again, we scaled down the regression (mean absolute) loss by a factor of ten manually $ (s_{period}=10) $ when back-propagating.", "The specific scale factor can be determined through monitoring the loss values in the validation phase.", "\\newline </subsection> <subsection> <title> 3.3 Shared representation layer </title> Since we are using a deep model as a feature extractor, we limit the back-propagation effects to only the additional layers (outputs per task and shared layer).", "In turn, we only train a small amount of parameters compared to the total number of parameters contained in the model because: \\newline <list> \\ We do not have enough labeled data to effectively adjust the filters in the deep model from scratch (for example Resnet-50 has 25,583,592 trainable parameters without the top output layers).", "\\newline \\ \\ Training only the final output blocks speeds up the whole process while still learning a good representation.", "\\newline \\ \\ The data dimensions are more manageable and the training effects are easier to study.", "\\newline \\ </list> \\newline Given that between each of the classes in the different tasks $ (T_{i}) $ there exists a joint probability, the shared layer is a joint representation of the data with respect to each task.", "We experimentally determined the shared layers configuration in terms of activations and amounts of hidden units.", "Different activation functions like Tanh [@bib:lecun2012efficient] and Sigmoid [@bib:lecun2012efficient] do not promote sparsity in our representation like ReLU [@bib:nair2010rectified] does. We believe that the sparsity factor plays a key role in the information absorption of the shared layer.", "The number of hidden units in the shared layer is dependent on the number of output targets per task and the diversity in the data itself.", "From a learning point of view this is expected, as more targets would require more trainable parameters for learning a valid representation and vice versa.", "\\newline Another point of view, derived from the experiments in stage one of this work would suggest that not all tasks require the same depth of output.", "Experimental results show that the type and period prediction tasks can be efficiently addressed with a shallower architecture.", "This would also imply a speed up in training times and also reduce memory consumption as the number of trainable parameters would decrease both in a fine-tune and from-scratch setting.", "However, dispersing the output layers in different depths of the model implies that we cannot model a joint loss influencing the combined data representation for all the tasks at once in a shared representation layer.", "\\newline Since this layer is not an output of the network it can also be used as a high-level feature extraction point.", "If the model performs well on each task, the features extracted at this point would be a valid representative of the input data.", "With lower dimensions because of the limited number of units in the shared layer, these features would be preferred when memory and computing capacity is limited.", "\\newline </subsection> <subsection> <title> 3.4 Base Layer </title> Our method is essentially agnostic to the choice of a feature extractor as the base for the shared representation because the features that are used for prediction and evaluation are the ones learned in the shared layer.", "With the success of deep models in visual recognition tasks, we experimented with a number of different deep architectures like VGG-16, VGG-19, Inception V2 and ResNet-50 as feature extractors.", "Our experimental results suggest that the ResNet-50 model generated the best base features, so we assigned as the feature extractor in our method.", "\\newline Features are extracted from the last layer before the classifier and propagated through a shared representation layer to a different evaluation blocks for each task.", "Back-propagation of the combined loss modifies the features in the shared representation layer with respect to every task.", "\\newline </subsection>  </section>"], ["<section> <title> 4 Experiments </title>  Through the course of our experiments we are aiming to answer the following questions: \\newline <list> \\ Which deep model performs best as a base feature extractor in artistic datasets? \\newline \\ \\ Does learning a representation on multiple interconnected tasks improve overall predictive performance and if so, how? \\newline \\ \\ How do different types of tasks (classification, regression, multi-label) affect each other in a combined setting? \\newline \\ \\ Which parameters work best in a shared representation setting when the tasks are of different types?", "\\newline \\ \\ Can the shared representation learn the semantic connections between the tasks and generate qualitative insight?", "\\newline \\ </list> \\newline Our experimental setup features two stages.", "In the first stage we evaluate the performance of individual models for each task in the Rijksmuseum Challenge and compare deep learning to Mensink et al. [@bib:mensink2014rijksmuseum] and other state-of-the-art approaches.", "We also provide baseline results on four tasks on the new OmniArt data set.", "After evaluating the models and choosing the one that has the best predictive performance we continue to Stage 2.", "\\newline Stage 2 of the experimental setup focuses on evaluating the multi-task model with a different sets of hyper-parameters, data set splits and shared representation sizes against the best performing single task deep learning model.", "Within this stage we also generate our final results.", "\\newline <subsection> <title> 4.1 Datasets </title> In our research we rely on multiple data sources like museums, art wiki-sites and pre-compiled datasets.", "First we crawled a data set from WikiArt containing 126,078 images from more than 3000 individual artists, 150 types and 14 different periods in history.", "This data set has been used to evaluate various algorithms as it associates artworks with style and genre [@bib:bar2014classification,elgammal2015quantifying,karayev2013recognizing,saleh2015large] .", "However, WikiArt lacks the material information and it is not included in OmniArt at the moment.", "A relatively new addition to digital artistic data is the on-line collection of the Metropolitan museum with almost half a million artworks combined with extensive meta-data.", "While assembling this data set, we noticed that almost half of the samples do not belong to the public domain or have no photographic reproduction and cannot be used.", "A rather smaller data set containing only paintings, is the YourPaintings data set with 5000 painting samples and is publicly available with object level annotations [@bib:crowley2014search,kaufmann2004toward] .", "Featuring 4,000 samples, the French National Library collection is also available [@bib:simon2014europeanatech] , but due to lack of material information and its reliance on French annotations, like the YourPaintings data set, it is also excluded at this time.", "\\newline All results apply to the same datasets and split types.", "We used 70% of the data set for training, 20% for validation and 10% for testing purposes.", "The splits were made per class, such that each class had the same distribution during all the experimental phases.", "\\newline Our method relies on a single pass through the data set, so it can only be split with respect to a single task $ (T_{i}) $ .", "In our case that task is artist attribution due to the highest number of categories in the data set and the fine-grained nature.", "Doing a split like this results in an imbalance to the sample distributions per class in the other tasks, but we combat that by assigning task weights $ (w_{i}) $ using their ratio in the combined loss on the validation set.", "\\newline As the artist is the most specific class in the hierarchy, we compute the data distribution with respect to this task.", "For this reason we can only compare our experimental results to the Rijksmuseum challenge in 2014, on the full data set in period, material and type prediction.", "\\newline Using our method, we report baseline performance on the same four tasks on the new OmniArt Challenge as well.", "We will release the model for feature extraction, data splits and evaluation engine as a museum-centric challenge upon acceptance and continue to gather more data.", "\\newline <subsubsection> <title> 4.1.1 The Rijks\u201914 dataset </title> The Rijks\u201914 data set was introduced by T. Mensink et al. [@bib:mensink2014rijksmuseum] in 2014 as part of the proposed Rijksmuseum challenge.", "This data set consists of 112,039 photographic reproductions of the artworks exhibited in the Rijksmuseum in Amsterdam.", "Since the data set for the Rijksmuseum Challenge 2014 is posed from a museum-centric point of view, it offers various object types including paintings, photographs, ceramics, furniture, sculptures, etc .", "Every entry in the data set has at most four labels.", "If a label is missing or unknown, the entry is assigned an Unknown class.", "\\newline </subsubsection> <subsubsection> <title> 4.1.2 OmniArt Challenge 2017 </title> Since 2014, the Rijksmuseum has updated their digitally available content with more than 90,000 photographic reproductions of artworks from their collection.", "The Metropolitan Museum of Art implemented a new policy known as Open Access, which makes images of artworks it believes to be in the public domain widely and freely available for unrestricted use in accordance with the Creative Commons Zero (CC0) designation.", "The Met also made meta-data from the entire on-line collection as annotation to the images like artist, title, period, medium and materials and dimensions available on their website.", "The current estimate of the total number of artworks in their collection is 442,554, but only half of those have photographic reproductions that belong to the public domain.", "Similar annotations can be found in the Web Gallery of Art data set where 40,000 (c. 28,000 paintings) artworks have been associated with rich meta-data like artists, techniques, period, type, school, geographical origins, etc.", "\\newline Using the updated Rijksmuseum collection, the newly available collection from the Met and the Web Gallery of Art collection, we created a new data set containing 432,217 photographic reproductions of artworks combined with rich meta-data.", "Moreover the quality of annotations is also improved as all the types and materials have been translated to English.", "Ambiguous labels on the artworks like Unknown , Anonymous and acronyms have been eliminated in the predefined train, validation and test splits so that the classification problem is well defined.", "In addition to the previously available data, we offer a meta-data expansion with attributes like IconClass [@bib:couprie1983iconclass] , ColorCodes , current location , real size and geographic origins and Techniques .", "\\newline </subsubsection> </subsection> <subsection> <title> 4.2 Preprocessing </title> Models with deep architectures have the downside of requiring vast amounts of data in order to train properly and learn relevant features [@bib:krizhevsky2012imagenet] .", "Having this in mind, we applied data augmentation techniques to our data to both expand the data set and introduce label-safe variations.", "\\newline We experimented with horizontal flips, random rotations, mean subtraction and ZCA whitening.", "Mean subtraction made performance worse in all cases.", "While maybe not expected, it is logical for period, type and material prediction, since the integrity of the input sample is important.", "Subtracting the mean from a metal engraved plate would result in a vague impression of the original image, loosing important texture information.", "\\newline We obtained best results when only horizontal flips were applied to random images in the data set which is therefore the only augmentation we used.", "\\newline </subsection> <subsection> <title> 4.3 Tasks description </title> Since we use the results of The Rijksmuseum 2014 Challenge as our primary baseline, below we describe the different tasks proposed in the challenge on which we evaluate our model.", "\\newline <subsubsection> <title> 4.3.1 Artist attribution </title> There are more than 21,000 artists in the OmniArt data set with 23 of them having more than 700 artworks in the collection.", "In the OmniArt data set there are artworks with an unknown artist."]], "target": "The unknown class is marked with a +u in Table for the Rijks\u201914 dataset. Those artworks are excluded from the experiments too because they might belong to an existing category for the OmniArt challenge."}, {"tabular": ["  CORD $ \\rightarrow $  &    &    &    &    &    &    &    &    &    &  ", " TREC $ \\downarrow $  &  1  &  2  &  3  &  4  &  5  &  6  &  7  &  8  &  9  &  10 ", " 1  &  -1  &  X  &  3  &  X  &  -3  &  -3  &  X  &  -6  &  -2  &  -3 ", " 2  &  X  &  X  &  X  &  X  &  -6  &  X  &  X  &  -3  &  X  &  1 ", " 3  &  X  &  -3  &  X  &  X  &  X  &  X  &  -6  &  -6  &  X  &  -3 ", " 4  &  -6  &  X  &  X  &  -3  &  X  &  X  &  3  &  X  &  -3  &  -3 ", " 5  &  X  &  X  &  3  &  X  &  X  &  X  &  -3  &  X  &  -3  &  -6 ", " 6  &  -3  &  -6  &  X  &  -5  &  -1  &  -3  &  0  &  -7  &  -9  &  -16 ", " 7  &  X  &  X  &  X  &  -3  &  X  &  X  &  X  &  X  &  X  &  X ", " 8  &  -5  &  -1  &  -10  &  X  &  X  &  -2  &  3  &  X  &  X  &  X ", " 9  &  -5  &  X  &  X  &  X  &  -3  &  1  &  X  &  X  &  X  &  X ", " 10  &  -3  &  X  &  -6  &  -6  &  -6  &  4  &  X  &  X  &  X  &  -1 ", " 11  &  -3  &  X  &  X  &  X  &  X  &  -3  &  X  &  X  &  X  &  -3 ", " 12  &  -3  &  -3  &  -6  &  -10  &  -4  &  0  &  -3  &  -6  &  X  &  -1 ", " 13  &  X  &  X  &  -6  &  -3  &  -7  &  X  &  -4  &  1  &  -6  &  X ", " 14  &  X  &  X  &  -3  &  X  &  X  &  0  &  X  &  -3  &  X  &  -3 ", " 15  &  X  &  X  &  X  &  -3  &  -1  &  X  &  -3  &  1  &  -3  &  X ", " 16  &  X  &  X  &  X  &  -3  &  X  &  X  &  X  &  -3  &  -3  &  X ", " 17  &  -8  &  -1  &  X  &  -3  &  -1  &  -3  &  -3  &  -1  &  -6  &  X ", " 18  &  -2  &  -6  &  X  &  X  &  -7  &  -1  &  -3  &  -10  &  -3  &  X ", " 19  &  X  &  X  &  -3  &  X  &  X  &  X  &  -2  &  X  &  X  &  X ", " 20  &  -9  &  -6  &  -3  &  -6  &  -4  &  0  &  -3  &  X  &  -12  &  -6 ", " 21  &  -6  &  -2  &  X  &  X  &  X  &  -6  &  X  &  -1  &  -3  &  X ", " 22  &  -3  &  X  &  X  &  -6  &  X  &  X  &  X  &  X  &  X  &  X ", " 23  &  -3  &  X  &  X  &  X  &  -3  &  -3  &  X  &  X  &  -3  &  -3 ", " 24  &  -3  &  X  &  X  &  X  &  -3  &  X  &  X  &  X  &  X  &  X ", " 25  &  X  &  X  &  X  &  X  &  X  &  -3  &  X  &  -3  &  -3  &  X ", " 26  &  X  &  -4  &  X  &  X  &  -1  &  X  &  -1  &  X  &  -9  &  -3 ", " 27  &  -4  &  X  &  -5  &  -6  &  X  &  -3  &  -4  &  -7  &  -12  &  -7 ", " 28  &  X  &  -3  &  X  &  X  &  -1  &  X  &  X  &  -3  &  -3  &  X ", " 29  &  -3  &  X  &  3  &  X  &  X  &  X  &  -12  &  -3  &  -6  &  -3 ", " 30  &  X  &  X  &  3  &  X  &  X  &  X  &  -3  &  -3  &  -3  &  X ", " 31  &  X  &  -4  &  -6  &  X  &  -3  &  X  &  X  &  X  &  -6  &  -1 ", " 32  &  X  &  X  &  X  &  X  &  X  &  -3  &  X  &  X  &  X  &  -3 ", " 33  &  X  &  X  &  X  &  X  &  X  &  X  &  X  &  X  &  X  &  X ", " 34  &  X  &  X  &  X  &  X  &  X  &  X  &  X  &  X  &  X  &  X ", " 35  &  X  &  -1  &  -1  &  X  &  X  &  X  &  X  &  X  &  X  &  1 ", " 36  &  X  &  -6  &  4  &  X  &  X  &  X  &  -9  &  X  &  X  &  X ", " 37  &  X  &  X  &  X  &  -3  &  -3  &  -3  &  X  &  -3  &  X  &  -3 ", " 38  &  -6  &  -6  &  -3  &  -9  &  0  &  -5  &  -6  &  -6  &  -21  &  -6 ", " 39  &  -3  &  -3  &  X  &  -3  &  X  &  -3  &  -6  &  -6  &  -16  &  -3 ", " 40  &  -2  &  X  &  4  &  0  &  -3  &  -3  &  -6  &  -6  &  X  &  -3  "], "ref_sec": [["<section> <title> 1 Introduction </title>  The novel coronavirus disease 2019 (COVID-19) began in Wuhan, China in late 2019 and to date has infected over 14M people worldwide, resulting in over 750,000 deaths .", "On March 10, 2020 the World Health Organization (WHO) declared the outbreak a global pandemic.", "Many academics and researchers, not restricted to the medical domain, began publishing papers presenting new discoveries related to COVID-19.", "Although well intentioned, the huge increase of publications about COVID-19 made it difficult for medical professionals to sift through the data and identify actionable insights.", "\\newline Hoping to encourage a more unified, organized investigation into the virus, the White House and a group of leading research labs in industry, lead by the Allen Institute for AI, released the CORD-19 dataset in March of 2020 [@bib:Wang2020CORD19TC] .", "The dataset contains academic journal articles relating to a variety of coronavirus and related viral infections, not only COVID-19, sourced from PubMed Central (PMC), PubMed, the World Health Organization (WHO), bioRxiv, medRxiv, and arXiv.", "Furthermore, the dataset is accompanied by 10 key questions that the community has been tasked with answering.", "\\newline As a consequence of the CORD-19 dataset not indicating which journal articles are helpful in answering each of the key questions posed, many of the initial efforts were positioned as clustering or data exploration studies [@bib:sonbhadra2020target,le2020visualising,fister2020discovering] .", "However, some individuals have taken it upon themselves to assemble well-structured, task-specific datasets from a subset of documents in CORD-19.", "Two such datasets for question answering are CovidQA [@bib:tang2020rapidly] and RECORD ( R esearch E ngine for C OVID O pen R esearch D ataset) [@bib:muffo2020record] .", "While these datasets are a valuable resource to the community, their heavy reliance on human annotation limits their utility and scalability as each dataset contains less than 150 records.", "\\newline The information retrieval (IR) community reframed the key questions asked in CORD-19 to more closely resemble a TREC competition, calling the resulting competition TREC-COVID [@bib:voorhees2020trec] .", "In each round of competition contestants are given a list of queries, or tasks, for which related documents are desired.", "Contestants then perform the queries using their proposed model, returning an ordered list of documents expected to be relevant to the query.", "To assess the performance of teams participating in the competition, human annotators prescribe relevancy annotations to journal articles that are returned most often for each task in TREC-COVID at the end of each round of competition.", "\\newline Although these two activities have received much attention from their respective communities, they are usually viewed in isolation.", "That is, efforts towards answering the queries associated with TREC-COVID have not been directly leveraged towards answering the key questions posed by CORD-19.", "While valuable human annotations have been obtained for TREC-COVID tasks, ground-truth labels for CORD-19 task have yet to be obtained even though it asks similar questions on the same dataset.", "\\newline Our initial attempts to train a model to perform both the TREC-COVID and CORD-19 tasks, either through multitask-learning or transfer learning, proved unfruitful.", "Learning to perform both sets of tasks in unison results in inferior performance than if the tasks were learned separately.", "This was an indication to us to focus more so on how annotated data can be repurposed instead of repurposing a model already trained to perform a specific task.", "\\newline We therefore present a method for re-purposing the labeled data for one task, TREC-COVID, for a task for which labeled training data is unavailable or only available in limited quantities, CORD-19.", "Our method begins by first defining a manual mapping from TREC-COVID tasks to CORD-19 tasks such that labels for the TREC-COVID task can be reused as labels for the corresponding CORD-19 task.", "We train a BioBERT model to make relevancy predictions for each CORD-19 task and compare the model\u2019s performance against that of three human annotators.", "We then employ a variety of techniques to refine the mapping between tasks until optimal model performance is reached.", "\\newline In total, our contributions are as follows: \\newline <list> \\ Demonstrate the ability of a BioBERT model to learn to make relevancy predictions for TREC-COVID tasks, achieving a true positive rate and true negative rate of 0.75% and 0.88%, respectively.", "\\newline \\ \\ Present a method for repurposing the annotations from TREC-COVID towards answering the key questions of CORD-19, achieving a Cohen\u2019s kappa of 0.443 with majority agreement human annotations.", "\\newline \\ </list> \\newline  </section>"], ["<section> <title> 2 Related Literature </title>  <subsection> <title> 2.1 Language Modeling </title> Language modeling (LM) is a long-studied discipline in Natural Language Processing (NLP) in which a model is tasked with learning the underlying distribution and relation between words in a pre-determined vocabulary [@bib:jozefowicz2016exploring] .", "It has become common practice for a language model (LM) to first be pre-trained on a large, general purpose corpus before being fine-tuned for a domain-specific NLP task.", "Leveraging a LM in such a capacity has lead to new state-of-the-art performance in a variety of natural language understanding (NLU) and natural language inference (NLI) tasks [@bib:mikolov2010recurrent,schwenk2012large,filippova2015sentence] .", "One of the more widely adopted pre-trained LM was released in late 2018 by Devlin et al dubbed BERT ( B idirectional E ncoder R epresentation from T ransformers) [@bib:devlin2018bert] .", "BERT was trained using two pre-training tasks: 1) Masked Language Modeling (MLM) and Next Sentence Prediction (NSP).", "For MLM, 15% of tokens in the input sequence were randomly masked and BERT was asked to impute the missing tokens.", "In the NSP task, BERT was presented with two sentences and asked to predict whether or not the appear next to each other in a source document.", "\\newline <subsubsection> <title> 2.1.1 BioBERT </title> Although the vanilla BERT model was shown to achieve strong performance on tasks making use of a more general vernacular, it struggled to adapt to some domain-specific applications which made use of a highly specialized vocabulary.", "To this end, Lee et al performed further pre-training of BERT using a corpus from the bio-medical domain, naming the new model BioBERT [@bib:lee2020biobert] .", "Starting from the weights of the vanilla BERT model, BioBERT was further pre-trained on an 18B word corpora composed of PubMed abstracts and full-text articles from PMC.", "BioBERT was shown to achieve new state-of-the-art performance on a variety of NLP tasks tailored to the bio-medical domain including named entity recognition (NER) and question answering (QA) among others [@bib:lee2020biobert] .", "\\newline </subsubsection> </subsection> <subsection> <title> 2.2 COVID-19 and CORD-19 </title> Lead by the Allen Institute for AI and the White House, a consortium of industry leaders aggregated academic journal articles related to COVID-19 and other coronaviruses, releasing the dataset to the public as CORD-19 [@bib:Wang2020CORD19TC] .", "The dataset and supplemental material are freely available on Kaggle .", "\\newline Sonbhadra et al [@bib:sonbhadra2020target] present a method for identifying journal articles relevant to each of the 10 CORD-19 tasks.", "The proposed method begins by clustering articles in CORD-19 based on their TF-IDF embeddings and training a one-class support vector machine (OCSVM) to identify samples belonging to each centroid.", "Next, doc2vec is used to create ebmeddings that represent each centroid and each Kaggle task.", "These embeddings are then used to calculate the cosine similarity, and consequently the association between, each centroid and Kaggle task.", "Although this method achieves high levels of performance with F1 scores approaching 0.999, the ground truth labels are assumed based on embedding vector similarity without human confirmation.", "It shows strong ability to identify which set of centroids a particular journal was assigned to, but whether or not the journal articles assigned to that centroid are truly relevant to the task is not confirmed.", "\\newline The National Institute of Health (NIH) also compiled a dataset of articles related to the ongoing pandemic and released to the community as LitCovid [@bib:chen2020keep] .", "Articles in this dataset are sourced from PubMed and exclusively discuss COVID-19.", "The dataset contains around 8,000 articles each annotated as one or more of the following categories: General , Transmission , Treatment , Case report , Forecasting , Prevention , Mechanism , and Diagnosis .", "Gutierrez et al assessed the performance of a variety of neural architectures on the dataset, including LSTM, CNN, BERT, BioBERT, and other transformer-based models [@bib:gutierrez2020document] .", "Ultimately, the group found that BioBERT and the Longformer, a variant of the transformer architecture [@bib:vaswani2017attention] , produced the best results with an micro-F1 score and accuracy of 81% and 69%, respectively, on the test set.", "BioBERT consistently outperformed the vanilla BERT models throughout their experiments, demonstrating the benefit of utilizing a LM fine-tuned for the biomedical domain.", "\\newline </subsection> <subsection> <title> 2.3 Transfer Learning </title> As defined by Torrey et al, transfer learning (TL) \u201c\u2026 is the improvement of learning in a new task through the transfer of knowledge from a related task that has already been learned\u201d [@bib:torrey2010transfer] .", "For a simple, pertinent example we remind the reader of the process of pre-training a LM on a large, general purpose before fine-tuning it for a specific task.", "In doing so, the model first learns general knowledge about words in the vocabulary being learned before refining it\u2019s understanding for optimal performance on a specific task.", "\\newline TL is typically discussed with respect to the model - i.e. a model learning to perform task B will make use of what it learned in learning to perform task A. In our experiments, however, we utilized TL in the data space instead of the model space .", "Human annotators prescribed relevancy annotations for journal articles in CORD-19 with respect to TREC-COVID tasks, and using those labels, we re-purpose the dataset such that it can be used to train a model to perform a new task.", "The knowledge obtained from the TREC-COVID annotations is never truly \u201cshared\u201d with the model learning to prescribe CORD-19 relevancy annotations, but used to re-purpose the dataset for a new task.", "\\newline </subsection> <subsection> <title> 2.4 Question Answering </title> Although CORD-19 on it\u2019s own is a completely unstructured dataset, some individuals have taken it upon themselves to assemble well-structured, task-specific datasets from a subset of documents in CORD-19.", "Two such datasets are CovidQA [@bib:tang2020rapidly] and RECORD ( R esearch E ngine for C OVID O pen R esearch D ataset) [@bib:muffo2020record] .", "Both datasets present a model with a query and a context string, asking the model to identify the span of text in the context that most accurately responds to the query.", "Due to the reliance on human labor to construct these fine-grain, task-specific datasets, the datasets only contain 124 and 112 question-answer pairs, respectively.", "\\newline </subsection>  </section>"], ["<section> <title> 3 Datasets </title>  <subsection> <title> 3.1 TREC-COVID </title> The TREC community answered the call to action against COVID-19 by announcing the TREC-COVID competition [@bib:voorhees2020trec] .", "Similar to many other TREC competitions, participants are given a set of queries and asked to find documents that are relevant to the query.", "In TREC-COVID, the system returns relevant articles in the CORD-19 dataset [@bib:Wang2020CORD19TC] .", "In each round of the competition, participants submit a list of articles returned for each query, ordered by predicted likelihood of relevancy.", "At the end of each round, human annotators annotate the articles that were most often returned for each query, and they are then used to score submissions.", "As of completion of round three of the competition, a total of 16,677 unique journal articles in CORD-19 have received a relevancy annotation with respect to one or more TREC-COVID tasks.", "\\newline TREC-COVID began with 30 tasks, or \u201cqueries\u201d, and adds 5 tasks for each round of the competition.", "Each task is expressed in three ways: 1) as a query, typically a few words in length, i.e. \u201ccoronavirus origin\u201d , 2) as a question, which poses the query in a slightly longer form, i.e. \u201cwhat is the origin of COVID-19\u201d , and 3) as a narrative, which further expands upon the corresponding question and query, i.e. \u201cseeking range of information about the SARS-CoV-2 virus\u2019s origin, including its evolution, animal source, and first transmission into humans\u201d .", "The queries for the 40 tasks included in round three of the TREC-COVID challenge are presented in table [@ref:LABEL:Tab:TREC-COVID-TASKS] .", "\\newline </subsection> <subsection> <title> 3.2 CORD-19 </title> Organized by the White House, Allen AI, and leading research groups, this dataset contains almost 200,000 journal articles about COVID-19 and related coronaviruses, around 80,000 of which contain the full text of the article [@bib:Wang2020CORD19TC] .", "The dataset poses 10 \u201ckey questions\u201d to the community, presented in table [@ref:LABEL:Tab:CORD-19-Key-Questions] .", "\\newline Journal articles in the CORD-19 dataset come from sources such as PubMed Central (PMC), PubMed, the World Health Organization (WHO), bioRxiv, medRxiv, and arXiv.", "The dataset does not exclusively focus on COVID-19 and includes journal articles relating to other viruses such as MERS, H1N1, and SARS.", "New articles are periodically added to the dataset as they become available.", "The version of the dataset used throughout this study, unless otherwise noted, was published on July 6, 2020.", "\\newline </subsection>  </section>"], ["<section> <title> 4 Methodology </title>  Although the CORD-19 dataset contains over 80,000 full-text academic articles and poses 10 key questions, it gives no indication as to which articles are helpful for answering the questions being asked.", "However, the TREC-COVID competition is asking similar questions about the same journal articles and provides human relevancy annotations for each task at the end of each round.", "Seeing this opportunity, the backbone of our methodology is the re-purposing of labeled data for one task, TREC-COVID, for use in a separate, related tasks for which labeled training data is unavailable or only available in limited quantity, CORD-19.", "\\newline We first create a manual mapping from TREC-COVID tasks to CORD-19 tasks and train a BioBERT model to predict whether or not a journal excerpt is relevant to each CORD-19 task.", "Next, for each CORD-19 task 20 journal articles are sampled and three human annotators gave relevancy annotations for the sampled articles and corresponding task.", "These annotations are used to assess model performance and the mapping between tasks is iteratively refined until optimal performance is reached.", "A diagram of the workflow in our methodology is presented in figure [@ref:LABEL:fig:workflow] .", "\\newline <subsection> <title> 4.1 Manual Task Mapping </title> The initial mapping between the TREC-COVID tasks and the CORD-19 tasks was done manually by one of the authors.", "Given the full details of both the TREC-COVID and Kaggle CORD-19 tasks, the author was asked to give their \u201cbest guess\u201d judgement as to which of the TREC-COVID tasks would best align with each of the Kaggle CORD-19 tasks.", "The initial manual mapping was defined using task descriptions from round 3 of TREC-COVID and is presented below in table [@ref:LABEL:Tab:Manual-Task-Map] .", "\\newline <subsubsection> <title> 4.1.1 Constructing Dataset </title> To frame the problem as a supervised learning task, we repurpose annotations for TREC-COVID tasks to serve as ground truth labels for the corresponding CORD-19 tasks.", "When constructing the training set for CORD-19 task i , we first identify the set of journal articles, $ J $ , that have received annotations for TREC-COVID tasks which are mapped on to CORD-19 task i .", "Since the majority of CORD-19 tasks have multiple TREC-COVID tasks mapped to them and a journal article may receive an annotation for more than one TREC-COVID task, it is possible for a journal article j , $ j\\in J $ , to have multiple, inconsistent labels for CORD-19 task i appropriated from corresponding TREC-COVID tasks.", "For example, if journal article j was annotated as \u201crelevant\u201d for TREC-COVID task x but \u201cnot relevant\u201d for TREC-COVID task y , and both TREC-COVID tasks x and y are mapped to CORD-19 task i , j would be labeled as both \u201crelevant\u201d and \u201cnot relevant\u201d for CORD-19 task i .", "If such a situation were to occur, j would not be included in the training set for CORD-19 task i .", "\\newline Individual records in the dataset consist of either the abstract or conclusion of a journal article.", "If available, the title of the journal article was prepended to either the abstract or conclusion.", "Therefore, any individual journal articles in CORD-19 may manifest as at most two records in the repurposed dataset.", "\\newline Each item in the newly constructed dataset is accompanied by an auxiliary sentence corresponding to the key question of the CORD-19 task for which the item represents.", "The input to the BioBERT model is formatted as follows: \\newline [CLS] JOURNAL TEXT [SEP] AUX.", "SENTENCE [SEP] \\newline In doing so, the model is learning a task that is similar to it\u2019s NSP pre-training task.", "\\newline </subsubsection> </subsection> <subsection> <title> 4.2 Human Annotation </title> In order to gauge a model\u2019s ability to prescribe relevancy predictions for the Kaggle tasks, we require a set of ground truth labels to compare it\u2019s predictions against.", "To this end, three human annotators were asked to annotate 20 journal articles for each Kaggle task resulting in 200 total annotations each.", "The human annotators were not experts in the bio-medical domain and were asked to prescribe annotations with respect to the general , medical domain.", "Put differently, the text being annotated need not be directly related to COVID-19 for it to be annotated as relevant if the content of the text answers the posed question.", "For example, a paragraph discussing the transmission of the H1N1 virus is to be marked relevant for Kaggle task 1 although it is not describing COVID-19 in particular.", "This was done to make the model more amenable to generalization in other viral applications and corpora.", "\\newline <subsubsection> <title> 4.2.1 Revising Annotations </title> As none of the annotators were experts in the bio-medical domain, the initial annotations were expected to contain at least some level of noise due to misunderstanding of domain terminology, Kaggle task definitions and/or scope, and requirements for a journal to be deemed relevant .", "After the three annotators gave their independent annotations, they met with the project PI to discuss items that the annotators did not agree on the correct annotation.", "During this time the group ensured that the annotators had a common understanding of domain terminology, task descriptions, and relevancy requirements.", "If the annotators could not reach a consensus agreement on their own, the project PI would cast the deciding vote.", "Annotators were then asked to revise their original annotations with the insights from this meeting in mind.", "After revisions, the annotations from our three non-expert annotators had an agreement of 0.3744 in terms of Fleiss\u2019 kappa.", "When compared to the majority agreement annotations, the annotators had agreements of 0.6587, 0.7538, and 0.5411 in terms of Cohen\u2019s kappa.", "\\newline </subsubsection> </subsection> <subsection> <title> 4.3 Refining Task Mappings </title> When comparing the predictions of a BioBERT model trained using the manual mapping with the human annotations, it was clear that the model was able to identify some sort of meaningful signal in the data, but higher of levels of performance were desired.", "To this end we explored how the data at our disposal, including newly obtained human annotations for CORD-19 tasks, could be used to refine the manual mapping between the TREC-COVID and CORD-19 tasks.", "\\newline <subsubsection> <title> 4.3.1 TREC-COVID Model </title> Given that we obtained 20 human annotations for each of the ten Kaggle tasks, we wanted to see if the documents that were annotated for the Kaggle tasks were also annotated for a TREC-COVID task.", "As of round 3 of the TREC-COVID competition, only 9 of the documents that received a human annotation for the Kaggle tasks received an annotation for any TREC-COVID task.", "However, to make further use of our annotations, we train another BioBERT model to prescribe COVID-TREC relevancy annotations for each of the 40 tasks in round 3 of TREC-COVID.", "\\newline Since we are not expecting this model to be highly competitive in the TREC-COVID competition, we relax the rules of the competition slightly and reframe the task as a binary instead of tertiary classification problem.", "Items in the TREC-COVID dataset that received an annotation of \u201csomewhat relevant\u201d were adjusted to have a label of \u201crelevant.", "\u201d More concretely, the BioBERT model was asked to predict if a text snippet is either \u201cnot relevant\u201d or \u201crelevant\u201d for a particular TREC-COVID task.", "\\newline Our TREC-COVID BioBERT model is then applied to each of the 200 journal articles that received human annotations for the Kaggle tasks, making relevancy predictions for each of the 40 TREC-COVID tasks.", "A relevancy prediction less 0.5 was taken as \u201cnot relevant\u201d while any prediction greater than or equal to 0.5 was taken as \u201crelevant.", "\u201d These relevancy predictions for the TREC-COVID tasks can then be viewed with respect to the human relevancy predictions for the Kaggle tasks, revising the mapping between the two sets of tasks accordingly.", "\\newline </subsubsection> <subsubsection> <title> 4.3.2 Automatic Task Mapping </title> To further refine the manually prescribed task mappings, we explore a variety of options for automatically mapping tasks in TREC-COVID to those in CORD-19 based on different data sources and data representations.", "In one method of obtaining automatic mappings, BioBERT was used to create an embedding vector for each task in both TREC-COVID and CORD-19.", "The similarity of each TREC-COVID task to each CORD-19 task was measured using cosine similarity.", "\\newline Additionally, term frequency vectors were created to represent each of the TREC-COVID and CORD-19 tasks.", "Articles marked as relevant to each task were included in the construction of each embedding vector, with ngrams up to size n=5 considered.", "Again, the similarity of each TREC-COVID task to each CORD-19 task was measured using cosine similarity.", "\\newline </subsubsection> </subsection>  </section>"], ["<section> <title> 5 Experiments </title>  In all experiments a BioBERT-base-cased model was fine-tuned using an Adam optimizer with lr= $ 5e^{-6} $ , $ \\beta_{1}=0.9 $ , and $ \\beta_{2}=0.999 $ .", "Models trained to perform the CORD-19 tasks were trained for 20 epochs while models performing the TREC-COVID tasks were trained for only 10 epochs.", "In both cases, a decaying learning rate with a 10% warmup was employed.", "\\newline <subsection> <title> 5.1 Manual Mapping </title> We begin experiments by fine-tuning a BioBERT model to make relevancy predictions for each CORD-19 task using original manual mapping between tasks, as presented in table [@ref:LABEL:Tab:Manual-Task-Map] .", "The model had optimal agreement with the majority annotations with a relevancy threshold of 50%.", "The model\u2019s performance, described in terms of Cohen\u2019s kappa, is presented below in figure [@ref:LABEL:fig:manual_vs_majority] .", "\\newline </subsection> <subsection> <title> 5.2 TREC-COVID Model </title> When fine-tuning the BioBERT model to make relevancy predictions for the TREC-COVID dataset, the incomplete nature of the annotations necessitate the problem being framed as a binary, one-vs-all classification problem.", "The model was trained using annotations for round 3 of the TREC-COVID competition and the resulting performance is described in table [@ref:LABEL:Tab:TREC-COVID-Perf] .", "\\newline Once trained, the TREC-COVID model is then applied to the journal articles in CORD-19 that were manually annotated for the CORD-19 tasks.", "For each article, the model makes 40 binary predictions as to the relevancy of the article to each of the TREC-COVID tasks.", "For an article to be considered relevant for a particular TREC-COVID task, the model must be no less than 50% confident the article excerpt is relevant.", "\\newline Next, for each TREC-COVID task we identify the set of journal excerpts, T , that the TREC-COVID model believes are relevant to that task.", "Then, for each CORD-19 task i , we calculate the number of relevant annotations minus the number of not-relevant annotations for that task i .", "The results of this process are presented below in table [@ref:LABEL:Tab:TREC-COVID-Apply] .", "\\newline </subsection> <subsection> <title> 5.3 Automatic Task Mapping </title> As mentioned above, we explored the use of BioBERT and term frequency embeddings when automatically mapping TREC-COVID tasks to CORD-19 tasks.", "The BioBERT model provided by Lee et al is used to create the BioBERT embeddings [@bib:lee2020biobert] .", "When using BioBERT embeddings, one input sequence was generated for each task in both TREC-COVID and CORD-19.", "When constructing the input for TREC-COVID tasks, the input is the task query and for CORD-19 tasks the input is the key question for each task.", "The results of our automatic task mapping method using BioBERT embeddings are presented below in figure [@ref:LABEL:fig:biobert-mapping] .", "\\newline When using term-frequency-based embeddings to calculate an automatic mapping between tasks, we are not restricted by BioBERT\u2019s maximum input sequence length, so we can construct an embedding using more information for each task.", "We therefore create term-frequency embeddings that make use of articles annotated as relevant for each task when constructing the embeddings.", "As mentioned above, ngrams up to size n=5 are included.", "The results of the term-frequency-based automatic task mappings are presented below in figure [@ref:LABEL:fig:term-freq-mapping] .", "In the figure, similarity scores are normalized with respect to each CORD-19 task.", "\\newline </subsection> <subsection> <title> 5.4 Optimal Task Mapping </title> Using the insights gleamed from applying the TREC-COVID model and the different methods to automatically map TREC-COVID task to CORD-19 tasks, we adjusted the originally defined task mapping.", "The mapping that lead to optimal performance is described in table [@ref:LABEL:Tab:Optimal-Task-Map] and corresponding performance metrics are presented in figure [@ref:LABEL:fig:optimal_vs_majority] .", "The decision process used when adjusting the mapping will be further explained in the Discussion sections.", "\\newline </subsection> <subsection> <title> 5.5 Performance Assessment </title> Both the CORD-19 and TREC-COVID competitions were active during our experiments, releasing new versions of their respective datasets as more journal articles become available.", "The majority of our experiments were performed during round 3 of the TREC-COVID competition, but we wanted to assess the impact of additional annotations with each round of competition.", "We therefore trained a BioBERT model to prescribe CORD-19 relevancy annotations using the identified optimal task mapping based on data from rounds 1-4 of the TREC-COVID competition.", "Furthermore, we trained a vanilla BERT model to perform this task as well to assess the performance that further in-domain pre-training had on resulting model performance.", "The performance achieved from performing the experiments described above are presented in table [@ref:LABEL:Tab:Impact] in terms of Cohen\u2019s kappa.", "\\newline </subsection>  </section>"], ["<section> <title> 6 Discussion </title>  In consulting figure [@ref:LABEL:fig:manual_vs_majority] we see that a BioBERT model trained to make relevancy annotations for CORD-19 tasks using the manually defined task mapping shows promising performance.", "The model shows a strong ability to make accurate annotations for CORD-19 task 10, but the same cannot be said for tasks 3, 4, 5, 8, and 9 - half of the ten CORD-19 tasks.", "When compared against majority annotations, the model has an agreement of 0.2853 in terms of Cohen\u2019s kappa.", "\\newline To squeeze more utility out of the human annotations for CORD-19 tasks, we consulted the results from applying the TREC-COVID model to journal articles which received human annotation.", "In doing so we are able to gain a better understanding of not only which TREC-COVID tasks correlate positively with CORD-19 tasks, but also those that correlate negatively with CORD-19 tasks.", "For example, TREC-COVID task 30 ( \u201c", "Is remdesivir an effective treatment for COVID-19?\u201d ) was not mapped to CORD-19 task 3 in the manual mapping."]], "target": "However, in table we see that journal articles our TREC-COVID model thinks are relevant to TREC-COVID task 30 receive three more \u201crelevant\u201d than \u201cnot relevant\u201d human annotations for CORD-19 task 3, suggesting TREC-COVID task 30 should be mapped to CORD-19 task 3. Furthermore, journal articles that our TREC-COVID model thinks are relevant to TREC-COVID task 17 receive eight fewer \u201crelevant\u201d than \u201cnot relevant\u201d human annotations for CORD-19 task 1, suggesting the mapping should be removed. We use these findings to adjust the mapping between tasks accordingly if the suggested adjustment passes a simple human sanity-check ."}, {"tabular": ["    &  CM  &  IC  &  OC  &  SC  &  MC  &  NE ", " Exp. failures  &  0.55  &  0.42  &  1.13  &  0.74  &  0.79  &  0.00  "], "ref_sec": [["<section> <title> 1 Introduction </title>  Visual tracking is a rapidly evolving field that has been increasingly attracting attention of the vision community.", "It offers many scientific challenges and it emerges in other computer vision problems such as motion analysis, event detection and activity recognition.", "A steady increase of hardware performance and its price reduction have opened a vast application potential for tracking algorithms including surveillance systems, automotive systems, transport, sports analytics, medical imaging, mobile robotics, film post-production and human-computer interfaces.", "\\newline The activity in the field is reflected in abundance of new tracking algorithms presented in journals and at conferences summarized in the many survey papers, e.g., [@bib:Gavrila99,Moeslund2001,Gabriel03,Hu2004,Moeslund2006,Yilmaz2006,Li2013] .", "However, the boom in tracker proposals has not been accompanied by standardization of the methodology for their objective comparison.", "\\newline One of the most influential performance analysis efforts for object tracking is PETS (Performance Evaluation of Tracking and Surveillance) [@bib:Young2005] .", "The first PETS workshop took place in 2000 aiming at evaluation of visual tracking algorithms for surveillance applications.", "Its focus gradually shifted to high-level event interpretation algorithms.", "Other frameworks and datasets have been presented since, but these focused on evaluation of surveillance systems and event detection, e.g., CAVIAR , i-LIDS , ETISEO , change detection [@bib:GoyetteCVPR12] , sports analytics (e.g., CVBASE ), specialized on tracking specific objects like faces, e.g., FERET [@bib:Phillips2000] , [@bib:Kasturi_TPAMI_2009] or tracking for autonomous vehicles, e.g., KITTI [@bib:Geiger2012CVPR] .", "Recently, several works have been published in the broad area of model-free visual object tracking evaluation, eg., [@bib:Bernardin2008,Karasulu2011,Salti2012,Wu2013,Smeulders2013,Pang2013,Kristan2013,Kristan2014] and following the success of the VOT challenges [@bib:Kristan2013,Kristan2014] a performance evaluation benchmark for multiple target tracking was presented as well [@bib:MOTChallenge2015] .", "\\newline There are several important subfields in visual tracking, ranging from multi-camera, multi-target [@bib:Bernardin2008,Fleuret08a,MOTChallenge2015] , to single-target [@bib:Wu2013,Smeulders2013,Pang2013,Kristan2013,Kristan2014] trackers.", "These subfields are quite diverse, without a unified evaluation methodology and specific methodologies have to be tailored to each subfield.", "\\newline In this paper, single-camera, single-target, model-free, causal trackers, applied to short-term tracking are considered.", "The model-free property means that the only supervised training example is provided by the bounding box in the first frame.", "The short-term tracking means that the tracker does not perform re-detection after the target is lost.", "Drifting off the target is considered a failure.", "The causality means that the tracker does not use any future frames to infer the object position in the current frame.", "The tracker output is specified by a rotated bounding box.", "\\newline <subsection> <title> 1.1 Requirements for tracker evaluation </title> The evaluation of new tracking algorithms depends on three essential components: (1) performance evaluation measures, (2) a dataset and (3) an evaluation system.", "In the following, the requirements for these components are stated.", "\\newline Performance measures.", "A wealth of performance measures have been proposed for single-object tracker evaluation, but there is no consensus on which measure should be preferred.", "Ideally, measures should clearly reflect different aspects of tracking.", "Apart from merely ranking, we also need to determine cases when two or more trackers are performing equally well.", "We require the following: The measures should allow an easy interpretation and should support tracker comparison with a well-defined tracker equivalence .", "\\newline Datasets.", "The dataset should allow evaluation of trackers under diverse conditions like partial occlusion, clutter and illumination changes.", "One approach is to construct a very large dataset, but this does not guarantee diversity in visual attributes and it significantly slows down the process of evaluation.", "A better approach is to annotate each sequence with the visual attributes occurring in that sequence and perform clustering to reduce the size of the dataset, while keeping it diverse.", "Annotation is also important for per-attribute tracker analysis.", "A common approach is to annotate a sequence globally with an attribute if that attribute occurs anywhere in the sequence.", "The trackers can then be compared only on the sequences corresponding to a particular attribute.", "However, visual phenomena do not usually last throughout the entire sequence.", "For example, a partial occlusion might occur at the end of a sequence, while a tracker might fail due to some other effects occurring at the beginning of the sequence.", "In this case, the failure would be falsely attributed to the occlusion.", "A per-frame dataset labeling is thus required to facilitate a more precise analysis.", "This motivates the following requirements: (1) The dataset should be diverse in visual attributes.", "(2) Per-frame annotation of visual attributes is required.", "\\newline Evaluation systems.", "For a rigorous evaluation, an evaluation system that performs the same experiment on different trackers using the same dataset is required.", "A wide-spread practice is to initialize the tracker in the first frame and let it run until the end of a sequence.", "However, the tracker might fail right at the beginning of the sequence due to some visual degradation, effectively meaning that the system utilized only the first few frames for evaluation of this tracker.", "Thus the first requirement for the system is that it fully uses the data.", "This means that once the tracker fails, the system has to detect the failure and reinitialize the tracker.", "Therefore, a certain level of interaction, that goes beyond simple running until the end of the sequence, is required.", "Furthermore, the evaluation system has to also account for the fact that the trackers are typically coded in various programming languages and often platform-dependent.", "This motivates the following set of requirements the evaluation system should meet: (1) Full use of the dataset.", "(2) Allow interaction with the tracker.", "(3) Support for multiple platforms.", "(4) Easy integration with trackers.", "\\newline </subsection> <subsection> <title> 1.2 Our contributions </title> In this paper we present the following four contributions: \\newline The first contribution is a novel tracker evaluation methodology based on two simple, easy interpretable, performance measures.", "A significant novelty of the proposed methodology is the use and first of its kind analysis of reinitializations at tracking failures.", "Reinitialization-based measures are compared theoretically and experimentally to standard counterparts that do not apply reinitialization.", "We propose a first of its kind tracker ranking methodology that addresses the concept of tracker equivalence and takes into account statistical significance as well as practical difference in tracking accuracy.", "A new visualization of ranks is proposed as well to aid comparative analysis.", "\\newline The second contribution is a new dataset and evaluation system.", "The dataset is constructed by a novel video clustering approach based on visual properties.", "The dataset is fully annotated, all the sequences are labeled per-frame with visual attributes to facilitate in-depth analysis.", "The benefits of per-frame attribute annotation are analyzed theoretically and experimentally.", "The proposed evaluation system enjoys multi-platform compatibility and offers easy integration with trackers.", "The system has been tested in a large-scale distributed experiment on the VOT2013 and VOT2014 challenges.", "\\newline The third contribution is a detailed comparative analysis of 38 trackers using the proposed methodology, making it the largest benchmark to date.", "\\newline The forth contribution is a novel analysis of the sequences in the dataset from the perspective of tracking success.", "\\newline Preliminary versions of some parts of this paper have been previously published (during the period 2013-2014) in three workshop papers [@bib:Kristan2013a,Kristan2014,KRISTAN_2014_ECCV] .", "\\newline The remainder of the paper is structured as follows: In Section [@ref:LABEL:sec:relatedWork] the most related work is reviewed and discussed.", "The new tracker evaluation methodology is presented and theoretically analyzed in Section [@ref:LABEL:sec:evalMethodology] , while the new dataset selection approach, the evaluation system and the results of the experimental analysis are presented in Section [@ref:LABEL:sec:experiments] .", "Conclusions are drawn in Section [@ref:LABEL:sec:Conclusion] .", "\\newline </subsection>  </section>"], ["<section> <title> 2 Related work </title>  <subsection> <title> 2.1 Performance measures </title> A wealth of performance measures have been proposed for single-object tracker evaluation.", "These range from basic measures like center error [@bib:Ross2008] , region overlap [@bib:Li2011] , tracking length [@bib:Kwon2009] , failure rate [@bib:Kristan2008b,Kristan2010b] , F-score [@bib:Karasulu2011,Smeulders2013] , pixel-based precision [@bib:Karasulu2011] , to more sophisticated measures, such as CoTPS [@bib:Nawaz2013] [@bib:Carvalho2012] , which combine several measures.", "A nice property of the combined measures is that they provide a single score to rank the trackers.", "A downside is that they offer little insight into the tracker performance which limits their interpretability.", "All measures strongly depend on the experimental setup within which they are computed.", "For example, some evaluation protocols, like Wu et al. [@bib:Wu2013] and Smeulders et al., [@bib:Smeulders2013] initialize the trackers at the beginning of the sequence and let them run until the end.", "Measures computed in such a setup are inappropriate for short-term tracking evaluation, since the trackers are not expected to perform re-detection.", "The values of performance measures thus become irrelevant after the point of tracking failure.", "Including the frames past the point of failure in the computation of a global performance measure introduces significant distortions since failures closer to the beginning of the sequence are significantly more penalized than failures occurring later in the sequence.", "\\newline While some authors choose several basic measures to compare their trackers, recent studies [@bib:Cehovin2014wacv,CehovinTracMeas2015] have shown that many measures are correlated and do not reflect diverse aspects of tracking performance.", "In this respect, choosing a large number of measures may in fact again bias results toward some particular aspects of tracking performance.", "Smeulders et al. [@bib:Smeulders2013] propose using two measures: an F-score calculated at the Pascal region overlap criterion (threshold $ 0.5 $ ) [@bib:Everingham2014] and a center error.", "Note that the F-score based measure was originally designed for object detection.", "The threshold $ 0.5 $ is also rather high and there is no clear justification of why exactly this threshold should be used to compare trackers [@bib:Wu2013] since it is hardly an indicator of tracking failure (see examples in Figure [@ref:LABEL:fig:overlap_half] ).", "\\newline Since the center error becomes arbitrary high once the tracker fails, Wu et al. [@bib:Wu2013] propose to measure the percentage of frames in which the center distance is within some prescribed threshold.", "However, this threshold significantly depends on the object size, which makes this particular measure quite brittle.", "A normalized center error measured during successful tracks may be used to alleviate the object size problem, however, the results in [@bib:Smeulders2013] show that the trackers do not differ significantly under this measure which makes it less appropriate for tracker comparison.", "As an additional measure, [@bib:Wu2013] propose an area under a ROC-like plot of thresholded overlaps.", "Recently, [@bib:Cehovin2014wacv] have shown that this is equivalent to the average region overlap measure computed from all frames of sequences.", "In fact, based on an extensive analysis of performance measures, \u010cehovin et al. [@bib:CehovinTracMeas2015] argue that the region overlap is superior to the center error.", "\\newline While it is important to study and evaluate the tracker performance separately in terms of several less correlated performance measures, it is sometimes required to rank trackers in a single rank list.", "In this case a convenient strategy is to combine these measures into rank averaging , similarly to what was done in the change detection challenge [@bib:GoyetteCVPR12] .", "In rank averaging, competing algorithms are ranked with respect to several performance measures and their ranks are averaged.", "This simulates competition of trackers with respect to different performance measures and assumes equal importance of all measures.", "The fact that trackers are ranked along each measure induces normalization of measures to a common scale prior to averaging.", "\\newline <subsubsection> <title> 2.1.1 Visual performance evaluation </title> Several authors propose to visually compare tracking performance via performance summarization plots.", "These plots show the percentage of frames for which the estimated object location is within some threshold distance of the ground truth.", "Most notable are precision plots [@bib:Yilmaz2006,babenko2011tpami,Wu2013] , which measure the object location accuracy in terms of center error.", "Alternatively, success plots [@bib:Salti2012,Wu2013] use the region overlap instead.", "Salti et al., [@bib:Salti2012] implicitly account for variable threshold dependency by plotting the percentage of correctly tracked frames with respect to the mean region overlap within these frames.", "\u010cehovin et al. [@bib:Cehovin2014wacv,CehovinTracMeas2015] propose a similar visualization, but they apply a single, zero, threshold on the overlap.", "A tracker is thus represented as a single point in this 2D space, rather than a curve, which allows easier comparison.", "A drawback of performance plots is that they typically become cluttered when comparing several trackers on several sequences in the same plot.", "To address this, Smeulders et al. [@bib:Smeulders2013] calculate a performance measure per sequence for a tracker and order these values from highest to lowest, thus obtaining a so-called survival curve.", "The performance of several trackers is then compared on the entire dataset by visualizing their survival curves.", "\\newline </subsubsection> </subsection> <subsection> <title> 2.2 Datasets </title> It is a common practice to compare trackers on many publicly-available sequences, which have became a de-facto standard in evaluation of new trackers.", "However, many of these sequences lack a standard ground truth labeling, which makes comparison of algorithms difficult.", "To sidestep this issue, Wu et al. [@bib:Wu_TPAMI2010] have proposed a protocol for stochastic tracker evaluation on a selected dataset that does not require ground truth labels.", "A similar approach was adapted by [@bib:SanMiguel2012] to evaluate tracking algorithms on long sequences.", "Datasets with various visual phenomena equally represented are not usually used.", "In fact, many popular sequences are conceptually similar, which makes the results biased toward some particular types of the phenomena.", "To address this issue, Wu et al. [@bib:Wu2013] annotated each sequence with several visual attributes and report tracker performance with respect to each attribute separately.", "However, a per-frame annotation is not provided and not all sequences are in color, which makes results skewed with proportions of color and gray sequences.", "Recently, Smeulders et al. [@bib:Smeulders2013] , have presented a very large dataset called \u2018Amsterdam Library of Ordinary Videos\u2019 (ALOV).", "The dataset is composed of over three hundred sequences collected from published datasets and additional YouTube videos.", "The sequences are assigned to one of thirteen classes of difficulty [@bib:Chu2010] and, with the exception of ten long sequences, are kept short to increase the diversity.", "The sequences are not annotated per-frame with visual attributes, some sequences contain cuts and ambiguously defined targets such as fireworks which makes the dataset inappropriate for short-term tracking evaluation.", "\\newline </subsection> <subsection> <title> 2.3 Evaluation systems </title> The most notable and general evaluation systems are ODViS [@bib:Jaynes2002] , VIVID [@bib:Collins2005] , ViPER [@bib:Doermann2000] .", "The former two focus on the design of surveillance systems, while the latter is a set of utilities/scripts for annotation and computation of different types of performance measures.", "The recently proposed ViCamPEv [@bib:Karasulu2011] toolkit is dedicated to testing a pre-determined set of OpenCV-based basic trackers.", "None of these systems support interaction with the tracker, which limits their applicability.", "Collecting the results from the existing publications is an alternative for benchmarking trackers.", "Pang et al. [@bib:Pang2013] have proposed a page-rank-like approach to data-mine the published results and compile unbiased ranked performance lists.", "However, as the authors state in their paper, the proposed protocol is not appropriate for creating ranks of the recently published trackers due to the lack of sufficiently many publications that would compare these trackers.", "\\newline </subsection>  </section>"], ["<section> <title> 3 Visual object tracker evaluation </title>  The proposed methodology assumes that the evaluation system and the dataset fulfill the requirements stated in Section [@ref:LABEL:sec:Requirements] , i.e., (i) the dataset is per-frame annotated by visual attributes and the object positions are denoted by possibly rotated bounding boxes, (ii) trackers are run on each sequence of the dataset.", "Once the tracker drifts off the target, the system detects a tracking failure and re-initializes the tracker.", "All trackers are run multiple times to account for their possibly stochastic nature.", "\\newline <subsection> <title> 3.1 Evaluation methodology </title> Based on the recent analysis of widely-used performance measures [@bib:Cehovin2014wacv,CehovinTracMeas2015] two weakly-correlated and easily interpretable measures were chosen: (i) accuracy and (ii) robustness.", "The accuracy at time-step $ t $ measures how well the bounding box $ A_{t}^{T} $ predicted by the tracker overlaps with the ground truth bounding box $ A_{t}^{G} $ and is defined as the intersection-over-union \\newline <equation> $ \\phi_{t}=\\frac{A_{t}^{G}\\cap A_{t}^{T}}{A_{t}^{G}\\cup A_{t}^{T}}. $ </equation>", "The robustness is the number of times the tracker failed, i.e., drifted from the target, and had to be reinitialized.", "A re-initialization is triggered when the overlap (Eq. [@ref:LABEL:eq:overlap] ) drops to zero.", "\\newline The re-initialization of trackers might introduce a bias into the performance measures.", "If a tracker fails at a particular frame, e.g., due to occlusion, it will likely fail again immediately after re-initialization.", "To reduce this bias, the tracker is re-initialized $ N_{\\mathrm{skip}}=5 $ frames after the failure.", "The reasoning behind the choice of this value is that short-term occlusions do not last for more than five frames and we provide experimental study of this parameter in Section [@ref:LABEL:sec:skipping_exp] for completeness.", "In the case of a full occlusion, the tracker is initialized on the first frame in which the object is not fully occluded.", "A similar bias occurs in the accuracy measure.", "The overlaps in the frames right after the initialization are biased towards higher values over several frames and it takes a few frames of the burn-in period to reduce the bias.", "This means that we label the frames in the burn-in period as invalid and do not use them in computation of the accuracy.", "In Section [@ref:LABEL:sec:burnin_exp] a study is reported in which we measured the time it takes for the overlap to approximately stabilize after reinitialization.", "According to the results of that study, the burn-in period is set to $ N_{\\mathrm{burnin}}=10 $ frames .", "\\newline A tracker is run on each sequence $ N_{\\mathrm{rep}} $ times which allows dealing with the potential variance of its performance.", "In particular, let $ \\Phi_{t}(i,k) $ denote the accuracy of $ i $ -th tracker at frame $ t $ at experiment repetition $ k $ .", "The per-frame accuracy is obtained by taking the average over these, i.e., $ \\Phi_{t}(i)={1\\over N_{\\mathrm{rep}}}\\sum\\nolimits_{k=1}^{N_{\\mathrm{rep}}}{% \\Phi_{t}(i,k)} $ .", "The average accuracy of the $ i $ -th tracker, $ \\rho_{\\mathrm{A}}(i) $ , over some set of $ N_{\\mathrm{valid}} $ valid frames is then calculated as the average of per-frame accuracies \\newline <equation> $ \\rho_{\\mathrm{A}}(i)={1\\over N_{\\mathrm{valid}}}\\sum\\nolimits_{j=1}^{N_{% \\mathrm{valid}}}{\\Phi_{j}(i)}. $ </equation> \\newline In contrast to accuracy measurements, a single measure of robustness per experiment repetition is obtained.", "Let $ F(i,k) $ be the number of times the $ i $ -th tracker failed in the experiment repetition $ k $ over a set of frames.", "The average robustness of the $ i $ -th tracker is then \\newline <equation> $ \\rho_{R}(i)={1\\over N_{\\mathrm{rep}}}\\sum\\limits_{k=1}^{N_{\\mathrm{rep}}}F(i,k).", "$ </equation> \\newline The overall performance on the dataset can be estimated as the weighted average of the per-sequence performance measures, with weights proportional to the lengths of the sequences.", "Note that this is equivalent to concatenating the sequence of per-frame overlaps/failures from the entire dataset into a single super-sequence and calculating the two averages in ( [@ref:LABEL:eq:avaccuracy] ) and ( [@ref:LABEL:eq:avrobustness] ).", "Similarly, per-visual-attribute performance can be evaluated for a specific attribute by collecting all the frames labelled as that attribute into an attribute super-sequence and calculating ( [@ref:", "LABEL:eq:avaccuracy] ) and ( [@ref:LABEL:eq:avrobustness] ).", "\\newline For a fair comparison, we propose a ranking-based methodology akin to [@bib:Everingham10,GoyetteCVPR12] but we introduce the concept of equally-ranked trackers.", "For each tracker, a group of so-called equivalent trackers containing trackers performing indistinguishably is determined and a corrected rank is then calculated.", "There are several choices for calculating the correction, e.g., one could take the min, max or mean of ranks in the group.", "The least conservative choice is max, since it always penalizes a tracker if the equivalency test cannot confirm the difference from a lower-ranked tracker, and on the other hand, the min is most conservative, since it always makes a correction in interest of the tracker.", "In the subsequent evaluation we use the mean of the ranks as a compromise between the two extrema.", "Note that the concept of equivalent trackers is not transitive, and should not be mistaken for the standard equivalence relation.", "For example, consider trackers $ T_{1} $ , $ T_{2} $ and $ T_{3} $ .", "It may happen that a tracker $ T_{2} $ performs indistinguishably from $ T_{1} $ and $ T_{3} $ , but this does not necessarily mean that $ T_{1} $ performs equally well as both, $ T_{2} $ and $ T_{3} $ .", "The equality of trackers should therefore be established for each tracker separately.", "Two types of tests for establishing performance equivalence are considered in the following.", "\\newline <subsubsection> <title> 3.1.1 Tests of statistical differences </title> A per-frame accuracy is available for each tracker.", "One way to gauge equivalence in this case is to apply a paired test to determine whether the difference in accuracies is statistically significant.", "When the differences are distributed normally, the Student\u2019s t-test, which is often used in the aeronautic tracking research [@bib:Yaakov01] , is the appropriate choice.", "However, in a preliminary study we have applied Anderson-Darling tests of normality [@bib:AndersonDarling1952] and have observed that the accuracies in frames are not always distributed normally, which might render the t-test inappropriate.", "As an alternative, the Wilcoxon Signed-Rank test as in [@bib:Demsar2006] is applied that tests a null hypothesis that differences come from a distribution with zero median (see [@bib:Navidi2011] for further details).", "\\newline In case of robustness, several measurements of the number of tracker failures over the entire sequence in different runs is obtained.", "However, these cannot be paired, and the Wilcoxon Rank-Sum (also known as Mann-Whitney U-test) [@bib:Demsar2006] is used instead to test the difference in the average number of failures.", "This is a two-sided rank sum test which tests the null hypothesis that the number of failures of two trackers are independent samples from distributions with equal medians (see [@bib:Navidi2011] for further details).", "\\newline </subsubsection> <subsubsection> <title> 3.1.2 Tests of practical differences </title> Note that statistical difference does not necessarily imply a practical difference [@bib:Demsar2008] , which is particularly important in equivalency tests for accuracy.", "The practical difference is a level of difference in accuracy that is considered negligibly small.", "This level can come from the noise in annotation, the fact that multiple ground truth annotations of bounding boxes might be equally valid, or simply from the fact that very small differences in tracking accuracy are negligible from a practical point of view.", "Therefore, a pair of trackers is considered to perform equally well in accuracy if their difference in performance is not statistically significant or if it fails the practical difference test.", "\\newline In terms of practical difference, a pair of trackers $ i $ and $ j $ is said to perform differently if the difference of their averages is greater than a predefined threshold $ \\gamma $ , i.e., $ |\\rho_{\\mathrm{A}}(i)-\\rho_{\\mathrm{A}}(j)|>\\gamma $ , or, by defining a difference at frame $ t $ , $ d_{t}(i,j)=\\phi_{t}(i)-\\phi_{t}(j) $ , expanding the sums and pulling the threshold into the summation, $ {1\\over T}|\\sum\\nolimits_{t=1}^{T}d_{t}(i,j)/\\gamma|>1 $ .", "Since the frames in the super-sequence come from multiple sequences, the thresholds $ \\gamma $ may vary over the frames.", "A pair of trackers therefore passes the test for the practical difference in accuracy if the following relation holds \\newline <equation> $ {1\\over T}|\\sum\\nolimits_{t=1}^{T}d_{t}(i,j)/\\gamma_{t}|>1, $ </equation> where $ \\gamma_{t} $ is the practical difference threshold corresponding to the $ t $ -th frame.", "\\newline </subsubsection> <subsubsection> <title> 3.1.3 Visualization of results </title> Results can be visualized by the accuracy-robustness plots proposed by [@bib:Cehovin2014wacv] in which a tracker is presented as a point in terms of accuracy and robustness.", "The accuracy is defined as in ( [@ref:LABEL:eq:avaccuracy] ), while the robustness is converted into a probability of tracker failing after $ S $ frames, thus scaling robustness into the range between zero and one.", "Since we have extended the methodology of [@bib:Cehovin2014wacv] to rankings, we also extend the visualization.", "In particular, the rank results can be displayed using the accuracy-robustness (AR) rank plots.", "Since each tracker is presented in terms of its rank with respect to robustness and accuracy, we can plot it as a single point on the corresponding 2D AR-rank plot.", "Trackers that perform well relative to the others are positioned in the top-right part of the plot, while the, relatively speaking, poorly-performing trackers occupy the bottom-left part.", "\\newline </subsubsection> </subsection> <subsection> <title> 3.2 Theoretical comparison to related works </title> The most related works to the performance evaluation methodology presented in this paper are the methodologies presented by Wu et al. [@bib:Wu2013] and Smeulders et al. [@bib:Smeulders2013] .", "In principle, all the methodologies use global averages based on the overlaps of tracker bounding boxes and ground truth.", "The main difference between [@bib:Wu2013] and [@bib:Smeulders2013] is that [@bib:Wu2013] computes the average-overlap-based measure (like our approach), while [@bib:Smeulders2013] computes an F-score at 0.5 overlap.", "For short-term tracking, the tracker is not required to re-detect the target after losing it.", "This means that the tracker is not required to report the target loss and the F-score from [@bib:Smeulders2013] reduces to precision, i.e., the ratio of frames in which the overlap with ground truth is grater than 0.5.", "Applying such a high threshold reduces the strength of the performance measure.", "For example, consider a pair of trackers, tracker A and B: tracker A performs at 0.47 overlap, whereas tracker B performs at 0.1 overlap and none of the trackers ever drifts off the target.", "The F-score at overlap 0.5 is zero for both trackers, meaning that the measure cannot discern the performance among the trackers since their overlap is below 0.5.", "Furthermore, the measure would induce a large distinction between trackers A (F-score 0) and a tracker that performs at overlap 0.5 (F-score 1) even though the difference between both is only 0.03 overlap.", "\\newline There are three notable differences between our methodology and [@bib:Wu2013,Smeulders2013] .", "The first difference is that our methodology detects tracking failure and applies re-initializations, while the [@bib:Wu2013] and [@bib:Smeulders2013] do not re-initialize, nor detect a failure.", "The methodology from [@bib:Wu2013] relies on compensating for this drawback by increasing the number of sequences to 50 and recently [@bib:Smeulders2013] proposed using over 300 sequences.", "The second difference is that our methodology is based on per-frame visual-attribute annotation for per-visual attribute performance evaluation.", "On the other hand, [@bib:Wu2013,Smeulders2013] globally annotate a sequence with all the appearing tributes.", "Per-visual attribute performance is then computed by using all frames of the sequences globally annotated by a particular attribute.", "The last difference relates to the ability to state that one tracker performs better than another.", "While all three methodologies produce ranks, only our methodology accounts for the practical as well as statistical difference and takes into account the noise in ground truth annotation to gauge equivalence of trackers.", "\\newline The aim of the methodologies is to estimate the tracker overall or per-visual attribute performance and rank trackers according to this estimate.", "In this respect, the methodologies can be thought of as state estimators in which the hidden state is the tracker true performance (e.g., expected overlap).", "Thus, methodologies can be studied from the perspective of bias and variance of state estimators.", "In the following we apply this view to further analyze the properties of estimators in terms of applying re-initialization as well as per-frame visual attribute annotation.", "\\newline <subsubsection> <title> 3.2.1 The importance of re-initialization </title> To establish some theoretical results on performance evaluation with or without applying re-initializations, the following thought experiment is considered.", "Assume a tracker is tested on a set of $ N $ sequences, each $ N_{\\mathrm{s}} $ frames long.", "A sequence $ j $ contains a critical point at the frame $ \\alpha_{j}N_{\\mathrm{s}} $ , where a tracker fails with probability $ p $ , i.e., it drifts and remains off the target for the remaining part of the sequence.", "During a successful period of tracking, the per-frame overlaps are sampled from a distribution with mean $ \\mu_{A} $ and variance $ \\sigma_{A}^{2} $ .", "After the failure, the overlaps fall to zero, i.e., they are sampled from a distribution with $ \\mu_{b}=0 $ and $ \\sigma_{B}^{2}=0 $ .", "A critical point can occur anywhere in the sequence with equal probability, meaning that these points are distributed uniformly along the sequence, i.e., $ \\alpha_{j}\\sim\\mathcal{U}(0,1) $ .", "A tracker is run on each sequence and a set of $ N $ per-sequence average overlaps $ \\{M_{j}\\}_{j=1:N} $ is calculated.", "The final performance is reported as the average over the sequences, i.e., an overall average overlap $ M={1\\over N}\\sum\\nolimits_{j=1:N}M_{j} $ .", "The aim of the estimator (evaluation methodology) is to recover the hidden average performance $ \\mu_{A} $ .", "In the following we will study the expected value and the variance of the output $ M $ depending on whether the tracker is re-initialized at failure (WIR) or the failure is ignored (NOR).", "\\newline The NOR-based methodologies ( [@bib:Wu2013,Smeulders2013] ) do not detect the failures and the overlaps after the failure affect the estimate of the true overlap $ \\mu_{A} $ .", "Alternatively, the WIR-based methodology (our approach) detects a failure, skips $ \\Delta $ frames and re-initializes the tracker.", "It can be shown that the expected value $ \\langle M_{\\mathrm{NOR}}\\rangle $ and the variance $ var(M_{\\mathrm{NOR}}) $ of the overall overlap $ M_{\\mathrm{NOR}} $ estimated without re-initialization on the theoretical tracking experiment are \\newline <equationgroup> <equation> $ \\langle M_{\\mathrm{NOR}}\\rangle=\\mu_{A}(1-\\frac{p}{2}), $ $ \\langle M_{\\mathrm{NOR}}\\rangle=\\mu_{A}(1-\\frac{p}{2}), $ </equation> <equation> $ \\mathrm{var}(M_{\\mathrm{NOR}})=\\frac{(2-p)\\sigma_{A}^{2}}{2NN_{% \\mathrm{s}}}+\\frac{p(4-3p)\\mu_{A}^{2}}{12N}, $ $ \\mathrm{var}(M_{\\mathrm{NOR}})=\\frac{(2-p)\\sigma_{A}^{2}}{2NN_{% \\mathrm{s}}}+\\frac{p(4-3p)\\mu_{A}^{2}}{12N}, $ </equation> </equationgroup> while the expected values and variance for the overall overlap estimated by WIR, i.e., $ M_{\\mathrm{WIR}} $ , are \\newline <equationgroup> <equation> $ \\langle M_{\\mathrm{WIR}}\\rangle=\\mu_{A}, $ $ \\langle M_{\\mathrm{WIR}}\\rangle=\\mu_{A}, $ </equation> <equation> $ \\mathrm{var}(M_{\\mathrm{WIR}})=\\sigma_{A}^{2}\\frac{N_{\\mathrm{s}}% -\\Delta(1-p)}{NN_{\\mathrm{s}}(N_{\\mathrm{s}}-\\Delta)}\\leq\\mathrm{var}(M_{% \\mathrm{NOR}}).", "$ $ \\mathrm{var}(M_{\\mathrm{WIR}})=\\sigma_{A}^{2}\\frac{N_{\\mathrm{s}}% -\\Delta(1-p)}{NN_{\\mathrm{s}}(N_{\\mathrm{s}}-\\Delta)}\\leq\\mathrm{var}(M_{% \\mathrm{NOR}}).", "$ </equation> </equationgroup> Please see the outline of derivation in Appendix [@ref:LABEL:app:DeriveNORWIR] .", "\\newline The following observations can be deduced from Eqs. ( [@ref:LABEL:eq:otb_est_overall] - [@ref:LABEL:eq:vot_est_overall_last] ).", "The NOR estimator is biased increasingly with the probability of failing at a critical point.", "If critical points always cause a failure, i.e., $ p=1 $ , then the overall average estimated by the NOR is half the true overlap.", "On the other hand, the WIR estimator is unbiased, recovers the true hidden overlap, and the mean does not depend on the critical points.", "The variance of the NOR estimator depends both on the variance of overlaps during successful track as well as the hidden overlap $ \\mu_{A} $ .", "This results in a large variance for trackers that track at high overlap and fail at critical points.", "On the other hand, the variance of the WIR does not show this effect and is always lower than for NOR, i.e., $ \\mathrm{var}(M_{\\mathrm{WIR}})\\leq\\mathrm{var}(M_{\\mathrm{NOR}}) $ .", "\\newline The asymptotic properties of the estimators are visualized in Figure [@ref:LABEL:fig:theoret_overall] w.r.t.", "the number of test sequences $ N $ for parameters $ \\mu_{A}=0.63 $ , $ \\sigma_{A}=0.4 $ , $ N_{\\mathrm{s}}=150 $ , $ p=0.5 $ , $ \\Delta=15 $ .", "Note that the WIR estimator is indeed asymptotically unbiased, while the NOR is biased toward a lower overlap values.", "Furthermore, the variance of the WIR is significantly smaller than that of NOR and decreases faster than for WIR, which is primarily due to the second term in $ \\mathrm{var}(M_{\\mathrm{NOR}}) $ ( [@ref:LABEL:eq:otb_est_overall] ), i.e., lack of re-initializations in NOR.", "A practical implication is that the methodologies like [@bib:Wu2013,Smeulders2013] require many more sequences than our methodology to produce similarly small variance of the estimate and their estimate will always be much more biased than ours when failures occur.", "Note that our theoretical model assumes sequences of equal length.", "If this constrained was further relaxed such that some sequences were allowed to be significantly longer than the others, it would not affect the WIR estimator, but would significantly increase the variance of the NOR even further.", "\\newline </subsubsection> <subsubsection> <title> 3.2.2 The importance of per-frame annotation </title> To study the impact of visual property annotation strategies, we will assume running a tracker on a dataset in which $ N $ sequences contain a particular attribute, e.g., a illumination change.", "The aim is to estimate tracking performance on this visual attribute.", "A tracker is thus run on each of $ N $ sequences, recovering the set of per-sequence overlaps $ \\{M_{j}\\}_{j=1:N} $ , and the average of these is reported as an overall performance, i.e., $ M={1\\over N}\\sum\\nolimits_{j=1:N}M_{j} $ .", "For ease of exposition assume that each sequence contains $ N_{\\mathrm{A}} $ frames with illumination change and the remaining $ N_{\\mathrm{B}}=\\eta N_{\\mathrm{A}} $ frames contain the other attributes.", "Thus the per-frame overlaps during the $ N_{\\mathrm{A}} $ frames can be described as samples from a distribution with mean $ \\mu_{\\mathrm{A}} $ and variance $ \\sigma_{A}^{2} $ , while the per-frame overlaps in the remaining $ N_{\\mathrm{B}} $ frames are governed by a distribution with mean $ \\mu_{\\mathrm{B}} $ and variance $ \\sigma_{B}^{2} $ .", "For clarity of the analysis we will assume that there are no critical points in any sequence, i.e., a tracker never fails during tracking, and that the variances $ \\sigma_{A}^{2} $ and $ \\sigma_{B}^{2} $ are equal.", "\\newline A global visual property annotation strategy (GLA) (e.g., [@bib:Wu2013,Smeulders2013] ) calculates overall per-visual property performance $ M_{\\mathrm{GLA}} $ using all the frames in sequences that contain at least one frame with the considered visual property.", "Alternatively, the per-frame annotation strategy (PFA) (our approach) considers only frames annotated with a particular visual attribute to estimate the performance $ M_{\\mathrm{PFA}} $ .", "Note, however, that some frames may be incorrectly annotated.", "From the perspective of bias in state estimation, the most critical frames are those that are incorrectly annotated as the considered attribute.", "Assume therefore, that in each sequence, a set of $ \\beta N_{\\mathrm{A}} $ are added as false annotations to the correctly annotated $ N_{\\mathrm{A}} $ frames.", "With these definitions, it is easy to show that the mean and variance of the $ M_{\\mathrm{GLA}} $ estimator are \\newline <equationgroup> <equation> $ \\langle M_{\\mathrm{GLA}}\\rangle=\\frac{1}{1+\\eta}\\mu_{A}+\\frac{% \\eta}{1+\\eta}\\mu_{B}, $ $ \\langle M_{\\mathrm{GLA}}\\rangle=\\frac{1}{1+\\eta}\\mu_{A}+\\frac{% \\eta}{1+\\eta}\\mu_{B}, $ </equation> <equation> $ \\mathrm{var}(M_{\\mathrm{GLA}})=\\frac{1}{NN_{\\mathrm{A}}(1+\\eta)}% \\sigma_{A}^{2}, $ $ \\mathrm{var}(M_{\\mathrm{GLA}})=\\frac{1}{NN_{\\mathrm{A}}(1+\\eta)}% \\sigma_{A}^{2}, $ </equation> </equationgroup> while the mean and variance for the and $ M_{\\mathrm{PFA}} $ estimator are, \\newline <equationgroup> <equation> $ \\langle M_{\\mathrm{PFA}}\\rangle=\\frac{1}{1+\\beta}\\mu_{A}+\\frac{% \\beta}{1+\\beta}\\mu_{B}, $ $ \\langle M_{\\mathrm{PFA}}\\rangle=\\frac{1}{1+\\beta}\\mu_{A}+\\frac{% \\beta}{1+\\beta}\\mu_{B}, $ </equation> <equation> $ \\mathrm{var}(M_{\\mathrm{PFA}})=\\frac{1}{NN_{\\mathrm{A}}(1+\\beta)}% \\sigma_{A}^{2}. $ $ \\mathrm{var}(M_{\\mathrm{PFA}})=\\frac{1}{NN_{\\mathrm{A}}(1+\\beta)}% \\sigma_{A}^{2}. $ </equation> </equationgroup> \\newline According to equations ( [@ref:LABEL:eq:otb_per_frame] , [@ref:LABEL:eq:vot_per_frame_last] ) both estimators are biased, but the bias in $ M_{\\mathrm{GLA}} $ is much greater than the bias in $ M_{\\mathrm{PFA}} $ .", "For example, assuming sequence lengths $ N_{\\mathrm{S}}=150 $ , with $ N_{\\mathrm{A}}=50 $ properly labelled frames and five frames per sequence mislabelled, results in $ \\eta=2 $ and $ \\beta=0.1 $ .", "This means that $ M_{\\mathrm{GLA}} $ is biased with $ 0.67\\mu_{B} $ , while the bias of $ M_{\\mathrm{PFA}} $ is only $ 0.09\\mu_{B} $ .", "In fact, since typical sequences contain only small subsets of frames with particular visual attribute, ( [@ref:LABEL:eq:otb_per_frame] ) shows that the $ M_{\\mathrm{GLA}} $ estimator actually reflects performance that is dominated by the other visual attributes, thus significantly skewing the per-visual attribute performance evaluation.", "Note that the variance of the $ M_{\\mathrm{GLA}} $ is lower than that of $ M_{\\mathrm{PFA}} $ by a constant $ \\frac{1+\\beta}{1+\\eta} $ since it applies more frames.", "Nevertheless, the variances of both estimators decrease linearly with factor $ NN_{\\mathrm{A}} $ .", "A practical implication of these results is that per-frame annotation of moderately-sized dataset (our approach), even with a reasonable number of mislabelled frames, provides a much better estimate of true per-visual attribute performance than a per-sequence labelled large dataset (methodologies used in [@bib:Wu2013,Smeulders2013] ).", "\\newline </subsubsection> </subsection>  </section>"], ["<section> <title> 4 Experimental evaluation </title>  <subsection> <title> 4.1 VOT2014 challenge </title> The tracker comparison methodology from Section [@ref:LABEL:sec:evalMethodology] was applied to a large-scale experiment, organized as a Visual Object Tracking challenge (VOT2014).", "An annotated dataset (Section [@ref:LABEL:sec:vot_dataset] ) was constructed and an evaluation system implemented in Matlab/Octave to fulfill the multi-platform, multi-programming language compatibility requirement from Section [@ref:LABEL:sec:Requirements] .", "A minimal API is defined to integrate a tracker with the system regardless of the programming language used to implement the tracker.", "The reader is referred to the evaluation kit document [@bib:Kristan2014] for further details.", "Researchers were invited to participate by downloading the evaluation kit, to integrate it into their trackers and to run it locally on their machines.", "The evaluation kit downloaded the VOT2014 dataset and performed a set of pre-defined experiments (Section [@ref:LABEL:sec:vot_experiments] ).", "To ensure a fair analysis, the authors were instructed to select a single set of parameters for all experiments.", "This way, the authors of the trackers themselves were responsible for setting the proper parameters and removing possible errors from the tracker implementations.", "The raw results from the evaluation system were then submitted to the VOT2014 homepage, along with a short description of the trackers and optionally with the binaries or source code to allow the VOT2014 committee further verification of their results.", "\\newline <subsubsection> <title> 4.1.1 Experiments </title> The VOT2014 challenge includes the following two experiments: \\newline <list> \\ Experiment 1 ( baseline ) runs a tracker on all sequences in the VOT2014 dataset by initializing it on the ground truth bounding boxes.", "\\newline \\ \\ Experiment 2 ( bounding box perturbation ) performs Experiment 1 with noisy bounding boxes.", "The noise affected the position and size by drawing perturbations uniformly from the $ \\pm 10\\% $ interval of the ground truth bounding box size and the rotation by drawing uniformly from the $ \\pm 0.1 $ radian range.", "\\newline \\ </list> \\newline All the experiments were automatically performed by the evaluation kit .", "A tracker was run on each sequence 15 times to obtain a better statistics on its performance.", "\\newline </subsubsection> <subsubsection> <title> 4.1.2 Tested trackers </title> In total $ 38 $ trackers were considered in the challenge, most of which had been published in recent years and represent the state-of-the-art.", "These included $ 33 $ original submissions and $ 5 $ baseline highly-cited trackers that were contributed by the VOT committee.", "We reference the unpublished trackers by the VOT2014 challenge report [@bib:KRISTAN_2014_ECCV] .", "For the interested readers a more detailed description of each tracker can be found in the supplementary material and a condensed summary of the trackers is available in Table [@ref:LABEL:tab:ranking] .", "\\newline Several trackers explicitly decomposed the target into parts.", "These ranged from key-point-based trackers CMT [@bib:Nebehay2014WACV] , IIVTv2 [@bib:KRISTAN_2014_ECCV] , Matrioska [@bib:Maresca2013] and its derivative MatFlow (a combination of Matrioska and FoT [@bib:vojir2011cvww] ) to general part-based trackers LT-FLO [@bib:Lebeda2013vot] , PT+ (an improvement of the Pixeltrack tracking algorithm [@bib:2013_DUFFNER] ), LGT [@bib:Cehovin2013] , OGT [@bib:2014_NAM] , DGT [@bib:2014_CAI] , ABS [@bib:KRISTAN_2014_ECCV] , while three trackers applied flock-of-trackers approaches FoT [@bib:vojir2011cvww] , BDF [@bib:2014_MARESCA_a] and FRT [@bib:Adam2006] .", "Several approaches were applying global generative visual models for target localization: a channel blurring approach EDFT [@bib:Felsberg2013vot] and its derivative qwsEDFT [@bib:2014_FELSBERG] (an improvement of both trackers DFT [@bib:sevilla2012cvpr] and EDFT [@bib:Felsberg2013vot] ), GMM-based VTDMG (an extension of [@bib:2012_YIJEONG] ), scale-adaptive mean shift eASMS (an extension of ASMS [@bib:2014_VOJIR] ), color and texture-based ACAT (a combination of Colour Attributes Tracker (CAT) [@bib:2014_DANELLJAN] and CSK tracker [@bib:2012_HENRIQUES] ), NCC based tracker with motion model IMPNCC (an improvement of the NCC tracker [@bib:2001_BRIECHLE] ), two color-based particle filters SIR-PF (a combination of particle filter, a background model as in [@bib:comaniciuTPAMI2003] and information coming from colour space YCbCr) and IPRT (an improvement of colour-based particle filter [@bib:Nummiaro03,Perez02] using particle re-propagation), a compressive tracker CT [@bib:zhang2012eccv] and intensitiy-template-based pca tracker IVT [@bib:Ross2008] .", "Two trackers applied fusion of flock-of-trackers and mean shift, HMM-TxD [@bib:KRISTAN_2014_ECCV] and DynMS (which is a Mean Shift tracker [@bib:2002_COMANICIU] with an isotropic kernel bootstrapped by a flock-of-features (FoF) tracker).", "Many trackers were based on discriminative models, i.e., boosting-based particle filter MCT [@bib:2014_DUFFNER] , multiple-instance-learning-based tracker MIL [@bib:babenko2011tpami] , detection-based FSDT [@bib:KRISTAN_2014_ECCV] while several applied regression-based techniques, i.e., variations of online structured SVM, Struck [@bib:hare2011iccv] , aStruck (a combination of optical-flow-based tracker and the discriminative tracker Struck [@bib:hare2011iccv] ), TStruck (a CUDA-based implementation of the Struck tracker [@bib:hare2011iccv] ), $ \\mathrm{PLT}_{13} $ [@bib:Kristan2013a] and $ \\mathrm{PLT}_{14} $ (an improved version of $ \\mathrm{PLT}_{13} $ tracker), kernelized-correlation-filter-based KCF [@bib:Henriques2014] , kernelized-least-squares-based ACT [@bib:2014_DANELLJAN] and discriminative correlation-based DSST [@bib:2014_DANELLJAN_BMVC] and SAMF [@bib:2014_LIZHU] .", "\\newline </subsubsection> </subsection> <subsection> <title> 4.2 The VOT2014 Dataset </title> A usual approach to creating a diverse dataset is collecting all sequences from existing datasets.", "However, a large dataset does not necessarily mean being rich in visual properties.", "In fact, many sequences may be visually similar and would not contribute to the diversity while they would significantly slow down the evaluation process.", "We have therefore applied an approach that leads to a dataset that includes various visual phenomena while containing a small number of sequences.", "\\newline The dataset was prepared as follows.", "The initial pool included $ 394 $ sequences, including sequences used by various authors in the tracking community, the VOT2013 benchmark [@bib:Kristan2013a] , the recently published ALOV dataset [@bib:Smeulders2013] , the Online Object Tracking Benchmark [@bib:Wu2013] and additional, so far unpublished, sequences.", "The set was manually filtered by removing sequences shorter than $ 200 $ frames, grayscale sequences, sequences containing poorly defined targets (e.g., fireworks) and sequences containing cuts.", "The following global intensity (it) and spatial (sp) attributes were automatically computed for each of the $ 193 $ remaining sequences: \\newline <list> \\ Illumination change is defined as the average of the absolute differences between the object intensity in the first and remaining frames (it).", "\\newline \\ \\ Object size change is the sum of averaged local size changes, where the local size change at frame $ t $ is defined as the average of absolute differences between the bounding box area in frame $ t $ and past fifteen frames (sp).", "\\newline \\ \\ Object motion is the average of absolute differences between ground truth center positions in consecutive frames (sp).", "\\newline \\ \\ Clutter is the average of per-frame distances between two histograms: one extracted from within the ground truth bounding box and one from an enlarged area (by factor 1.5) outside of the bounding box (it).", "\\newline \\ \\ Camera motion is defined as the average of translation vector lengths estimated by key-point-based RANSAC between consecutive frames (sp).", "\\newline \\ \\ Blur was measured by the Bayes-spectral-entropy camera focus measure [@bib:Kristan2005a] (it).", "\\newline \\ \\ Aspect-ratio change is defined as the average of per-frame aspect ratio changes.", "The aspect ratio change at frame $ t $ is calculated as the ratio of the bounding box width and height in frame $ t $ divided by the ratio of the bounding box width and height in the first frame (sp); \\newline \\ \\ Object color change defined as the change of the average hue value inside the bounding box (it); \\newline \\ \\ Deformation is calculated by dividing the images into $ 8 $ $ \\times $ $ 8 $ grid of cells and computing the sum of squared differences of averaged pixel intensity over the cells in current and first frame (it).", "\\newline \\ \\ Scene complexity represents the level of randomness (entropy) in the frames and it was calculated as $ e=\\sum_{i=0}^{255}b_{i}\\log b_{i} $ , where $ b_{i} $ is the number of pixels with value equal to $ i $ (it).", "\\newline \\ </list> In this way each sequence was represented as a $ 10 $ -dimensional feature vector.", "Sequences were clustered in an unsupervised way using affinity propagation [@bib:Frey2007] into $ 12 $ clusters .", "From these, $ 25 $ sequences were manually selected such that the various visual phenomena like, occlusion, were still represented well within the selection.", "\\newline The selected objects in each sequence are manually annotated by bounding boxes.", "For most sequences, the authors provide axis-aligned bounding boxes placed over the target.", "For most frames, the axis-aligned bounding boxes approximated the target well with large percentage of pixels within the bounding box (at least $ >60\\% $ ) belonging to the target.", "Some sequences contained elongated, rotating or deforming targets and these were re-annotated by rotated bounding boxes.", "After inspecting all the bounding box annotations, sequences with misplaced original annotations were re-annotated.", "\\newline Additionally, we labeled each frame in each sequence with five visual attributes that reflect a particular challenge in appearance degradation: (1) camera motion, (2) illumination change, (3) motion change, (4) size change and (5) occlusion.", "In case a particular frame had none of the five attributes, we labeled the frame as (6) neutral.", "A summary of sequence properties is presented in Figure [@ref:LABEL:fig:datasetstats] .", "The average length of consecutive frames containing an attribute was $ 335.6 $ for camera motion, $ 107.1 $ for illumination change, $ 16.9 $ for occlusion, $ 27.7 $ for motion change, $ 34.5 $ for occlusion, and $ 99.5 $ for neutral frames.", "\\newline <subsubsection> <title> 4.2.1 Estimation of practical difference thresholds </title> The practical difference (Section [@ref:LABEL:sec:prac_difference] ) strongly depends on the target as well as the free parameters of the annotation model.", "Ideally, a per-frame estimate of $ \\gamma $ would be required for each sequence, but that would present a significant undertaking.", "On the other hand, using a single threshold for the entire dataset is too restrictive as the properties of targets vary across the sequences.", "A compromise can be taken in this case by computing a single threshold per sequence.", "We propose selecting $ M $ frames per sequence and have $ J $ expert annotators place the bounding boxes carefully $ K $ times on each frame.", "In this way $ N=K\\times J $ bounding boxes are obtained per frame.", "One of the bounding boxes can be taken as a possible ground truth and $ N-1 $ overlaps can be computed with the remaining ones.", "Since all annotations are considered \u201ccorrect\u201d, any two overlaps should be considered equivalent, therefore the difference between these two overlaps is an example of negligibly small difference.", "By choosing each of the bounding boxes as ground truth, $ M(N((N-1)^{2}-N+1))/2 $ samples of differences are obtained per sequence.", "The practical difference threshold per sequence is estimated as the average of these values.", "\\newline Seven experts have annotated four frames per sequence three times.", "A single frame with an overlayed ground truth bounding box per sequence was displayed during annotation, serving as a guideline of what should be annotated.", "Thus a set of 15960 samples of differences was obtained per sequence and used to compute the per-sequence practical difference thresholds.", "The boxplots of the differences are shown in Figure [@ref:LABEL:fig:annotExamples] along with a few frames with overlaid annotations.", "It is clear that the threshold on practical difference varies over the sequences.", "For the sequences containing rigid objects, the practical difference threshold is small (e.g., ball), but becomes large for sequences with deformable/articulated objects (e.g., bolt).", "\\newline </subsubsection> </subsection> <subsection> <title> 4.3 Study of the methodology parameters </title> <subsubsection> <title> 4.3.1 Estimation of the burn-in period </title> A study was designed to estimate the burn-in period.", "Seven trackers were run with re-initialization on the VOT2013 dataset [@bib:KristanVOT2013] , which contains sequences recorded at approximately 20 frames per second.", "After each re-initialization we recorded the per-frame overlaps with the ground truth (an overlap sequence).", "Using this protocol we obtained 3249 overlap sequences, which were averaged into a single average overlap sequence shown in Figure [@ref:LABEL:fig:burnIn] .", "The rate of temporal change in overlap is characterized by the derivative of this sequence (also shown in Figure [@ref:LABEL:fig:burnIn] ).", "It is apparent that the rate of overlap change stabilizes at ten frames after re-initialization.", "We have therefore set the burn-in period to $ N_{\\mathrm{burnin}}=10 $ frames in our methodology.", "\\newline The effect of the burn-in period was further quantified by running several state-of-the-art trackers STRUCK [@bib:hare2011iccv] , DSST [@bib:2014_DANELLJAN_BMVC] , SAMF ( [@bib:2014_LIZHU] ) and KCF [@bib:Henriques2014] and two trackers commonly used as baselines, CT [@bib:zhang2012eccv] and FRT [@bib:Adam2006] on the VOT2014 dataset.", "Table [@ref:LABEL:tbl:results_burnin] shows the average accuracy for different values of the burn-in period.", "The average accuracy is, as expected, slightly reduced when including the frames from the burn-in period.", "The extent of the drop in accuracy is larger for trackers that fail more often.", "\\newline </subsubsection> <subsubsection> <title> 4.3.2 Influence of the re-initialization frame skipping </title> As explained in Section [@ref:LABEL:sec:vot_eval_met] , $ N_{\\mathrm{skip}} $ frames are skipped after re-initialization to remove the bias of potentially re-initializing the tracker on the same visual content that caused the failure.", "The effect of the $ N_{\\mathrm{skip}} $ values was quantified by re-running the trackers from previous section on the VOT2014 dataset.", "The number of failures and robustness ranks w.r.t.", "the skipping values $ N_{\\mathrm{skip}} $ are shown in Table [@ref:LABEL:tab:results_skip] .", "The number of failures most significantly changes between one to three skipped frames and remains stable with increasing $ N_{\\mathrm{skip}} $ .", "The relative changes are consistent across trackers.", "This is confirmed by the ranking, which remains stable.", "\\newline </subsubsection> <subsubsection> <title> 4.3.3 Influence of difference tests </title> The proposed methodology applies tests of performance equivalence by testing statistical and practical differences in tracker performance.", "In absence of these tests, trackers that perform slightly differently in average values of performance measures would be assigned different ranks even tough the difference in performance might not be statistically significant or below the annotation noise level (practical difference).", "To quantify the variations in ranks, we sampled 50 random sub-sets of 15 sequences from VOT2014 dataset, ranked DSST, KCF, SAMF, CT, FRT and Struck on all subsets and computed the average of the rank variances over all trackers.", "Table [@ref:LABEL:tab:rank_var] reports the rank variations for sequence-pooled and attribute-normalized ranking.", "The difference tests consistently reduce the variance in both setups.", "\\newline </subsubsection> </subsection> <subsection> <title> 4.4 Comparison with related methodologies </title> Performance evaluation methodologies mainly differ in use of re-initialization and detail of visual attribute annotation in sequences.", "The theoretical predictions derived in Section [@ref:LABEL:sec:theoreticalEval] were again validated experimentally on the VOT2014 dataset using the trackers from previous section.", "\\newline <subsubsection> <title> 4.4.1 Effects of re-initialization </title> The theoretical comparison of estimators (Section [@ref:LABEL:sec:TheoryReinit] ) that apply re-initialization, ( $ M_{\\mathrm{WIR}} $ ), and those that do not, $ M_{\\mathrm{NOR}} $ , was evaluated experimentally.", "Each tracker was run on all sequences in the VOT2014 dataset once with re-intializations and once without.", "A set of $ K $ sequences was randomly sampled and average overlap was computed on this set for each estimator.", "The process was repeated thousand times for $ K<24 $ to estimate the mean and variance.", "For $ K=24 $ there are only 25 possible different combinations of sequences, therefore the mean and variance were computed only on these.", "Table [@ref:LABEL:tab:resultsReinit] shows results for varying $ K $ .", "Due to sampling with replacement, sequences were repeated across the sets, which means that the variance was underestimated, especially for the $ K=24 $ .", "The actual variances of the average accuracy are expected to be higher.", "Nevertheless, the relative trends are as predicted by the theoretical model.", "The means of $ M_{\\mathrm{NOR}} $ are consistently lower than for $ M_{\\mathrm{WIR}} $ , which is especially evident for trackers that fail frequently, e.g., FRT and CT.", "Moreover, the variance of $ M_{\\mathrm{NOR}} $ is consistently higher than for $ M_{\\mathrm{WIR}} $ across all trackers.", "The Wilcoxon paired tests showed that both types of differences are statistically significant at $ p<0.01 $ .", "\\newline </subsubsection> <subsubsection> <title> 4.4.2 Importance of per-frame annotation </title> The properties of estimators that apply per-frame visual attribute annotation, $ M_{\\mathrm{GLA}} $ , and the estimators that apply only per-sequence annotation, $ M_{\\mathrm{PFA}} $ , were estimated using a similar experiment as in previous section.", "For a fair comparison, re-initialization was applied in all experiments.", "The results for $ K=24 $ sequences are visualized in Figure [@ref:LABEL:fig:perFrameAnnot] and confirm the predictions from our theoretical model.", "The variance of per-attribute $ M_{\\mathrm{GLA}} $ is generally slightly smaller than $ M_{\\mathrm{PFA}} $ since $ M_{\\mathrm{GLA}} $ uses more frames in estimation, of which many might not contain the attribute in question, making the $ M_{\\mathrm{GLA}} $ estimator strongly biased toward the global mean.", "This bias is also reflected in the dispersion of per-attribute values around their global mean, which is greater for $ M_{\\mathrm{PFA}} $ than for $ M_{\\mathrm{GLA}} $ .", "This means that the $ M_{\\mathrm{GLA}} $ is much weaker at making predictions regarding per-visual attribute performance evaluation.", "For example, consider the trackers DSST, KCF and SAMF.", "These are highly similar trackers by design, which is reflected in the trends of per-attribute values in Figure [@ref:LABEL:fig:perFrameAnnot] .", "Nevertheless, the $ M_{\\mathrm{GLA}} $ cannot distinguish performance with respect to attributes motion change, scale change and occlusion, while the performance difference is clear from $ M_{\\mathrm{PFA}} $ .", "A Wilcoxon paired test on pairs with varying $ K=15:24 $ showed that the variance of $ M_{\\mathrm{PFA}} $ is lower than that of $ M_{\\mathrm{GLA}} $ at level $ p<0.01 $ and an F-test on dispersion showed a difference at significance $ p<0.05 $ .", "\\newline </subsubsection> </subsection> <subsection> <title> 4.5 Application to tracker analysis on VOT2014 </title> The results of the baseline and bounding box perturbation experiments described in Section [@ref:LABEL:sec:vot_experiments] are visualized in Figure [@ref:LABEL:fig:rankingplots] and summarized in Table [@ref:LABEL:tab:ranking] .", "The AR-rank plots in Figure [@ref:LABEL:fig:rankingplots] are obtained by concatenating results of all sequences into a super-sequence, calculate the average performance measures and calculate the ranks from these.", "In Table [@ref:LABEL:tab:ranking] , these results are denoted as sequence-pooled ranking.", "In addition to rank plots, we show the accuracy/robustness raw plots (AR-raw) as proposed in [@bib:CehovinTracMeas2015] as well.", "Note that the AR-raw plots [@bib:CehovinTracMeas2015] compute the robustness as the probability of a tracker still tracking after $ S $ frames.", "This parameter affects only scaling, but does not change the order of trackers.", "We chose $ S=100 $ to fully utilize the horizontal space in the AR-raw plots.", "\\newline The top-performing trackers in robustness considering both the baseline and noise experiments are $ \\mathrm{PLT}_{13} $ , $ \\mathrm{PLT}_{14} $ , MatFlow and DGT.", "$ \\mathrm{PLT}_{13} $ and $ \\mathrm{PLT}_{14} $ are trackers that apply holistic models.", "Both trackers are extensions of the Struck [@bib:hare2011iccv] tracker which uses a structured SVM on grayscale patches to learn a regression from intensity to center of object displacement.", "In contrast to Struck, the $ \\mathrm{PLT}_{13} $ and $ \\mathrm{PLT}_{14} $ also apply histogram backprojection as feature selection strategy in the SVM training.", "The $ \\mathrm{PLT}_{13} $ is the winner of the VOT2013 challenge [@bib:Kristan2013a] which does not adapt the target size, while the $ \\mathrm{PLT}_{14} $ is an extension of $ \\mathrm{PLT}_{13} $ that adapts the size as well.", "Interestingly, the $ \\mathrm{PLT}_{14} $ does improve in accuracy compared to $ \\mathrm{PLT}_{13} $ , at a cost of slightly decreased robustness.", "The MatFlow and DGT are part-based trackers.", "The MatFlow tracker is an extension of Matrioska [@bib:Maresca2013] which applies a ORB/SURF keypoints and robust voting and matching techniques.", "Looking at the noise AR-rank plots in Figure [@ref:LABEL:fig:rankingplots] we see that the rank of Matflow significantly drops compared to PLT trackers.", "The DGT tracker decomposes a target into parts by superpixels and casts tracking as graph matching between corresponding superpixels across consecutive frames.", "The DGT also applies segmentation to improve part selection.", "\\newline In terms of accuracy, the top-performing trackers are DSST, SAMF, KCF and DGT.", "The DSST, SAMF and KCF are correlation-filter-based trackers derived from MOSSE [@bib:Bolme2010] that apply holistic models, i.e., a HOG [@bib:Dalal05] .", "In fact, DSST and SAMF are extensions of the KCF tracker.", "The similarity in design is reflected in the AR plots (e.g., Figure [@ref:LABEL:fig:rankingplots] ).", "Note that these trackers form a cluster in the AR-rank space.", "\\newline It is interesting to further study trackers that apply similar concepts for target localization.", "MatFlow extends Matrioska by applying a flock-of-trackers variant BDF.", "At a comparable accuracy ranks, the MatFlow by far outperforms the original Matrioska in robustness.", "The boost in robustness ranks might be attributed to addition of BDF, which is supported by the fact that BDF alone outperforms in robustness the flock-of-trackers tracker FoT as well as trackers based on variations of FoT, i.e., aStruck, HMM-TxD and dynMS.", "This speaks of resiliency to outliers in flock selection in BDF.", "\\newline Two trackers combine color-based mean shift with flow, i.e., dynMS and HMM-TxD and obtain comparable ranks in robustness, however, the HMM-TxD achieves a significantly higher accuracy rank, which might be due to considerably more sophisticated tracker merging scheme in HMM-TxD. Both methods are outperformed in robustness by the scale-adaptive mean shift eASMS that applies motion prediction and colour space selection.", "\\newline The set of evaluated trackers included the original Struck and two variations, TStruck and aStruck.", "TStruck is a CUDA-speeded-up TStruck and performs quite similarly to the original Struck in baseline and noise experiment.", "The aStruck applies the flock-of-trackers for scale adaptation in Struck and improves in robustness on the baseline experiment, but is ranked lower in the noise experiment.", "This implies that estimation of fewer parameters in Struck results in more accurate and robust performance in cases of poor initialization.", "This is consistent with the results of comparison of PLT trackers, which are derived from Struck.", "Note that these trackers by far outperform Struck, which further supports the importance of feature selection in PLT trackers.", "\\newline The per-visual attribute AR-rank plots are shown in Figure [@ref:LABEL:fig:rankingplots2] .", "At illumination changes, trackers form several equivalent classes of robustness.", "The top-performing trackers in accuracy and robustness remain the DSST, KCF, SAMF and most robust is $ \\mathrm{PLT}_{13} $ .", "However, the DGT drops drastically in accuracy as well as in robustness, since DGT relies heavily on the color information in segmentation.", "A similar degradation is observed for the size-adaptive color mean-shift eASMS whose performance also significantly drops a illumination change.", "Still, the color segmentation in DGT significantly improves tracking during occlusion.", "The benefits of size adaptation in DGT and eASMS are most apparent from the ranks at size-change and motion-change attributes.", "The neutral visual attribute does not present particular difficulties in terms of robustness for most trackers.", "While most trackers fail rarely during this attribute, there is observable difference in the accuracy of tracking.", "\\newline Figure [@ref:LABEL:fig:rankingplotsAttr] shows the per-visual attribute normalized AR-rank plot for the baseline experiment.", "This plot was obtained by ranking trackers with respect to each attribute and averaging the ranking lists.", "In Table [@ref:LABEL:tab:ranking] , these results are denoted as per-attribute normalization.", "The AR-raw plot in Figure [@ref:LABEL:fig:rankingplotsAttr] was obtained by averaging per-attribute average raw performance measures.", "The general layout of the trackers is similar to the sequence-pooled AR plots in Figure [@ref:LABEL:fig:rankingplots] , but there are differences in local ranks.", "The reason is that the sequence-pooled plots significantly depend on the distribution of the visual attributes in the dataset.", "This is confirmed by noting that the most strongly presented attributes in our dataset are camera motion and object motion (Figure [@ref:LABEL:fig:datasetstats] ) and by observing that the structure of the AR-rank plot for the baseline experiment (Figure [@ref:LABEL:fig:rankingplots] ) is very similar to the camera motion and object motion AR-rank plots from Figure [@ref:LABEL:fig:rankingplotsAttr] .", "The attribute-normalized AR plots in Figure [@ref:LABEL:fig:rankingplots2] removes this bias, giving equal importance to all the visual attributes.", "Averaging the accuracy and robustness ranks in the per-attribute normalization setup, the top performing trackers are DSST, SAMF, KCF, DGT and PLT trackers (see Table [@ref:LABEL:tab:ranking] ).", "For reference, we also report the results for the sequence-normalized ranking which ranks trackers with respect to each sequence separately and averages the ranking lists.", "The resulting plots are shown in the bottom row of Figure [@ref:LABEL:fig:rankingplotsAttr] .", "Observe that the general distribution of the trackers remains similar to the sequence-pooled plots Figure [@ref:LABEL:fig:rankingplots] , reflecting the influence of the dominant visual attributes in the dataset.", "The most apparent difference is that the trackers are less dispersed in the AR-rank space.", "This is because 25 ranking lists are averaged, indicating that the tracker ranking lists vary over the individual sequences and are consequently pulled to the average rank by averaging.", "\\newline Note that majority of the tested trackers are highly competitive.", "This is supported by the fact that the trackers, that are often used as baseline trackers, NCC, MIL, CT, FRT and IVT, occupy the bottom-left part of the AR-rank plots.", "Obviously these approaches vary in accuracy and robustness and are thus spread perpendicularly to the bottom-left-to-upper-right diagonal of AR-rank plots.", "In both experiments, the NCC is the least robust tracker.", "The Struck, which is often considered a state-of-the-art tracker is positioned in the middle of the AR plots, which further supports the quality of the tested trackers.", "\\newline Next, we have ranked the individual types of visual degradation according to the tracking difficulty they present to the tested trackers.", "The expected number of failures per hundred frames was computed on each attribute for all trackers."]], "target": "The median of these per visual attribute was taken as a measure of tracking difficulty (see Table ). The properties that present most difficulty are occlusion, motion change and size change, followed by camera motion and illumination change. Subsequences that do not contain any specific attribute (neutral) present little difficulty for the trackers in general as most trackers do not fail on such intervals."}]